{
  "repoUrl": "https://github.com/saleor/saleor",
  "generationDate": "2025-12-10",
  "evalCommits": [
    {
      "id": "add-attribute-numeric",
      "sha": "56dfa35a662fba817954267ffae7ceaa0402a447",
      "parentSha": "5657587b2e9bf9618c94712f5db053e9fce96dd5",
      "spec": "Implement a dedicated numeric column for AttributeValue and refactor related logic to use it, adding safe locking for concurrent operations.\n\nModel and indexing\n- In saleor/attribute/models/base.py:\n  - Add a nullable, blankable FloatField named `numeric` to AttributeValue.\n  - Add a BTreeIndex on the `numeric` field named `attribute_value_numeric_idx` to the model's Meta.indexes.\n  - Update AttributeValueManager.bulk_update logic to wrap updates in a transaction and pre-lock the affected AttributeValue rows using a new helper (see Locking section) to avoid race conditions; then perform bulk_update inside the same transaction.\n\nLocking helper\n- Create saleor/attribute/lock_objects.py exporting a function `attribute_value_qs_select_for_update() -> QuerySet[AttributeValue]` that returns a queryset ordered by sort_order and pk and applies select_for_update(of=[\"self\"]). Use this helper wherever locking AttributeValue rows prior to delete/update is required.\n\nMigrations and backfill\n- Add Django migrations under saleor/attribute/migrations:\n  - 0051_attributevalue_numeric.py: Add the FloatField `numeric` to AttributeValue (nullable/blank).\n  - 0052_attributevalue_attribute_value_numeric_idx.py: Add the BTree index on the `numeric` field concurrently (atomic = False, and include dependencies on page and product apps if required by the project’s migration order).\n  - 0053_fulfill_numeric_attribute_value.py: On post_migrate, enqueue a Celery task to backfill `numeric` for existing AttributeValue records where attribute.input_type is numeric and numeric is null. Use post_migrate signal to dispatch.\n- Add a Celery task under saleor/attribute/migrations/tasks/saleor3_22.py:\n  - Define `fulfill_attribute_value_numeric_field` to process AttributeValue rows in batches (e.g., 500 at a time), selecting rows with numeric__isnull=True and attribute__input_type=\"numeric\" ordered by pk. Inside a single transaction, lock the batch rows and update `numeric` by casting from the current string field (name) to float. Chain subsequent batches recursively by passing the last processed pk.\n- Register the new tasks path in saleor/celeryconf.py by adding \"saleor.attribute.migrations.tasks\" to the app.autodiscover_tasks packages list so the migration task is discoverable.\n\nGraphQL attribute operations\n- In saleor/graphql/attribute/bulk_mutations.py (AttributeValueBulkDelete): Wrap deletion in a transaction, lock the target AttributeValue rows using the new helper filtered by the queryset’s pks, collect the values list while locked, then delete. Continue emitting webhook events using the collected values.\n- In saleor/graphql/attribute/mutations/attribute_bulk_update.py (AttributeBulkUpdate): Wrap operations in a single transaction; bulk_update attributes; lock attribute values slated for removal using the helper and delete them by id; then bulk_create new values.\n- In saleor/graphql/attribute/mutations/attribute_delete.py: Override perform_mutation to delete an attribute within a transaction by first locking all its AttributeValue rows via the helper, deleting those values, and then deleting the attribute. Trigger the post-save event after deletion.\n- In saleor/graphql/attribute/utils/type_handlers.py:\n  - NumericAttributeHandler: when creating/updating values for numeric attributes, set defaults to include both `name` (string form) and `numeric` (float) so the new column is populated.\n  - LegacyValuesHandler: similarly, when handling single legacy numeric value input, set both `name` and `numeric` defaults.\n\nGraphQL page operations and filters\n- In saleor/graphql/page/bulk_mutations.py:\n  - For PageBulkDelete and PageTypeBulkDelete: Wrap in a transaction, use the locking helper to lock AttributeValue rows identified by EXISTS filters (only for attributes with unique values). Delete by id using the locked ids.\n- In saleor/graphql/page/filters.py:\n  - Replace any casting of AttributeValue name to float. Filter numeric attributes using the new `numeric` column. Ensure queries only consider rows where numeric is not null and apply numeric range filtering against the numeric field directly.\n\nGraphQL product operations and filters\n- In saleor/graphql/product/mutations/product/product_delete.py:\n  - Wrap the attribute-value cleanup in a transaction; lock the target AttributeValue rows via the helper using the existing EXISTS filters and delete by locked ids.\n- In saleor/graphql/product/mutations/product_variant/product_variant_delete.py:\n  - For delete_assigned_attribute_values, wrap in a transaction; lock matching AttributeValue ids using the helper and delete by the locked ids.\n- In saleor/graphql/product/filters.py:\n  - Remove casting from name to float and references to FloatField/Cast for numeric attribute filtering.\n  - Restrict numeric filtering to AttributeValue rows where `numeric` is not null and use that column for range comparisons, value grouping, and mapping. Adjust types for values_map accordingly (float-based keys) and skip entries without a numeric value.\n\nTests and fixtures\n- Update fixtures in saleor/attribute/tests/fixtures/attribute.py so numeric attribute values also set the `numeric` field consistently when created.\n- Update GraphQL tests that create, update, or query numeric attributes across pages/products/variants:\n  - Ensure mutations that add numeric attribute values set both the string representation in name and the numeric value in the `numeric` column.\n  - Adjust expectations to check that the created/updated AttributeValue has the `numeric` value set and appropriate slug/name.\n  - Where tests previously relied on casting or name strings for numeric filtering, update them to rely on the `numeric` field.\n- Add/import utilities as needed in tests (e.g., to_global_id_or_none) and set up page/product types to include numeric attributes where applicable.\n\nConsistency and safety\n- Ensure all new delete/update paths that operate on AttributeValue rows use the `attribute_value_qs_select_for_update` helper within a database transaction to avoid race conditions and maintain deterministic lock ordering.\n- Ensure Celery backfill task uses allow_writer and transaction.atomic with select_for_update within each batch to safely update rows.\n- Ensure the Celery tasks module is discoverable via celeryconf.\n\nAcceptance criteria\n- AttributeValue has a `numeric` FloatField with a BTree index and populated for numeric attributes.\n- All numeric filtering in GraphQL uses the `numeric` column, not casting from the name field, and returns the same or improved results.\n- AttributeValue deletions/updates in GraphQL that affect related objects lock rows prior to modification and run in atomic transactions.\n- Post-migrate backfill task enqueues and completes successfully on datasets with existing numeric attributes.\n- Unit/integration tests updated to set and assert the numeric field pass reliably.",
      "prompt": "Add first-class support for numeric attribute values and make numeric filtering more efficient and reliable. Introduce a dedicated numeric column on attribute values, index it, and backfill existing data after migrations via a Celery task. Update GraphQL filters and mutations to use this numeric column for comparisons instead of casting strings, and ensure row-level locking is applied during bulk deletions and updates to prevent concurrency issues. Adjust tests and fixtures to set and assert numeric values accordingly.",
      "supplementalFiles": [
        "saleor/checkout/lock_objects.py",
        "saleor/order/lock_objects.py",
        "saleor/warehouse/lock_objects.py",
        "saleor/attribute/utils.py",
        "saleor/attribute/error_codes.py",
        "saleor/core/tracing.py",
        "saleor/product/models.py",
        "saleor/page/models.py",
        "saleor/graphql/schema.graphql",
        "README.md"
      ],
      "fileDiffs": [
        {
          "path": "saleor/attribute/lock_objects.py",
          "status": "added",
          "diff": "Index: saleor/attribute/lock_objects.py\n===================================================================\n--- saleor/attribute/lock_objects.py\t5657587 (parent)\n+++ saleor/attribute/lock_objects.py\t56dfa35 (commit)\n@@ -0,0 +1,9 @@\n+from django.db.models import QuerySet\n+\n+from .models.base import AttributeValue\n+\n+\n+def attribute_value_qs_select_for_update() -> QuerySet[AttributeValue]:\n+    return AttributeValue.objects.order_by(\"sort_order\", \"pk\").select_for_update(\n+        of=([\"self\"])\n+    )\n"
        },
        {
          "path": "saleor/attribute/migrations/0051_attributevalue_numeric.py",
          "status": "added",
          "diff": "Index: saleor/attribute/migrations/0051_attributevalue_numeric.py\n===================================================================\n--- saleor/attribute/migrations/0051_attributevalue_numeric.py\t5657587 (parent)\n+++ saleor/attribute/migrations/0051_attributevalue_numeric.py\t56dfa35 (commit)\n@@ -0,0 +1,17 @@\n+# Generated by Django 5.2.1 on 2025-07-17 10:56\n+\n+from django.db import migrations, models\n+\n+\n+class Migration(migrations.Migration):\n+    dependencies = [\n+        (\"attribute\", \"0050_alter_attribute_input_type\"),\n+    ]\n+\n+    operations = [\n+        migrations.AddField(\n+            model_name=\"attributevalue\",\n+            name=\"numeric\",\n+            field=models.FloatField(blank=True, null=True),\n+        ),\n+    ]\n"
        },
        {
          "path": "saleor/attribute/migrations/0052_attributevalue_attribute_value_numeric_idx.py",
          "status": "added",
          "diff": "Index: saleor/attribute/migrations/0052_attributevalue_attribute_value_numeric_idx.py\n===================================================================\n--- saleor/attribute/migrations/0052_attributevalue_attribute_value_numeric_idx.py\t5657587 (parent)\n+++ saleor/attribute/migrations/0052_attributevalue_attribute_value_numeric_idx.py\t56dfa35 (commit)\n@@ -0,0 +1,24 @@\n+# Generated by Django 5.2.1 on 2025-07-17 11:03\n+\n+import django.contrib.postgres.indexes\n+from django.contrib.postgres.operations import AddIndexConcurrently\n+from django.db import migrations\n+\n+\n+class Migration(migrations.Migration):\n+    atomic = False\n+\n+    dependencies = [\n+        (\"attribute\", \"0051_attributevalue_numeric\"),\n+        (\"page\", \"0031_alter_page_metadata_alter_page_private_metadata_and_more\"),\n+        (\"product\", \"0201_productvariant_variant_gin\"),\n+    ]\n+\n+    operations = [\n+        AddIndexConcurrently(\n+            model_name=\"attributevalue\",\n+            index=django.contrib.postgres.indexes.BTreeIndex(\n+                fields=[\"numeric\"], name=\"attribute_value_numeric_idx\"\n+            ),\n+        ),\n+    ]\n"
        },
        {
          "path": "saleor/attribute/migrations/0053_fulfill_numeric_attribute_value.py",
          "status": "added",
          "diff": "Index: saleor/attribute/migrations/0053_fulfill_numeric_attribute_value.py\n===================================================================\n--- saleor/attribute/migrations/0053_fulfill_numeric_attribute_value.py\t5657587 (parent)\n+++ saleor/attribute/migrations/0053_fulfill_numeric_attribute_value.py\t56dfa35 (commit)\n@@ -0,0 +1,28 @@\n+from django.apps import apps as registry\n+from django.db import migrations\n+from django.db.models.signals import post_migrate\n+\n+from .tasks.saleor3_22 import fulfill_attribute_value_numeric_field\n+\n+\n+def set_up_numeric_attribute_values(apps, _schema_editor):\n+    def on_migrations_complete(sender=None, **kwargs):\n+        fulfill_attribute_value_numeric_field.delay()\n+\n+    sender = registry.get_app_config(\"attribute\")\n+    post_migrate.connect(on_migrations_complete, weak=False, sender=sender)\n+\n+\n+class Migration(migrations.Migration):\n+    atomic = False\n+\n+    dependencies = [\n+        (\"attribute\", \"0052_attributevalue_attribute_value_numeric_idx\"),\n+    ]\n+\n+    operations = [\n+        migrations.RunPython(\n+            set_up_numeric_attribute_values,\n+            reverse_code=migrations.RunPython.noop,\n+        )\n+    ]\n"
        },
        {
          "path": "saleor/attribute/migrations/tasks/__init__.py",
          "status": "added",
          "diff": "Index: saleor/attribute/migrations/tasks/__init__.py\n===================================================================\n--- saleor/attribute/migrations/tasks/__init__.py\t5657587 (parent)\n+++ saleor/attribute/migrations/tasks/__init__.py\t56dfa35 (commit)\n"
        },
        {
          "path": "saleor/attribute/migrations/tasks/saleor3_22.py",
          "status": "added",
          "diff": "Index: saleor/attribute/migrations/tasks/saleor3_22.py\n===================================================================\n--- saleor/attribute/migrations/tasks/saleor3_22.py\t5657587 (parent)\n+++ saleor/attribute/migrations/tasks/saleor3_22.py\t56dfa35 (commit)\n@@ -0,0 +1,40 @@\n+from django.db import transaction\n+from django.db.models import F, FloatField\n+from django.db.models.functions import Cast\n+\n+from ....celeryconf import app\n+from ....core.db.connection import allow_writer\n+from ...models.base import AttributeValue\n+\n+# Takes around 0.11 seconds to process the batch.\n+# The memory usage is marginal (~1MB).\n+BATCH_SIZE = 500\n+\n+\n+@app.task\n+@allow_writer()\n+def fulfill_attribute_value_numeric_field(attribute_value_pk=0):\n+    value_ids = list(\n+        AttributeValue.objects.filter(\n+            pk__gte=attribute_value_pk,\n+            numeric__isnull=True,\n+            attribute__input_type=\"numeric\",\n+        )\n+        .order_by(\"pk\")\n+        .values_list(\"id\", flat=True)[:BATCH_SIZE]\n+    )\n+\n+    if not value_ids:\n+        return\n+\n+    with transaction.atomic():\n+        locked_values = (\n+            AttributeValue.objects.filter(id__in=value_ids)\n+            .order_by(\"sort_order\", \"pk\")\n+            .select_for_update()\n+            .values_list(\"id\", flat=True)\n+        )\n+        AttributeValue.objects.filter(id__in=locked_values).update(\n+            numeric=Cast(F(\"name\"), FloatField())\n+        )\n+    fulfill_attribute_value_numeric_field.delay(value_ids[-1])\n"
        },
        {
          "path": "saleor/attribute/models/base.py",
          "status": "modified",
          "diff": "Index: saleor/attribute/models/base.py\n===================================================================\n--- saleor/attribute/models/base.py\t5657587 (parent)\n+++ saleor/attribute/models/base.py\t56dfa35 (commit)\n@@ -1,7 +1,7 @@\n from typing import TYPE_CHECKING, TypeVar, Union\n \n-from django.contrib.postgres.indexes import GinIndex\n+from django.contrib.postgres.indexes import BTreeIndex, GinIndex\n from django.db import models, transaction\n from django.db.models import Case, Exists, F, OrderBy, OuterRef, Q, Value, When\n \n from ...core.db.fields import SanitizedJSONField\n@@ -318,13 +318,21 @@\n                 ignore_conflicts=True,\n             )\n \n         if objects_to_be_updated:\n-            self.bulk_update(\n-                objects_to_be_updated,\n-                fields=update_fields,\n-            )\n+            from ..lock_objects import attribute_value_qs_select_for_update\n \n+            with transaction.atomic():\n+                _locked_qs = (\n+                    attribute_value_qs_select_for_update()\n+                    .filter(pk__in=[obj.pk for obj in objects_to_be_updated])\n+                    .select_for_update(of=([\"self\"]))\n+                )\n+                self.bulk_update(\n+                    objects_to_be_updated,\n+                    fields=update_fields,\n+                )\n+\n         return results\n \n     def _add_new_records(self, objects_enumerated, objects_not_in_db, results):\n         for index, obj in objects_enumerated:\n@@ -354,8 +362,9 @@\n         null=True,\n     )\n     boolean = models.BooleanField(blank=True, null=True)\n     date_time = models.DateTimeField(blank=True, null=True)\n+    numeric = models.FloatField(null=True, blank=True)\n \n     reference_product = models.ForeignKey(\n         Product,\n         related_name=\"references\",\n@@ -404,9 +413,13 @@\n                 name=\"attribute_search_gin\",\n                 # `opclasses` and `fields` should be the same length\n                 fields=[\"name\", \"slug\"],\n                 opclasses=[\"gin_trgm_ops\"] * 2,\n-            )\n+            ),\n+            BTreeIndex(\n+                fields=[\"numeric\"],\n+                name=\"attribute_value_numeric_idx\",\n+            ),\n         ]\n \n     def __str__(self) -> str:\n         return self.name\n"
        },
        {
          "path": "saleor/attribute/tests/fixtures/attribute.py",
          "status": "modified",
          "diff": "Index: saleor/attribute/tests/fixtures/attribute.py\n===================================================================\n--- saleor/attribute/tests/fixtures/attribute.py\t5657587 (parent)\n+++ saleor/attribute/tests/fixtures/attribute.py\t56dfa35 (commit)\n@@ -486,10 +486,14 @@\n         filterable_in_storefront=True,\n         filterable_in_dashboard=True,\n         available_in_grid=True,\n     )\n-    AttributeValue.objects.create(attribute=attribute, name=\"9.5\", slug=\"10_5\")\n-    AttributeValue.objects.create(attribute=attribute, name=\"15.2\", slug=\"15_2\")\n+    AttributeValue.objects.create(\n+        attribute=attribute, name=\"9.5\", slug=\"10_5\", numeric=9.5\n+    )\n+    AttributeValue.objects.create(\n+        attribute=attribute, name=\"15.2\", slug=\"15_2\", numeric=15.2\n+    )\n     return attribute\n \n \n @pytest.fixture\n@@ -502,10 +506,10 @@\n         filterable_in_storefront=True,\n         filterable_in_dashboard=True,\n         available_in_grid=True,\n     )\n-    AttributeValue.objects.create(attribute=attribute, name=\"9\", slug=\"9\")\n-    AttributeValue.objects.create(attribute=attribute, name=\"15\", slug=\"15\")\n+    AttributeValue.objects.create(attribute=attribute, name=\"9\", slug=\"9\", numeric=9)\n+    AttributeValue.objects.create(attribute=attribute, name=\"15\", slug=\"15\", numeric=15)\n     return attribute\n \n \n @pytest.fixture\n"
        },
        {
          "path": "saleor/celeryconf.py",
          "status": "modified",
          "diff": "Index: saleor/celeryconf.py\n===================================================================\n--- saleor/celeryconf.py\t5657587 (parent)\n+++ saleor/celeryconf.py\t56dfa35 (commit)\n@@ -36,8 +36,9 @@\n app.autodiscover_tasks(\n     packages=[\n         \"saleor.order.migrations.tasks\",\n         \"saleor.account.migrations.tasks\",\n+        \"saleor.attribute.migrations.tasks\",\n     ],\n     related_name=\"saleor3_22\",\n )\n app.autodiscover_tasks(lambda: discover_plugins_modules(settings.PLUGINS))\n"
        },
        {
          "path": "saleor/graphql/attribute/bulk_mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/bulk_mutations.py\n===================================================================\n--- saleor/graphql/attribute/bulk_mutations.py\t5657587 (parent)\n+++ saleor/graphql/attribute/bulk_mutations.py\t56dfa35 (commit)\n@@ -1,8 +1,10 @@\n import graphene\n+from django.db import transaction\n from django.db.models import Exists, OuterRef, Q\n \n from ...attribute import models\n+from ...attribute.lock_objects import attribute_value_qs_select_for_update\n from ...permission.enums import PageTypePermissions\n from ...product import models as product_models\n from ...webhook.event_types import WebhookEventAsyncType\n from ...webhook.utils import get_webhooks_for_event\n@@ -125,10 +127,14 @@\n \n     @classmethod\n     def bulk_action(cls, info: ResolveInfo, queryset, /):\n         attributes = {value.attribute for value in queryset}\n-        values = list(queryset)\n-        queryset.delete()\n+        with transaction.atomic():\n+            locked_qs = attribute_value_qs_select_for_update()\n+            locked_qs = locked_qs.filter(pk__in=queryset.values_list(\"pk\", flat=True))\n+            values = list(locked_qs)\n+            queryset.delete()\n+\n         manager = get_plugin_manager_promise(info.context).get()\n         webhooks = get_webhooks_for_event(WebhookEventAsyncType.ATTRIBUTE_VALUE_DELETED)\n         for value in values:\n             cls.call_event(manager.attribute_value_deleted, value, webhooks=webhooks)\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_bulk_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_bulk_update.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_bulk_update.py\t5657587 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_bulk_update.py\t56dfa35 (commit)\n@@ -1,16 +1,18 @@\n from collections import defaultdict\n \n import graphene\n from django.core.exceptions import ValidationError\n+from django.db import transaction\n from django.db.models import Q\n from django.utils.text import slugify\n from graphene.utils.str_converters import to_camel_case\n from graphql.error import GraphQLError\n from text_unidecode import unidecode\n \n from ....attribute import models\n from ....attribute.error_codes import AttributeBulkUpdateErrorCode\n+from ....attribute.lock_objects import attribute_value_qs_select_for_update\n from ....core.tracing import traced_atomic_transaction\n from ....permission.enums import PageTypePermissions, ProductTypePermissions\n from ....webhook.utils import get_webhooks_for_event\n from ...core import ResolveInfo\n@@ -571,26 +573,30 @@\n \n             values_to_remove.extend(attribute_data[\"remove_values\"])\n             values_to_create.extend(attribute_data[\"add_values\"])\n \n-        models.Attribute.objects.bulk_update(\n-            attributes_to_update,\n-            [\n-                \"name\",\n-                \"slug\",\n-                \"unit\",\n-                \"value_required\",\n-                \"visible_in_storefront\",\n-                \"is_variant_only\",\n-                \"filterable_in_dashboard\",\n-                \"external_reference\",\n-            ],\n-        )\n+        with transaction.atomic():\n+            models.Attribute.objects.bulk_update(\n+                attributes_to_update,\n+                [\n+                    \"name\",\n+                    \"slug\",\n+                    \"unit\",\n+                    \"value_required\",\n+                    \"visible_in_storefront\",\n+                    \"is_variant_only\",\n+                    \"filterable_in_dashboard\",\n+                    \"external_reference\",\n+                ],\n+            )\n+            locked_ids = (\n+                attribute_value_qs_select_for_update()\n+                .filter(pk__in=[value.pk for value in values_to_remove])\n+                .values_list(\"pk\", flat=True)\n+            )\n+            models.AttributeValue.objects.filter(id__in=locked_ids).delete()\n \n-        models.AttributeValue.objects.filter(\n-            id__in=[values_to_remove.id for values_to_remove in values_to_remove]\n-        ).delete()\n-        models.AttributeValue.objects.bulk_create(values_to_create)\n+            models.AttributeValue.objects.bulk_create(values_to_create)\n \n         updated_attributes.extend(attributes_to_update)\n         return updated_attributes, values_to_remove, values_to_create\n \n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_delete.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_delete.py\t5657587 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_delete.py\t56dfa35 (commit)\n@@ -1,7 +1,9 @@\n import graphene\n+from django.db import transaction\n \n from ....attribute import models as models\n+from ....attribute.lock_objects import attribute_value_qs_select_for_update\n from ....permission.enums import ProductTypePermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n from ...core.context import ChannelContext\n@@ -43,4 +45,27 @@\n     @classmethod\n     def post_save_action(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n         cls.call_event(manager.attribute_deleted, instance)\n+\n+    @classmethod\n+    def perform_mutation(  # type: ignore[override]\n+        cls, _root, info: ResolveInfo, /, *, external_reference=None, id=None\n+    ):\n+        \"\"\"Perform a mutation that deletes a model instance.\"\"\"\n+        instance = cls.get_instance(info, external_reference=external_reference, id=id)\n+\n+        cls.clean_instance(info, instance)\n+        db_id = instance.id\n+        with transaction.atomic():\n+            # Lock the attribute values to prevent concurrent modifications\n+            locked_qs = attribute_value_qs_select_for_update().filter(\n+                attribute_id=instance.id\n+            )\n+            models.AttributeValue.objects.filter(id__in=locked_qs).delete()\n+            instance.delete()\n+\n+        # After the instance is deleted, set its ID to the original database's\n+        # ID so that the success response contains ID of the deleted object.\n+        instance.id = db_id\n+        cls.post_save_action(info, instance, None)\n+        return cls.success_response(instance)\n"
        },
        {
          "path": "saleor/graphql/attribute/tests/queries/test_attribute_query.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/tests/queries/test_attribute_query.py\n===================================================================\n--- saleor/graphql/attribute/tests/queries/test_attribute_query.py\t5657587 (parent)\n+++ saleor/graphql/attribute/tests/queries/test_attribute_query.py\t56dfa35 (commit)\n@@ -812,11 +812,17 @@\n     assert size_attribute.values.count() > 1\n \n     AttributeValue.objects.bulk_create(\n         [\n-            AttributeValue(slug=\"10\", name=\"num-10\", attribute=numeric_attribute),\n-            AttributeValue(slug=\"20\", name=\"num-20\", attribute=numeric_attribute),\n-            AttributeValue(slug=\"30\", name=\"num-30\", attribute=numeric_attribute),\n+            AttributeValue(\n+                slug=\"10\", name=\"10\", numeric=10, attribute=numeric_attribute\n+            ),\n+            AttributeValue(\n+                slug=\"20\", name=\"20\", numeric=20, attribute=numeric_attribute\n+            ),\n+            AttributeValue(\n+                slug=\"30\", name=\"30\", numeric=30, attribute=numeric_attribute\n+            ),\n         ]\n     )\n     limit = 1\n     variables = {\"limit\": limit}\n@@ -836,11 +842,17 @@\n ):\n     # given\n     AttributeValue.objects.bulk_create(\n         [\n-            AttributeValue(slug=\"10\", name=\"num-10\", attribute=numeric_attribute),\n-            AttributeValue(slug=\"20\", name=\"num-20\", attribute=numeric_attribute),\n-            AttributeValue(slug=\"30\", name=\"num-30\", attribute=numeric_attribute),\n+            AttributeValue(\n+                slug=\"10\", name=\"10\", numeric=10, attribute=numeric_attribute\n+            ),\n+            AttributeValue(\n+                slug=\"20\", name=\"20\", numeric=20, attribute=numeric_attribute\n+            ),\n+            AttributeValue(\n+                slug=\"30\", name=\"30\", numeric=30, attribute=numeric_attribute\n+            ),\n         ]\n     )\n     attribute_count = {\n         att.slug: att.values_count\n"
        },
        {
          "path": "saleor/graphql/attribute/utils/type_handlers.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/utils/type_handlers.py\n===================================================================\n--- saleor/graphql/attribute/utils/type_handlers.py\t5657587 (parent)\n+++ saleor/graphql/attribute/utils/type_handlers.py\t56dfa35 (commit)\n@@ -561,8 +561,9 @@\n         if numeric_val is None:\n             return []\n         defaults = {\n             \"name\": numeric_val,\n+            \"numeric\": float(numeric_val),\n         }\n         return self._update_or_create_value(instance, defaults)\n \n \n@@ -673,8 +674,9 @@\n         if self.attribute.input_type == AttributeInputType.NUMERIC:\n             value = self.values_input.values[0]\n             defaults = {\n                 \"name\": value,\n+                \"numeric\": float(value),\n             }\n             return self._update_or_create_value(instance, defaults)\n \n         return self.prepare_attribute_values(self.attribute, self.values_input.values)\n"
        },
        {
          "path": "saleor/graphql/page/bulk_mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/bulk_mutations.py\n===================================================================\n--- saleor/graphql/page/bulk_mutations.py\t5657587 (parent)\n+++ saleor/graphql/page/bulk_mutations.py\t56dfa35 (commit)\n@@ -1,10 +1,12 @@\n import graphene\n from django.core.exceptions import ValidationError\n+from django.db import transaction\n from django.db.models.expressions import Exists, OuterRef\n \n from ...attribute import AttributeInputType\n from ...attribute import models as attribute_models\n+from ...attribute.lock_objects import attribute_value_qs_select_for_update\n from ...core.tracing import traced_atomic_transaction\n from ...page import models\n from ...permission.enums import PagePermissions, PageTypePermissions\n from ...webhook.event_types import WebhookEventAsyncType\n@@ -50,12 +52,20 @@\n         attributes = attribute_models.Attribute.objects.filter(\n             input_type__in=AttributeInputType.TYPES_WITH_UNIQUE_VALUES\n         )\n \n-        attribute_models.AttributeValue.objects.filter(\n-            Exists(assigned_values.filter(value_id=OuterRef(\"id\"))),\n-            Exists(attributes.filter(id=OuterRef(\"attribute_id\"))),\n-        ).delete()\n+        with transaction.atomic():\n+            locked_ids = (\n+                attribute_value_qs_select_for_update()\n+                .filter(\n+                    Exists(assigned_values.filter(value_id=OuterRef(\"id\"))),\n+                    Exists(attributes.filter(id=OuterRef(\"attribute_id\"))),\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            attribute_models.AttributeValue.objects.filter(\n+                id__in=locked_ids,\n+            ).delete()\n \n \n class PageBulkPublish(BaseBulkMutation):\n     class Arguments:\n@@ -126,8 +136,16 @@\n         attributes = attribute_models.Attribute.objects.filter(\n             input_type__in=AttributeInputType.TYPES_WITH_UNIQUE_VALUES\n         )\n \n-        attribute_models.AttributeValue.objects.filter(\n-            Exists(assigned_values.filter(value_id=OuterRef(\"id\"))),\n-            Exists(attributes.filter(id=OuterRef(\"attribute_id\"))),\n-        ).delete()\n+        with transaction.atomic():\n+            locked_ids = (\n+                attribute_value_qs_select_for_update()\n+                .filter(\n+                    Exists(assigned_values.filter(value_id=OuterRef(\"id\"))),\n+                    Exists(attributes.filter(id=OuterRef(\"attribute_id\"))),\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            attribute_models.AttributeValue.objects.filter(\n+                id__in=locked_ids,\n+            ).delete()\n"
        },
        {
          "path": "saleor/graphql/page/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/filters.py\n===================================================================\n--- saleor/graphql/page/filters.py\t5657587 (parent)\n+++ saleor/graphql/page/filters.py\t56dfa35 (commit)\n@@ -1,10 +1,9 @@\n from typing import Literal\n \n import django_filters\n import graphene\n-from django.db.models import Exists, FloatField, OuterRef, Q\n-from django.db.models.functions import Cast\n+from django.db.models import Exists, OuterRef, Q\n from graphql import GraphQLError\n \n from ...attribute import AttributeInputType\n from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue\n@@ -98,14 +97,13 @@\n \n \n def filter_by_numeric_attribute(attr_id, numeric_value, db_connection_name: str):\n     qs_by_numeric = AttributeValue.objects.using(db_connection_name).filter(\n-        attribute_id=attr_id\n+        attribute_id=attr_id, numeric__isnull=False\n     )\n-    qs_by_numeric = qs_by_numeric.annotate(numeric_value=Cast(\"name\", FloatField()))\n     qs_by_numeric = filter_where_by_numeric_field(\n         qs_by_numeric,\n-        \"numeric_value\",\n+        \"numeric\",\n         numeric_value,\n     )\n     assigned_attr_value = AssignedPageAttributeValue.objects.using(\n         db_connection_name\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_create.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_create.py\t5657587 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_create.py\t56dfa35 (commit)\n@@ -12,8 +12,9 @@\n from .....page.error_codes import PageErrorCode\n from .....page.models import Page, PageType\n from .....tests.utils import dummy_editorjs\n from .....webhook.event_types import WebhookEventAsyncType\n+from ....core.utils import to_global_id_or_none\n from ....tests.utils import get_graphql_content\n \n CREATE_PAGE_MUTATION = \"\"\"\n     mutation CreatePage(\n@@ -59,15 +60,20 @@\n \"\"\"\n \n \n @freeze_time(\"2020-03-18 12:00:00\")\n-def test_page_create_mutation(staff_api_client, permission_manage_pages, page_type):\n+def test_page_create_mutation(\n+    staff_api_client, permission_manage_pages, page_type, numeric_attribute\n+):\n+    # given\n     page_slug = \"test-slug\"\n     page_content = dummy_editorjs(\"test content\", True)\n     page_title = \"test title\"\n     page_is_published = True\n     page_type_id = graphene.Node.to_global_id(\"PageType\", page_type.pk)\n \n+    page_type.page_attributes.add(numeric_attribute)\n+\n     # Default attributes defined in page_type fixture\n     tag_attr = page_type.page_attributes.get(name=\"tag\")\n     tag_value_slug = tag_attr.values.first().slug\n     tag_attr_id = graphene.Node.to_global_id(\"Attribute\", tag_attr.id)\n@@ -77,8 +83,11 @@\n     size_attr = page_type.page_attributes.get(name=\"Page size\")\n     size_attr_id = graphene.Node.to_global_id(\"Attribute\", size_attr.id)\n     non_existent_attr_value = \"New value\"\n \n+    numeric_value = 42.1\n+    numeric_name = str(numeric_value)\n+\n     # test creating root page\n     variables = {\n         \"input\": {\n             \"title\": page_title,\n@@ -88,15 +97,22 @@\n             \"pageType\": page_type_id,\n             \"attributes\": [\n                 {\"id\": tag_attr_id, \"values\": [tag_value_name]},\n                 {\"id\": size_attr_id, \"values\": [non_existent_attr_value]},\n+                {\n+                    \"id\": to_global_id_or_none(numeric_attribute),\n+                    \"values\": [numeric_name],\n+                },\n             ],\n         }\n     }\n \n+    # when\n     response = staff_api_client.post_graphql(\n         CREATE_PAGE_MUTATION, variables, permissions=[permission_manage_pages]\n     )\n+\n+    # then\n     content = get_graphql_content(response)\n     data = content[\"data\"][\"pageCreate\"]\n     assert data[\"errors\"] == []\n     assert data[\"page\"][\"title\"] == page_title\n@@ -113,8 +129,11 @@\n         data[\"page\"][\"attributes\"][1][\"values\"][0][\"slug\"],\n     )\n     assert slugify(non_existent_attr_value) in values\n     assert tag_value_slug in values\n+    assert numeric_attribute.values.filter(\n+        name=numeric_name, numeric=numeric_value\n+    ).exists()\n \n \n @freeze_time(\"2020-03-18 12:00:00\")\n def test_page_create_mutation_with_published_at_date(\n@@ -1496,4 +1515,62 @@\n         for ref, attr, name in references\n     ]\n     for attr_data in attributes_data:\n         assert attr_data in expected_attributes_data\n+\n+\n+@freeze_time(\"2020-03-18 12:00:00\")\n+def test_page_create_mutation_with_numeric_attribue(\n+    staff_api_client, permission_manage_pages, page_type, numeric_attribute\n+):\n+    # given\n+    page_slug = \"test-slug\"\n+    page_content = dummy_editorjs(\"test content\", True)\n+    page_title = \"test title\"\n+    page_is_published = True\n+    page_type_id = graphene.Node.to_global_id(\"PageType\", page_type.pk)\n+    page_type.page_attributes.all().delete()\n+    page_type.page_attributes.add(numeric_attribute)\n+\n+    numeric_value = 42.1\n+    numeric_name = str(numeric_value)\n+\n+    # test creating root page\n+    variables = {\n+        \"input\": {\n+            \"title\": page_title,\n+            \"content\": page_content,\n+            \"isPublished\": page_is_published,\n+            \"slug\": page_slug,\n+            \"pageType\": page_type_id,\n+            \"attributes\": [\n+                {\n+                    \"id\": to_global_id_or_none(numeric_attribute),\n+                    \"numeric\": numeric_name,\n+                },\n+            ],\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        CREATE_PAGE_MUTATION, variables, permissions=[permission_manage_pages]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"pageCreate\"]\n+    assert data[\"errors\"] == []\n+\n+    assert len(data[\"page\"][\"attributes\"]) == 1\n+    attribute = data[\"page\"][\"attributes\"][0]\n+    assert attribute[\"attribute\"][\"slug\"] == numeric_attribute.slug\n+    assert len(attribute[\"values\"]) == 1\n+    assert (\n+        attribute[\"values\"][0][\"slug\"]\n+        == f\"{Page.objects.get().id}_{numeric_attribute.id}\"\n+    )\n+    assert attribute[\"values\"][0][\"name\"] == numeric_name\n+\n+    assert numeric_attribute.values.filter(\n+        name=numeric_name, numeric=numeric_value\n+    ).exists()\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_update.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_update.py\t5657587 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_update.py\t56dfa35 (commit)\n@@ -20,8 +20,9 @@\n from .....page.error_codes import PageErrorCode\n from .....page.models import Page\n from .....tests.utils import dummy_editorjs\n from .....webhook.event_types import WebhookEventAsyncType\n+from ....core.utils import to_global_id_or_none\n from ....tests.utils import get_graphql_content\n \n UPDATE_PAGE_MUTATION = \"\"\"\n     mutation updatePage(\n@@ -1412,4 +1413,52 @@\n         for ref, attr, name in references\n     ]\n     for attr_data in attributes_data:\n         assert attr_data in expected_attributes_data\n+\n+\n+def test_update_page_with_numeric_attribute(\n+    staff_api_client, permission_manage_pages, page, numeric_attribute\n+):\n+    # given\n+    query = UPDATE_PAGE_MUTATION\n+\n+    page_type = page.page_type\n+    page_type.page_attributes.all().delete()\n+    page_type.page_attributes.add(numeric_attribute)\n+\n+    numeric_value = 33.12\n+    numeric_name = str(numeric_value)\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(page),\n+        \"input\": {\n+            \"attributes\": [\n+                {\n+                    \"id\": to_global_id_or_none(numeric_attribute),\n+                    \"numeric\": numeric_value,\n+                }\n+            ],\n+        },\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        query, variables, permissions=[permission_manage_pages]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"pageUpdate\"]\n+\n+    assert not data[\"errors\"]\n+    attributes = data[\"page\"][\"attributes\"]\n+    assert len(attributes) == 1\n+    assert attributes[0][\"attribute\"][\"slug\"] == numeric_attribute.slug\n+    assert len(attributes[0][\"values\"]) == 1\n+    assert attributes[0][\"values\"][0][\"slug\"] == f\"{page.pk}_{numeric_attribute.pk}\"\n+    assert attributes[0][\"values\"][0][\"name\"] == numeric_name\n+\n+    assert numeric_attribute.values.filter(\n+        name=numeric_name,\n+        numeric=numeric_value,\n+    ).exists()\n"
        },
        {
          "path": "saleor/graphql/page/tests/queries/test_pages_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/queries/test_pages_with_where.py\n===================================================================\n--- saleor/graphql/page/tests/queries/test_pages_with_where.py\t5657587 (parent)\n+++ saleor/graphql/page/tests/queries/test_pages_with_where.py\t56dfa35 (commit)\n@@ -2,9 +2,8 @@\n \n import graphene\n import pytest\n \n-from .....attribute import AttributeInputType\n from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.models import Page, PageType\n from ....core.utils import to_global_id_or_none\n@@ -332,13 +331,15 @@\n \n     attr_value_1 = numeric_attribute_without_unit.values.first()\n     attr_value_1.name = \"1.2\"\n     attr_value_1.slug = \"1.2\"\n+    attr_value_1.numeric = 1.2\n     attr_value_1.save()\n \n     attr_value_2 = numeric_attribute_without_unit.values.last()\n     attr_value_2.name = \"2\"\n     attr_value_2.slug = \"2\"\n+    attr_value_2.numeric = 2\n     attr_value_2.save()\n \n     associate_attribute_values_to_instance(\n         page_list[0], {numeric_attribute_without_unit.pk: [attr_value_1]}\n@@ -1605,9 +1606,9 @@\n             [\n                 {\n                     \"slug\": \"page-size\",\n                     \"value\": {\n-                        \"numeric\": {\"range\": {\"lte\": 89}},\n+                        \"slug\": {\"eq\": \"10\"},\n                     },\n                 },\n                 {\n                     \"slug\": \"tag\",\n@@ -1760,11 +1761,8 @@\n     boolean_attribute.type = \"PAGE_TYPE\"\n     boolean_attribute.save()\n \n     page_type.page_attributes.add(size_page_attribute)\n-    size_page_attribute.input_type = AttributeInputType.NUMERIC\n-    size_page_attribute.save()\n-\n     page_type.page_attributes.add(tag_page_attribute)\n     page_type.page_attributes.add(author_page_attribute)\n     page_type.page_attributes.add(boolean_attribute)\n \n"
        },
        {
          "path": "saleor/graphql/product/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/filters.py\n===================================================================\n--- saleor/graphql/product/filters.py\t5657587 (parent)\n+++ saleor/graphql/product/filters.py\t56dfa35 (commit)\n@@ -4,12 +4,12 @@\n from typing import TypedDict\n \n import django_filters\n import graphene\n-from django.db.models import Exists, FloatField, OuterRef, Q, Subquery, Sum\n+from django.db.models import Exists, OuterRef, Q, Subquery, Sum\n from django.db.models.expressions import ExpressionWrapper\n from django.db.models.fields import IntegerField\n-from django.db.models.functions import Cast, Coalesce\n+from django.db.models.functions import Coalesce\n from django.utils import timezone\n \n from ...attribute import AttributeInputType\n from ...attribute.models import (\n@@ -156,22 +156,26 @@\n         input_type=AttributeInputType.NUMERIC\n     )\n     values = (\n         AttributeValue.objects.using(database_connection_name)\n-        .filter(Exists(attributes.filter(pk=OuterRef(\"attribute_id\"))))\n-        .annotate(numeric_value=Cast(\"name\", FloatField()))\n+        .filter(\n+            Exists(attributes.filter(pk=OuterRef(\"attribute_id\"))),\n+            numeric__isnull=False,\n+        )\n         .select_related(\"attribute\")\n     )\n \n     attributes_map: dict[str, int] = {}\n-    values_map: defaultdict[str, defaultdict[str, list[int]]] = defaultdict(\n+    values_map: defaultdict[str, defaultdict[float, list[int]]] = defaultdict(\n         lambda: defaultdict(list)\n     )\n     for value_data in values.values_list(\n-        \"attribute_id\", \"attribute__slug\", \"pk\", \"numeric_value\"\n+        \"attribute_id\", \"attribute__slug\", \"pk\", \"numeric\"\n     ):\n         attr_pk, attr_slug, pk, numeric_value = value_data\n         attributes_map[attr_slug] = attr_pk\n+        if not numeric_value:\n+            continue\n         values_map[attr_slug][numeric_value].append(pk)\n \n     for attr_name, val_range in filter_value:\n         if attr_name not in attributes_map:\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product/product_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product/product_delete.py\n===================================================================\n--- saleor/graphql/product/mutations/product/product_delete.py\t5657587 (parent)\n+++ saleor/graphql/product/mutations/product/product_delete.py\t56dfa35 (commit)\n@@ -1,9 +1,11 @@\n import graphene\n+from django.db import transaction\n from django.db.models.expressions import Exists, OuterRef\n \n from .....attribute import AttributeInputType\n from .....attribute import models as attribute_models\n+from .....attribute.lock_objects import attribute_value_qs_select_for_update\n from .....core.tracing import traced_atomic_transaction\n from .....order import events as order_events\n from .....order import models as order_models\n from .....order.tasks import recalculate_orders_task\n@@ -96,8 +98,16 @@\n         attributes = attribute_models.Attribute.objects.filter(\n             input_type__in=AttributeInputType.TYPES_WITH_UNIQUE_VALUES\n         )\n \n-        attribute_models.AttributeValue.objects.filter(\n-            Exists(assigned_values.filter(value_id=OuterRef(\"id\"))),\n-            Exists(attributes.filter(id=OuterRef(\"attribute_id\"))),\n-        ).delete()\n+        with transaction.atomic():\n+            locked_ids = (\n+                attribute_value_qs_select_for_update()\n+                .filter(\n+                    Exists(assigned_values.filter(value_id=OuterRef(\"id\"))),\n+                    Exists(attributes.filter(id=OuterRef(\"attribute_id\"))),\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            attribute_models.AttributeValue.objects.filter(\n+                id__in=locked_ids,\n+            ).delete()\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_delete.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_delete.py\t5657587 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_delete.py\t56dfa35 (commit)\n@@ -1,10 +1,12 @@\n import graphene\n from django.core.exceptions import ValidationError\n+from django.db import transaction\n from django.db.models import Exists, OuterRef\n \n from .....attribute import AttributeInputType\n from .....attribute import models as attribute_models\n+from .....attribute.lock_objects import attribute_value_qs_select_for_update\n from .....core.tracing import traced_atomic_transaction\n from .....discount.utils.promotion import mark_active_catalogue_promotion_rules_as_dirty\n from .....order import events as order_events\n from .....order import models as order_models\n@@ -141,12 +143,16 @@\n         return response\n \n     @staticmethod\n     def delete_assigned_attribute_values(instance):\n-        attribute_models.AttributeValue.objects.filter(\n-            variantassignments__variant_id=instance.id,\n-            attribute__input_type__in=AttributeInputType.TYPES_WITH_UNIQUE_VALUES,\n-        ).delete()\n+        with transaction.atomic():\n+            locked_ids = attribute_value_qs_select_for_update().filter(\n+                variantassignments__variant_id=instance.id,\n+                attribute__input_type__in=AttributeInputType.TYPES_WITH_UNIQUE_VALUES,\n+            )\n+            attribute_models.AttributeValue.objects.filter(\n+                id__in=locked_ids,\n+            ).delete()\n \n     @staticmethod\n     def delete_product_channel_listings_without_available_variants(instance):\n         \"\"\"Delete invalid product channel listings.\n"
        },
        {
          "path": "saleor/graphql/product/tests/mutations/test_product_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/mutations/test_product_create.py\n===================================================================\n--- saleor/graphql/product/tests/mutations/test_product_create.py\t5657587 (parent)\n+++ saleor/graphql/product/tests/mutations/test_product_create.py\t56dfa35 (commit)\n@@ -2487,17 +2487,16 @@\n     category,\n     numeric_attribute,\n     permission_manage_products,\n ):\n+    # given\n     query = CREATE_PRODUCT_MUTATION\n \n     product_type_id = graphene.Node.to_global_id(\"ProductType\", product_type.pk)\n     category_id = graphene.Node.to_global_id(\"Category\", category.pk)\n     product_name = \"test name\"\n     product_slug = \"product-test-slug\"\n \n-    values_count = numeric_attribute.values.count()\n-\n     # Add second attribute\n     product_type.product_attributes.set([numeric_attribute])\n     attr_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.id)\n \n@@ -2511,11 +2510,14 @@\n             \"attributes\": [{\"id\": attr_id, \"values\": [value]}],\n         }\n     }\n \n+    # when\n     response = staff_api_client.post_graphql(\n         query, variables, permissions=[permission_manage_products]\n     )\n+\n+    # then\n     content = get_graphql_content(response)\n     data = content[\"data\"][\"productCreate\"]\n     assert data[\"errors\"] == []\n     product_pk = graphene.Node.from_global_id(data[\"product\"][\"id\"])[1]\n@@ -2532,9 +2534,9 @@\n     assert values[0][\"name\"] == expected_name\n     assert values[0][\"slug\"] == f\"{product_pk}_{numeric_attribute.id}\"\n \n     numeric_attribute.refresh_from_db()\n-    assert numeric_attribute.values.count() == values_count + 1\n+    assert numeric_attribute.values.filter(name=expected_name, numeric=value).exists()\n \n \n def test_create_product_with_numeric_attribute_existing_value(\n     staff_api_client,\n"
        },
        {
          "path": "saleor/graphql/product/tests/mutations/test_product_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/mutations/test_product_update.py\n===================================================================\n--- saleor/graphql/product/tests/mutations/test_product_update.py\t5657587 (parent)\n+++ saleor/graphql/product/tests/mutations/test_product_update.py\t56dfa35 (commit)\n@@ -639,9 +639,10 @@\n     product_id = graphene.Node.to_global_id(\"Product\", product.pk)\n     attribute_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.pk)\n     product_type.product_attributes.add(numeric_attribute)\n \n-    new_value = \"45.2\"\n+    numeric_value = 45.2\n+    new_value = str(numeric_value)\n \n     variables = {\n         \"productId\": product_id,\n         \"input\": {\"attributes\": [{\"id\": attribute_id, \"values\": [new_value]}]},\n@@ -675,8 +676,12 @@\n             }\n         ],\n     }\n     assert expected_att_data in attributes\n+    assert numeric_attribute.values.filter(\n+        name=new_value,\n+        numeric=numeric_value,\n+    ).exists()\n \n     updated_webhook_mock.assert_called_once_with(product)\n \n \n@@ -697,15 +702,16 @@\n     attribute_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.pk)\n     product_type.product_attributes.add(numeric_attribute)\n     slug_value = slugify(f\"{product.id}_{numeric_attribute.id}\", allow_unicode=True)\n     value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, slug=slug_value, name=\"20.0\"\n+        attribute=numeric_attribute, slug=slug_value, name=\"20.0\", numeric=20.0\n     )\n     associate_attribute_values_to_instance(product, {numeric_attribute.pk: [value]})\n \n     value_count = AttributeValue.objects.count()\n \n-    new_value = \"45.2\"\n+    numeric_value = 45.2\n+    new_value = str(numeric_value)\n \n     variables = {\n         \"productId\": product_id,\n         \"input\": {\"attributes\": [{\"id\": attribute_id, \"values\": [new_value]}]},\n@@ -742,8 +748,9 @@\n \n     assert AttributeValue.objects.count() == value_count\n     value.refresh_from_db()\n     assert value.name == new_value\n+    assert value.numeric == numeric_value\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.product_updated\")\n def test_update_product_clear_attribute_values(\n@@ -2355,9 +2362,10 @@\n     product_id = graphene.Node.to_global_id(\"Product\", product.pk)\n     attribute_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.pk)\n     product_type.product_attributes.add(numeric_attribute)\n \n-    new_value = \"45.2\"\n+    numeric_value = 45.2\n+    new_value = str(numeric_value)\n \n     variables = {\n         \"productId\": product_id,\n         \"input\": {\"attributes\": [{\"id\": attribute_id, \"numeric\": new_value}]},\n@@ -2391,8 +2399,11 @@\n             }\n         ],\n     }\n     assert expected_att_data in attributes\n+    assert numeric_attribute.values.filter(\n+        name=new_value, numeric=numeric_value\n+    ).first()\n \n     updated_webhook_mock.assert_called_once_with(product)\n \n \n@@ -2411,9 +2422,9 @@\n     attribute_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.pk)\n     product_type.product_attributes.add(numeric_attribute)\n     slug_value = slugify(f\"{product.id}_{numeric_attribute.id}\", allow_unicode=True)\n     value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, slug=slug_value, name=\"20.0\"\n+        attribute=numeric_attribute, slug=slug_value, name=\"20.0\", numeric=20.0\n     )\n     associate_attribute_values_to_instance(product, {numeric_attribute.pk: [value]})\n \n     variables = {\n@@ -2448,15 +2459,16 @@\n     attribute_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.pk)\n     product_type.product_attributes.add(numeric_attribute)\n     slug_value = slugify(f\"{product.id}_{numeric_attribute.id}\", allow_unicode=True)\n     value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, slug=slug_value, name=\"20.0\"\n+        attribute=numeric_attribute, slug=slug_value, name=\"20.0\", numeric=20.0\n     )\n     associate_attribute_values_to_instance(product, {numeric_attribute.pk: [value]})\n \n     value_count = AttributeValue.objects.count()\n \n-    new_value = \"45.2\"\n+    numeric_value = 45.2\n+    new_value = str(numeric_value)\n \n     variables = {\n         \"productId\": product_id,\n         \"input\": {\"attributes\": [{\"id\": attribute_id, \"numeric\": new_value}]},\n@@ -2493,8 +2505,9 @@\n \n     assert AttributeValue.objects.count() == value_count\n     value.refresh_from_db()\n     assert value.name == new_value\n+    assert value.numeric == numeric_value\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.product_updated\")\n def test_update_product_with_dropdown_attribute_non_existing_value(\n"
        },
        {
          "path": "saleor/graphql/product/tests/mutations/test_product_variant_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/mutations/test_product_variant_create.py\n===================================================================\n--- saleor/graphql/product/tests/mutations/test_product_variant_create.py\t5657587 (parent)\n+++ saleor/graphql/product/tests/mutations/test_product_variant_create.py\t56dfa35 (commit)\n@@ -1446,16 +1446,18 @@\n     permission_manage_products,\n     warehouse,\n     numeric_attribute,\n ):\n+    # given\n     query = CREATE_VARIANT_MUTATION\n     product_id = graphene.Node.to_global_id(\"Product\", product.pk)\n     sku = \"1\"\n     weight = 10.22\n     product_type.variant_attributes.set([numeric_attribute])\n     variant_slug = numeric_attribute.slug\n     attribute_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.pk)\n-    variant_value = \"22.31\"\n+    numeric_value = 22.31\n+    numeric_name = \"22.31\"\n     stocks = [\n         {\n             \"warehouse\": graphene.Node.to_global_id(\"Warehouse\", warehouse.pk),\n             \"quantity\": 20,\n@@ -1467,15 +1469,19 @@\n             \"product\": product_id,\n             \"sku\": sku,\n             \"stocks\": stocks,\n             \"weight\": weight,\n-            \"attributes\": [{\"id\": attribute_id, \"values\": [variant_value]}],\n+            \"attributes\": [{\"id\": attribute_id, \"values\": [numeric_name]}],\n             \"trackInventory\": True,\n         }\n     }\n+\n+    # when\n     response = staff_api_client.post_graphql(\n         query, variables, permissions=[permission_manage_products]\n     )\n+\n+    # then\n     content = get_graphql_content(response)[\"data\"][\"productVariantCreate\"]\n     assert not content[\"errors\"]\n     data = content[\"productVariant\"]\n     variant_pk = graphene.Node.from_global_id(data[\"id\"])[1]\n@@ -1492,9 +1498,14 @@\n     assert data[\"stocks\"][0][\"quantity\"] == stocks[0][\"quantity\"]\n     assert data[\"stocks\"][0][\"warehouse\"][\"slug\"] == warehouse.slug\n     created_webhook_mock.assert_called_once_with(product.variants.last())\n \n+    assert numeric_attribute.values.filter(\n+        name=numeric_name,\n+        numeric=numeric_value,\n+    ).first()\n \n+\n @patch(\"saleor.plugins.manager.PluginsManager.product_updated\")\n def test_create_variant_with_numeric_attribute_not_numeric_value_given(\n     updated_webhook_mock,\n     staff_api_client,\n"
        },
        {
          "path": "saleor/graphql/product/tests/mutations/test_product_variant_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/mutations/test_product_variant_update.py\n===================================================================\n--- saleor/graphql/product/tests/mutations/test_product_variant_update.py\t5657587 (parent)\n+++ saleor/graphql/product/tests/mutations/test_product_variant_update.py\t56dfa35 (commit)\n@@ -1455,9 +1455,9 @@\n     product_variant_updated.assert_called_once_with(product.variants.last())\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.product_variant_updated\")\n-def test_update_variant_with_numeric_attribute(\n+def test_update_variant_removes_numeric_attribute_value(\n     product_variant_updated,\n     permission_manage_products,\n     product,\n     product_type,\n@@ -1500,8 +1500,61 @@\n     assert numeric_attribute.values.count() == values_count\n     product_variant_updated.assert_called_once_with(product.variants.last())\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.product_variant_updated\")\n+def test_update_variant_adds_numeric_attribute(\n+    product_variant_updated,\n+    permission_manage_products,\n+    product,\n+    product_type,\n+    staff_api_client,\n+    numeric_attribute,\n+    warehouse,\n+):\n+    # given\n+    product_type.variant_attributes.add(numeric_attribute)\n+\n+    numeric_value = 33.12\n+    numeric_name = str(numeric_value)\n+\n+    variant = product.variants.first()\n+    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.pk)\n+    attr_id = graphene.Node.to_global_id(\"Attribute\", numeric_attribute.id)\n+    query = QUERY_UPDATE_VARIANT_ATTRIBUTES\n+    variables = {\n+        \"id\": variant_id,\n+        \"attributes\": [\n+            {\"id\": attr_id, \"numeric\": numeric_name},\n+        ],\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        query, variables, permissions=[permission_manage_products]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)[\"data\"][\"productVariantUpdate\"]\n+    variant.refresh_from_db()\n+    data = content[\"productVariant\"]\n+\n+    assert not content[\"errors\"]\n+\n+    attribute_data = [\n+        attr_data\n+        for attr_data in data[\"attributes\"]\n+        if attr_data[\"attribute\"][\"slug\"] == numeric_attribute.slug\n+    ][0]\n+    assert attribute_data[\"attribute\"][\"slug\"] == numeric_attribute.slug\n+    assert attribute_data[\"values\"][0][\"name\"] == numeric_name\n+\n+    assert numeric_attribute.values.filter(\n+        name=numeric_name, numeric=numeric_value\n+    ).first()\n+    product_variant_updated.assert_called_once_with(product.variants.last())\n+\n+\n def test_update_product_variant_with_new_attribute(\n     staff_api_client,\n     product_with_variant_with_two_attributes,\n     color_attribute,\n"
        },
        {
          "path": "saleor/graphql/product/tests/queries/test_products_query_with_filter.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/queries/test_products_query_with_filter.py\n===================================================================\n--- saleor/graphql/product/tests/queries/test_products_query_with_filter.py\t5657587 (parent)\n+++ saleor/graphql/product/tests/queries/test_products_query_with_filter.py\t56dfa35 (commit)\n@@ -137,9 +137,9 @@\n         product_type=product_type,\n         category=category,\n     )\n     attr_value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, name=\"5\", slug=\"5\"\n+        attribute=numeric_attribute, name=\"5\", slug=\"5\", numeric=5.0\n     )\n \n     associate_attribute_values_to_instance(\n         second_product,\n@@ -152,9 +152,9 @@\n         product_type=product_type,\n         category=category,\n     )\n     attr_value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, name=\"5\", slug=\"5_X\"\n+        attribute=numeric_attribute, name=\"5\", slug=\"5_X\", numeric=5.0\n     )\n \n     associate_attribute_values_to_instance(\n         third_product,\n@@ -369,9 +369,9 @@\n         product_type=product_type,\n         category=category,\n     )\n     attr_value_2 = AttributeValue.objects.create(\n-        attribute=numeric_attribute, name=\"5.2\", slug=\"5_2\"\n+        attribute=numeric_attribute, name=\"5.2\", slug=\"5_2\", numeric=5.2\n     )\n \n     associate_attribute_values_to_instance(\n         second_product,\n@@ -1377,9 +1377,10 @@\n     numeric_attribute.save(update_fields=[\"unit\"])\n \n     numeric_attr_value = numeric_attribute.values.first()\n     numeric_attr_value.name = \"13456\"\n-    numeric_attr_value.save(update_fields=[\"name\"])\n+    numeric_attr_value.numeric = 13456\n+    numeric_attr_value.save(update_fields=[\"name\", \"numeric\"])\n \n     associate_attribute_values_to_instance(\n         product_with_numeric_attr,\n         {numeric_attribute.id: [numeric_attr_value]},\n@@ -1425,9 +1426,10 @@\n     product_type.product_attributes.add(numeric_attribute)\n \n     numeric_attr_value = numeric_attribute.values.first()\n     numeric_attr_value.name = \"13456\"\n-    numeric_attr_value.save(update_fields=[\"name\"])\n+    numeric_attr_value.numeric = 13456\n+    numeric_attr_value.save(update_fields=[\"name\", \"numeric\"])\n \n     associate_attribute_values_to_instance(\n         product_with_numeric_attr,\n         {numeric_attribute.id: [numeric_attr_value]},\n"
        },
        {
          "path": "saleor/graphql/product/tests/queries/test_products_query_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/queries/test_products_query_with_where.py\n===================================================================\n--- saleor/graphql/product/tests/queries/test_products_query_with_where.py\t5657587 (parent)\n+++ saleor/graphql/product/tests/queries/test_products_query_with_where.py\t56dfa35 (commit)\n@@ -10,13 +10,9 @@\n     get_product_attributes,\n )\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....product import ProductTypeKind\n-from .....product.models import (\n-    Product,\n-    ProductChannelListing,\n-    ProductType,\n-)\n+from .....product.models import Product, ProductChannelListing, ProductType\n from .....warehouse.models import Allocation, Reservation, Stock, Warehouse\n from ....tests.utils import get_graphql_content\n \n PRODUCTS_WHERE_QUERY = \"\"\"\n@@ -876,17 +872,17 @@\n     numeric_attribute.product_types.add(product_type)\n \n     product_list[1].product_type = product_type\n     attr_value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, name=\"5\", slug=\"5\"\n+        attribute=numeric_attribute, name=\"5\", slug=\"5\", numeric=5.0\n     )\n     associate_attribute_values_to_instance(\n         product_list[1],\n         {numeric_attribute.id: [attr_value]},\n     )\n \n     attr_value = AttributeValue.objects.create(\n-        attribute=numeric_attribute, name=\"5\", slug=\"5_X\"\n+        attribute=numeric_attribute, name=\"5\", slug=\"5_X\", numeric=5.0\n     )\n     product_list[2].product_type = product_type\n     associate_attribute_values_to_instance(\n         product_list[2],\n@@ -989,9 +985,9 @@\n     numeric_attribute.product_types.add(product_type)\n \n     product_list[1].product_type = product_type\n     attr_value_2 = AttributeValue.objects.create(\n-        attribute=numeric_attribute, name=\"1.2\", slug=\"1_2\"\n+        attribute=numeric_attribute, name=\"1.2\", slug=\"1_2\", numeric=1.2\n     )\n     associate_attribute_values_to_instance(\n         product_list[1],\n         {numeric_attribute.id: [attr_value_2]},\n"
        }
      ]
    },
    {
      "id": "add-checkout-authorized",
      "sha": "3c5dcc46513f82435ffb8223566f9698acdce814",
      "parentSha": "b35783838e51cfc118e07d632f64b01bc3a2c4bb",
      "spec": "Implement a new async webhook event for when a checkout becomes fully authorized and wire it end-to-end, following the existing checkout_fully_paid pattern.\n\n1) Event type and registry\n- In saleor/webhook/event_types.py:\n  - Add a new async event constant CHECKOUT_FULLY_AUTHORIZED = \"checkout_fully_authorized\".\n  - Include it in CHOICES and in the event metadata map with:\n    - name: \"Checkout fully authorized\"\n    - permission: CheckoutPermissions.MANAGE_CHECKOUTS\n    - Do not set deferred payload (follow the fully paid pattern as in the diff).\n\n2) Emit event in checkout actions\n- In saleor/checkout/actions.py:\n  - Add a mapping entry in CHECKOUT_WEBHOOK_EVENT_MAP for WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED pointing to PluginsManager.checkout_fully_authorized.__name__.\n  - In _transaction_amounts_for_checkout_updated(...):\n    - Compute previous_authorize_status_is_full and current_authorize_status_is_full booleans.\n    - If not previously full and now full, call call_checkout_info_event with WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED, passing the current checkout_info and lines.\n    - Refactor the automatic checkout completion branch to reuse the above booleans in the condition, maintaining the single-trigger guarantee.\n    - Keep the existing fully paid event call intact.\n\n3) Plugin manager and base plugin API\n- In saleor/plugins/base_plugin.py:\n  - Declare checkout_fully_authorized: Callable[[\"Checkout\", Any, None], Any] with deprecation note consistent with other webhook methods.\n- In saleor/plugins/manager.py:\n  - Add a method checkout_fully_authorized(self, checkout: \"Checkout\", webhooks=None) that delegates via __run_method_on_plugins with channel_slug=checkout.channel.slug and default_value=None.\n- In saleor/plugins/tests/sample_plugins.py:\n  - Implement a no-op checkout_fully_authorized to satisfy tests, mirroring checkout_fully_paid.\n- In saleor/plugins/tests/test_manager.py:\n  - Add a unit test to assert that PluginsManager.checkout_fully_authorized forwards to the sample plugin with the correct arguments.\n\n4) Webhook plugin trigger implementation\n- In saleor/plugins/webhook/plugin.py:\n  - Implement BasePlugin.checkout_fully_authorized(...) similar to checkout_fully_paid, but using WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED.\n  - Resolve webhooks for the checkout's channel and trigger async deliveries using generate_checkout_payload and queue=settings.CHECKOUT_WEBHOOK_EVENTS_CELERY_QUEUE_NAME.\n\n5) GraphQL schema and subscription support\n- In saleor/graphql/schema.graphql:\n  - Add CHECKOUT_FULLY_AUTHORIZED to WebhookEventTypeEnum and WebhookEventTypeAsyncEnum with descriptions indicating it is emitted when authorizeStatus becomes FULL and only for Transaction API checkouts.\n  - Add CHECKOUT_FULLY_AUTHORIZED to WebhookSampleEventTypeEnum.\n  - Update the descriptive text for CheckoutFullyPaid to clarify it is not sent for authorization-only flows and is only for Transaction API.\n  - Define a new type CheckoutFullyAuthorized implementing Event with fields: issuedAt, version, issuingPrincipal, recipient, checkout.\n  - Add a new subscription field checkoutFullyAuthorized(channels: [String!]) returning CheckoutFullyAuthorized with the same feature preview notes and channel filtering behavior as other checkout subscriptions.\n- In saleor/graphql/webhook/enums.py:\n  - Add checkout_fully_authorized_event_enum_description mirroring the schema description and add it to WEBHOOK_EVENT_DESCRIPTION for WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED.\n  - Update the description for CHECKOUT_FULLY_PAID to match the new wording.\n- In saleor/graphql/webhook/subscription_types.py:\n  - Update CheckoutFullyPaid.description to the new wording.\n  - Add a new SubscriptionObjectType CheckoutFullyAuthorized(CheckoutBase) implementing Event with description consistent with schema.\n  - Add a Subscription BaseField checkout_fully_authorized with ADDED_IN_321 and PREVIEW_FEATURE markers, using default_channel_filterable_resolver and DOC_CATEGORY_CHECKOUT.\n  - Extend ASYNC_WEBHOOK_TYPES_MAP to map WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED to CheckoutFullyAuthorized.\n\n6) Trigger paths and integration tests adjustments\n- In tests across checkout/payment mutation flows and transaction event handling, ensure that when a checkout becomes fully authorized:\n  - PluginsManager.checkout_fully_authorized is called exactly once with webhooks supplied/set(), alongside existing fully paid calls where applicable.\n  - Automatic checkout completion task still only triggers once and only when the authorize status transitions to FULL and the channel setting is enabled.\n  - Add tests for webhook deliveries and subscription payloads for the new event, similar to existing fully paid tests (e.g., create deliveries for asynchronous subscription, ensure sync webhooks are invoked as required when the async event requires sync data, and ensure no deliveries when the channel filter doesn't match).\n\n7) Fixtures and subscription queries\n- In saleor/tests/fixtures.py and saleor/webhook/tests/fixtures/subscription_webhooks.py:\n  - Add fixtures for subscription_checkout_fully_authorized_webhook and include it in async_subscription_webhooks_with_root_objects mapping.\n- In saleor/webhook/tests/subscription_webhooks/subscription_queries.py:\n  - Add CHECKOUT_FULLY_AUTHORIZED subscription query used by tests.\n- In saleor/webhook/tests/fixtures/webhook.py:\n  - Extend the webhook fragment selection to include CheckoutFullyAuthorized cases, similar to other checkout events.\n\nAcceptance criteria\n- When a checkout's authorize_status transitions from non-FULL to FULL, the CHECKOUT_FULLY_AUTHORIZED async webhook is emitted once, with correct payload, respecting channel filters.\n- Existing CHECKOUT_FULLY_PAID behavior remains unchanged; both events may be emitted when applicable.\n- Automatic completion behavior remains single-trigger and is unaffected except for using the refactored full-status booleans.\n- GraphQL enums, schema descriptions, and subscription field support the new event and appear in introspection as defined.\n- PluginsManager exposes checkout_fully_authorized and WebhookPlugin triggers async deliveries as per queue settings.\n",
      "prompt": "Add a new checkout webhook that fires when a checkout becomes fully authorized. Expose it end-to-end in the platform:\n- Define an async webhook event for a fully authorized checkout and register it with the existing webhook event registry and permissions.\n- Emit this event when a checkout’s authorization status first becomes FULL, without affecting the existing fully paid flow.\n- Add a corresponding plugin manager method and implement a webhook plugin trigger that generates and enqueues async deliveries for the checkout object.\n- Extend the GraphQL schema and subscriptions to include this event with appropriate descriptions and channel filtering, mirroring the existing fully paid event structure.\n- Keep automatic checkout completion behavior unchanged except to use a clear, single-transition check. Ensure both events can fire together when applicable.\n- Update tests and fixtures to cover the new event across action paths (transaction updates, create/process/initialize mutations), subscription deliveries, and manager/plugin method calls.",
      "supplementalFiles": [
        "saleor/checkout/__init__.py",
        "saleor/checkout/models.py",
        "saleor/checkout/tasks.py",
        "saleor/webhook/utils.py",
        "saleor/webhook/payloads.py",
        "saleor/webhook/transport/asynchronous/transport.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/actions.py\n===================================================================\n--- saleor/checkout/actions.py\tb357838 (parent)\n+++ saleor/checkout/actions.py\t3c5dcc4 (commit)\n@@ -35,8 +35,9 @@\n \n CHECKOUT_WEBHOOK_EVENT_MAP = {\n     WebhookEventAsyncType.CHECKOUT_CREATED: PluginsManager.checkout_created.__name__,\n     WebhookEventAsyncType.CHECKOUT_UPDATED: PluginsManager.checkout_updated.__name__,\n+    WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED: PluginsManager.checkout_fully_authorized.__name__,\n     WebhookEventAsyncType.CHECKOUT_FULLY_PAID: PluginsManager.checkout_fully_paid.__name__,\n     WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED: PluginsManager.checkout_metadata_updated.__name__,\n }\n \n@@ -309,18 +310,28 @@\n             event_name=WebhookEventAsyncType.CHECKOUT_FULLY_PAID,\n             checkout_info=checkout_info,\n             lines=lines,\n         )\n+    previous_authorize_status_is_full = (\n+        previous_authorize_status == CheckoutAuthorizeStatus.FULL\n+    )\n+    current_authorize_status_is_full = (\n+        checkout_info.checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n+    )\n+    if not previous_authorize_status_is_full and current_authorize_status_is_full:\n+        call_checkout_info_event(\n+            manager,\n+            event_name=WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED,\n+            checkout_info=checkout_info,\n+            lines=lines,\n+        )\n \n     channel = checkout_info.channel\n     if (\n         channel.automatically_complete_fully_paid_checkouts\n         and\n         # ensure that checkout completion is triggered only once\n-        (\n-            previous_authorize_status != CheckoutAuthorizeStatus.FULL\n-            and checkout_info.checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n-        )\n+        (not previous_authorize_status_is_full and current_authorize_status_is_full)\n     ):\n         user_id = user.id if user else None\n         app_id = app.id if app else None\n         automatic_checkout_completion_task.delay(checkout.pk, user_id, app_id)\n"
        },
        {
          "path": "saleor/checkout/tests/test_actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_actions.py\n===================================================================\n--- saleor/checkout/tests/test_actions.py\tb357838 (parent)\n+++ saleor/checkout/tests/test_actions.py\t3c5dcc4 (commit)\n@@ -25,9 +25,11 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_for_checkout_updated_fully_paid(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n@@ -54,14 +56,17 @@\n     checkout.refresh_from_db()\n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_fully_paid.assert_called_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_with(checkout, webhooks=set())\n     assert not mocked_automatic_checkout_completion_task.called\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_for_checkout_fully_paid_automatic_checkout_complete(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n@@ -91,16 +96,19 @@\n     checkout.refresh_from_db()\n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_called_once_with(\n         checkout.pk, None, app.id\n     )\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_for_checkout_updated_not_fully_paid_no_automatic_complete(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n@@ -129,16 +137,19 @@\n     # then\n     checkout.refresh_from_db()\n     assert checkout.charge_status == CheckoutChargeStatus.PARTIAL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.PARTIAL\n+    assert not mocked_fully_authorized.called\n     assert not mocked_fully_paid.called\n     assert not mocked_automatic_checkout_completion_task.called\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_for_checkout_updated_with_already_fully_paid(\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n     plugins_manager,\n@@ -169,14 +180,69 @@\n     checkout.refresh_from_db()\n     assert checkout.charge_status == CheckoutChargeStatus.OVERCHARGED\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     assert not mocked_fully_paid.called\n+    assert not mocked_fully_authorized.called\n     assert not mocked_automatic_checkout_completion_task.called\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n+def test_transaction_amounts_for_checkout_updated_with_already_fully_authorized(\n+    mocked_fully_paid,\n+    mocked_fully_authorized,\n+    mocked_automatic_checkout_completion_task,\n+    checkout_with_items,\n+    transaction_item_generator,\n+    plugins_manager,\n+    django_capture_on_commit_callbacks,\n+):\n+    # given\n+    checkout = checkout_with_items\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, plugins_manager)\n+    checkout_info, _ = fetch_checkout_data(checkout_info, plugins_manager, lines)\n+    total = calculate_checkout_total(\n+        manager=plugins_manager, checkout_info=checkout_info, lines=lines, address=None\n+    )\n+\n+    first_authorized_amount = total.gross.amount - 1\n+    second_authorized_amount = 1\n+    transaction_item_generator(\n+        checkout_id=checkout.pk,\n+        authorized_value=first_authorized_amount,\n+    )\n+\n+    second_transaction = transaction_item_generator(\n+        checkout_id=checkout.pk, authorized_value=second_authorized_amount\n+    )\n+\n+    fetch_checkout_data(checkout_info, plugins_manager, lines, force_status_update=True)\n+\n+    assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n+    assert checkout.charge_status == CheckoutChargeStatus.NONE\n+\n+    # when\n+    with django_capture_on_commit_callbacks(execute=True):\n+        transaction_amounts_for_checkout_updated(\n+            second_transaction, manager=plugins_manager, user=None, app=None\n+        )\n+\n+    # then\n+    checkout.refresh_from_db()\n+    assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n+    assert checkout.charge_status == CheckoutChargeStatus.NONE\n+    assert not mocked_fully_paid.called\n+    assert not mocked_fully_authorized.called\n+    assert not mocked_automatic_checkout_completion_task.called\n+\n+\n+@patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_for_checkout_updated_fully_authorized(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n@@ -205,13 +271,16 @@\n     assert checkout.charge_status == CheckoutChargeStatus.NONE\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     assert not mocked_fully_paid.called\n     assert not mocked_automatic_checkout_completion_task.called\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_for_checkout_fully_authorized_automatic_checkout_complete(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n@@ -245,13 +314,16 @@\n     assert not mocked_fully_paid.called\n     mocked_automatic_checkout_completion_task.assert_called_once_with(\n         checkout.pk, staff_user.id, None\n     )\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_amounts_automatic_checkout_complete_called_once(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_items,\n     transaction_item_generator,\n@@ -293,8 +365,9 @@\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_called_once_with(\n         checkout.pk, None, app.id\n     )\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @pytest.mark.parametrize(\n     \"previous_modified_at\",\n@@ -1324,21 +1397,139 @@\n     tax_delivery = tax_delivery_call.args[0]\n     assert tax_delivery.webhook_id == tax_webhook.id\n \n     assert wrapped_call_checkout_info_event.called\n-    mocked_call_event_including_protected_events.assert_called_once_with(\n+\n+    assert mocked_call_event_including_protected_events.call_count == 2\n+    mocked_call_event_including_protected_events.assert_any_call(\n         plugins_manager.checkout_fully_paid,\n         checkout_with_items,\n         webhooks={checkout_fully_paid_webhook},\n     )\n+    mocked_call_event_including_protected_events.assert_any_call(\n+        plugins_manager.checkout_fully_authorized,\n+        checkout_with_items,\n+        webhooks=set(),\n+    )\n \n \n @freeze_time(\"2023-05-31 12:00:01\")\n+@patch(\n+    \"saleor.checkout.actions.call_checkout_info_event\",\n+    wraps=call_checkout_info_event,\n+)\n @patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n @patch(\n     \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n )\n+@patch(\n+    \"saleor.checkout.actions.call_event_including_protected_events\",\n+    wraps=call_event_including_protected_events,\n+)\n @override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n+def test_transaction_amounts_for_checkout_fully_authorized_triggers_sync_webhook(\n+    mocked_call_event_including_protected_events,\n+    mocked_send_webhook_request_async,\n+    mocked_send_webhook_request_sync,\n+    wrapped_call_checkout_info_event,\n+    setup_checkout_webhooks,\n+    settings,\n+    checkout_with_items,\n+    transaction_item_generator,\n+    django_capture_on_commit_callbacks,\n+    address,\n+):\n+    # given\n+    plugins_manager = get_plugins_manager(allow_replica=False)\n+    checkout_with_items.price_expiration = timezone.now() - datetime.timedelta(hours=10)\n+\n+    # Ensure shipping is set so shipping webhooks are emitted\n+    checkout_with_items.shipping_address = address\n+    checkout_with_items.billing_address = address\n+\n+    checkout_with_items.save(\n+        update_fields=[\"price_expiration\", \"billing_address\", \"shipping_address\"]\n+    )\n+\n+    mocked_send_webhook_request_sync.return_value = []\n+    (\n+        tax_webhook,\n+        shipping_webhook,\n+        shipping_filter_webhook,\n+        checkout_fully_authorized_webhook,\n+    ) = setup_checkout_webhooks(WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED)\n+    checkout = checkout_with_items\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, plugins_manager)\n+    checkout_info, _ = fetch_checkout_data(checkout_info, plugins_manager, lines)\n+\n+    transaction = transaction_item_generator(\n+        checkout_id=checkout.pk,\n+        authorized_value=checkout_info.checkout.total.gross.amount,\n+    )\n+\n+    # when\n+    with django_capture_on_commit_callbacks(execute=True):\n+        transaction_amounts_for_checkout_updated(\n+            transaction, manager=plugins_manager, user=None, app=None\n+        )\n+\n+    # then\n+\n+    # confirm that event delivery was generated for each async webhook.\n+    checkout_fully_authorized_delivery = EventDelivery.objects.get(\n+        webhook_id=checkout_fully_authorized_webhook.id\n+    )\n+    mocked_send_webhook_request_async.assert_called_once_with(\n+        kwargs={\n+            \"event_delivery_id\": checkout_fully_authorized_delivery.id,\n+            \"telemetry_context\": ANY,\n+        },\n+        queue=settings.CHECKOUT_WEBHOOK_EVENTS_CELERY_QUEUE_NAME,\n+        MessageGroupId=\"example.com:saleor.app.additional\",\n+    )\n+\n+    # confirm each sync webhook was called without saving event delivery\n+    assert mocked_send_webhook_request_sync.call_count == 3\n+    assert not EventDelivery.objects.exclude(\n+        webhook_id=checkout_fully_authorized_webhook.id\n+    ).exists()\n+\n+    tax_delivery_call, shipping_methods_call, filter_shipping_call = (\n+        mocked_send_webhook_request_sync.mock_calls\n+    )\n+    shipping_methods_delivery = shipping_methods_call.args[0]\n+    assert shipping_methods_delivery.webhook_id == shipping_webhook.id\n+    assert (\n+        shipping_methods_delivery.event_type\n+        == WebhookEventSyncType.SHIPPING_LIST_METHODS_FOR_CHECKOUT\n+    )\n+\n+    filter_shipping_delivery = filter_shipping_call.args[0]\n+    assert filter_shipping_delivery.webhook_id == shipping_filter_webhook.id\n+    assert (\n+        filter_shipping_delivery.event_type\n+        == WebhookEventSyncType.CHECKOUT_FILTER_SHIPPING_METHODS\n+    )\n+\n+    tax_delivery = tax_delivery_call.args[0]\n+    assert tax_delivery.webhook_id == tax_webhook.id\n+\n+    assert wrapped_call_checkout_info_event.called\n+\n+    mocked_call_event_including_protected_events.assert_called_once_with(\n+        plugins_manager.checkout_fully_authorized,\n+        checkout_with_items,\n+        webhooks={checkout_fully_authorized_webhook},\n+    )\n+\n+\n+@freeze_time(\"2023-05-31 12:00:01\")\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n def test_call_checkout_events_incorrect_webhook_event(\n     mocked_send_webhook_request_async,\n     mocked_send_webhook_request_sync,\n     checkout_with_items,\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_create.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_create.py\tb357838 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_create.py\t3c5dcc4 (commit)\n@@ -1198,9 +1198,11 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_create_for_checkout_fully_paid(\n+    mocked_checkout_fully_authorized,\n     mocked_checkout_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_prices,\n     permission_manage_payments,\n@@ -1248,14 +1250,17 @@\n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_create_for_checkout_fully_paid_automatic_completion(\n     mocked_checkout_fully_paid,\n+    mocked_checkout_fully_authorized,\n     checkout_with_prices,\n     permission_manage_payments,\n     staff_api_client,\n     plugins_manager,\n@@ -1301,8 +1306,9 @@\n     )\n \n     # then\n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     with pytest.raises(Checkout.DoesNotExist):\n         checkout.refresh_from_db()\n \n     order = Order.objects.get(checkout_token=checkout_token)\n@@ -1313,11 +1319,13 @@\n     ).exists()\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_create_for_checkout_fully_authorized(\n     mocked_checkout_fully_paid,\n+    mocked_checkout_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_prices,\n     permission_manage_payments,\n     staff_api_client,\n@@ -1363,15 +1371,18 @@\n     checkout.refresh_from_db()\n     assert checkout.charge_status == CheckoutChargeStatus.NONE\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_checkout_fully_paid.assert_not_called()\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_create_for_checkout_fully_authorized_automatic_completion(\n     mocked_checkout_fully_paid,\n+    mocked_checkout_fully_authorized,\n     checkout_with_prices,\n     permission_manage_payments,\n     staff_api_client,\n     plugins_manager,\n@@ -1416,8 +1427,9 @@\n         MUTATION_TRANSACTION_CREATE, variables, permissions=[permission_manage_payments]\n     )\n \n     # then\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_checkout_fully_paid.assert_not_called()\n \n     with pytest.raises(Checkout.DoesNotExist):\n         checkout.refresh_from_db()\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_event_report.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\tb357838 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\t3c5dcc4 (commit)\n@@ -1389,9 +1389,11 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_event_updates_checkout_full_paid_with_charged_amount(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app_api_client,\n@@ -1454,15 +1456,18 @@\n \n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_event_updates_checkout_full_paid_with_pending_charge_amount(\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app_api_client,\n     permission_manage_payments,\n@@ -1521,14 +1526,17 @@\n \n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_event_updates_checkout_full_paid_automatic_completion(\n     mocked_fully_paid,\n+    checkout_fully_authorized,\n     transaction_item_generator,\n     app_api_client,\n     permission_manage_payments,\n     checkout_with_prices,\n@@ -1598,14 +1606,17 @@\n     assert order.events.filter(\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n \n+    checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_event_updates_checkout_full_paid_pending_charge_automatic_complete(\n     mocked_fully_paid,\n+    checkout_fully_authorized,\n     transaction_item_generator,\n     app_api_client,\n     permission_manage_payments,\n     checkout_with_prices,\n@@ -1672,13 +1683,16 @@\n     assert order.charge_status == CheckoutChargeStatus.NONE\n     assert order.authorize_status == CheckoutAuthorizeStatus.NONE\n \n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_event_updates_checkout_fully_authorized(\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app_api_client,\n@@ -1740,15 +1754,19 @@\n     checkout.refresh_from_db()\n \n     assert checkout.charge_status == CheckoutChargeStatus.NONE\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n+\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_event_updates_checkout_fully_authorized_automatic_complete(\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     transaction_item_generator,\n     app_api_client,\n     permission_manage_payments,\n     checkout_with_prices,\n@@ -1818,13 +1836,16 @@\n     assert order.events.filter(\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n def test_transaction_event_updates_checkout_fully_authorized_pending_automatic_complete(\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     transaction_item_generator,\n     app_api_client,\n     permission_manage_payments,\n     checkout_with_prices,\n@@ -1891,8 +1912,9 @@\n     order = Order.objects.get(checkout_token=checkout_token)\n     assert order.charge_status == CheckoutChargeStatus.NONE\n     assert order.authorize_status == CheckoutAuthorizeStatus.NONE\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n def test_transaction_event_report_with_info_event(\n     transaction_item_generator,\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_initialize.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_initialize.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_initialize.py\tb357838 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_initialize.py\t3c5dcc4 (commit)\n@@ -1827,11 +1827,13 @@\n     \"result\", [TransactionEventType.CHARGE_REQUEST, TransactionEventType.CHARGE_SUCCESS]\n )\n @mock.patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_initialize_session\")\n def test_checkout_fully_paid(\n     mocked_initialize,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     result,\n     user_api_client,\n@@ -1874,18 +1876,21 @@\n     content = get_graphql_content(response)\n     assert not content[\"data\"][\"transactionInitialize\"][\"errors\"]\n     checkout.refresh_from_db()\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n \n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_initialize_session\")\n def test_checkout_fully_paid_automatic_completion(\n     mocked_initialize,\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n     transaction_session_response,\n@@ -1936,15 +1941,18 @@\n     assert order.events.filter(\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_initialize_session\")\n def test_checkout_fully_paid_pending_charge_automatic_completion(\n     mocked_initialize,\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n     transaction_session_response,\n@@ -1992,8 +2000,9 @@\n     order = Order.objects.get(checkout_token=checkout_token)\n     assert order.charge_status == CheckoutChargeStatus.NONE\n     assert order.authorize_status == CheckoutAuthorizeStatus.NONE\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @pytest.mark.parametrize(\n     \"result\",\n@@ -2003,11 +2012,13 @@\n     ],\n )\n @mock.patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_initialize_session\")\n def test_checkout_fully_authorized(\n     mocked_initialize,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     result,\n     user_api_client,\n@@ -2052,16 +2063,19 @@\n     checkout.refresh_from_db()\n     assert checkout.charge_status == CheckoutChargeStatus.NONE\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_automatic_checkout_completion_task.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_fully_paid.assert_not_called()\n \n \n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_initialize_session\")\n def test_checkout_fully_authorized_automatic_completion(\n     mocked_initialize,\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n     transaction_session_response,\n@@ -2112,15 +2126,18 @@\n     assert order.events.filter(\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_initialize_session\")\n def test_checkout_fully_authorizaed_pending_authorization_automatic_completion(\n     mocked_initialize,\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n     transaction_session_response,\n@@ -2168,8 +2185,9 @@\n     order = Order.objects.get(checkout_token=checkout_token)\n     assert order.charge_status == CheckoutChargeStatus.NONE\n     assert order.authorize_status == CheckoutAuthorizeStatus.NONE\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n def test_user_missing_permission_for_customer_ip_address(\n     user_api_client,\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_process.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_process.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_process.py\tb357838 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_process.py\t3c5dcc4 (commit)\n@@ -1124,11 +1124,13 @@\n     \"result\", [TransactionEventType.CHARGE_REQUEST, TransactionEventType.CHARGE_SUCCESS]\n )\n @mock.patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_process_session\")\n def test_checkout_fully_paid(\n     mocked_process,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     result,\n     user_api_client,\n@@ -1183,17 +1185,20 @@\n     assert not content[\"data\"][\"transactionProcess\"][\"errors\"]\n \n     checkout.refresh_from_db()\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n \n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_process_session\")\n def test_checkout_fully_paid_automatic_completion(\n     mocked_process,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n@@ -1256,15 +1261,18 @@\n     assert order.authorize_status == CheckoutAuthorizeStatus.FULL\n     assert order.events.filter(\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n \n \n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_process_session\")\n def test_checkout_fully_paid_pending_automatic_completion(\n     mocked_process,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n@@ -1325,8 +1333,9 @@\n     order = Order.objects.get(checkout_token=checkout_token)\n     assert order.charge_status == CheckoutChargeStatus.NONE\n     assert order.authorize_status == CheckoutAuthorizeStatus.NONE\n     mocked_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @pytest.mark.parametrize(\n     \"result\",\n@@ -1335,13 +1344,15 @@\n         TransactionEventType.AUTHORIZATION_SUCCESS,\n     ],\n )\n @mock.patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_process_session\")\n def test_checkout_fully_authorized(\n     mocked_process,\n     mocked_fully_paid,\n+    mocked_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     result,\n     user_api_client,\n     checkout_with_prices,\n@@ -1396,16 +1407,19 @@\n \n     checkout.refresh_from_db()\n     mocked_fully_paid.assert_not_called()\n     mocked_automatic_checkout_completion_task.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     assert checkout.charge_status == CheckoutChargeStatus.NONE\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n \n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_process_session\")\n def test_checkout_fully_authorized_automatic_completion(\n     mocked_process,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n@@ -1469,14 +1483,17 @@\n     assert order.events.filter(\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@mock.patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n @mock.patch(\"saleor.plugins.manager.PluginsManager.transaction_process_session\")\n def test_checkout_fully_authorized_pending_automatic_completion(\n     mocked_process,\n+    mocked_fully_authorized,\n     mocked_fully_paid,\n     user_api_client,\n     checkout_with_prices,\n     webhook_app,\n@@ -1537,8 +1554,9 @@\n     order = Order.objects.get(checkout_token=checkout_token)\n     assert order.charge_status == CheckoutChargeStatus.NONE\n     assert order.authorize_status == CheckoutAuthorizeStatus.NONE\n     mocked_fully_paid.assert_not_called()\n+    mocked_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n def test_transaction_process_doesnt_accept_old_id(\n     user_api_client,\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_update.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_update.py\tb357838 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_update.py\t3c5dcc4 (commit)\n@@ -2692,9 +2692,11 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_update_for_checkout_fully_paid(\n+    mocked_checkout_fully_authorized,\n     mocked_checkout_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_prices,\n     permission_manage_payments,\n@@ -2740,13 +2742,16 @@\n     assert checkout.charge_status == CheckoutChargeStatus.FULL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_update_for_checkout_fully_paid_automatic_completion(\n+    mocked_checkout_fully_authorized,\n     mocked_checkout_fully_paid,\n     checkout_with_prices,\n     permission_manage_payments,\n     app_api_client,\n@@ -2800,13 +2805,16 @@\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n \n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_update_for_checkout_fully_authorized(\n+    mocked_checkout_fully_authorized,\n     mocked_checkout_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     checkout_with_prices,\n     permission_manage_payments,\n@@ -2852,13 +2860,16 @@\n     assert checkout.charge_status == CheckoutChargeStatus.PARTIAL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n \n     mocked_checkout_fully_paid.assert_not_called()\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_transaction_update_for_checkout_fully_authorized_automatic_completion(\n+    mocked_checkout_fully_authorized,\n     mocked_checkout_fully_paid,\n     checkout_with_prices,\n     permission_manage_payments,\n     app_api_client,\n@@ -2910,8 +2921,9 @@\n         type=OrderEvents.PLACED_AUTOMATICALLY_FROM_PAID_CHECKOUT\n     ).exists()\n \n     mocked_checkout_fully_paid.assert_not_called()\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n \n \n def test_transaction_update_accepts_old_id_for_old_transaction(\n     transaction_item_generator, permission_manage_payments, app_api_client\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\tb357838 (parent)\n+++ saleor/graphql/schema.graphql\t3c5dcc4 (commit)\n@@ -2051,8 +2051,21 @@\n   \"\"\"\n   A checkout is updated. It also triggers all updates related to the checkout.\n   \"\"\"\n   CHECKOUT_UPDATED\n+\n+  \"\"\"\n+  A checkout was fully authorized (its `authorizeStatus` is `FULL`).\n+  \n+  This event is emitted only for checkouts whose payments are processed through the Transaction API.\n+  \"\"\"\n+  CHECKOUT_FULLY_AUTHORIZED\n+\n+  \"\"\"\n+  A checkout was fully paid (its `chargeStatus` is `FULL` or `OVERCHARGED`). This event is not sent if payments are only authorized but not fully charged.\n+  \n+  This event is emitted only for checkouts whose payments are processed through the Transaction API.\n+  \"\"\"\n   CHECKOUT_FULLY_PAID\n \n   \"\"\"A checkout metadata is updated.\"\"\"\n   CHECKOUT_METADATA_UPDATED\n@@ -2613,8 +2626,21 @@\n   \"\"\"\n   A checkout is updated. It also triggers all updates related to the checkout.\n   \"\"\"\n   CHECKOUT_UPDATED\n+\n+  \"\"\"\n+  A checkout was fully authorized (its `authorizeStatus` is `FULL`).\n+  \n+  This event is emitted only for checkouts whose payments are processed through the Transaction API.\n+  \"\"\"\n+  CHECKOUT_FULLY_AUTHORIZED\n+\n+  \"\"\"\n+  A checkout was fully paid (its `chargeStatus` is `FULL` or `OVERCHARGED`). This event is not sent if payments are only authorized but not fully charged.\n+  \n+  This event is emitted only for checkouts whose payments are processed through the Transaction API.\n+  \"\"\"\n   CHECKOUT_FULLY_PAID\n \n   \"\"\"A checkout metadata is updated.\"\"\"\n   CHECKOUT_METADATA_UPDATED\n@@ -3424,8 +3450,9 @@\n   PRODUCT_VARIANT_BACK_IN_STOCK\n   PRODUCT_VARIANT_STOCK_UPDATED\n   CHECKOUT_CREATED\n   CHECKOUT_UPDATED\n+  CHECKOUT_FULLY_AUTHORIZED\n   CHECKOUT_FULLY_PAID\n   CHECKOUT_METADATA_UPDATED\n   NOTIFY_USER\n   PAGE_CREATED\n@@ -31016,8 +31043,22 @@\n     channels: [String!]\n   ): CheckoutFullyPaid @doc(category: \"Checkout\")\n \n   \"\"\"\n+  Event sent when checkout is fully authorized.\n+  \n+  Added in Saleor 3.21.\n+  \n+  Note: this API is currently in Feature Preview and can be subject to changes at later point.\n+  \"\"\"\n+  checkoutFullyAuthorized(\n+    \"\"\"\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n+    \"\"\"\n+    channels: [String!]\n+  ): CheckoutFullyAuthorized @doc(category: \"Checkout\")\n+\n+  \"\"\"\n   Event sent when checkout metadata is updated.\n   \n   Added in Saleor 3.21.\n   \n@@ -31355,9 +31396,11 @@\n   checkout: Checkout\n }\n \n \"\"\"\n-Event sent when checkout is fully paid with transactions. The checkout is considered as fully paid when the checkout `charge_status` is `FULL` or `OVERCHARGED`. The event is not sent when the checkout authorization flow strategy is used.\n+Event sent when a checkout was fully paid. A checkout is considered fully paid when its `chargeStatus` is `FULL` or `OVERCHARGED`. This event is not sent if payments are only authorized but not fully charged.\n+\n+It is triggered only for checkouts whose payments are processed through the Transaction API.\n \"\"\"\n type CheckoutFullyPaid implements Event @doc(category: \"Checkout\") {\n   \"\"\"Time of the event.\"\"\"\n   issuedAt: DateTime\n@@ -31374,8 +31417,30 @@\n   \"\"\"The checkout the event relates to.\"\"\"\n   checkout: Checkout\n }\n \n+\"\"\"\n+Event sent when a checkout was fully authorized. A checkout is considered fully authorized when its `authorizeStatus` is `FULL`.\n+\n+It is triggered only for checkouts whose payments are processed through the Transaction API.\n+\"\"\"\n+type CheckoutFullyAuthorized implements Event @doc(category: \"Checkout\") {\n+  \"\"\"Time of the event.\"\"\"\n+  issuedAt: DateTime\n+\n+  \"\"\"Saleor version that triggered the event.\"\"\"\n+  version: String\n+\n+  \"\"\"The user or application that triggered the event.\"\"\"\n+  issuingPrincipal: IssuingPrincipal\n+\n+  \"\"\"The application receiving the webhook.\"\"\"\n+  recipient: App\n+\n+  \"\"\"The checkout the event relates to.\"\"\"\n+  checkout: Checkout\n+}\n+\n \"\"\"Event sent when checkout metadata is updated.\"\"\"\n type CheckoutMetadataUpdated implements Event @doc(category: \"Checkout\") {\n   \"\"\"Time of the event.\"\"\"\n   issuedAt: DateTime\n"
        },
        {
          "path": "saleor/graphql/webhook/enums.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/enums.py\n===================================================================\n--- saleor/graphql/webhook/enums.py\tb357838 (parent)\n+++ saleor/graphql/webhook/enums.py\t3c5dcc4 (commit)\n@@ -25,10 +25,21 @@\n order_updated_event_enum_description = (\n     \"An order is updated; triggered for all changes related to an order; \"\n     \"covers all other order webhooks, except for ORDER_CREATED.\"\n )\n+checkout_fully_authorized_event_enum_description = (\n+    \"A checkout was fully authorized (its `authorizeStatus` is `FULL`).\"\n+    \"\\n\\nThis event is emitted only for checkouts whose payments are \"\n+    \"processed through the Transaction API.\"\n+)\n+checkout_fully_paid_event_enum_description = (\n+    \"A checkout was fully paid (its `chargeStatus` is `FULL` \"\n+    \"or `OVERCHARGED`). This event is not sent if payments are only authorized \"\n+    \"but not fully charged.\"\n+    \"\\n\\nThis event is emitted only for checkouts whose payments are processed\"\n+    \" through the Transaction API.\"\n+)\n \n-\n WEBHOOK_EVENT_DESCRIPTION = {\n     WebhookEventAsyncType.ACCOUNT_CONFIRMATION_REQUESTED: (\n         \"An account confirmation is requested.\"\n     ),\n@@ -64,8 +75,10 @@\n     WebhookEventAsyncType.CHANNEL_STATUS_CHANGED: \"A channel status is changed.\",\n     WebhookEventAsyncType.CHANNEL_METADATA_UPDATED: \"A channel metadata is updated.\",\n     WebhookEventAsyncType.CHECKOUT_CREATED: \"A new checkout is created.\",\n     WebhookEventAsyncType.CHECKOUT_UPDATED: checkout_updated_event_enum_description,\n+    WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED: checkout_fully_authorized_event_enum_description,\n+    WebhookEventAsyncType.CHECKOUT_FULLY_PAID: checkout_fully_paid_event_enum_description,\n     WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED: \"A checkout metadata is updated.\",\n     WebhookEventAsyncType.COLLECTION_CREATED: \"A new collection is created.\",\n     WebhookEventAsyncType.COLLECTION_UPDATED: \"A collection is updated.\",\n     WebhookEventAsyncType.COLLECTION_DELETED: \"A collection is deleted.\",\n"
        },
        {
          "path": "saleor/graphql/webhook/subscription_types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/subscription_types.py\n===================================================================\n--- saleor/graphql/webhook/subscription_types.py\tb357838 (parent)\n+++ saleor/graphql/webhook/subscription_types.py\t3c5dcc4 (commit)\n@@ -1505,16 +1505,30 @@\n         root_type = \"Checkout\"\n         enable_dry_run = True\n         interfaces = (Event,)\n         description = (\n-            \"Event sent when checkout is fully paid with transactions.\"\n-            \" The checkout is considered as fully paid when the checkout \"\n-            \"`charge_status` is `FULL` or `OVERCHARGED`. \"\n-            \"The event is not sent when the checkout authorization flow strategy \"\n-            \"is used.\"\n+            \"Event sent when a checkout was fully paid. A checkout is \"\n+            \"considered fully paid when its `chargeStatus` is `FULL` \"\n+            \"or `OVERCHARGED`. This event is not sent if payments are only \"\n+            \"authorized but not fully charged.\"\n+            \"\\n\\nIt is triggered only for checkouts whose payments are \"\n+            \"processed through the Transaction API.\"\n         )\n \n \n+class CheckoutFullyAuthorized(SubscriptionObjectType, CheckoutBase):\n+    class Meta:\n+        root_type = \"Checkout\"\n+        enable_dry_run = True\n+        interfaces = (Event,)\n+        description = (\n+            \"Event sent when a checkout was fully authorized. A checkout is \"\n+            \"considered fully authorized when its `authorizeStatus` is `FULL`.\"\n+            \"\\n\\nIt is triggered only for checkouts whose payments are processed through \"\n+            \"the Transaction API.\"\n+        )\n+\n+\n class CheckoutMetadataUpdated(SubscriptionObjectType, CheckoutBase):\n     class Meta:\n         root_type = \"Checkout\"\n         enable_dry_run = True\n@@ -2782,8 +2796,19 @@\n         resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_CHECKOUT,\n     )\n+    checkout_fully_authorized = BaseField(\n+        CheckoutFullyAuthorized,\n+        description=(\n+            \"Event sent when checkout is fully authorized.\"\n+            + ADDED_IN_321\n+            + PREVIEW_FEATURE\n+        ),\n+        resolver=default_channel_filterable_resolver,\n+        channels=channels_argument,\n+        doc_category=DOC_CATEGORY_CHECKOUT,\n+    )\n     checkout_metadata_updated = BaseField(\n         CheckoutMetadataUpdated,\n         description=(\n             \"Event sent when checkout metadata is updated.\"\n@@ -3006,8 +3031,9 @@\n     WebhookEventAsyncType.COLLECTION_DELETED: CollectionDeleted,\n     WebhookEventAsyncType.COLLECTION_METADATA_UPDATED: CollectionMetadataUpdated,\n     WebhookEventAsyncType.CHECKOUT_CREATED: CheckoutCreated,\n     WebhookEventAsyncType.CHECKOUT_UPDATED: CheckoutUpdated,\n+    WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED: CheckoutFullyAuthorized,\n     WebhookEventAsyncType.CHECKOUT_FULLY_PAID: CheckoutFullyPaid,\n     WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED: CheckoutMetadataUpdated,\n     WebhookEventAsyncType.PAGE_CREATED: PageCreated,\n     WebhookEventAsyncType.PAGE_UPDATED: PageUpdated,\n"
        },
        {
          "path": "saleor/payment/tests/test_utils/test_create_transaction_event_for_transaction_session.py",
          "status": "modified",
          "diff": "Index: saleor/payment/tests/test_utils/test_create_transaction_event_for_transaction_session.py\n===================================================================\n--- saleor/payment/tests/test_utils/test_create_transaction_event_for_transaction_session.py\tb357838 (parent)\n+++ saleor/payment/tests/test_utils/test_create_transaction_event_for_transaction_session.py\t3c5dcc4 (commit)\n@@ -915,9 +915,11 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_create_transaction_event_from_session_when_authorized_triggers_checkout_completion(\n+    mocked_checkout_fully_authorized,\n     mocked_checkout_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app,\n@@ -962,8 +964,9 @@\n     # then\n     checkout.refresh_from_db()\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_checkout_fully_paid.assert_not_called()\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_called_once_with(\n         checkout.pk, None, app.id\n     )\n \n"
        },
        {
          "path": "saleor/payment/tests/test_utils/test_utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/tests/test_utils/test_utils.py\n===================================================================\n--- saleor/payment/tests/test_utils/test_utils.py\tb357838 (parent)\n+++ saleor/payment/tests/test_utils/test_utils.py\t3c5dcc4 (commit)\n@@ -819,10 +819,12 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_create_transaction_event_from_request_when_paid(\n     mocked_checkout_fully_paid,\n+    mocked_checkout_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app,\n     checkout_with_prices,\n@@ -859,16 +861,19 @@\n     # then\n     checkout.refresh_from_db()\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n @patch.object(logger, \"error\")\n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_create_transaction_event_from_request_when_authorized_logs_warnning(\n     mocked_checkout_fully_paid,\n+    mocked_checkout_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     mocked_logger,\n     transaction_item_generator,\n     app,\n@@ -912,17 +917,20 @@\n     # be called for `AUTHORIZATION_REQUEST` event type\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.NONE\n     checkout.refresh_from_db()\n     mocked_checkout_fully_paid.assert_not_called()\n+    mocked_checkout_fully_authorized.assert_not_called()\n     mocked_automatic_checkout_completion_task.assert_not_called()\n     assert mocked_logger.call_count == 1\n     assert len(mocked_logger.call_args) == 2\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n+@patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_authorized\")\n def test_create_transaction_event_from_request_when_paid_triggers_checkout_completion(\n     mocked_checkout_fully_paid,\n+    mocked_checkout_fully_authorized,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app,\n     checkout_with_prices,\n@@ -966,8 +974,9 @@\n     # then\n     checkout.refresh_from_db()\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n+    mocked_checkout_fully_authorized.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_called_once_with(\n         checkout.pk, None, app.id\n     )\n \n"
        },
        {
          "path": "saleor/plugins/base_plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/base_plugin.py\n===================================================================\n--- saleor/plugins/base_plugin.py\tb357838 (parent)\n+++ saleor/plugins/base_plugin.py\t3c5dcc4 (commit)\n@@ -544,8 +544,17 @@\n     # Note: This method is deprecated and will be removed in a future release.\n     # Webhook-related functionality will be moved from the plugin to core modules.\n     checkout_fully_paid: Callable[[\"Checkout\", Any, None], Any]\n \n+    # Trigger when checkout is fully authorized with transactions.\n+    #\n+    # Overwrite this method if you need to trigger specific logic when a checkout is\n+    # updated.\n+    #\n+    # Note: This method is deprecated and will be removed in a future release.\n+    # Webhook-related functionality will be moved from the plugin to core modules.\n+    checkout_fully_authorized: Callable[[\"Checkout\", Any, None], Any]\n+\n     # Trigger when checkout metadata is updated.\n     #\n     # Overwrite this method if you need to trigger specific logic when a checkout\n     # metadata is updated.\n"
        },
        {
          "path": "saleor/plugins/manager.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/manager.py\n===================================================================\n--- saleor/plugins/manager.py\tb357838 (parent)\n+++ saleor/plugins/manager.py\t3c5dcc4 (commit)\n@@ -1365,8 +1365,20 @@\n         )\n \n     # Note: this method is deprecated and will be removed in a future release.\n     # Webhook-related functionality will be moved from plugin to core modules.\n+    def checkout_fully_authorized(self, checkout: \"Checkout\", webhooks=None):\n+        default_value = None\n+        return self.__run_method_on_plugins(\n+            \"checkout_fully_authorized\",\n+            default_value,\n+            checkout,\n+            channel_slug=checkout.channel.slug,\n+            webhooks=webhooks,\n+        )\n+\n+    # Note: this method is deprecated and will be removed in a future release.\n+    # Webhook-related functionality will be moved from plugin to core modules.\n     def checkout_fully_paid(self, checkout: \"Checkout\", webhooks=None):\n         default_value = None\n         return self.__run_method_on_plugins(\n             \"checkout_fully_paid\",\n"
        },
        {
          "path": "saleor/plugins/tests/sample_plugins.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/tests/sample_plugins.py\n===================================================================\n--- saleor/plugins/tests/sample_plugins.py\tb357838 (parent)\n+++ saleor/plugins/tests/sample_plugins.py\t3c5dcc4 (commit)\n@@ -338,8 +338,11 @@\n \n     def checkout_fully_paid(self, checkout, previous_value, webhooks):\n         return None\n \n+    def checkout_fully_authorized(self, checkout, previous_value, webhooks):\n+        return None\n+\n     def order_fully_refunded(self, order, previous_value, webhooks):\n         return None\n \n     def order_paid(self, order, previous_value):\n"
        },
        {
          "path": "saleor/plugins/tests/test_manager.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/tests/test_manager.py\n===================================================================\n--- saleor/plugins/tests/test_manager.py\tb357838 (parent)\n+++ saleor/plugins/tests/test_manager.py\t3c5dcc4 (commit)\n@@ -1275,8 +1275,28 @@\n         checkout, previous_value=None, webhooks=webhooks\n     )\n \n \n+@patch(\"saleor.plugins.tests.sample_plugins.PluginSample.checkout_fully_authorized\")\n+def test_checkout_fully_authorized(mocked_sample_method, checkout, webhook):\n+    # given\n+    plugins = [\n+        \"saleor.plugins.tests.sample_plugins.PluginSample\",\n+        \"saleor.plugins.tests.sample_plugins.PluginInactive\",\n+    ]\n+\n+    manager = PluginsManager(plugins=plugins)\n+    webhooks = {webhook}\n+\n+    # when\n+    manager.checkout_fully_authorized(checkout, webhooks=webhooks)\n+\n+    # then\n+    mocked_sample_method.assert_called_once_with(\n+        checkout, previous_value=None, webhooks=webhooks\n+    )\n+\n+\n @patch(\"saleor.plugins.tests.sample_plugins.PluginSample.order_fully_refunded\")\n def test_order_fully_refunded(mocked_sample_method, order, webhook):\n     # given\n     plugins = [\n"
        },
        {
          "path": "saleor/plugins/webhook/plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/plugin.py\n===================================================================\n--- saleor/plugins/webhook/plugin.py\tb357838 (parent)\n+++ saleor/plugins/webhook/plugin.py\t3c5dcc4 (commit)\n@@ -2122,8 +2122,33 @@\n                 queue=settings.CHECKOUT_WEBHOOK_EVENTS_CELERY_QUEUE_NAME,\n             )\n         return previous_value\n \n+    def checkout_fully_authorized(\n+        self, checkout: \"Checkout\", previous_value: None, webhooks=None\n+    ) -> None:\n+        if not self.active:\n+            return previous_value\n+        event_type = WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, checkout.channel.slug, webhooks\n+        ):\n+            checkout_data_generator = partial(\n+                generate_checkout_payload,\n+                checkout,\n+                self.requestor,\n+            )\n+            self.trigger_webhooks_async(\n+                None,\n+                event_type,\n+                webhooks,\n+                checkout,\n+                self.requestor,\n+                legacy_data_generator=checkout_data_generator,\n+                queue=settings.CHECKOUT_WEBHOOK_EVENTS_CELERY_QUEUE_NAME,\n+            )\n+        return previous_value\n+\n     def checkout_fully_paid(\n         self, checkout: \"Checkout\", previous_value: None, webhooks=None\n     ) -> None:\n         if not self.active:\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_authorized.py",
          "status": "added",
          "diff": "Index: saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_authorized.py\n===================================================================\n--- saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_authorized.py\tb357838 (parent)\n+++ saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_authorized.py\t3c5dcc4 (commit)\n@@ -0,0 +1,247 @@\n+import json\n+from unittest.mock import patch\n+\n+import graphene\n+from django.test import override_settings\n+\n+from ......core.models import EventDelivery\n+from ......graphql.webhook.subscription_query import SubscriptionQuery\n+from ......webhook.event_types import WebhookEventAsyncType\n+from .....manager import get_plugins_manager\n+\n+CHECKOUT_FULLY_AUTHORIZED_SUBSCRIPTION = \"\"\"\n+subscription {\n+  checkoutFullyAuthorized(channels: [\"%s\"]) {\n+    checkout {\n+      id\n+      token\n+      lines {\n+        id\n+        variant {\n+          id\n+        }\n+      }\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_fully_authorized(\n+    mocked_async, checkout_with_item, subscription_webhook, settings\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED\n+\n+    query = CHECKOUT_FULLY_AUTHORIZED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_fully_authorized(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutFullyAuthorized\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_fully_authorized_without_channels_input(\n+    mocked_async, checkout_with_item, subscription_webhook\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED\n+\n+    query = \"\"\"subscription {\n+      checkoutFullyAuthorized {\n+        checkout {\n+          id\n+          token\n+          lines {\n+            id\n+            variant {\n+              id\n+            }\n+          }\n+        }\n+      }\n+    }\"\"\"\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_fully_authorized(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutFullyAuthorized\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_fully_authorized_with_different_channel(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_JPY_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_JPY_with_item\n+    channel = checkout.channel\n+    assert channel.slug != settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED\n+\n+    query = CHECKOUT_FULLY_AUTHORIZED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_fully_authorized(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_different_event_doesnt_trigger_webhook(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+\n+    checkout = checkout_with_item\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = CHECKOUT_FULLY_AUTHORIZED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_fully_authorized(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/test_webhook.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/tests/test_webhook.py\n===================================================================\n--- saleor/plugins/webhook/tests/test_webhook.py\tb357838 (parent)\n+++ saleor/plugins/webhook/tests/test_webhook.py\t3c5dcc4 (commit)\n@@ -1268,10 +1268,44 @@\n         mocked_webhook_trigger.call_args.kwargs[\"legacy_data_generator\"], partial\n     )\n \n \n+@freeze_time(\"2014-06-28 10:50\")\n @mock.patch(\"saleor.plugins.webhook.plugin.get_webhooks_for_event\")\n @mock.patch(\"saleor.plugins.webhook.plugin.trigger_webhooks_async\")\n+def test_checkout_fully_authorized(\n+    mocked_webhook_trigger,\n+    mocked_get_webhooks_for_event,\n+    any_webhook,\n+    settings,\n+    checkout_with_items,\n+):\n+    # given\n+    mocked_get_webhooks_for_event.return_value = [any_webhook]\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    manager = get_plugins_manager(allow_replica=False)\n+\n+    # when\n+    manager.checkout_fully_authorized(checkout_with_items)\n+\n+    # then\n+    mocked_webhook_trigger.assert_called_once_with(\n+        None,\n+        WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED,\n+        [any_webhook],\n+        checkout_with_items,\n+        None,\n+        legacy_data_generator=ANY,\n+        allow_replica=False,\n+        queue=settings.CHECKOUT_WEBHOOK_EVENTS_CELERY_QUEUE_NAME,\n+    )\n+    assert isinstance(\n+        mocked_webhook_trigger.call_args.kwargs[\"legacy_data_generator\"], partial\n+    )\n+\n+\n+@mock.patch(\"saleor.plugins.webhook.plugin.get_webhooks_for_event\")\n+@mock.patch(\"saleor.plugins.webhook.plugin.trigger_webhooks_async\")\n def test_checkout_metadata_updated(\n     mocked_webhook_trigger,\n     mocked_get_webhooks_for_event,\n     any_webhook,\n"
        },
        {
          "path": "saleor/tests/fixtures.py",
          "status": "modified",
          "diff": "Index: saleor/tests/fixtures.py\n===================================================================\n--- saleor/tests/fixtures.py\tb357838 (parent)\n+++ saleor/tests/fixtures.py\t3c5dcc4 (commit)\n@@ -1238,8 +1238,9 @@\n     subscription_collection_deleted_webhook,\n     subscription_collection_metadata_updated_webhook,\n     subscription_checkout_created_webhook,\n     subscription_checkout_updated_webhook,\n+    subscription_checkout_fully_authorized_webhook,\n     subscription_checkout_fully_paid_webhook,\n     subscription_checkout_metadata_updated_webhook,\n     subscription_page_created_webhook,\n     subscription_page_updated_webhook,\n@@ -1526,8 +1527,12 @@\n         events.CHECKOUT_FULLY_PAID: [\n             subscription_checkout_fully_paid_webhook,\n             checkout,\n         ],\n+        events.CHECKOUT_FULLY_AUTHORIZED: [\n+            subscription_checkout_fully_authorized_webhook,\n+            checkout,\n+        ],\n         events.CHECKOUT_METADATA_UPDATED: [\n             subscription_checkout_metadata_updated_webhook,\n             checkout,\n         ],\n"
        },
        {
          "path": "saleor/webhook/event_types.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/event_types.py\n===================================================================\n--- saleor/webhook/event_types.py\tb357838 (parent)\n+++ saleor/webhook/event_types.py\t3c5dcc4 (commit)\n@@ -144,8 +144,9 @@\n     PRODUCT_VARIANT_STOCK_UPDATED = \"product_variant_stock_updated\"\n \n     CHECKOUT_CREATED = \"checkout_created\"\n     CHECKOUT_UPDATED = \"checkout_updated\"\n+    CHECKOUT_FULLY_AUTHORIZED = \"checkout_fully_authorized\"\n     CHECKOUT_FULLY_PAID = \"checkout_fully_paid\"\n     CHECKOUT_METADATA_UPDATED = \"checkout_metadata_updated\"\n \n     NOTIFY_USER = \"notify_user\"  # deprecated\n@@ -606,8 +607,12 @@\n             \"name\": \"Checkout updated\",\n             \"permission\": CheckoutPermissions.MANAGE_CHECKOUTS,\n             \"is_deferred_payload\": True,\n         },\n+        CHECKOUT_FULLY_AUTHORIZED: {\n+            \"name\": \"Checkout fully authorized\",\n+            \"permission\": CheckoutPermissions.MANAGE_CHECKOUTS,\n+        },\n         CHECKOUT_FULLY_PAID: {\n             \"name\": \"Checkout fully paid\",\n             \"permission\": CheckoutPermissions.MANAGE_CHECKOUTS,\n         },\n"
        },
        {
          "path": "saleor/webhook/tests/fixtures/subscription_webhooks.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/fixtures/subscription_webhooks.py\n===================================================================\n--- saleor/webhook/tests/fixtures/subscription_webhooks.py\tb357838 (parent)\n+++ saleor/webhook/tests/fixtures/subscription_webhooks.py\t3c5dcc4 (commit)\n@@ -811,8 +811,16 @@\n     )\n \n \n @pytest.fixture\n+def subscription_checkout_fully_authorized_webhook(subscription_webhook):\n+    return subscription_webhook(\n+        queries.CHECKOUT_FULLY_AUTHORIZED,\n+        WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED,\n+    )\n+\n+\n+@pytest.fixture\n def subscription_checkout_metadata_updated_webhook(subscription_webhook):\n     return subscription_webhook(\n         queries.CHECKOUT_METADATA_UPDATED,\n         WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED,\n"
        },
        {
          "path": "saleor/webhook/tests/fixtures/webhook.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/fixtures/webhook.py\n===================================================================\n--- saleor/webhook/tests/fixtures/webhook.py\tb357838 (parent)\n+++ saleor/webhook/tests/fixtures/webhook.py\t3c5dcc4 (commit)\n@@ -135,8 +135,16 @@\n           checkout {\n             ...CheckoutFragment\n           }\n         }\n+        ... on CheckoutFullyAuthorized {\n+          issuingPrincipal {\n+            ...IssuingPrincipal\n+          }\n+          checkout {\n+            ...CheckoutFragment\n+          }\n+        }\n         ... on CheckoutMetadataUpdated {\n           issuingPrincipal {\n             ...IssuingPrincipal\n           }\n"
        },
        {
          "path": "saleor/webhook/tests/subscription_webhooks/subscription_queries.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/subscription_webhooks/subscription_queries.py\n===================================================================\n--- saleor/webhook/tests/subscription_webhooks/subscription_queries.py\tb357838 (parent)\n+++ saleor/webhook/tests/subscription_webhooks/subscription_queries.py\t3c5dcc4 (commit)\n@@ -1803,8 +1803,20 @@\n       }\n     }\n \"\"\"\n \n+CHECKOUT_FULLY_AUTHORIZED = \"\"\"\n+    subscription{\n+      event{\n+        ...on CheckoutFullyAuthorized{\n+          checkout{\n+            id\n+          }\n+        }\n+      }\n+    }\n+\"\"\"\n+\n CHECKOUT_METADATA_UPDATED = \"\"\"\n     subscription{\n       event{\n         ...on CheckoutMetadataUpdated{\n"
        },
        {
          "path": "saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_subscription.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_subscription.py\n===================================================================\n--- saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_subscription.py\tb357838 (parent)\n+++ saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_subscription.py\t3c5dcc4 (commit)\n@@ -2177,8 +2177,27 @@\n     assert len(deliveries) == len(webhooks)\n     assert deliveries[0].webhook == webhooks[0]\n \n \n+def test_checkout_fully_authorized(\n+    checkout, subscription_checkout_fully_authorized_webhook\n+):\n+    # given\n+    webhooks = [subscription_checkout_fully_authorized_webhook]\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_AUTHORIZED\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    deliveries = create_deliveries_for_subscriptions(event_type, checkout, webhooks)\n+\n+    # then\n+    expected_payload = json.dumps({\"checkout\": {\"id\": checkout_id}})\n+\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert len(deliveries) == len(webhooks)\n+    assert deliveries[0].webhook == webhooks[0]\n+\n+\n def test_checkout_metadata_updated(\n     checkout, subscription_checkout_metadata_updated_webhook\n ):\n     webhooks = [subscription_checkout_metadata_updated_webhook]\n"
        }
      ]
    },
    {
      "id": "add-checkout-delivery",
      "sha": "92f6b3670e4d9f49855847d307eb74868142b6fb",
      "parentSha": "66b8f9b708ddffed35be0b1938fc730f46edd618",
      "spec": "Implement a new Checkout.delivery field and delivery-related checkout problems, wire them through GraphQL dataloaders, and update schema/descriptions.\n\n1) saleor/checkout/problems.py\n- Imports: Include Checkout and CheckoutDelivery from .models along with CheckoutLine.\n- New problem dataclasses: Define CheckoutProblemDeliveryMethodStale and CheckoutProblemDeliveryMethodInvalid, each containing a single field delivery: CheckoutDelivery.\n- Type aliases: Extend CHECKOUT_PROBLEM_TYPE to include the two new problem classes in addition to existing line-level problems.\n- get_checkout_problems signature and behavior:\n  - Change signature to accept checkout: Checkout and assigned_delivery: CheckoutDelivery | None, plus the existing checkout_lines_problem mapping and other inputs.\n  - Aggregate and include existing line-level problems from checkout_lines_problem.\n  - If assigned_delivery is None, return aggregated line problems.\n  - If checkout.delivery_methods_stale_at is set and is earlier than current UTC time (i.e., methods are stale), append CheckoutProblemDeliveryMethodStale with the assigned_delivery.\n  - If assigned_delivery.is_valid is False, append CheckoutProblemDeliveryMethodInvalid with the assigned_delivery.\n  - Return the resulting list of problems.\n\n2) saleor/graphql/checkout/dataloaders/problems.py\n- Imports: Import CheckoutDelivery and the dataloaders CheckoutDeliveryByIdLoader and CheckoutByTokenLoader.\n- CheckoutProblemsByCheckoutIdDataloader.batch_load:\n  - Load checkouts for keys using CheckoutByTokenLoader.\n  - Collect assigned_delivery_id values from loaded checkouts and batch-load those deliveries via CheckoutDeliveryByIdLoader.\n  - Also load line-level problems via the existing CheckoutLinesProblemsByCheckoutIdLoader.\n  - For each checkout, call get_checkout_problems(checkout, assigned_delivery_for_checkout, checkout_lines_problems) and map results by checkout primary key.\n  - Return the list of problems for each key in the same order as keys. Ensure the keys and dict mapping use the same type (UUID token) for correct lookups.\n\n3) saleor/graphql/checkout/types.py\n- Descriptions: Import and use ADDED_IN_323 in descriptions for new/specific fields and types.\n- New GraphQL object types:\n  - Delivery: GraphQL object with fields: id (global ID using type \"CheckoutDelivery\") and shippingMethod (returns ShippingMethod). Implement resolve_id to return the global ID for CheckoutDelivery; implement resolve_shipping_method using convert_checkout_delivery_to_shipping_method_data to expose stored delivery data (no webhook fetch).\n  - CheckoutProblemDeliveryMethodStale and CheckoutProblemDeliveryMethodInvalid: GraphQL object types that expose delivery: Delivery! and describe the condition (stale delivery methods / invalid selected delivery method). Use SyncWebhookControlContextObjectType as base to match existing problems’ pattern.\n- CheckoutProblem union:\n  - Extend the union to include the two new delivery-related problem types ahead of existing CheckoutLineProblem types.\n  - In resolve_type, return the respective type when the wrapped instance is CheckoutProblemDeliveryMethodStale or CheckoutProblemDeliveryMethodInvalid; otherwise delegate to line problem resolution and base behavior.\n- Checkout type additions/changes:\n  - Add delivery: Delivery field with description noting it’s added in 3.23. Implement resolver to return None when no assigned_delivery_id is set; otherwise load the CheckoutDelivery by ID using CheckoutDeliveryByIdLoader and return it (no webhook calls or filtering based on is_valid).\n  - Update deprecation reasons: shipping_method deprecation_reason should be “Use `delivery` instead.” and delivery_method deprecation_reason should be “Use `delivery` instead.”\n\n4) saleor/graphql/schema.graphql\n- Add a Delivery type definition with fields id: ID! and shippingMethod: ShippingMethod and description noting addition in 3.23.\n- In the Checkout type:\n  - Add the delivery: Delivery field with the appropriate description text indicating addition in Saleor 3.23.\n  - Update deprecation reasons: shippingMethod -> “Use `delivery` instead.” and deliveryMethod -> “Use `delivery` instead.”\n- Extend CheckoutProblem union to include CheckoutProblemDeliveryMethodStale and CheckoutProblemDeliveryMethodInvalid.\n- Add type definitions for CheckoutProblemDeliveryMethodStale and CheckoutProblemDeliveryMethodInvalid exposing delivery: Delivery! and appropriate descriptions.\n\n5) Tests (GraphQL behavior to verify)\n- Add tests that:\n  - Return delivery for checkouts with external and built-in shipping methods, asserting the delivery ID and that delivery.shippingMethod.name matches the underlying stored method (for external delivery, use the stored name; for built-in, the shipping method’s name).\n  - Ensure resolving checkout.delivery does not trigger any shipping-related webhooks, even when delivery_methods_stale_at is in the past; the field must read from cached/assigned delivery only.\n  - Verify Checkout.problems includes CheckoutProblemDeliveryMethodStale when delivery_methods_stale_at is in the past and an assigned delivery exists; includes CheckoutProblemDeliveryMethodInvalid when the assigned delivery has is_valid=False; and includes both when both conditions are met. When no assigned delivery exists, no delivery-related problems should be returned.\n\n6) Call-site updates\n- Ensure all calls to get_checkout_problems are updated to pass the new parameters (checkout and assigned_delivery). The only relevant call should be inside saleor/graphql/checkout/dataloaders/problems.py’s CheckoutProblemsByCheckoutIdDataloader.\n\nConstraints/Notes:\n- Do not trigger webhook calls in the Delivery field resolver; it should use the denormalized CheckoutDelivery data only.\n- Delivery.shippingMethod should reflect the stored data from CheckoutDelivery via convert_checkout_delivery_to_shipping_method_data, including active and message flags derived from the cached delivery.\n- Preserve existing dataloader context keys and batching behavior; maintain return order consistent with input keys.\n- Keep descriptions and deprecation messages exactly as specified for consistency with the schema and tests.",
      "prompt": "Add a new GraphQL field on Checkout that returns the selected delivery option and expose two new checkout problem variants related to delivery freshness and validity.\n\nRequirements:\n- Expose a Delivery object on Checkout with an ID and a nested shipping method based on the assigned delivery. This field must use cached/assigned delivery data and must not trigger any shipping webhooks.\n- Introduce and surface two new checkout problem types: one when delivery methods are stale for the checkout and one when the selected delivery has been marked invalid.\n- Ensure the problem computation includes both line-level problems and the new delivery-related problems when appropriate.\n- Update the problems dataloader to load the checkout and its assigned delivery and pass them to the problem computation.\n- Extend the GraphQL schema and union types accordingly and mark legacy fields as deprecated in favor of the new delivery field.\n- Add tests that validate reading the delivery field for both external and built-in shipping methods, that no webhooks are triggered while resolving it, and that the new checkout problems appear correctly when stale/invalid conditions occur.",
      "supplementalFiles": [
        "saleor/checkout/models.py",
        "saleor/shipping/utils.py",
        "saleor/graphql/checkout/dataloaders/checkout_delivery.py",
        "saleor/graphql/checkout/dataloaders/models.py",
        "saleor/graphql/checkout/dataloaders/checkout_infos.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/problems.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/problems.py\n===================================================================\n--- saleor/checkout/problems.py\t66b8f9b (parent)\n+++ saleor/checkout/problems.py\t92f6b36 (commit)\n@@ -6,9 +6,9 @@\n from ..graphql.core.context import ChannelContext\n from ..product.models import ProductChannelListing, ProductVariant\n from ..warehouse.models import Stock\n from .fetch import CheckoutInfo, CheckoutLineInfo\n-from .models import CheckoutLine\n+from .models import Checkout, CheckoutDelivery, CheckoutLine\n \n \n @dataclass\n class CheckoutLineProblemInsufficientStock:\n@@ -21,13 +21,26 @@\n class CheckoutLineProblemVariantNotAvailable:\n     line: CheckoutLine\n \n \n+@dataclass\n+class CheckoutProblemDeliveryMethodStale:\n+    delivery: CheckoutDelivery\n+\n+\n+@dataclass\n+class CheckoutProblemDeliveryMethodInvalid:\n+    delivery: CheckoutDelivery\n+\n+\n CHECKOUT_LINE_PROBLEM_TYPE = (\n     CheckoutLineProblemInsufficientStock | CheckoutLineProblemVariantNotAvailable\n )\n CHECKOUT_PROBLEM_TYPE = (\n-    CheckoutLineProblemInsufficientStock | CheckoutLineProblemVariantNotAvailable\n+    CheckoutLineProblemInsufficientStock\n+    | CheckoutLineProblemVariantNotAvailable\n+    | CheckoutProblemDeliveryMethodStale\n+    | CheckoutProblemDeliveryMethodInvalid\n )\n \n VARIANT_ID = int\n PRODUCT_ID = int\n@@ -178,8 +191,10 @@\n     return problems\n \n \n def get_checkout_problems(\n+    checkout: Checkout,\n+    assigned_delivery: CheckoutDelivery | None,\n     checkout_lines_problem: dict[\n         CHECKOUT_LINE_PK_TYPE, list[CHECKOUT_LINE_PROBLEM_TYPE]\n     ],\n ):\n@@ -189,8 +204,23 @@\n     for the given line. It returns a list of the problems with the checkout.\n \n     The stocks need to have annotated available_quantity field.\n     \"\"\"\n-    problems = []\n+    problems: list[CHECKOUT_PROBLEM_TYPE] = []\n     for line_problems in checkout_lines_problem.values():\n         problems.extend(line_problems)\n+\n+    if assigned_delivery is None:\n+        return problems\n+\n+    if (\n+        checkout.delivery_methods_stale_at\n+        and checkout.delivery_methods_stale_at < datetime.datetime.now(tz=datetime.UTC)\n+    ):\n+        problems.append(CheckoutProblemDeliveryMethodStale(delivery=assigned_delivery))\n+\n+    if assigned_delivery and not assigned_delivery.is_valid:\n+        problems.append(\n+            CheckoutProblemDeliveryMethodInvalid(delivery=assigned_delivery)\n+        )\n+\n     return problems\n"
        },
        {
          "path": "saleor/graphql/checkout/dataloaders/problems.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/dataloaders/problems.py\n===================================================================\n--- saleor/graphql/checkout/dataloaders/problems.py\t66b8f9b (parent)\n+++ saleor/graphql/checkout/dataloaders/problems.py\t92f6b36 (commit)\n@@ -2,8 +2,9 @@\n from collections.abc import Iterable\n \n from promise import Promise\n \n+from ....checkout.models import CheckoutDelivery\n from ....checkout.problems import (\n     CHANNEL_SLUG,\n     CHECKOUT_LINE_PROBLEM_TYPE,\n     CHECKOUT_PROBLEM_TYPE,\n@@ -21,12 +22,14 @@\n )\n from ...warehouse.dataloaders import (\n     StocksWithAvailableQuantityByProductVariantIdCountryCodeAndChannelLoader,\n )\n+from .checkout_delivery import CheckoutDeliveryByIdLoader\n from .checkout_infos import (\n     CheckoutInfoByCheckoutTokenLoader,\n     CheckoutLinesInfoByCheckoutTokenLoader,\n )\n+from .models import CheckoutByTokenLoader\n \n \n class CheckoutLinesProblemsByCheckoutIdLoader(\n     DataLoader[str, dict[str, list[CHECKOUT_LINE_PROBLEM_TYPE]]]\n@@ -138,20 +141,52 @@\n ):\n     context_key = \"checkout_problems_by_checkout_id\"\n \n     def batch_load(self, keys):\n-        line_problems_dataloader = CheckoutLinesProblemsByCheckoutIdLoader(self.context)\n-\n-        def _resolve_problems(\n-            checkouts_lines_problems: list[dict[str, list[CHECKOUT_LINE_PROBLEM_TYPE]]],\n-        ):\n-            checkout_problems = defaultdict(list)\n-            for checkout_pk, checkout_lines_problems in zip(\n-                keys, checkouts_lines_problems, strict=False\n+        def _with_assigned_delivery(checkouts):\n+            def _resolve_problems(\n+                data: tuple[\n+                    list[dict[str, list[CHECKOUT_LINE_PROBLEM_TYPE]]],\n+                    list[CheckoutDelivery | None],\n+                ],\n             ):\n-                checkout_problems[checkout_pk] = get_checkout_problems(\n-                    checkout_lines_problems\n-                )\n+                checkouts_lines_problems, checkouts_deliveries = data\n+                checkout_problems = defaultdict(list)\n+                checkout_delivery_map = {\n+                    delivery.pk: delivery\n+                    for delivery in checkouts_deliveries\n+                    if delivery\n+                }\n+                for checkout_lines_problems, checkout in zip(\n+                    checkouts_lines_problems,\n+                    checkouts,\n+                    strict=False,\n+                ):\n+                    checkout_problems[checkout.pk] = get_checkout_problems(\n+                        checkout,\n+                        checkout_delivery_map.get(checkout.assigned_delivery_id),\n+                        checkout_lines_problems,\n+                    )\n \n-            return [checkout_problems.get(key, []) for key in keys]\n+                return [checkout_problems.get(key, []) for key in keys]\n \n-        return line_problems_dataloader.load_many(keys).then(_resolve_problems)\n+            assigned_delivery_ids = [\n+                checkout.assigned_delivery_id\n+                for checkout in checkouts\n+                if checkout.assigned_delivery_id\n+            ]\n+            checkout_delivery_dataloader = CheckoutDeliveryByIdLoader(self.context)\n+            line_problems_dataloader = CheckoutLinesProblemsByCheckoutIdLoader(\n+                self.context\n+            )\n+            return Promise.all(\n+                [\n+                    line_problems_dataloader.load_many(keys),\n+                    checkout_delivery_dataloader.load_many(assigned_delivery_ids),\n+                ]\n+            ).then(_resolve_problems)\n+\n+        return (\n+            CheckoutByTokenLoader(self.context)\n+            .load_many(keys)\n+            .then(_with_assigned_delivery)\n+        )\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkout.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkout.py\t66b8f9b (parent)\n+++ saleor/graphql/checkout/tests/test_checkout.py\t92f6b36 (commit)\n@@ -5203,4 +5203,199 @@\n     assert checkout.price_expiration == expected_price_expiration\n     assert content[\"data\"][\"checkout\"][\"shippingMethod\"][\"id\"] == to_global_id_or_none(\n         shipping_method\n     )\n+\n+\n+def test_checkout_delivery_returns_external_shipping_methods(\n+    user_api_client, checkout_with_delivery_method_for_external_shipping\n+):\n+    # given\n+    checkout = checkout_with_delivery_method_for_external_shipping\n+    delivery = checkout.assigned_delivery\n+\n+    query = \"\"\"\n+    query getCheckout($id: ID) {\n+        checkout(id: $id) {\n+            delivery {\n+                id\n+                shippingMethod {\n+                    id\n+                    name\n+                }\n+            }\n+        }\n+    }\n+    \"\"\"\n+    variables = {\"id\": to_global_id_or_none(checkout)}\n+\n+    # when\n+    response = user_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkout\"][\"delivery\"]\n+    assert data is not None\n+    assert data[\"id\"] == to_global_id_or_none(delivery)\n+    assert data[\"shippingMethod\"][\"name\"] == delivery.name\n+\n+\n+def test_checkout_delivery_returns_built_in_shipping_methods(\n+    user_api_client, checkout_with_item, checkout_delivery, shipping_method, address\n+):\n+    # given\n+    checkout = checkout_with_item\n+    checkout.shipping_address = address\n+    checkout.assigned_delivery = checkout_delivery(checkout, shipping_method)\n+    checkout.save()\n+\n+    delivery = checkout.assigned_delivery\n+\n+    query = \"\"\"\n+    query getCheckout($id: ID) {\n+        checkout(id: $id) {\n+            delivery {\n+                id\n+                shippingMethod {\n+                    id\n+                    name\n+                }\n+            }\n+        }\n+    }\n+    \"\"\"\n+    variables = {\"id\": to_global_id_or_none(checkout)}\n+\n+    # when\n+    response = user_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkout\"][\"delivery\"]\n+    assert data is not None\n+    assert data[\"id\"] == to_global_id_or_none(delivery)\n+    assert data[\"shippingMethod\"][\"name\"] == shipping_method.name\n+\n+\n+def test_checkout_delivery_returns_none_when_no_delivery_assigned(\n+    user_api_client, checkout_with_item\n+):\n+    # given\n+    checkout = checkout_with_item\n+    assert checkout.assigned_delivery_id is None\n+\n+    query = \"\"\"\n+    query getCheckout($id: ID) {\n+        checkout(id: $id) {\n+            delivery {\n+                id\n+                shippingMethod {\n+                    id\n+                    name\n+                }\n+            }\n+        }\n+    }\n+    \"\"\"\n+    variables = {\"id\": to_global_id_or_none(checkout)}\n+\n+    # when\n+    response = user_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"checkout\"][\"delivery\"] is None\n+\n+\n+@freezegun.freeze_time(\"2023-01-01 12:00:00\")\n+@mock.patch(\n+    \"saleor.plugins.webhook.plugin.WebhookPlugin.get_shipping_methods_for_checkout\"\n+)\n+@override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n+def test_checkout_delivery_do_not_trigger_any_webhook_calls(\n+    mocked_shipping_webhook_fetch,\n+    user_api_client,\n+    checkout_with_item,\n+    checkout_delivery,\n+    shipping_method,\n+    address,\n+):\n+    # given\n+    checkout = checkout_with_item\n+    checkout.shipping_address = address\n+    checkout.assigned_delivery = checkout_delivery(checkout, shipping_method)\n+    checkout.delivery_methods_stale_at = timezone.now()\n+    checkout.save()\n+\n+    query = \"\"\"\n+    query getCheckout($id: ID) {\n+        checkout(id: $id) {\n+            delivery {\n+                id\n+                shippingMethod {\n+                    id\n+                    name\n+                }\n+            }\n+        }\n+    }\n+    \"\"\"\n+    variables = {\"id\": to_global_id_or_none(checkout)}\n+\n+    # when\n+    response = user_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"checkout\"][\"delivery\"] is not None\n+    # Ensure no webhook was triggered\n+    mocked_shipping_webhook_fetch.assert_not_called()\n+\n+\n+@mock.patch(\n+    \"saleor.plugins.webhook.plugin.WebhookPlugin.get_shipping_methods_for_checkout\"\n+)\n+def test_checkout_delivery_returns_shipping_when_marked_as_invalid(\n+    mocked_shipping_webhook_fetch,\n+    user_api_client,\n+    checkout_with_item,\n+    checkout_delivery,\n+    shipping_method,\n+    address,\n+):\n+    # given\n+    checkout = checkout_with_item\n+    checkout.shipping_address = address\n+    checkout.assigned_delivery = checkout_delivery(checkout, shipping_method)\n+    checkout.save()\n+\n+    delivery = checkout.assigned_delivery\n+    # Mark the delivery as invalid\n+    delivery.is_valid = False\n+    delivery.save(update_fields=[\"is_valid\"])\n+\n+    query = \"\"\"\n+    query getCheckout($id: ID) {\n+        checkout(id: $id) {\n+            delivery {\n+                id\n+                shippingMethod {\n+                    id\n+                    name\n+                }\n+            }\n+        }\n+    }\n+    \"\"\"\n+    variables = {\"id\": to_global_id_or_none(checkout)}\n+\n+    # when\n+    response = user_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkout\"][\"delivery\"]\n+    # The delivery field should still return the delivery object even when marked as invalid\n+    assert data is not None\n+    assert data[\"id\"] == to_global_id_or_none(delivery)\n+    assert data[\"shippingMethod\"][\"name\"] == shipping_method.name\n+    mocked_shipping_webhook_fetch.assert_not_called()\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkout_problems.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkout_problems.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkout_problems.py\t66b8f9b (parent)\n+++ saleor/graphql/checkout/tests/test_checkout_problems.py\t92f6b36 (commit)\n@@ -1,7 +1,8 @@\n import datetime\n \n from django.utils import timezone\n+from freezegun import freeze_time\n \n from ....product.models import ProductChannelListing, ProductVariantChannelListing\n from ....warehouse.models import Allocation, Reservation\n from ...core.utils import to_global_id_or_none\n@@ -26,8 +27,20 @@\n         line{\n           id\n         }\n       }\n+      ... on CheckoutProblemDeliveryMethodStale{\n+        __typename\n+        delivery {\n+            id\n+        }\n+      }\n+      ... on CheckoutProblemDeliveryMethodInvalid{\n+        __typename\n+        delivery {\n+            id\n+        }\n+      }\n     }\n   }\n }\n \"\"\"\n@@ -420,4 +433,109 @@\n     )\n     assert content[\"data\"][\"checkout\"][\"problems\"][0][\"line\"][\n         \"id\"\n     ] == to_global_id_or_none(checkout_line)\n+\n+\n+@freeze_time(\"2024-05-31 12:00:01\")\n+def test_checkout_problems_delivery_method_stale(\n+    checkout_with_items_and_shipping, api_client\n+):\n+    # given\n+    checkout = checkout_with_items_and_shipping\n+    checkout.delivery_methods_stale_at = timezone.now() - datetime.timedelta(minutes=5)\n+    checkout.save(update_fields=[\"delivery_methods_stale_at\"])\n+\n+    checkout_id = to_global_id_or_none(checkout)\n+    variables = {\"id\": checkout_id, \"channel\": checkout.channel.slug}\n+\n+    # when\n+    response = api_client.post_graphql(QUERY_CHECKOUT_WITH_PROBLEMS, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"checkout\"][\"id\"] == checkout_id\n+    assert len(content[\"data\"][\"checkout\"][\"problems\"]) == 1\n+    problem = content[\"data\"][\"checkout\"][\"problems\"][0]\n+    assert problem[\"__typename\"] == \"CheckoutProblemDeliveryMethodStale\"\n+    assert problem[\"delivery\"][\"id\"] == to_global_id_or_none(checkout.assigned_delivery)\n+\n+\n+@freeze_time(\"2024-05-31 12:00:01\")\n+def test_checkout_problems_delivery_method_invalid(\n+    checkout_with_items_and_shipping, api_client\n+):\n+    # given\n+    checkout = checkout_with_items_and_shipping\n+    checkout.assigned_delivery.is_valid = False\n+    checkout.assigned_delivery.save(update_fields=[\"is_valid\"])\n+\n+    checkout_id = to_global_id_or_none(checkout)\n+    variables = {\"id\": checkout_id, \"channel\": checkout.channel.slug}\n+\n+    # when\n+    response = api_client.post_graphql(QUERY_CHECKOUT_WITH_PROBLEMS, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"checkout\"][\"id\"] == checkout_id\n+    assert len(content[\"data\"][\"checkout\"][\"problems\"]) == 1\n+    problem = content[\"data\"][\"checkout\"][\"problems\"][0]\n+    assert problem[\"__typename\"] == \"CheckoutProblemDeliveryMethodInvalid\"\n+    assert problem[\"delivery\"][\"id\"] == to_global_id_or_none(checkout.assigned_delivery)\n+\n+\n+@freeze_time(\"2024-05-31 12:00:01\")\n+def test_checkout_problems_delivery_method_stale_and_invalid(\n+    checkout_with_items_and_shipping, api_client\n+):\n+    # given\n+    checkout = checkout_with_items_and_shipping\n+    checkout.assigned_delivery.is_valid = False\n+    checkout.assigned_delivery.save(\n+        update_fields=[\n+            \"is_valid\",\n+        ]\n+    )\n+    checkout.delivery_methods_stale_at = timezone.now() - datetime.timedelta(minutes=5)\n+    checkout.save(update_fields=[\"delivery_methods_stale_at\"])\n+\n+    checkout_id = to_global_id_or_none(checkout)\n+    variables = {\"id\": checkout_id, \"channel\": checkout.channel.slug}\n+\n+    # when\n+    response = api_client.post_graphql(QUERY_CHECKOUT_WITH_PROBLEMS, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"checkout\"][\"id\"] == checkout_id\n+    assert len(content[\"data\"][\"checkout\"][\"problems\"]) == 2\n+    problems = content[\"data\"][\"checkout\"][\"problems\"]\n+    problem_types = [problem[\"__typename\"] for problem in problems]\n+    assert \"CheckoutProblemDeliveryMethodStale\" in problem_types\n+    assert \"CheckoutProblemDeliveryMethodInvalid\" in problem_types\n+\n+    assigned_delivery_id = to_global_id_or_none(checkout.assigned_delivery)\n+    assert problems[0][\"delivery\"][\"id\"] == assigned_delivery_id\n+    assert problems[1][\"delivery\"][\"id\"] == assigned_delivery_id\n+\n+\n+@freeze_time(\"2024-05-31 12:00:01\")\n+def test_checkout_problems_without_delivery_method(\n+    checkout_with_items_and_shipping, api_client\n+):\n+    # given\n+    checkout = checkout_with_items_and_shipping\n+    checkout.assigned_delivery = None\n+    checkout.delivery_methods_stale_at = timezone.now() - datetime.timedelta(minutes=5)\n+    checkout.save(update_fields=[\"delivery_methods_stale_at\", \"assigned_delivery\"])\n+\n+    checkout_id = to_global_id_or_none(checkout)\n+    variables = {\"id\": checkout_id, \"channel\": checkout.channel.slug}\n+\n+    # when\n+    response = api_client.post_graphql(QUERY_CHECKOUT_WITH_PROBLEMS, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"checkout\"][\"id\"] == checkout_id\n+    assert len(content[\"data\"][\"checkout\"][\"problems\"]) == 0\n"
        },
        {
          "path": "saleor/graphql/checkout/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/types.py\n===================================================================\n--- saleor/graphql/checkout/types.py\t66b8f9b (parent)\n+++ saleor/graphql/checkout/types.py\t92f6b36 (commit)\n@@ -47,8 +47,9 @@\n from ..core.descriptions import (\n     ADDED_IN_318,\n     ADDED_IN_319,\n     ADDED_IN_321,\n+    ADDED_IN_323,\n     PREVIEW_FEATURE,\n )\n from ..core.doc_category import DOC_CATEGORY_CHECKOUT\n from ..core.enums import LanguageCodeEnum\n@@ -240,8 +241,32 @@\n         return CheckoutLineProblemVariantNotAvailable\n     return None\n \n \n+class CheckoutProblemDeliveryMethodStale(\n+    SyncWebhookControlContextObjectType[problems.CheckoutProblemDeliveryMethodStale]\n+):\n+    delivery = graphene.Field(\"saleor.graphql.checkout.types.Delivery\", required=True)\n+\n+    class Meta:\n+        default_resolver = SyncWebhookControlContextObjectType.resolver_with_context\n+        description = \"Indicates that the delivery methods are stale.\" + ADDED_IN_323\n+        doc_category = DOC_CATEGORY_CHECKOUT\n+\n+\n+class CheckoutProblemDeliveryMethodInvalid(\n+    SyncWebhookControlContextObjectType[problems.CheckoutProblemDeliveryMethodInvalid]\n+):\n+    delivery = graphene.Field(\"saleor.graphql.checkout.types.Delivery\", required=True)\n+\n+    class Meta:\n+        default_resolver = SyncWebhookControlContextObjectType.resolver_with_context\n+        description = (\n+            \"Indicates that the selected delivery method is invalid.\" + ADDED_IN_323\n+        )\n+        doc_category = DOC_CATEGORY_CHECKOUT\n+\n+\n class CheckoutLineProblem(graphene.Union):\n     class Meta:\n         types = (\n             CheckoutLineProblemInsufficientStock,\n@@ -263,9 +288,12 @@\n \n \n class CheckoutProblem(graphene.Union):\n     class Meta:\n-        types = [] + list(CheckoutLineProblem._meta.types)\n+        types = [\n+            CheckoutProblemDeliveryMethodStale,\n+            CheckoutProblemDeliveryMethodInvalid,\n+        ] + list(CheckoutLineProblem._meta.types)\n         description = \"Represents an problem in the checkout.\"\n         doc_category = DOC_CATEGORY_CHECKOUT\n \n     @classmethod\n@@ -276,8 +304,15 @@\n     ):\n         line_problem_type = _resolve_line_problem_type(instance)\n         if line_problem_type:\n             return line_problem_type\n+\n+        problem_instance = instance.node\n+        if isinstance(problem_instance, problems.CheckoutProblemDeliveryMethodStale):\n+            return CheckoutProblemDeliveryMethodStale\n+        if isinstance(problem_instance, problems.CheckoutProblemDeliveryMethodInvalid):\n+            return CheckoutProblemDeliveryMethodInvalid\n+\n         return super().resolve_type(instance.node, info)\n \n \n class CheckoutLine(SyncWebhookControlContextModelObjectType[models.CheckoutLine]):\n@@ -625,8 +660,28 @@\n \n         return super().resolve_type(instance, info)\n \n \n+class Delivery(graphene.ObjectType):\n+    id = graphene.ID(required=True, description=\"The ID of the delivery.\")\n+    shipping_method = graphene.Field(\n+        ShippingMethod,\n+        description=\"Shipping method represented by the delivery.\",\n+    )\n+\n+    class Meta:\n+        description = \"Represents a delivery option for the checkout.\" + ADDED_IN_323\n+        doc_category = DOC_CATEGORY_CHECKOUT\n+\n+    def resolve_id(root: models.CheckoutDelivery, info: ResolveInfo) -> str:\n+        return graphene.Node.to_global_id(\"CheckoutDelivery\", root.pk)\n+\n+    def resolve_shipping_method(\n+        root: models.CheckoutDelivery, _info: ResolveInfo\n+    ) -> ShippingMethodData | None:\n+        return convert_checkout_delivery_to_shipping_method_data(root)\n+\n+\n def _should_load_denormalized_checkout_deliveries(\n     checkout_context: SyncWebhookControlContext[models.Checkout],\n ):\n     return not checkout_context.allow_sync_webhooks or (\n@@ -925,12 +980,17 @@\n                 description=CHECKOUT_CALCULATE_TAXES_MESSAGE,\n             ),\n         ],\n     )\n+    delivery = BaseField(\n+        Delivery,\n+        description=\"The delivery method selected for this checkout.\" + ADDED_IN_323,\n+    )\n+\n     shipping_method = BaseField(\n         ShippingMethod,\n         description=\"The shipping method related with checkout.\",\n-        deprecation_reason=\"Use `deliveryMethod` instead.\",\n+        deprecation_reason=\"Use `delivery` instead.\",\n         webhook_events_info=[\n             WebhookEventInfo(\n                 type=WebhookEventSyncType.SHIPPING_LIST_METHODS_FOR_CHECKOUT,\n                 description=(\n@@ -949,8 +1009,9 @@\n     )\n     delivery_method = BaseField(\n         DeliveryMethod,\n         description=\"The delivery method selected for this checkout.\",\n+        deprecation_reason=\"Use `delivery` instead.\",\n         webhook_events_info=[\n             WebhookEventInfo(\n                 type=WebhookEventSyncType.SHIPPING_LIST_METHODS_FOR_CHECKOUT,\n                 description=(\n@@ -1155,8 +1216,19 @@\n \n         return _resolve_checkout_delivery(root, info)\n \n     @staticmethod\n+    def resolve_delivery(\n+        root: SyncWebhookControlContext[models.Checkout], info: ResolveInfo\n+    ):\n+        if not root.node.assigned_delivery_id:\n+            return None\n+\n+        return CheckoutDeliveryByIdLoader(info.context).load(\n+            root.node.assigned_delivery_id\n+        )\n+\n+    @staticmethod\n     def resolve_quantity(\n         root: SyncWebhookControlContext[models.Checkout], info: ResolveInfo\n     ):\n         checkout_info = CheckoutLinesInfoByCheckoutTokenLoader(info.context).load(\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\t66b8f9b (parent)\n+++ saleor/graphql/schema.graphql\t92f6b36 (commit)\n@@ -10619,24 +10619,31 @@\n   \"\"\"\n   shippingPrice: TaxedMoney! @webhookEventsInfo(asyncEvents: [], syncEvents: [CHECKOUT_CALCULATE_TAXES])\n \n   \"\"\"\n+  The delivery method selected for this checkout.\n+  \n+  Added in Saleor 3.23.\n+  \"\"\"\n+  delivery: Delivery\n+\n+  \"\"\"\n   The shipping method related with checkout.\n   \n   Triggers the following webhook events:\n   - SHIPPING_LIST_METHODS_FOR_CHECKOUT (sync): Optionally triggered when cached external shipping methods are invalid.\n   - CHECKOUT_FILTER_SHIPPING_METHODS (sync): Optionally triggered when cached filtered shipping methods are invalid.\n   \"\"\"\n-  shippingMethod: ShippingMethod @webhookEventsInfo(asyncEvents: [], syncEvents: [SHIPPING_LIST_METHODS_FOR_CHECKOUT, CHECKOUT_FILTER_SHIPPING_METHODS]) @deprecated(reason: \"Use `deliveryMethod` instead.\")\n+  shippingMethod: ShippingMethod @webhookEventsInfo(asyncEvents: [], syncEvents: [SHIPPING_LIST_METHODS_FOR_CHECKOUT, CHECKOUT_FILTER_SHIPPING_METHODS]) @deprecated(reason: \"Use `delivery` instead.\")\n \n   \"\"\"\n   The delivery method selected for this checkout.\n   \n   Triggers the following webhook events:\n   - SHIPPING_LIST_METHODS_FOR_CHECKOUT (sync): Optionally triggered when cached external shipping methods are invalid.\n   - CHECKOUT_FILTER_SHIPPING_METHODS (sync): Optionally triggered when cached filtered shipping methods are invalid.\n   \"\"\"\n-  deliveryMethod: DeliveryMethod @webhookEventsInfo(asyncEvents: [], syncEvents: [SHIPPING_LIST_METHODS_FOR_CHECKOUT, CHECKOUT_FILTER_SHIPPING_METHODS])\n+  deliveryMethod: DeliveryMethod @webhookEventsInfo(asyncEvents: [], syncEvents: [SHIPPING_LIST_METHODS_FOR_CHECKOUT, CHECKOUT_FILTER_SHIPPING_METHODS]) @deprecated(reason: \"Use `delivery` instead.\")\n \n   \"\"\"\n   The price of the checkout before shipping, with taxes included.\n   \n@@ -11034,8 +11041,21 @@\n   line: CheckoutLine!\n }\n \n \"\"\"\n+Represents a delivery option for the checkout.\n+\n+Added in Saleor 3.23.\n+\"\"\"\n+type Delivery {\n+  \"\"\"The ID of the delivery.\"\"\"\n+  id: ID!\n+\n+  \"\"\"Shipping method represented by the delivery.\"\"\"\n+  shippingMethod: ShippingMethod\n+}\n+\n+\"\"\"\n Represents a delivery method chosen for the checkout. `Warehouse` type is used when checkout is marked as \"click and collect\" and `ShippingMethod` otherwise.\n \"\"\"\n union DeliveryMethod = Warehouse | ShippingMethod\n \n@@ -12739,10 +12759,28 @@\n   INTERACTIVE\n }\n \n \"\"\"Represents an problem in the checkout.\"\"\"\n-union CheckoutProblem = CheckoutLineProblemInsufficientStock | CheckoutLineProblemVariantNotAvailable\n+union CheckoutProblem = CheckoutProblemDeliveryMethodStale | CheckoutProblemDeliveryMethodInvalid | CheckoutLineProblemInsufficientStock | CheckoutLineProblemVariantNotAvailable\n \n+\"\"\"\n+Indicates that the delivery methods are stale.\n+\n+Added in Saleor 3.23.\n+\"\"\"\n+type CheckoutProblemDeliveryMethodStale @doc(category: \"Checkout\") {\n+  delivery: Delivery!\n+}\n+\n+\"\"\"\n+Indicates that the selected delivery method is invalid.\n+\n+Added in Saleor 3.23.\n+\"\"\"\n+type CheckoutProblemDeliveryMethodInvalid @doc(category: \"Checkout\") {\n+  delivery: Delivery!\n+}\n+\n type CheckoutCountableConnection @doc(category: \"Checkout\") {\n   \"\"\"Pagination data for this connection.\"\"\"\n   pageInfo: PageInfo!\n   edges: [CheckoutCountableEdge!]!\n"
        }
      ]
    },
    {
      "id": "add-page-attr-filter",
      "sha": "01138c1e4e6fd014ee214cb048f03560a302df5e",
      "parentSha": "f50682afab6aeb2438d8073f00cf26e099a13097",
      "spec": "Implement where-filtering of pages by associated attributes and update schema, tests, and changelog accordingly.\n\nScope\n- Extend the pages where-input to accept an \"attributes\" filter array. Support filtering by:\n  - Attribute existence (provide only attribute slug)\n  - Attribute value slug/name (eq/oneOf)\n  - Numeric values (eq/oneOf/range)\n  - Boolean values (True/False)\n  - Date values (range on date portion of date_time)\n  - DateTime values (range)\n- Validate input for duplicates, empty or multiple value keys, and ensure type-specific value keys match the attribute input type.\n\nFiles and required changes\n1) saleor/graphql/page/filters.py\n- Add imports: Exists, FloatField, OuterRef, Cast, GraphQLError; AttributeInputType; AssignedPageAttributeValue, Attribute, AttributeValue; BaseInputObjectType, DateRangeInput, DateTimeRangeInput; ListObjectTypeWhereFilter; DecimalFilterInput; filter_range_field; filter_where_by_numeric_field.\n- Define helper functions for attribute filtering:\n  - filter_by_slug_or_name(attr_id, attr_value, db): Returns Q(Exists(...)) matching AttributeValue.slug/name by eq/oneOf and AssignedPageAttributeValue by page.\n  - filter_by_numeric_attribute(attr_id, numeric_value, db): Cast AttributeValue.name to float and filter by eq/oneOf/range; wrap in Exists on AssignedPageAttributeValue.\n  - filter_by_boolean_attribute(attr_id, boolean_value, db): Filter AttributeValue.boolean and wrap in Exists.\n  - filter_by_date_attribute(attr_id, date_value, db): Filter AttributeValue.date_time__date with gte/lte and wrap in Exists.\n  - filter_by_date_time_attribute(attr_id, date_time_value, db): Filter AttributeValue.date_time with gte/lte and wrap in Exists.\n- Define filter_pages_by_attributes(qs, value):\n  - Resolve provided attribute slugs to Attribute records; if any slug is unknown, return qs.none().\n  - Support entries without \"value\": filter pages that have any value assigned for those attributes via Exists, OR’ed into the overall expression and AND’ed with other value-specific filters.\n  - For value-specific entries, dispatch per attribute.input_type or slug/name presence and AND all conditions.\n  - Apply the combined Q expression to qs or return qs.none() if no expression was built.\n- Define validate_attribute_value_input(attributes, db):\n  - Reject duplicate attribute slugs.\n  - If a \"value\" key is present but empty or None, raise GraphQLError.\n  - Reject entries where \"value\" contains more than one key (e.g., both slug and name); raise GraphQLError.\n  - For type-specific keys (numeric/date/date_time/boolean), ensure the attribute’s input_type matches; collect mismatches and raise GraphQLError.\n  - Error messages must match the expectations: \n    - Duplicates: \"Duplicated attribute slugs in attribute 'where' input are not allowed.\"\n    - Empty/null value: \"Incorrect input for attributes with slugs: <comma-separated>. Provided 'value' cannot be empty or null.\"\n    - Multiple keys: \"Incorrect input for attributes with slugs: <comma-separated>. Provided 'value' must have only one input key.\"\n    - Type mismatch: \"Incorrect input for attributes with slugs: <comma-separated>. Provided 'value' do not match the attribute input type.\"\n- Define input shapes for the new where inputs:\n  - class AttributeValuePageInput(BaseInputObjectType): fields slug (StringFilterInput), name (StringFilterInput), numeric (DecimalFilterInput), date (DateRangeInput), date_time (DateTimeRangeInput), boolean (Boolean).\n  - class AttributePageWhereInput(BaseInputObjectType): fields slug (String, required), value (AttributeValuePageInput, optional; exactly one of its fields must be provided if present).\n- Extend PageWhere to add:\n  - attributes = ListObjectTypeWhereFilter(input_class=AttributePageWhereInput, method=\"filter_attributes\", help_text=\"Filter by attributes associated with the page.\")\n  - filter_attributes(qs, _, value): if value present, return filter_pages_by_attributes(qs, value); else return qs.\n  - Override is_valid to call validate_attribute_value_input on provided attributes prior to super().is_valid().\n\n2) saleor/graphql/schema.graphql\n- Update PageWhereInput to include:\n  - attributes: [AttributePageWhereInput!] with description \"Filter by attributes associated with the page.\"\n- Add definitions:\n  - input AttributePageWhereInput { slug: String!; value: AttributeValuePageInput }\n  - input AttributeValuePageInput { slug: StringFilterInput; name: StringFilterInput; numeric: DecimalFilterInput; date: DateRangeInput; dateTime: DateTimeRangeInput; boolean: Boolean }\n  - Ensure dateTime uses camelCase in SDL (Graphene will map from date_time in Python).\n\n3) saleor/graphql/page/tests/queries/test_pages_with_where.py\n- Add tests to cover new behavior, including but not limited to:\n  - Filtering by attribute slug (returns pages that have any value for the attribute assigned).\n  - Filtering by attribute value slug eq and oneOf; name eq and oneOf.\n  - Numeric values via both numeric (eq, oneOf, range) and string-based slug/name equality; set attribute type to PAGE_TYPE and associate to page type before assignments.\n  - Date values via date range (gte/lte) and name/slug equality; ensure date_time on AttributeValue reflects dates; set attribute.type = PAGE_TYPE.\n  - DateTime values via dateTime range (gte/lte) and name/slug equality; set attribute.type = PAGE_TYPE.\n  - Boolean attribute filtering via boolean true/false and name/slug equality of the true value; set attribute.type = PAGE_TYPE.\n  - Validation failures: duplicated attribute slugs; empty/None value; multiple keys in value; type-mismatch (e.g., boolean provided to numeric attribute). Assert GraphQLError and null data.\n  - Non-matching cases: unknown attribute slug; known attribute with value that doesn’t exist; numeric out-of-range; boolean with no matching records; mixed list where one attr doesn’t exist should yield zero results, not errors.\n  - Multiple attribute filters combined should AND conditions across attributes and return the expected count.\n- Reuse existing helper utilities (associate_attribute_values_to_instance) and fixtures from the test suite. Ensure variable names and GraphQL input naming match the schema (e.g., dateTime, value, slug).\n\n4) CHANGELOG.md\n- Add a bullet under the GraphQL query changes section: \"Add support for filtering `pages` by associated attributes\" and maintain adjacent formatting as in the diff (preserve spacing/blank lines).\n\nBehavioral notes\n- When any provided attribute slug does not exist in the DB, return an empty queryset rather than raising an error.\n- For entries without a \"value\" block, match pages having at least one value assigned for the given attribute.\n- All provided attribute filters in the list are combined with logical AND at the page level.\n- Where-input operators behave as existing core operators: eq matches exact value; oneOf matches any in list; range supports gte/lte; boolean is a simple boolean.\n\nPerformance constraints\n- Use Exists/OuterRef subqueries for attribute value assignment checks to avoid joins and keep DB-side evaluation.\n- For numeric comparison, annotate and cast AttributeValue.name to Float for filter evaluation.\n\nDocumentation and typing\n- Match GraphQL descriptions from the product analogs where appropriate.\n- Ensure field names align with Graphene’s snake_case to camelCase mapping (e.g., date_time -> dateTime in SDL/tests).\n",
      "prompt": "Add support for filtering pages by their associated attributes in the pages where-input. Extend the pages GraphQL where filter to accept a list of attribute conditions that can match by attribute slug alone (existence) or by a single value field, supporting string (slug/name), numeric (with eq/oneOf/range), boolean, date (range), and dateTime (range). Combine multiple attribute conditions with AND. Validate that each attribute condition has a unique slug, that when a value is provided it contains exactly one key and is non-empty, and that any type-specific key matches the attribute’s input type. Update the GraphQL schema/types accordingly, use efficient DB-side filtering (Exists/OuterRef), and add comprehensive tests covering positive cases, validation errors, non-matching filters, and multi-attribute combinations. Also add a concise changelog entry announcing the new pages attribute filtering capability.",
      "supplementalFiles": [
        "saleor/graphql/core/filters/where_filters.py",
        "saleor/graphql/core/filters/where_input.py",
        "saleor/graphql/utils/filters.py",
        "saleor/graphql/product/filters.py",
        "saleor/graphql/attribute/types.py",
        "saleor/graphql/page/types.py",
        "saleor/page/models.py",
        "saleor/attribute/models/page.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\tf50682a (parent)\n+++ CHANGELOG.md\t01138c1 (commit)\n@@ -11,8 +11,9 @@\n - Added support for filtering products by attribute value names. The `AttributeInput` now includes a `valueNames` field, enabling filtering by the names of attribute values, in addition to the existing filtering by value slugs.\n - You can now filter and search orders using the new `where` and `search` fields on the `pages` query.\n   - Use `where` to define complex conditions with `AND`/`OR` logic and operators like `eq`, `oneOf`, `range`.\n   - Use `search` to perform full-text search across relevant fields.\n+- Add support for filtering `pages` by associated attributes\n - You can now filter and search orders using the new `where` and `search` fields on the `orders` query.\n   - Use `where` to define complex conditions with `AND`/`OR` logic and operators like `eq`, `oneOf`, `range`.\n   - Use `search` to perform full-text search across relevant fields.\n   - Added filtering options for orders:\n@@ -77,8 +78,9 @@\n   - `category.products`\n   - `collection.products`\n   - `pageType.availableAttributes`\n \n+\n ### Webhooks\n - Transaction webhooks responsible for processing payments can now return payment method details`, which will be associated with the corresponding transaction. See [docs](https://docs.saleor.io/developer/extending/webhooks/synchronous-events/transaction#response-4) to learn more.\n \n ### Other changes\n"
        },
        {
          "path": "saleor/graphql/page/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/filters.py\n===================================================================\n--- saleor/graphql/page/filters.py\tf50682a (parent)\n+++ saleor/graphql/page/filters.py\t01138c1 (commit)\n@@ -1,8 +1,12 @@\n import django_filters\n import graphene\n-from django.db.models import Q\n+from django.db.models import Exists, FloatField, OuterRef, Q\n+from django.db.models.functions import Cast\n+from graphql import GraphQLError\n \n+from ...attribute import AttributeInputType\n+from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue\n from ...page import models\n from ..core.doc_category import DOC_CATEGORY_PAGES\n from ..core.filters import (\n     FilterInputObjectType,\n@@ -11,22 +15,28 @@\n     MetadataFilterBase,\n )\n from ..core.filters.where_filters import (\n     GlobalIDMultipleChoiceWhereFilter,\n+    ListObjectTypeWhereFilter,\n     MetadataWhereBase,\n     OperationObjectTypeWhereFilter,\n )\n from ..core.filters.where_input import (\n+    DecimalFilterInput,\n     GlobalIDFilterInput,\n     StringFilterInput,\n     WhereInputObjectType,\n )\n+from ..core.types.base import BaseInputObjectType\n+from ..core.types.common import DateRangeInput, DateTimeRangeInput\n from ..utils import resolve_global_ids_to_primary_keys\n from ..utils.filters import (\n     filter_by_id,\n     filter_by_ids,\n+    filter_range_field,\n     filter_slug_list,\n     filter_where_by_id_field,\n+    filter_where_by_numeric_field,\n     filter_where_by_value_field,\n )\n from .types import Page, PageType\n \n@@ -53,8 +63,267 @@\n         return qs\n     return qs.filter(Q(name__trigram_similar=value) | Q(slug__trigram_similar=value))\n \n \n+def filter_by_slug_or_name(attr_id, attr_value, db_connection_name: str):\n+    attribute_values = AttributeValue.objects.using(db_connection_name).filter(\n+        attribute_id=attr_id\n+    )\n+    if \"slug\" in attr_value:\n+        attribute_values = filter_where_by_value_field(\n+            attribute_values, \"slug\", attr_value[\"slug\"]\n+        )\n+    if \"name\" in attr_value:\n+        attribute_values = filter_where_by_value_field(\n+            attribute_values, \"name\", attr_value[\"name\"]\n+        )\n+    assigned_attr_value = AssignedPageAttributeValue.objects.using(\n+        db_connection_name\n+    ).filter(\n+        Exists(attribute_values.filter(id=OuterRef(\"value_id\"))),\n+        page_id=OuterRef(\"id\"),\n+    )\n+    return Q(Exists(assigned_attr_value))\n+\n+\n+def filter_by_numeric_attribute(attr_id, numeric_value, db_connection_name: str):\n+    qs_by_numeric = AttributeValue.objects.using(db_connection_name).filter(\n+        attribute_id=attr_id\n+    )\n+    qs_by_numeric = qs_by_numeric.annotate(numeric_value=Cast(\"name\", FloatField()))\n+    qs_by_numeric = filter_where_by_numeric_field(\n+        qs_by_numeric,\n+        \"numeric_value\",\n+        numeric_value,\n+    )\n+    assigned_attr_value = AssignedPageAttributeValue.objects.using(\n+        db_connection_name\n+    ).filter(\n+        Exists(qs_by_numeric.filter(id=OuterRef(\"value_id\"))),\n+        page_id=OuterRef(\"id\"),\n+    )\n+    return Q(Exists(assigned_attr_value))\n+\n+\n+def filter_by_boolean_attribute(attr_id, boolean_value, db_connection_name: str):\n+    qs_by_boolean = AttributeValue.objects.using(db_connection_name).filter(\n+        attribute_id=attr_id\n+    )\n+    qs_by_boolean = qs_by_boolean.filter(boolean=boolean_value)\n+    assigned_attr_value = AssignedPageAttributeValue.objects.using(\n+        db_connection_name\n+    ).filter(\n+        Exists(qs_by_boolean.filter(id=OuterRef(\"value_id\"))),\n+        page_id=OuterRef(\"id\"),\n+    )\n+    return Q(Exists(assigned_attr_value))\n+\n+\n+def filter_by_date_attribute(attr_id, date_value, db_connection_name: str):\n+    qs_by_date = AttributeValue.objects.using(db_connection_name).filter(\n+        attribute_id=attr_id\n+    )\n+    qs_by_date = filter_range_field(\n+        qs_by_date,\n+        \"date_time__date\",\n+        date_value,\n+    )\n+    assigned_attr_value = AssignedPageAttributeValue.objects.using(\n+        db_connection_name\n+    ).filter(\n+        Exists(qs_by_date.filter(id=OuterRef(\"value_id\"))),\n+        page_id=OuterRef(\"id\"),\n+    )\n+    return Q(Exists(assigned_attr_value))\n+\n+\n+def filter_by_date_time_attribute(attr_id, date_time_value, db_connection_name: str):\n+    qs_by_date_time = AttributeValue.objects.using(db_connection_name).filter(\n+        attribute_id=attr_id\n+    )\n+    qs_by_date_time = filter_range_field(\n+        qs_by_date_time,\n+        \"date_time\",\n+        date_time_value,\n+    )\n+    assigned_attr_value = AssignedPageAttributeValue.objects.using(\n+        db_connection_name\n+    ).filter(\n+        Exists(qs_by_date_time.filter(id=OuterRef(\"value_id\"))),\n+        page_id=OuterRef(\"id\"),\n+    )\n+    return Exists(assigned_attr_value)\n+\n+\n+def filter_pages_by_attributes(qs, value):\n+    attribute_slugs = {attr_filter[\"slug\"] for attr_filter in value}\n+    attributes_map = {\n+        attr.slug: attr\n+        for attr in Attribute.objects.using(qs.db).filter(slug__in=attribute_slugs)\n+    }\n+    if len(attribute_slugs) != len(attributes_map.keys()):\n+        # Filter over non existing attribute\n+        return qs.none()\n+\n+    attr_filter_expression = Q()\n+    attr_without_values_input = [\n+        attributes_map[attr_filter[\"slug\"]]\n+        for attr_filter in value\n+        if not attr_filter.get(\"value\")\n+    ]\n+    if attr_without_values_input:\n+        atr_value_qs = AttributeValue.objects.using(qs.db).filter(\n+            attribute_id__in=[attr.id for attr in attr_without_values_input]\n+        )\n+        assigned_attr_value = AssignedPageAttributeValue.objects.using(qs.db).filter(\n+            Exists(atr_value_qs.filter(id=OuterRef(\"value_id\"))),\n+            page_id=OuterRef(\"id\"),\n+        )\n+        attr_filter_expression = Q(Exists(assigned_attr_value))\n+\n+    for attr_filter in value:\n+        attr_value = attr_filter.get(\"value\")\n+        if not attr_value:\n+            # attrs without value input are handled separately\n+            continue\n+\n+        attr = attributes_map[attr_filter[\"slug\"]]\n+        attr_value = attr_filter[\"value\"]\n+        if \"slug\" in attr_value or \"name\" in attr_value:\n+            attr_filter_expression &= filter_by_slug_or_name(\n+                attr.id,\n+                attr_value,\n+                qs.db,\n+            )\n+        elif attr.input_type == AttributeInputType.NUMERIC:\n+            attr_filter_expression &= filter_by_numeric_attribute(\n+                attr.id, attr_value[\"numeric\"], qs.db\n+            )\n+        elif attr.input_type == AttributeInputType.BOOLEAN:\n+            attr_filter_expression &= filter_by_boolean_attribute(\n+                attr.id, attr_value[\"boolean\"], qs.db\n+            )\n+        elif attr.input_type == AttributeInputType.DATE:\n+            attr_filter_expression &= filter_by_date_attribute(\n+                attr.id, attr_value[\"date\"], qs.db\n+            )\n+        elif attr.input_type == AttributeInputType.DATE_TIME:\n+            attr_filter_expression &= filter_by_date_time_attribute(\n+                attr.id, attr_value[\"date_time\"], qs.db\n+            )\n+    if attr_filter_expression != Q():\n+        return qs.filter(attr_filter_expression)\n+    return qs.none()\n+\n+\n+def validate_attribute_value_input(attributes: list[dict], db_connection_name: str):\n+    slug_list = [attr[\"slug\"] for attr in attributes]\n+    value_as_empty_list = []\n+    value_more_than_one_list = []\n+    invalid_input_type_list = []\n+    if len(slug_list) != len(set(slug_list)):\n+        raise GraphQLError(\n+            message=\"Duplicated attribute slugs in attribute 'where' input are not allowed.\"\n+        )\n+\n+    type_specific_value_list = {}\n+    for attr in attributes:\n+        if \"value\" not in attr:\n+            continue\n+        value = attr[\"value\"]\n+        if not value:\n+            value_as_empty_list.append(attr[\"slug\"])\n+            continue\n+        value_keys = value.keys()\n+        if len(value_keys) > 1:\n+            value_more_than_one_list.append(attr[\"slug\"])\n+            continue\n+        value_key = list(value_keys)[0]\n+        if value_key not in [\"slug\", \"name\"]:\n+            type_specific_value_list[attr[\"slug\"]] = value_key\n+        if value[value_key] is None:\n+            value_as_empty_list.append(attr[\"slug\"])\n+            continue\n+\n+    if type_specific_value_list:\n+        attribute_input_type_map = Attribute.objects.using(db_connection_name).in_bulk(\n+            type_specific_value_list.keys(),\n+            field_name=\"slug\",\n+        )\n+\n+        for attr_slug, value_key in type_specific_value_list.items():\n+            if attr_slug not in attribute_input_type_map:\n+                continue\n+\n+            input_type = attribute_input_type_map[attr_slug].input_type\n+            if \"numeric\" == value_key and input_type != AttributeInputType.NUMERIC:\n+                invalid_input_type_list.append(attr_slug)\n+            if \"date\" == value_key and input_type != AttributeInputType.DATE:\n+                invalid_input_type_list.append(attr_slug)\n+            if \"date_time\" == value_key and input_type != AttributeInputType.DATE_TIME:\n+                invalid_input_type_list.append(attr_slug)\n+            if \"boolean\" == value_key and input_type != AttributeInputType.BOOLEAN:\n+                invalid_input_type_list.append(attr_slug)\n+\n+    if value_as_empty_list:\n+        raise GraphQLError(\n+            message=(\n+                f\"Incorrect input for attributes with slugs: {','.join(value_as_empty_list)}. \"\n+                \"Provided 'value' cannot be empty or null.\"\n+            )\n+        )\n+    if value_more_than_one_list:\n+        raise GraphQLError(\n+            message=(\n+                f\"Incorrect input for attributes with slugs: {','.join(value_more_than_one_list)}. \"\n+                \"Provided 'value' must have only one input key.\"\n+            )\n+        )\n+    if invalid_input_type_list:\n+        raise GraphQLError(\n+            message=(\n+                f\"Incorrect input for attributes with slugs: {','.join(invalid_input_type_list)}. \"\n+                \"Provided 'value' do not match the attribute input type.\"\n+            )\n+        )\n+\n+\n+class AttributeValuePageInput(BaseInputObjectType):\n+    slug = StringFilterInput(\n+        description=\"Filter by slug assigned to AttributeValue.\",\n+    )\n+    name = StringFilterInput(\n+        description=\"Filter by name assigned to AttributeValue.\",\n+    )\n+    numeric = DecimalFilterInput(\n+        required=False,\n+        description=\"Filter by numeric value for attributes of numeric type.\",\n+    )\n+    date = DateRangeInput(\n+        required=False,\n+        description=\"Filter by date value for attributes of date type.\",\n+    )\n+    date_time = DateTimeRangeInput(\n+        required=False,\n+        description=\"Filter by date time value for attributes of date time type.\",\n+    )\n+    boolean = graphene.Boolean(\n+        required=False,\n+        description=\"Filter by boolean value for attributes of boolean type.\",\n+    )\n+\n+\n+class AttributePageWhereInput(BaseInputObjectType):\n+    slug = graphene.String(description=\"Filter by attribute slug.\", required=True)\n+    value = AttributeValuePageInput(\n+        required=False,\n+        description=(\n+            \"Filter by value of the attribute. Only one value input field is allowed. \"\n+            \"If provided more than one, the error will be raised.\"\n+        ),\n+    )\n+\n+\n class PageWhere(MetadataWhereBase):\n     ids = GlobalIDMultipleChoiceWhereFilter(method=filter_by_ids(\"Page\"))\n     slug = OperationObjectTypeWhereFilter(\n         input_class=StringFilterInput,\n@@ -65,8 +334,13 @@\n         input_class=GlobalIDFilterInput,\n         method=\"filter_page_type\",\n         help_text=\"Filter by page type.\",\n     )\n+    attributes = ListObjectTypeWhereFilter(\n+        input_class=AttributePageWhereInput,\n+        method=\"filter_attributes\",\n+        help_text=\"Filter by attributes associated with the page.\",\n+    )\n \n     @staticmethod\n     def filter_page_slug(qs, _, value):\n         return filter_where_by_value_field(qs, \"slug\", value)\n@@ -76,9 +350,20 @@\n         if not value:\n             return qs\n         return filter_where_by_id_field(qs, \"page_type\", value, \"PageType\")\n \n+    @staticmethod\n+    def filter_attributes(qs, _, value):\n+        if not value:\n+            return qs\n+        return filter_pages_by_attributes(qs, value)\n \n+    def is_valid(self):\n+        if attributes := self.data.get(\"attributes\"):\n+            validate_attribute_value_input(attributes, self.queryset.db)\n+        return super().is_valid()\n+\n+\n def filter_page_search(qs, _, value):\n     # Skip search, as search is applied on resolver side.\n     return qs\n \n"
        },
        {
          "path": "saleor/graphql/page/tests/queries/test_pages_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/queries/test_pages_with_where.py\n===================================================================\n--- saleor/graphql/page/tests/queries/test_pages_with_where.py\tf50682a (parent)\n+++ saleor/graphql/page/tests/queries/test_pages_with_where.py\t01138c1 (commit)\n@@ -1,7 +1,11 @@\n+import datetime\n+\n import graphene\n import pytest\n \n+from .....attribute import AttributeInputType\n+from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.models import Page, PageType\n from ....tests.utils import get_graphql_content\n \n QUERY_PAGES_WITH_WHERE = \"\"\"\n@@ -143,15 +147,869 @@\n \n def test_pages_query_with_where_by_ids(\n     staff_api_client, permission_manage_pages, page_list, page_list_unpublished\n ):\n+    # given\n     query = QUERY_PAGES_WITH_WHERE\n \n     page_ids = [\n         graphene.Node.to_global_id(\"Page\", page.pk)\n         for page in [page_list[0], page_list_unpublished[-1]]\n     ]\n     variables = {\"where\": {\"ids\": page_ids}}\n+\n+    # when\n     staff_api_client.user.user_permissions.add(permission_manage_pages)\n+\n+    # then\n     response = staff_api_client.post_graphql(query, variables)\n     content = get_graphql_content(response)\n     assert content[\"data\"][\"pages\"][\"totalCount\"] == len(page_ids)\n+\n+\n+def test_pages_query_with_attribute_slug(\n+    staff_api_client, page_list, page_type, size_page_attribute\n+):\n+    # given\n+    page_type.page_attributes.add(size_page_attribute)\n+    page_attr_value = size_page_attribute.values.first()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {size_page_attribute.pk: [page_attr_value]}\n+    )\n+\n+    variables = {\"where\": {\"attributes\": [{\"slug\": size_page_attribute.slug}]}}\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == 1\n+    assert pages_nodes[0][\"node\"][\"id\"] == graphene.Node.to_global_id(\n+        \"Page\", page_list[0].pk\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"slug_input\", \"expected_count\"),\n+    [\n+        ({\"eq\": \"test-slug-1\"}, 1),\n+        ({\"oneOf\": [\"test-slug-1\", \"test-slug-2\"]}, 2),\n+    ],\n+)\n+def test_pages_query_with_attribute_value_slug(\n+    slug_input,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    size_page_attribute,\n+):\n+    # given\n+    page_type.page_attributes.add(size_page_attribute)\n+\n+    attr_value_1 = size_page_attribute.values.first()\n+    attr_value_1.slug = \"test-slug-1\"\n+    attr_value_1.save()\n+\n+    attr_value_2 = size_page_attribute.values.last()\n+    attr_value_2.slug = \"test-slug-2\"\n+    attr_value_2.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {size_page_attribute.pk: [attr_value_1]}\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1], {size_page_attribute.pk: [attr_value_2]}\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\"slug\": size_page_attribute.slug, \"value\": {\"slug\": slug_input}}\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"name_input\", \"expected_count\"),\n+    [\n+        ({\"eq\": \"test-name-1\"}, 1),\n+        ({\"oneOf\": [\"test-name-1\", \"test-name-2\"]}, 2),\n+    ],\n+)\n+def test_pages_query_with_attribute_value_name(\n+    name_input,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    size_page_attribute,\n+):\n+    # given\n+    page_type.page_attributes.add(size_page_attribute)\n+\n+    attr_value_1 = size_page_attribute.values.first()\n+    attr_value_1.name = \"test-name-1\"\n+    attr_value_1.save()\n+\n+    attr_value_2 = size_page_attribute.values.last()\n+    attr_value_2.name = \"test-name-2\"\n+    attr_value_2.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {size_page_attribute.pk: [attr_value_1]}\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1], {size_page_attribute.pk: [attr_value_2]}\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\"slug\": size_page_attribute.slug, \"value\": {\"name\": name_input}}\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"numeric_input\", \"expected_count\"),\n+    [\n+        ({\"numeric\": {\"eq\": 1.2}}, 1),\n+        ({\"numeric\": {\"oneOf\": [1.2, 2]}}, 2),\n+        ({\"numeric\": {\"range\": {\"gte\": 1, \"lte\": 2}}}, 2),\n+        ({\"name\": {\"eq\": \"1.2\"}}, 1),\n+        ({\"slug\": {\"eq\": \"1.2\"}}, 1),\n+        ({\"name\": {\"oneOf\": [\"1.2\", \"2\"]}}, 2),\n+        ({\"slug\": {\"oneOf\": [\"1.2\", \"2\"]}}, 2),\n+    ],\n+)\n+def test_pages_query_with_attribute_value_numeric(\n+    numeric_input,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    numeric_attribute_without_unit,\n+):\n+    # given\n+    numeric_attribute_without_unit.type = \"PAGE_TYPE\"\n+    numeric_attribute_without_unit.save()\n+\n+    page_type.page_attributes.add(numeric_attribute_without_unit)\n+\n+    attr_value_1 = numeric_attribute_without_unit.values.first()\n+    attr_value_1.name = \"1.2\"\n+    attr_value_1.slug = \"1.2\"\n+    attr_value_1.save()\n+\n+    attr_value_2 = numeric_attribute_without_unit.values.last()\n+    attr_value_2.name = \"2\"\n+    attr_value_2.slug = \"2\"\n+    attr_value_2.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {numeric_attribute_without_unit.pk: [attr_value_1]}\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1], {numeric_attribute_without_unit.pk: [attr_value_2]}\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": numeric_attribute_without_unit.slug,\n+                    \"value\": numeric_input,\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"date_input\", \"expected_count\"),\n+    [\n+        ({\"date\": {\"gte\": \"2021-01-01\"}}, 2),\n+        ({\"name\": {\"eq\": \"date-name-1\"}}, 1),\n+        ({\"slug\": {\"eq\": \"date-slug-1\"}}, 1),\n+        (\n+            {\n+                \"name\": {\"oneOf\": [\"date-name-1\", \"date-name-2\"]},\n+            },\n+            2,\n+        ),\n+        (\n+            {\n+                \"slug\": {\"oneOf\": [\"date-slug-1\", \"date-slug-2\"]},\n+            },\n+            2,\n+        ),\n+        ({\"date\": {\"gte\": \"2021-01-01\", \"lte\": \"2021-01-02\"}}, 1),\n+    ],\n+)\n+def test_pages_query_with_attribute_value_date(\n+    date_input,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    date_attribute,\n+):\n+    # given\n+    date_attribute.type = \"PAGE_TYPE\"\n+    date_attribute.save()\n+\n+    page_type.page_attributes.add(date_attribute)\n+\n+    attr_value_1 = date_attribute.values.first()\n+    attr_value_1.date_time = datetime.datetime(2021, 1, 3, tzinfo=datetime.UTC)\n+    attr_value_1.name = \"date-name-1\"\n+    attr_value_1.slug = \"date-slug-1\"\n+    attr_value_1.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {date_attribute.pk: [attr_value_1]}\n+    )\n+\n+    second_attr_value = date_attribute.values.last()\n+    second_attr_value.date_time = datetime.datetime(2021, 1, 1, tzinfo=datetime.UTC)\n+    second_attr_value.name = \"date-name-2\"\n+    second_attr_value.slug = \"date-slug-2\"\n+    second_attr_value.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1], {date_attribute.pk: [second_attr_value]}\n+    )\n+\n+    variables = {\n+        \"where\": {\"attributes\": [{\"slug\": date_attribute.slug, \"value\": date_input}]}\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"date_time_input\", \"expected_count\"),\n+    [\n+        (\n+            {\n+                \"name\": {\"eq\": \"datetime-name-1\"},\n+            },\n+            1,\n+        ),\n+        (\n+            {\n+                \"slug\": {\"eq\": \"datetime-slug-1\"},\n+            },\n+            1,\n+        ),\n+        (\n+            {\n+                \"name\": {\"oneOf\": [\"datetime-name-1\", \"datetime-name-2\"]},\n+            },\n+            2,\n+        ),\n+        (\n+            {\n+                \"slug\": {\"oneOf\": [\"datetime-slug-1\", \"datetime-slug-2\"]},\n+            },\n+            2,\n+        ),\n+        ({\"dateTime\": {\"gte\": \"2021-01-01T00:00:00Z\"}}, 2),\n+        (\n+            {\n+                \"dateTime\": {\n+                    \"gte\": \"2021-01-01T00:00:00Z\",\n+                    \"lte\": \"2021-01-02T00:00:00Z\",\n+                }\n+            },\n+            1,\n+        ),\n+    ],\n+)\n+def test_pages_query_with_attribute_value_date_time(\n+    date_time_input,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    date_time_attribute,\n+):\n+    # given\n+    date_time_attribute.type = \"PAGE_TYPE\"\n+    date_time_attribute.save()\n+\n+    page_type.page_attributes.add(date_time_attribute)\n+\n+    attr_value_1 = date_time_attribute.values.first()\n+    attr_value_1.date_time = datetime.datetime(2021, 1, 3, tzinfo=datetime.UTC)\n+    attr_value_1.name = \"datetime-name-1\"\n+    attr_value_1.slug = \"datetime-slug-1\"\n+    attr_value_1.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {date_time_attribute.pk: [attr_value_1]}\n+    )\n+\n+    second_attr_value = date_time_attribute.values.last()\n+    second_attr_value.date_time = datetime.datetime(2021, 1, 1, tzinfo=datetime.UTC)\n+    second_attr_value.name = \"datetime-name-2\"\n+    second_attr_value.slug = \"datetime-slug-2\"\n+    second_attr_value.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1], {date_time_attribute.pk: [second_attr_value]}\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": date_time_attribute.slug,\n+                    \"value\": date_time_input,\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    \"boolean_input\",\n+    [\n+        {\"boolean\": True},\n+        {\n+            \"name\": {\"eq\": \"True-name\"},\n+        },\n+        {\n+            \"slug\": {\"eq\": \"true_slug\"},\n+        },\n+        {\"name\": {\"oneOf\": [\"True-name\", \"True-name-2\"]}},\n+        {\n+            \"slug\": {\"oneOf\": [\"true_slug\"]},\n+        },\n+    ],\n+)\n+def test_pages_query_with_attribute_value_boolean(\n+    boolean_input,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    boolean_attribute,\n+):\n+    # given\n+    boolean_attribute.type = \"PAGE_TYPE\"\n+    boolean_attribute.save()\n+\n+    page_type.page_attributes.add(boolean_attribute)\n+\n+    true_value = boolean_attribute.values.filter(boolean=True).first()\n+    true_value.name = \"True-name\"\n+    true_value.slug = \"true_slug\"\n+    true_value.save()\n+\n+    false_value = boolean_attribute.values.filter(boolean=False).first()\n+    false_value.name = \"False-name\"\n+    false_value.slug = \"false_slug\"\n+    false_value.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0], {boolean_attribute.pk: [true_value]}\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1], {boolean_attribute.pk: [false_value]}\n+    )\n+\n+    variables = {\"where\": {\"attributes\": [{\"slug\": \"boolean\", \"value\": boolean_input}]}}\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == 1\n+    assert pages_nodes[0][\"node\"][\"id\"] == graphene.Node.to_global_id(\n+        \"Page\", page_list[0].pk\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    \"attribute_filter\",\n+    [\n+        # When input receives None\n+        [{\"slug\": \"page-size\"}, {\"slug\": \"page-size\"}],\n+        [{\"slug\": \"page-size\", \"value\": {\"slug\": None}}],\n+        [{\"slug\": \"page-size\", \"value\": {\"name\": None}}],\n+        # Cant have multiple value input fields\n+        [\n+            {\n+                \"slug\": \"page-size\",\n+                \"value\": {\n+                    \"slug\": {\"eq\": \"true_slug\"},\n+                    \"name\": {\"eq\": \"name\"},\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"page-size\",\n+                \"value\": {\n+                    \"slug\": {\"oneOf\": [\"true_slug\"]},\n+                    \"name\": {\"oneOf\": [\"name\"]},\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"page-size\",\n+                \"value\": {\n+                    \"name\": {\"eq\": \"name\"},\n+                },\n+            },\n+            {\"slug\": \"count\", \"value\": {\"numeric\": None}},\n+        ],\n+        # numeric attribute\n+        [{\"slug\": \"count\", \"value\": {\"numeric\": None}}],\n+        [{\"slug\": \"count\", \"value\": {\"name\": None}}],\n+        [{\"slug\": \"count\", \"value\": {\"slug\": None}}],\n+        # Numeric can't be used with non numeric fields\n+        [{\"slug\": \"count\", \"value\": {\"boolean\": False}}],\n+        # boolean attribute\n+        [{\"slug\": \"boolean\", \"value\": {\"boolean\": None}}],\n+        [{\"slug\": \"boolean\", \"value\": {\"name\": None}}],\n+        [{\"slug\": \"boolean\", \"value\": {\"slug\": None}}],\n+        # Boolean can't be used with non boolean fields\n+        [{\"slug\": \"boolean\", \"value\": {\"numeric\": {\"eq\": 1.2}}}],\n+        # date attribute\n+        [{\"slug\": \"date\", \"value\": {\"date\": None}}],\n+        [{\"slug\": \"date\", \"value\": {\"name\": None}}],\n+        [{\"slug\": \"date\", \"value\": {\"slug\": None}}],\n+        # Date can't be used with non date fields\n+        [{\"slug\": \"date\", \"value\": {\"numeric\": {\"eq\": 1.2}}}],\n+        # datetime attribute\n+        [{\"slug\": \"date_time\", \"value\": {\"dateTime\": None}}],\n+        [{\"slug\": \"date_time\", \"value\": {\"name\": None}}],\n+        [{\"slug\": \"date_time\", \"value\": {\"slug\": None}}],\n+        # Date time can't be used with non date time fields\n+        [{\"slug\": \"date_time\", \"value\": {\"numeric\": {\"eq\": 1.2}}}],\n+    ],\n+)\n+def test_pages_query_failed_filter_validation(\n+    attribute_filter,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    size_page_attribute,\n+    tag_page_attribute,\n+    boolean_attribute,\n+    numeric_attribute_without_unit,\n+    date_attribute,\n+    date_time_attribute,\n+):\n+    # given\n+    boolean_attribute.type = \"PAGE_TYPE\"\n+    boolean_attribute.save()\n+    numeric_attribute_without_unit.type = \"PAGE_TYPE\"\n+    numeric_attribute_without_unit.save()\n+\n+    page_type.page_attributes.add(size_page_attribute)\n+    page_type.page_attributes.add(tag_page_attribute)\n+    page_type.page_attributes.add(boolean_attribute)\n+    page_type.page_attributes.add(numeric_attribute_without_unit)\n+    page_type.page_attributes.add(date_attribute)\n+    page_type.page_attributes.add(date_time_attribute)\n+\n+    size_value = size_page_attribute.values.get(slug=\"10\")\n+    tag_value = tag_page_attribute.values.get(name=\"About\")\n+    boolean_value = boolean_attribute.values.filter(boolean=True).first()\n+    numeric_value = numeric_attribute_without_unit.values.first()\n+    date_time_value = date_time_attribute.values.first()\n+    date_value = date_attribute.values.first()\n+\n+    date_attribute.slug = \"date\"\n+    date_attribute.save()\n+    date_time_attribute.slug = \"date_time\"\n+    date_time_attribute.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0],\n+        {\n+            size_page_attribute.pk: [size_value],\n+            tag_page_attribute.pk: [tag_value],\n+            boolean_attribute.pk: [boolean_value],\n+            numeric_attribute_without_unit.pk: [numeric_value],\n+            date_attribute.pk: [date_value],\n+            date_time_attribute.pk: [date_time_value],\n+        },\n+    )\n+\n+    variables = {\"where\": {\"attributes\": attribute_filter}}\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response, ignore_errors=True)\n+    assert \"errors\" in content\n+    assert content[\"data\"][\"pages\"] is None\n+\n+\n+@pytest.mark.parametrize(\n+    \"attribute_filter\",\n+    [\n+        # Non-existing attribute slug\n+        [{\"slug\": \"non-existing-attribute\"}],\n+        # Existing attribute with non-existing value name\n+        [{\"slug\": \"tag\", \"value\": {\"name\": {\"eq\": \"Non-existing Name\"}}}],\n+        # Existing numeric attribute with out-of-range value\n+        [{\"slug\": \"count\", \"value\": {\"numeric\": {\"eq\": 999}}}],\n+        # Existing boolean attribute with no matching boolean value\n+        [{\"slug\": \"boolean\", \"value\": {\"boolean\": False}}],\n+        # Multiple attributes where one doesn't exist\n+        [\n+            {\"slug\": \"page-size\", \"value\": {\"slug\": {\"eq\": \"10\"}}},\n+            {\"slug\": \"non-existing-attr\", \"value\": {\"slug\": {\"eq\": \"some-value\"}}},\n+        ],\n+    ],\n+)\n+def test_pages_query_with_non_matching_records(\n+    attribute_filter,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    size_page_attribute,\n+    tag_page_attribute,\n+    boolean_attribute,\n+    numeric_attribute_without_unit,\n+    date_attribute,\n+    date_time_attribute,\n+):\n+    # given\n+    boolean_attribute.type = \"PAGE_TYPE\"\n+    boolean_attribute.save()\n+    numeric_attribute_without_unit.type = \"PAGE_TYPE\"\n+    numeric_attribute_without_unit.save()\n+\n+    page_type.page_attributes.add(size_page_attribute)\n+    page_type.page_attributes.add(tag_page_attribute)\n+    page_type.page_attributes.add(boolean_attribute)\n+    page_type.page_attributes.add(numeric_attribute_without_unit)\n+    page_type.page_attributes.add(date_attribute)\n+    page_type.page_attributes.add(date_time_attribute)\n+\n+    size_value = size_page_attribute.values.get(slug=\"10\")\n+    tag_value = tag_page_attribute.values.get(name=\"About\")\n+    boolean_value = boolean_attribute.values.filter(boolean=True).first()\n+    numeric_value = numeric_attribute_without_unit.values.first()\n+    date_time_value = date_time_attribute.values.first()\n+    date_value = date_attribute.values.first()\n+\n+    date_attribute.slug = \"date\"\n+    date_attribute.save()\n+    date_time_attribute.slug = \"date_time\"\n+    date_time_attribute.save()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0],\n+        {\n+            size_page_attribute.pk: [size_value],\n+            tag_page_attribute.pk: [tag_value],\n+            boolean_attribute.pk: [boolean_value],\n+            numeric_attribute_without_unit.pk: [numeric_value],\n+            date_attribute.pk: [date_value],\n+            date_time_attribute.pk: [date_time_value],\n+        },\n+    )\n+\n+    variables = {\"where\": {\"attributes\": attribute_filter}}\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == 0\n+\n+\n+@pytest.mark.parametrize(\n+    (\"attribute_where_input\", \"expected_count_result\"),\n+    [\n+        (\n+            [\n+                {\n+                    \"slug\": \"page-size\",\n+                    \"value\": {\n+                        \"numeric\": {\"range\": {\"lte\": 89}},\n+                    },\n+                },\n+                {\n+                    \"slug\": \"tag\",\n+                    \"value\": {\"name\": {\"oneOf\": [\"About\", \"Help\"]}},\n+                },\n+                {\n+                    \"slug\": \"author\",\n+                    \"value\": {\n+                        \"slug\": {\"oneOf\": [\"test-author-1\"]},\n+                    },\n+                },\n+                {\"slug\": \"boolean\", \"value\": {\"boolean\": True}},\n+            ],\n+            1,\n+        ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\n+        #                 \"slug\": {\"eq\": \"10\"},\n+        #             },\n+        #         },\n+        #         {\n+        #             \"slug\": \"tag\",\n+        #             \"value\": {\"name\": {\"oneOf\": [\"About\", \"Help\"]}},\n+        #         },\n+        #     ],\n+        #     1,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"eq\": \"10\"}},\n+        #         },\n+        #         {\"slug\": \"boolean\", \"value\": {\"boolean\": False}},\n+        #     ],\n+        #     0,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"tag\",\n+        #             \"value\": {\n+        #                 \"name\": {\"eq\": \"About\"},\n+        #             },\n+        #         },\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"eq\": \"10\"}},\n+        #         },\n+        #     ],\n+        #     1,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"eq\": \"15\"}},\n+        #         },\n+        #         {\n+        #             \"slug\": \"tag\",\n+        #             \"value\": {\"name\": {\"eq\": \"Help\"}},\n+        #         },\n+        #         {\"slug\": \"boolean\", \"value\": {\"boolean\": False}},\n+        #     ],\n+        #     0,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"author\",\n+        #             \"value\": {\"slug\": {\"oneOf\": [\"test-author-1\", \"test-author-2\"]}},\n+        #         },\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"eq\": \"10\"}},\n+        #         },\n+        #     ],\n+        #     1,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"eq\": \"10\"}},\n+        #         },\n+        #         {\n+        #             \"slug\": \"author\",\n+        #             \"value\": {\"name\": {\"eq\": \"Test author 1\"}},\n+        #         },\n+        #     ],\n+        #     1,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"eq\": \"10\"}},\n+        #         },\n+        #         {\n+        #             \"slug\": \"tag\",\n+        #             \"value\": {\"name\": {\"eq\": \"About\"}},\n+        #         },\n+        #         {\n+        #             \"slug\": \"author\",\n+        #             \"value\": {\"slug\": {\"eq\": \"test-author-1\"}},\n+        #         },\n+        #     ],\n+        #     1,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"oneOf\": [\"10\", \"15\"]}},\n+        #         },\n+        #         {\n+        #             \"slug\": \"tag\",\n+        #             \"value\": {\"name\": {\"oneOf\": [\"About\", \"Help\"]}},\n+        #         },\n+        #     ],\n+        #     2,\n+        # ),\n+        # (\n+        #     [\n+        #         {\n+        #             \"slug\": \"page-size\",\n+        #             \"value\": {\"slug\": {\"oneOf\": [\"10\", \"15\"]}},\n+        #         },\n+        #         {\"slug\": \"boolean\", \"value\": {\"boolean\": True}},\n+        #     ],\n+        #     1,\n+        # ),\n+    ],\n+)\n+def test_pages_query_with_multiple_attribute_filters(\n+    attribute_where_input,\n+    expected_count_result,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    size_page_attribute,\n+    tag_page_attribute,\n+    author_page_attribute,\n+    boolean_attribute,\n+):\n+    # given\n+    boolean_attribute.type = \"PAGE_TYPE\"\n+    boolean_attribute.save()\n+\n+    page_type.page_attributes.add(size_page_attribute)\n+    size_page_attribute.input_type = AttributeInputType.NUMERIC\n+    size_page_attribute.save()\n+\n+    page_type.page_attributes.add(tag_page_attribute)\n+    page_type.page_attributes.add(author_page_attribute)\n+    page_type.page_attributes.add(boolean_attribute)\n+\n+    size_value = size_page_attribute.values.get(slug=\"10\")\n+    tag_value = tag_page_attribute.values.get(name=\"About\")\n+    author_value = author_page_attribute.values.get(slug=\"test-author-1\")\n+    boolean_value = boolean_attribute.values.filter(boolean=True).first()\n+\n+    associate_attribute_values_to_instance(\n+        page_list[0],\n+        {\n+            size_page_attribute.pk: [size_value],\n+            tag_page_attribute.pk: [tag_value],\n+            author_page_attribute.pk: [author_value],\n+            boolean_attribute.pk: [boolean_value],\n+        },\n+    )\n+\n+    tag_value_2 = tag_page_attribute.values.get(name=\"Help\")\n+    size_value_15 = size_page_attribute.values.get(slug=\"15\")\n+\n+    associate_attribute_values_to_instance(\n+        page_list[1],\n+        {\n+            size_page_attribute.pk: [size_value_15],\n+            tag_page_attribute.pk: [tag_value_2],\n+        },\n+    )\n+\n+    variables = {\"where\": {\"attributes\": attribute_where_input}}\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count_result\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\tf50682a (parent)\n+++ saleor/graphql/schema.graphql\t01138c1 (commit)\n@@ -12866,8 +12866,11 @@\n \n   \"\"\"Filter by page type.\"\"\"\n   pageType: GlobalIDFilterInput\n \n+  \"\"\"Filter by attributes associated with the page.\"\"\"\n+  attributes: [AttributePageWhereInput!]\n+\n   \"\"\"List of conditions that must be met.\"\"\"\n   AND: [PageWhereInput!]\n \n   \"\"\"A list of conditions of which at least one must be met.\"\"\"\n@@ -12903,8 +12906,38 @@\n   \"\"\"The value included in.\"\"\"\n   oneOf: [String!]\n }\n \n+input AttributePageWhereInput {\n+  \"\"\"Filter by attribute slug.\"\"\"\n+  slug: String!\n+\n+  \"\"\"\n+  Filter by value of the attribute. Only one value input field is allowed. If provided more than one, the error will be raised.\n+  \"\"\"\n+  value: AttributeValuePageInput\n+}\n+\n+input AttributeValuePageInput {\n+  \"\"\"Filter by slug assigned to AttributeValue.\"\"\"\n+  slug: StringFilterInput\n+\n+  \"\"\"Filter by name assigned to AttributeValue.\"\"\"\n+  name: StringFilterInput\n+\n+  \"\"\"Filter by numeric value for attributes of numeric type.\"\"\"\n+  numeric: DecimalFilterInput\n+\n+  \"\"\"Filter by date value for attributes of date type.\"\"\"\n+  date: DateRangeInput\n+\n+  \"\"\"Filter by date time value for attributes of date time type.\"\"\"\n+  dateTime: DateTimeRangeInput\n+\n+  \"\"\"Filter by boolean value for attributes of boolean type.\"\"\"\n+  boolean: Boolean\n+}\n+\n type PageTypeCountableConnection @doc(category: \"Pages\") {\n   \"\"\"Pagination data for this connection.\"\"\"\n   pageInfo: PageInfo!\n   edges: [PageTypeCountableEdge!]!\n"
        }
      ]
    },
    {
      "id": "add-page-ref-search",
      "sha": "5dc9b646788a201d95e5ccf4258a830e06d08af1",
      "parentSha": "7b108c39541fa5a6401b3ca13a0a7da0b14f49ed",
      "spec": "Implement page reference attributes in product search and propagate updates via GraphQL mutations.\n\nScope\n- Product search indexing\n- GraphQL base mutation tracking (instance tracker)\n- Page and PageType mutations affecting product search\n- Save method signature unification across mutations\n\nRequirements\n1) Extend product search to include page reference attributes\n- In saleor/product/search.py, when generating search vectors for attribute values:\n  - If an attribute input type is REFERENCE or SINGLE_REFERENCE (page references only for now), include the referenced page title in the product's search_vector with weight B and config simple.\n  - Introduce a helper that returns the searchable value for a reference AttributeValue (page title; empty string if not available).\n- Ensure existing search update utilities continue to work without modification to their external API.\n\n2) Add InstanceTracker support to Base GraphQL model mutations\n- In saleor/graphql/core/mutations.py:\n  - Extend DeprecatedModelMutation.__init_subclass_with_meta__ to accept a new Meta option: instance_tracker_fields (list of field names to track; default []). Store it on _meta.\n  - In DeprecatedModelMutation.perform_mutation(): if instance_tracker_fields is non-empty, construct an InstanceTracker for the instance before cleaning/saving. Pass the tracker into save().\n  - Update DeprecatedModelMutation.save() signature to accept an optional instance_tracker parameter and pass it through to overrides. The default implementation should still just save the instance.\n  - Import InstanceTracker from saleor/core/utils/update_mutation_manager.py.\n\n3) Update save() signatures in concrete mutations\n- For all overriding save() methods changed in the diff, update their signatures to accept an optional instance_tracker parameter (default None) while preserving existing logic:\n  - Account: account_address_create.py (AccountAddressCreate), account_update.py (AccountUpdate)\n  - Staff: customer_create.py (CustomerCreate), customer_update.py (CustomerUpdate)\n  - App: app_create.py (AppCreate), app_retry_install.py (AppRetryInstall; keep positional-only args while appending instance_tracker)\n  - Checkout: checkout_create.py (CheckoutCreate)\n  - Order: draft_order_create.py (DraftOrderCreate), order_line_update.py (OrderLineUpdate)\n  - Page: page_create.py (PageCreate), page_update.py (PageUpdate), page_delete.py (PageDelete)\n  - Product: product_create.py (ProductCreate), product_update.py (ProductUpdate), product_type_update.py (ProductTypeUpdate), product_variant_create.py (ProductVariantCreate)\n  - Shipping: shipping/mutations/base.py (ShippingPriceMixin.save)\n  - Tax: tax_class_create.py (TaxClassCreate), tax_class_update.py (TaxClassUpdate), tax_configuration_update.py (TaxConfigurationUpdate)\n  - Webhook: webhook_create.py (WebhookCreate), webhook_update.py (WebhookUpdate)\n- No behavioral changes are required in these methods except for handling the optional instance_tracker when needed (see #4).\n\n4) Use InstanceTracker in PageUpdate to trigger product search updates\n- In saleor/graphql/page/mutations/page_update.py:\n  - Set Meta.instance_tracker_fields to [\"title\"].\n  - In save(), after calling the parent save, if the instance_tracker reports that title changed, trigger an update routine to mark impacted products for search reindex.\n\n5) Mark products referencing pages/page types as search-index dirty on delete/bulk delete and relevant updates\n- Add a helper to lock Product rows deterministically:\n  - saleor/product/lock_objects.py: implement product_qs_select_for_update() returning Product.objects ordered by pk with select_for_update(of=(['self'])).\n- Page delete (saleor/graphql/page/mutations/page_delete.py):\n  - Before performing the delete, mark products that reference the page via AssignedProductAttributeValue → AttributeValue(reference_page=page) as search_index_dirty=True.\n  - Use transaction.atomic() and product_qs_select_for_update(); determine product IDs using EXISTS subqueries (no explicit JOIN). Then bulk update those products.\n- Page type delete (saleor/graphql/page/mutations/page_type_delete.py):\n  - Similarly, mark products referencing any pages under the page type as search_index_dirty=True. Compute page_ids for the page type, then products via EXISTS subqueries. Lock products and update within a transaction.\n- Page bulk delete (saleor/graphql/page/bulk_mutations.py):\n  - For the set of pages being deleted, mark products referencing them as search_index_dirty=True using the same pattern (EXISTS + locking + transaction) before performing bulk deletion.\n- Page type bulk delete (saleor/graphql/page/bulk_mutations.py):\n  - For the set of page types being deleted, compute page_ids across those types and mark products referencing them as search_index_dirty=True with the same pattern.\n- Keep existing behavior of removing AssignedPageAttributeValue and invoking events; only add the product search dirtying step.\n\n6) Use EXISTS subqueries and transactions\n- Replace joins with EXISTS subqueries when identifying impacted products that have AttributeValue.reference_page pointing to the targeted pages. Wrap updates in transaction.atomic() and lock product rows using product_qs_select_for_update() before updating search_index_dirty.\n\n7) Import adjustments\n- When adding EXISTS-based logic in page bulk mutations, import Exists and OuterRef from django.db.models rather than django.db.models.expressions.\n- Import product_qs_select_for_update and Product where needed in page mutations.\n\nBehavioral outcome\n- Product search vectors include text from referenced pages (page title) via page reference attributes.\n- When a page title changes, related products are marked dirty and reindexing removes old page titles and includes the updated one.\n- When a page or page type is deleted (including bulk operations), related products are marked dirty so subsequent reindexing removes the deleted page’s title from their search vectors.\n- GraphQL mutation save() methods accept an optional instance_tracker; the base mutation creates and passes it when instance_tracker_fields are configured.",
      "prompt": "Add support for indexing referenced page information in product search and ensure product search stays consistent when related pages are modified or removed.\n\nSpecifically:\n- Extend product search so that products include the titles of referenced pages (via reference attributes) in their search index.\n- Introduce an instance change tracking mechanism in the base GraphQL model mutation so individual mutations can react to field changes; expose a way for mutations to declare fields to track and receive a tracker in their save.\n- Update page-related mutations so that when pages or page types are updated or deleted (individually or in bulk), any products that reference them are marked for search reindexing. Use efficient EXISTS-based queries and lock products while updating.\n- Update mutation save methods across the code to accept an optional instance tracker parameter, preserving existing behavior.\n\nEnsure you cover both single and bulk delete flows for pages and page types, and trigger reindexing when a page title changes. Use transactions and row locking where appropriate to avoid race conditions.",
      "supplementalFiles": [
        "saleor/core/utils/update_mutation_manager.py",
        "saleor/product/models.py",
        "saleor/page/models.py",
        "saleor/attribute/utils.py",
        "saleor/graphql/page/filters.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/account/mutations/account/account_address_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/account/account_address_create.py\n===================================================================\n--- saleor/graphql/account/mutations/account/account_address_create.py\t7b108c3 (parent)\n+++ saleor/graphql/account/mutations/account/account_address_create.py\t5dc9b64 (commit)\n@@ -99,9 +99,9 @@\n                 utils.change_user_default_address(user, address, address_type, manager)\n         return AccountAddressCreate(user=user, address=address)\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         user = cleaned_input.pop(\"user\")\n         super().save(info, instance, cleaned_input)\n         remove_the_oldest_user_address_if_address_limit_is_reached(user)\n         instance.user_addresses.add(user)\n"
        },
        {
          "path": "saleor/graphql/account/mutations/account/account_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/account/account_update.py\n===================================================================\n--- saleor/graphql/account/mutations/account/account_update.py\t7b108c3 (parent)\n+++ saleor/graphql/account/mutations/account/account_update.py\t5dc9b64 (commit)\n@@ -96,9 +96,15 @@\n         return super().perform_mutation(root, info, **data)\n \n     @classmethod\n     @traced_atomic_transaction()\n-    def save(cls, info: ResolveInfo, instance: models.User, cleaned_input):\n+    def save(\n+        cls,\n+        info: ResolveInfo,\n+        instance: models.User,\n+        cleaned_input,\n+        instance_tracker=None,\n+    ):\n         manager = get_plugin_manager_promise(info.context).get()\n \n         cls.save_default_addresses(cleaned_input=cleaned_input, user_instance=instance)\n \n"
        },
        {
          "path": "saleor/graphql/account/mutations/staff/customer_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/staff/customer_create.py\n===================================================================\n--- saleor/graphql/account/mutations/staff/customer_create.py\t7b108c3 (parent)\n+++ saleor/graphql/account/mutations/staff/customer_create.py\t5dc9b64 (commit)\n@@ -98,9 +98,9 @@\n                 raise\n \n     @classmethod\n     @traced_atomic_transaction()\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         addresses_to_set_on_user = []\n         if default_shipping_address := cleaned_input.get(SHIPPING_ADDRESS_FIELD):\n             addresses_to_set_on_user.append(default_shipping_address)\n             default_shipping_address.save()\n"
        },
        {
          "path": "saleor/graphql/account/mutations/staff/customer_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/staff/customer_update.py\n===================================================================\n--- saleor/graphql/account/mutations/staff/customer_update.py\t7b108c3 (parent)\n+++ saleor/graphql/account/mutations/staff/customer_update.py\t5dc9b64 (commit)\n@@ -165,9 +165,9 @@\n         return cls.success_response(new_instance)\n \n     @classmethod\n     @traced_atomic_transaction()\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         manager = get_plugin_manager_promise(info.context).get()\n \n         cls.save_default_addresses(\n             cleaned_input=cleaned_input,\n"
        },
        {
          "path": "saleor/graphql/app/mutations/app_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/mutations/app_create.py\n===================================================================\n--- saleor/graphql/app/mutations/app_create.py\t7b108c3 (parent)\n+++ saleor/graphql/app/mutations/app_create.py\t5dc9b64 (commit)\n@@ -89,9 +89,9 @@\n         cls.call_event(manager.app_installed, instance)\n         return response\n \n     @classmethod\n-    def save(cls, info, instance, cleaned_input):\n+    def save(cls, info, instance, cleaned_input, instance_tracker=None):\n         instance.save()\n         if not instance.identifier:\n             instance.identifier = graphene.Node.to_global_id(\"App\", instance.pk)\n             instance.save(update_fields=[\"identifier\"])\n"
        },
        {
          "path": "saleor/graphql/app/mutations/app_retry_install.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/mutations/app_retry_install.py\n===================================================================\n--- saleor/graphql/app/mutations/app_retry_install.py\t7b108c3 (parent)\n+++ saleor/graphql/app/mutations/app_retry_install.py\t5dc9b64 (commit)\n@@ -37,9 +37,11 @@\n             ),\n         ]\n \n     @classmethod\n-    def save(cls, _info: ResolveInfo, instance, _cleaned_input, /):\n+    def save(\n+        cls, _info: ResolveInfo, instance, _cleaned_input, /, instance_tracker=None\n+    ):\n         instance.status = JobStatus.PENDING\n         instance.save()\n \n     @classmethod\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_create.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_create.py\t7b108c3 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_create.py\t5dc9b64 (commit)\n@@ -461,9 +461,15 @@\n         cleaned_input[\"country\"] = country\n         return cleaned_input\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance: models.Checkout, cleaned_input):\n+    def save(\n+        cls,\n+        info: ResolveInfo,\n+        instance: models.Checkout,\n+        cleaned_input,\n+        instance_tracker=None,\n+    ):\n         with traced_atomic_transaction():\n             # Create the checkout object\n             instance.save()\n \n"
        },
        {
          "path": "saleor/graphql/core/mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/mutations.py\n===================================================================\n--- saleor/graphql/core/mutations.py\t7b108c3 (parent)\n+++ saleor/graphql/core/mutations.py\t5dc9b64 (commit)\n@@ -23,8 +23,9 @@\n from ...core.db.connection import allow_writer\n from ...core.exceptions import PermissionDenied\n from ...core.utils import metadata_manager\n from ...core.utils.events import call_event\n+from ...core.utils.update_mutation_manager import InstanceTracker\n from ...permission.auth_filters import AuthorizationFilters\n from ...permission.enums import BasePermissionEnum\n from ...permission.utils import (\n     all_permissions_required,\n@@ -655,8 +656,9 @@\n         arguments=None,\n         model=None,\n         return_field_name=None,\n         object_type=None,\n+        instance_tracker_fields=None,\n         _meta=None,\n         **options,\n     ):\n         if not model:\n@@ -672,11 +674,15 @@\n             return_field_name = get_model_name(model)\n         if arguments is None:\n             arguments = {}\n \n+        if instance_tracker_fields is None:\n+            instance_tracker_fields = []\n+\n         _meta.model = model\n         _meta.object_type = object_type\n         _meta.return_field_name = return_field_name\n+        _meta.instance_tracker_fields = instance_tracker_fields\n         super().__init_subclass_with_meta__(_meta=_meta, **options)\n \n         model_type = cls.get_type_for_model()\n         if not model_type:\n@@ -747,9 +753,16 @@\n         \"\"\"Return a success response.\"\"\"\n         return cls(**{cls._meta.return_field_name: instance, \"errors\": []})\n \n     @classmethod\n-    def save(cls, _info: ResolveInfo, instance, _cleaned_input, /):\n+    def save(\n+        cls,\n+        _info: ResolveInfo,\n+        instance,\n+        _cleaned_input,\n+        /,\n+        instance_tracker: InstanceTracker | None = None,\n+    ):\n         instance.save()\n \n     @classmethod\n     def diff_instance_data_fields(cls, fields, old_instance_data, new_instance_data):\n@@ -799,9 +812,15 @@\n         updates an existing one. If `id` argument is present, it is assumed\n         that this is an \"update\" mutation. Otherwise, a new instance is\n         created based on the model associated with this mutation.\n         \"\"\"\n+        instance_tracker = None\n         instance = cls.get_instance(info, **data)\n+        if cls._meta.instance_tracker_fields:\n+            instance_tracker = InstanceTracker(\n+                instance, cls._meta.instance_tracker_fields\n+            )\n+\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, instance, data)\n \n         metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n@@ -821,9 +840,9 @@\n         cls.validate_and_update_metadata(\n             instance, metadata_collection, private_metadata_collection\n         )\n         cls.clean_instance(info, instance)\n-        cls.save(info, instance, cleaned_input)\n+        cls.save(info, instance, cleaned_input, instance_tracker)\n         cls._save_m2m(info, instance, cleaned_input)\n \n         # add to cleaned_input popped metadata to allow running post save events\n         # that depends on the metadata inputs\n"
        },
        {
          "path": "saleor/graphql/order/mutations/draft_order_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_create.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_create.py\t7b108c3 (parent)\n+++ saleor/graphql/order/mutations/draft_order_create.py\t5dc9b64 (commit)\n@@ -387,9 +387,9 @@\n                 order_lines=lines,\n             )\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         manager = get_plugin_manager_promise(info.context).get()\n         app = get_app_promise(info.context).get()\n \n         with traced_atomic_transaction():\n"
        },
        {
          "path": "saleor/graphql/order/mutations/order_line_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/order_line_update.py\n===================================================================\n--- saleor/graphql/order/mutations/order_line_update.py\t7b108c3 (parent)\n+++ saleor/graphql/order/mutations/order_line_update.py\t5dc9b64 (commit)\n@@ -70,9 +70,9 @@\n \n         return cleaned_input\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         manager = get_plugin_manager_promise(info.context).get()\n \n         order_is_unconfirmed = instance.order.is_unconfirmed()\n         line_allocation = instance.allocations.first()\n"
        },
        {
          "path": "saleor/graphql/page/bulk_mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/bulk_mutations.py\n===================================================================\n--- saleor/graphql/page/bulk_mutations.py\t7b108c3 (parent)\n+++ saleor/graphql/page/bulk_mutations.py\t5dc9b64 (commit)\n@@ -1,15 +1,17 @@\n import graphene\n from django.core.exceptions import ValidationError\n from django.db import transaction\n-from django.db.models.expressions import Exists, OuterRef\n+from django.db.models import Exists, OuterRef\n \n from ...attribute import AttributeInputType\n from ...attribute import models as attribute_models\n from ...attribute.lock_objects import attribute_value_qs_select_for_update\n from ...core.tracing import traced_atomic_transaction\n from ...page import models\n from ...permission.enums import PagePermissions, PageTypePermissions\n+from ...product.lock_objects import product_qs_select_for_update\n+from ...product.models import Product\n from ...webhook.event_types import WebhookEventAsyncType\n from ...webhook.utils import get_webhooks_for_event\n from ..core import ResolveInfo\n from ..core.mutations import BaseBulkMutation, ModelBulkDeleteMutation\n@@ -41,12 +43,33 @@\n             pks = cls.get_global_ids_or_error(ids, only_type=Page, field=\"pk\")\n         except ValidationError as error:\n             return 0, error\n         cls.delete_assigned_attribute_values(pks)\n+        cls.update_products_search_index(pks)\n         return super().perform_mutation(_root, info, ids=ids)\n \n-    @staticmethod\n-    def delete_assigned_attribute_values(instance_pks):\n+    @classmethod\n+    def update_products_search_index(cls, instance_pks):\n+        # Mark products that use these page instances as references as dirty\n+        with transaction.atomic():\n+            locked_ids = (\n+                product_qs_select_for_update()\n+                .filter(\n+                    Exists(\n+                        attribute_models.AssignedProductAttributeValue.objects.filter(\n+                            product_id=OuterRef(\"id\"),\n+                            value__in=attribute_models.AttributeValue.objects.filter(\n+                                reference_page__in=instance_pks\n+                            ),\n+                        )\n+                    )\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            Product.objects.filter(id__in=locked_ids).update(search_index_dirty=True)\n+\n+    @classmethod\n+    def delete_assigned_attribute_values(cls, instance_pks):\n         assigned_values = attribute_models.AssignedPageAttributeValue.objects.filter(\n             page_id__in=instance_pks\n         )\n         attributes = attribute_models.Attribute.objects.filter(\n@@ -115,12 +138,37 @@\n         try:\n             pks = cls.get_global_ids_or_error(ids, only_type=PageType, field=\"pk\")\n         except ValidationError as error:\n             return 0, error\n+        cls.update_products_search_index(pks)\n         cls.delete_assigned_attribute_values(pks)\n         return super().perform_mutation(_root, info, ids=ids)\n \n     @classmethod\n+    def update_products_search_index(cls, instance_pks):\n+        # Mark products that use pages belonging to these page types as reference as\n+        # dirty\n+        page_ids = models.Page.objects.filter(page_type__in=instance_pks).values_list(\n+            \"id\", flat=True\n+        )\n+        with transaction.atomic():\n+            locked_ids = (\n+                product_qs_select_for_update()\n+                .filter(\n+                    Exists(\n+                        attribute_models.AssignedProductAttributeValue.objects.filter(\n+                            product_id=OuterRef(\"id\"),\n+                            value__in=attribute_models.AttributeValue.objects.filter(\n+                                reference_page_id__in=page_ids\n+                            ),\n+                        )\n+                    )\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            Product.objects.filter(id__in=locked_ids).update(search_index_dirty=True)\n+\n+    @classmethod\n     def bulk_action(cls, info: ResolveInfo, queryset, /):\n         page_types = list(queryset)\n         queryset.delete()\n         manager = get_plugin_manager_promise(info.context).get()\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_create.py\n===================================================================\n--- saleor/graphql/page/mutations/page_create.py\t7b108c3 (parent)\n+++ saleor/graphql/page/mutations/page_create.py\t5dc9b64 (commit)\n@@ -130,9 +130,9 @@\n             if attributes:\n                 AttributeAssignmentMixin.save(instance, attributes)\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         super().save(info, instance, cleaned_input)\n         manager = get_plugin_manager_promise(info.context).get()\n         cls.call_event(manager.page_created, instance)\n \n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_delete.py\n===================================================================\n--- saleor/graphql/page/mutations/page_delete.py\t7b108c3 (parent)\n+++ saleor/graphql/page/mutations/page_delete.py\t5dc9b64 (commit)\n@@ -1,12 +1,15 @@\n import graphene\n+from django.db import transaction\n from django.db.models.expressions import Exists, OuterRef\n \n from ....attribute import AttributeInputType\n from ....attribute import models as attribute_models\n from ....core.tracing import traced_atomic_transaction\n from ....page import models\n from ....permission.enums import PagePermissions\n+from ....product.lock_objects import product_qs_select_for_update\n+from ....product.models import Product\n from ...core import ResolveInfo\n from ...core.context import ChannelContext\n from ...core.mutations import ModelDeleteMutation\n from ...core.types import PageError\n@@ -32,14 +35,35 @@\n         manager = get_plugin_manager_promise(info.context).get()\n         page_type = page.page_type\n         with traced_atomic_transaction():\n             cls.delete_assigned_attribute_values(page)\n+            cls.update_products_search_index(page)\n             response = super().perform_mutation(_root, info, **data)\n             page.page_type = page_type\n             cls.call_event(manager.page_deleted, page)\n         response.page = ChannelContext(page, channel_slug=None)\n         return response\n \n+    @classmethod\n+    def update_products_search_index(cls, instance):\n+        # Mark products that use this instance as reference as dirty\n+        with transaction.atomic():\n+            locked_ids = (\n+                product_qs_select_for_update()\n+                .filter(\n+                    Exists(\n+                        attribute_models.AssignedProductAttributeValue.objects.filter(\n+                            value__in=attribute_models.AttributeValue.objects.filter(\n+                                reference_page=instance\n+                            ),\n+                            product_id=OuterRef(\"id\"),\n+                        )\n+                    )\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            Product.objects.filter(id__in=locked_ids).update(search_index_dirty=True)\n+\n     @staticmethod\n     def delete_assigned_attribute_values(instance):\n         assigned_values = attribute_models.AssignedPageAttributeValue.objects.filter(\n             page_id=instance.pk\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_type_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_type_delete.py\n===================================================================\n--- saleor/graphql/page/mutations/page_type_delete.py\t7b108c3 (parent)\n+++ saleor/graphql/page/mutations/page_type_delete.py\t5dc9b64 (commit)\n@@ -1,12 +1,15 @@\n import graphene\n+from django.db import transaction\n from django.db.models.expressions import Exists, OuterRef\n \n from ....attribute import AttributeInputType\n from ....attribute import models as attribute_models\n from ....core.tracing import traced_atomic_transaction\n from ....page import models\n from ....permission.enums import PageTypePermissions\n+from ....product.lock_objects import product_qs_select_for_update\n+from ....product.models import Product\n from ...core import ResolveInfo\n from ...core.mutations import ModelDeleteMutation\n from ...core.types import PageError\n from ...plugins.dataloaders import get_plugin_manager_promise\n@@ -31,10 +34,34 @@\n     ):\n         page_type_pk = cls.get_global_id_or_error(id, only_type=PageType, field=\"pk\")\n         with traced_atomic_transaction():\n             cls.delete_assigned_attribute_values(page_type_pk)\n+            cls.update_products_search_index(page_type_pk)\n             return super().perform_mutation(_root, info, id=id)\n \n+    @classmethod\n+    def update_products_search_index(cls, instance):\n+        # Mark products that use pages belonging to this page type as reference as dirty\n+        page_ids = models.Page.objects.filter(page_type=instance).values_list(\n+            \"id\", flat=True\n+        )\n+        with transaction.atomic():\n+            locked_ids = (\n+                product_qs_select_for_update()\n+                .filter(\n+                    Exists(\n+                        attribute_models.AssignedProductAttributeValue.objects.filter(\n+                            product_id=OuterRef(\"id\"),\n+                            value__in=attribute_models.AttributeValue.objects.filter(\n+                                reference_page_id__in=page_ids\n+                            ),\n+                        )\n+                    )\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            Product.objects.filter(id__in=locked_ids).update(search_index_dirty=True)\n+\n     @staticmethod\n     def delete_assigned_attribute_values(instance_pk):\n         assigned_values = attribute_models.AssignedPageAttributeValue.objects.filter(\n             page__page_type_id=instance_pk\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_update.py\n===================================================================\n--- saleor/graphql/page/mutations/page_update.py\t7b108c3 (parent)\n+++ saleor/graphql/page/mutations/page_update.py\t5dc9b64 (commit)\n@@ -1,8 +1,14 @@\n import graphene\n+from django.db import transaction\n+from django.db.models import Exists, OuterRef\n \n+from ....attribute import models as attribute_models\n+from ....core.utils.update_mutation_manager import InstanceTracker\n from ....page import models\n from ....permission.enums import PagePermissions\n+from ....product.lock_objects import product_qs_select_for_update\n+from ....product.models import Product\n from ...attribute.utils.attribute_assignment import AttributeAssignmentMixin\n from ...core import ResolveInfo\n from ...core.context import ChannelContext\n from ...core.types import PageError\n@@ -24,8 +30,11 @@\n         object_type = Page\n         permissions = (PagePermissions.MANAGE_PAGES,)\n         error_type_class = PageError\n         error_type_field = \"page_errors\"\n+        instance_tracker_fields = [\n+            \"title\",\n+        ]\n \n     @classmethod\n     def clean_attributes(cls, attributes: list[dict], page_type: models.PageType):\n         attributes_qs = page_type.page_attributes.prefetch_related(\"values\")\n@@ -34,14 +43,45 @@\n         )\n         return cleaned_attributes\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(\n+        cls,\n+        info: ResolveInfo,\n+        instance,\n+        cleaned_input,\n+        instance_tracker: InstanceTracker | None = None,\n+    ):\n         super(PageCreate, cls).save(info, instance, cleaned_input)\n         manager = get_plugin_manager_promise(info.context).get()\n         cls.call_event(manager.page_updated, instance)\n \n+        if instance_tracker is not None:\n+            modified_instance_fields = instance_tracker.get_modified_fields()\n+            if \"title\" in modified_instance_fields:\n+                cls.update_products_search_index(instance)\n+\n     @classmethod\n+    def update_products_search_index(cls, instance):\n+        # Mark products that use this instance as reference as dirty\n+        with transaction.atomic():\n+            locked_ids = (\n+                product_qs_select_for_update()\n+                .filter(\n+                    Exists(\n+                        attribute_models.AssignedProductAttributeValue.objects.filter(\n+                            value__in=attribute_models.AttributeValue.objects.filter(\n+                                reference_page=instance\n+                            ),\n+                            product_id=OuterRef(\"id\"),\n+                        )\n+                    )\n+                )\n+                .values_list(\"id\", flat=True)\n+            )\n+            Product.objects.filter(id__in=locked_ids).update(search_index_dirty=True)\n+\n+    @classmethod\n     def success_response(cls, instance):\n         response = super().success_response(instance)\n         response.page = ChannelContext(instance, channel_slug=None)\n         return response\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_bulk_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_bulk_delete.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_bulk_delete.py\t7b108c3 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_bulk_delete.py\t5dc9b64 (commit)\n@@ -3,8 +3,9 @@\n \n from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.models import Page\n+from .....product.search import update_products_search_vector\n from ....tests.utils import get_graphql_content\n \n PAGE_BULK_DELETE_MUTATION = \"\"\"\n     mutation pageBulkDelete($ids: [ID!]!) {\n@@ -211,4 +212,65 @@\n     content = get_graphql_content(response)\n     errors = content[\"data\"][\"pageBulkDelete\"][\"errors\"][0]\n \n     assert errors[\"code\"] == \"GRAPHQL_ERROR\"\n+\n+\n+def test_page_bulk_delete_reference_attribute_sets_search_index_dirty_in_product(\n+    product_type_page_reference_attribute,\n+    page,\n+    product,\n+    staff_api_client,\n+    permission_manage_pages,\n+):\n+    # given\n+    query = PAGE_BULK_DELETE_MUTATION\n+\n+    # Set up page reference attribute\n+    attribute = product_type_page_reference_attribute\n+    product.product_type.product_attributes.add(attribute)\n+    page.title = \"Brand\"\n+    page.save(update_fields=[\"title\"])\n+\n+    attr_value = AttributeValue.objects.create(\n+        attribute=attribute,\n+        name=page.title,\n+        slug=f\"{product.pk}_{page.pk}\",\n+        reference_page=page,\n+    )\n+\n+    associate_attribute_values_to_instance(product, {attribute.pk: [attr_value]})\n+\n+    # Ensure product search index is initially clean\n+    product.search_index_dirty = False\n+    product.save(update_fields=[\"search_index_dirty\"])\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() in product.search_vector\n+\n+    # when\n+    page_id = graphene.Node.to_global_id(\"Page\", page.pk)\n+    variables = {\"ids\": [page_id]}\n+    response = staff_api_client.post_graphql(\n+        query, variables, permissions=[permission_manage_pages]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"pageBulkDelete\"]\n+\n+    # Check that page was deleted\n+    with pytest.raises(page._meta.model.DoesNotExist):\n+        page.refresh_from_db()\n+\n+    # Check that attribute value was deleted\n+    with pytest.raises(attr_value._meta.model.DoesNotExist):\n+        attr_value.refresh_from_db()\n+\n+    # Check that product search_index_dirty flag was set to True\n+    product.refresh_from_db(fields=[\"search_index_dirty\"])\n+    assert product.search_index_dirty is True\n+    assert not data[\"errors\"]\n+\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() not in product.search_vector\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_delete.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_delete.py\t7b108c3 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_delete.py\t5dc9b64 (commit)\n@@ -7,8 +7,9 @@\n from django.utils.functional import SimpleLazyObject\n \n from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n+from .....product.search import update_products_search_vector\n from .....webhook.event_types import WebhookEventAsyncType\n from ....tests.utils import get_graphql_content\n \n PAGE_DELETE_MUTATION = \"\"\"\n@@ -256,4 +257,65 @@\n     with pytest.raises(page_ref._meta.model.DoesNotExist):\n         page_ref.refresh_from_db()\n \n     assert not data[\"errors\"]\n+\n+\n+def test_page_delete_reference_attribute_sets_search_index_dirty_in_product(\n+    product_type_page_reference_attribute,\n+    page,\n+    product,\n+    staff_api_client,\n+    permission_manage_pages,\n+):\n+    # given\n+    query = PAGE_DELETE_MUTATION\n+\n+    # Set up page reference attribute\n+    attribute = product_type_page_reference_attribute\n+    product.product_type.product_attributes.add(attribute)\n+    page.title = \"Brand\"\n+    page.save(update_fields=[\"title\"])\n+\n+    attr_value = AttributeValue.objects.create(\n+        attribute=attribute,\n+        name=page.title,\n+        slug=f\"{product.pk}_{page.pk}\",\n+        reference_page=page,\n+    )\n+\n+    associate_attribute_values_to_instance(product, {attribute.pk: [attr_value]})\n+\n+    # Ensure product search index is initially clean\n+    product.search_index_dirty = False\n+    product.save(update_fields=[\"search_index_dirty\"])\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() in product.search_vector\n+\n+    # when\n+    page_id = graphene.Node.to_global_id(\"Page\", page.pk)\n+    variables = {\"id\": page_id}\n+    response = staff_api_client.post_graphql(\n+        query, variables, permissions=[permission_manage_pages]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"pageDelete\"]\n+\n+    # Check that page was deleted\n+    with pytest.raises(page._meta.model.DoesNotExist):\n+        page.refresh_from_db()\n+\n+    # Check that attribute value was deleted\n+    with pytest.raises(attr_value._meta.model.DoesNotExist):\n+        attr_value.refresh_from_db()\n+\n+    # Check that product search_index_dirty flag was set to True\n+    product.refresh_from_db(fields=[\"search_index_dirty\"])\n+    assert product.search_index_dirty is True\n+    assert not data[\"errors\"]\n+\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() not in product.search_vector\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_type_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_type_delete.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_type_delete.py\t7b108c3 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_type_delete.py\t5dc9b64 (commit)\n@@ -5,11 +5,13 @@\n import pytest\n from django.utils.functional import SimpleLazyObject\n from freezegun import freeze_time\n \n+from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....core.utils.json_serializer import CustomJsonEncoder\n from .....page.models import Page\n+from .....product.search import update_products_search_vector\n from .....webhook.event_types import WebhookEventAsyncType\n from .....webhook.payloads import generate_meta, generate_requestor\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n@@ -213,4 +215,72 @@\n     with pytest.raises(page_type._meta.model.DoesNotExist):\n         page_type.refresh_from_db()\n     with pytest.raises(value._meta.model.DoesNotExist):\n         value.refresh_from_db()\n+\n+\n+def test_page_type_delete_sets_search_index_dirty_in_product_with_page_reference(\n+    staff_api_client,\n+    page_type,\n+    page,\n+    product,\n+    product_type_page_reference_attribute,\n+    permission_manage_page_types_and_attributes,\n+):\n+    # given\n+    # Set up page reference attribute\n+    attribute = product_type_page_reference_attribute\n+    product.product_type.product_attributes.add(attribute)\n+    page.title = \"Brand\"\n+    page.save(update_fields=[\"title\"])\n+\n+    attr_value = AttributeValue.objects.create(\n+        attribute=attribute,\n+        name=page.title,\n+        slug=f\"{product.pk}_{page.pk}\",\n+        reference_page=page,\n+    )\n+\n+    associate_attribute_values_to_instance(product, {attribute.pk: [attr_value]})\n+\n+    # Ensure product search index is initially clean\n+    product.search_index_dirty = False\n+    product.save(update_fields=[\"search_index_dirty\"])\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() in product.search_vector\n+\n+    # when\n+    page_type_id = graphene.Node.to_global_id(\"PageType\", page_type.pk)\n+    variables = {\"id\": page_type_id}\n+    staff_api_client.user.user_permissions.add(\n+        permission_manage_page_types_and_attributes\n+    )\n+    response = staff_api_client.post_graphql(DELETE_PAGE_TYPE_MUTATION, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"pageTypeDelete\"]\n+\n+    assert not data[\"errors\"]\n+    assert data[\"pageType\"][\"id\"] == page_type_id\n+\n+    # Check that page type was deleted\n+    with pytest.raises(page_type._meta.model.DoesNotExist):\n+        page_type.refresh_from_db()\n+\n+    # Check that page was deleted (cascade from page type)\n+    with pytest.raises(page._meta.model.DoesNotExist):\n+        page.refresh_from_db()\n+\n+    # Check that attribute value was deleted\n+    with pytest.raises(attr_value._meta.model.DoesNotExist):\n+        attr_value.refresh_from_db()\n+\n+    # Check that product search_index_dirty flag was set to True\n+    product.refresh_from_db(fields=[\"search_index_dirty\"])\n+    assert product.search_index_dirty is True\n+\n+    # Verify search vector no longer contains the deleted page title\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() not in product.search_vector\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_types_bulk_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_types_bulk_delete.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_types_bulk_delete.py\t7b108c3 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_types_bulk_delete.py\t5dc9b64 (commit)\n@@ -2,10 +2,12 @@\n \n import graphene\n import pytest\n \n+from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.models import Page\n+from .....product.search import update_products_search_vector\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n PAGE_TYPE_BULK_DELETE_MUTATION = \"\"\"\n     mutation PageTypeBulkDelete($ids: [ID!]!) {\n@@ -232,4 +234,80 @@\n     content = get_graphql_content(response)\n     errors = content[\"data\"][\"pageTypeBulkDelete\"][\"errors\"][0]\n \n     assert errors[\"code\"] == \"GRAPHQL_ERROR\"\n+\n+\n+def test_page_type_bulk_delete_sets_search_index_dirty_in_product_with_page_reference(\n+    staff_api_client,\n+    page_type_list,\n+    product,\n+    product_type_page_reference_attribute,\n+    permission_manage_page_types_and_attributes,\n+):\n+    # given\n+    # Set up page reference attribute\n+    attribute = product_type_page_reference_attribute\n+    product.product_type.product_attributes.add(attribute)\n+\n+    # Use the first page type and create a page with a specific title\n+    page_type = page_type_list[0]\n+    page = Page.objects.filter(page_type=page_type).first()\n+    page.title = \"Brand\"\n+    page.save(update_fields=[\"title\"])\n+\n+    attr_value = AttributeValue.objects.create(\n+        attribute=attribute,\n+        name=page.title,\n+        slug=f\"{product.pk}_{page.pk}\",\n+        reference_page=page,\n+    )\n+\n+    associate_attribute_values_to_instance(product, {attribute.pk: [attr_value]})\n+\n+    # Ensure product search index is initially clean\n+    product.search_index_dirty = False\n+    product.save(update_fields=[\"search_index_dirty\"])\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() in product.search_vector\n+\n+    # when\n+    variables = {\n+        \"ids\": [\n+            graphene.Node.to_global_id(\"PageType\", page_type.pk)\n+            for page_type in page_type_list\n+        ]\n+    }\n+    staff_api_client.user.user_permissions.add(\n+        permission_manage_page_types_and_attributes\n+    )\n+    response = staff_api_client.post_graphql(PAGE_TYPE_BULK_DELETE_MUTATION, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"pageTypeBulkDelete\"]\n+\n+    assert not data[\"errors\"]\n+    assert data[\"count\"] == len(page_type_list)\n+\n+    # Check that page types were deleted\n+    for page_type in page_type_list:\n+        with pytest.raises(page_type._meta.model.DoesNotExist):\n+            page_type.refresh_from_db()\n+\n+    # Check that page was deleted (cascade from page type)\n+    with pytest.raises(page._meta.model.DoesNotExist):\n+        page.refresh_from_db()\n+\n+    # Check that attribute value was deleted\n+    with pytest.raises(attr_value._meta.model.DoesNotExist):\n+        attr_value.refresh_from_db()\n+\n+    # Check that product search_index_dirty flag was set to True\n+    product.refresh_from_db(fields=[\"search_index_dirty\"])\n+    assert product.search_index_dirty is True\n+\n+    # Verify search vector no longer contains the deleted page title\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert page.title.lower() not in product.search_vector\n"
        },
        {
          "path": "saleor/graphql/page/tests/mutations/test_page_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/mutations/test_page_update.py\n===================================================================\n--- saleor/graphql/page/tests/mutations/test_page_update.py\t7b108c3 (parent)\n+++ saleor/graphql/page/tests/mutations/test_page_update.py\t5dc9b64 (commit)\n@@ -18,8 +18,9 @@\n )\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.error_codes import PageErrorCode\n from .....page.models import Page\n+from .....product.search import update_products_search_vector\n from .....tests.utils import dummy_editorjs\n from .....webhook.event_types import WebhookEventAsyncType\n from ....core.utils import to_global_id_or_none\n from ....tests.utils import get_graphql_content\n@@ -1462,4 +1463,67 @@\n     assert numeric_attribute.values.filter(\n         name=numeric_name,\n         numeric=numeric_value,\n     ).exists()\n+\n+\n+def test_page_update_reference_attribute_sets_search_index_dirty_in_product(\n+    staff_api_client,\n+    page,\n+    product,\n+    product_type_page_reference_attribute,\n+    permission_manage_pages,\n+):\n+    # given\n+    query = UPDATE_PAGE_MUTATION\n+    page_id = graphene.Node.to_global_id(\"Page\", page.id)\n+\n+    old_title = \"Brand\"\n+    page.title = old_title\n+    page.save(update_fields=[\"title\"])\n+\n+    # Set up page reference attribute\n+    attribute = product_type_page_reference_attribute\n+    attribute_value = AttributeValue.objects.create(\n+        attribute=attribute,\n+        name=page.title,\n+        slug=f\"{page.pk}_{page.id}\",\n+        reference_page=page,\n+    )\n+    product.product_type.product_attributes.add(attribute)\n+    associate_attribute_values_to_instance(product, {attribute.id: [attribute_value]})\n+\n+    # Ensure product search index is initially clean\n+    product.search_index_dirty = False\n+    product.save(update_fields=[\"search_index_dirty\"])\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    assert old_title.lower() in product.search_vector\n+\n+    # when\n+    new_title = \"Extra Brand\"\n+    variables = {\n+        \"id\": page_id,\n+        \"input\": {\"title\": new_title},\n+    }\n+    response = staff_api_client.post_graphql(\n+        query, variables, permissions=[permission_manage_pages]\n+    )\n+\n+    # then\n+    data = get_graphql_content(response)\n+    assert not data[\"data\"][\"pageUpdate\"][\"errors\"]\n+\n+    # Check that page was updated\n+    page.refresh_from_db()\n+    assert page.title == new_title\n+\n+    # Check that product search_index_dirty flag was set to True\n+    product.refresh_from_db()\n+    update_products_search_vector([product.id])\n+    product.refresh_from_db()\n+    updated_search_vector = str(product.search_vector)\n+\n+    # Verify search vector now contains the new page title\n+    assert \"extra\" in updated_search_vector\n+    # Verify search index dirty flag is reset\n+    assert product.search_index_dirty is False\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product/product_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product/product_create.py\n===================================================================\n--- saleor/graphql/product/mutations/product/product_create.py\t7b108c3 (parent)\n+++ saleor/graphql/product/mutations/product/product_create.py\t5dc9b64 (commit)\n@@ -166,9 +166,9 @@\n             except ValidationError as e:\n                 raise ValidationError({\"attributes\": e}) from e\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         with traced_atomic_transaction():\n             instance.search_index_dirty = True\n             instance.save()\n             attributes = cleaned_input.get(\"attributes\")\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product/product_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product/product_update.py\n===================================================================\n--- saleor/graphql/product/mutations/product/product_update.py\t7b108c3 (parent)\n+++ saleor/graphql/product/mutations/product/product_update.py\t5dc9b64 (commit)\n@@ -107,9 +107,9 @@\n             instance, metadata_collection, private_metadata_collection\n         )\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         with traced_atomic_transaction():\n             instance.search_index_dirty = True\n             instance.save()\n             attributes = cleaned_input.get(\"attributes\")\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_type/product_type_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_type/product_type_update.py\n===================================================================\n--- saleor/graphql/product/mutations/product_type/product_type_update.py\t7b108c3 (parent)\n+++ saleor/graphql/product/mutations/product_type/product_type_update.py\t5dc9b64 (commit)\n@@ -28,9 +28,9 @@\n     def clean_product_kind(cls, instance, data):\n         return data.get(\"kind\", instance.kind)\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         variant_attr = cleaned_input.get(\"variant_attributes\")\n         if variant_attr:\n             variant_attr = set(variant_attr)\n             variant_attr_ids = [attr.pk for attr in variant_attr]\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_create.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_create.py\t7b108c3 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_create.py\t5dc9b64 (commit)\n@@ -245,9 +245,9 @@\n                 else track_inventory\n             )\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         new_variant = instance.pk is None\n         cls.set_track_inventory(info, instance, cleaned_input)\n         with traced_atomic_transaction():\n             instance.save()\n"
        },
        {
          "path": "saleor/graphql/shipping/mutations/base.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/shipping/mutations/base.py\n===================================================================\n--- saleor/graphql/shipping/mutations/base.py\t7b108c3 (parent)\n+++ saleor/graphql/shipping/mutations/base.py\t5dc9b64 (commit)\n@@ -401,9 +401,9 @@\n                 error_msg, code=ShippingErrorCode.INVALID.value\n             )\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         with traced_atomic_transaction():\n             super().save(info, instance, cleaned_input)  # type: ignore[misc] # mixin\n \n             delete_postal_code_rules = cleaned_input.get(\"delete_postal_code_rules\")\n"
        },
        {
          "path": "saleor/graphql/tax/mutations/tax_class_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/tax/mutations/tax_class_create.py\n===================================================================\n--- saleor/graphql/tax/mutations/tax_class_create.py\t7b108c3 (parent)\n+++ saleor/graphql/tax/mutations/tax_class_create.py\t5dc9b64 (commit)\n@@ -74,8 +74,8 @@\n         ]\n         models.TaxClassCountryRate.objects.bulk_create(to_create)\n \n     @classmethod\n-    def save(cls, _info, instance, cleaned_input):\n+    def save(cls, _info, instance, cleaned_input, instance_tracker=None):\n         instance.save()\n         create_country_rates = cleaned_input.get(\"create_country_rates\", [])\n         cls.create_country_rates(instance, create_country_rates)\n"
        },
        {
          "path": "saleor/graphql/tax/mutations/tax_class_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/tax/mutations/tax_class_update.py\n===================================================================\n--- saleor/graphql/tax/mutations/tax_class_update.py\t7b108c3 (parent)\n+++ saleor/graphql/tax/mutations/tax_class_update.py\t5dc9b64 (commit)\n@@ -137,9 +137,9 @@\n     def remove_country_rates(cls, country_codes):\n         models.TaxClassCountryRate.objects.filter(country__in=country_codes).delete()\n \n     @classmethod\n-    def save(cls, _info, instance, cleaned_input):\n+    def save(cls, _info, instance, cleaned_input, instance_tracker=None):\n         instance.save()\n         update_country_rates = cleaned_input.get(\"update_country_rates\", [])\n         remove_country_rates = cleaned_input.get(\"remove_country_rates\", [])\n         cls.update_country_rates(instance, update_country_rates)\n"
        },
        {
          "path": "saleor/graphql/tax/mutations/tax_configuration_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/tax/mutations/tax_configuration_update.py\n===================================================================\n--- saleor/graphql/tax/mutations/tax_configuration_update.py\t7b108c3 (parent)\n+++ saleor/graphql/tax/mutations/tax_configuration_update.py\t5dc9b64 (commit)\n@@ -367,9 +367,9 @@\n             country__in=country_codes\n         ).delete()\n \n     @classmethod\n-    def save(cls, _info, instance, cleaned_input):\n+    def save(cls, _info, instance, cleaned_input, instance_tracker=None):\n         instance.save()\n         update_countries_configuration = cleaned_input.get(\n             \"update_countries_configuration\", []\n         )\n"
        },
        {
          "path": "saleor/graphql/webhook/mutations/webhook_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/mutations/webhook_create.py\n===================================================================\n--- saleor/graphql/webhook/mutations/webhook_create.py\t7b108c3 (parent)\n+++ saleor/graphql/webhook/mutations/webhook_create.py\t5dc9b64 (commit)\n@@ -177,9 +177,9 @@\n         instance.app = app\n         return instance\n \n     @classmethod\n-    def save(cls, _info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, _info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         instance.save()\n         events = set(cleaned_input.get(\"events\", []))\n         models.WebhookEvent.objects.bulk_create(\n             [\n"
        },
        {
          "path": "saleor/graphql/webhook/mutations/webhook_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/mutations/webhook_update.py\n===================================================================\n--- saleor/graphql/webhook/mutations/webhook_update.py\t7b108c3 (parent)\n+++ saleor/graphql/webhook/mutations/webhook_update.py\t5dc9b64 (commit)\n@@ -88,9 +88,9 @@\n         error_type_class = WebhookError\n         error_type_field = \"webhook_errors\"\n \n     @classmethod\n-    def save(cls, _info: ResolveInfo, instance, cleaned_input):\n+    def save(cls, _info: ResolveInfo, instance, cleaned_input, instance_tracker=None):\n         instance.save()\n         events = set(cleaned_input.get(\"events\", []))\n         cls.validate_events(events)\n         if events:\n"
        },
        {
          "path": "saleor/product/lock_objects.py",
          "status": "added",
          "diff": "Index: saleor/product/lock_objects.py\n===================================================================\n--- saleor/product/lock_objects.py\t7b108c3 (parent)\n+++ saleor/product/lock_objects.py\t5dc9b64 (commit)\n@@ -0,0 +1,7 @@\n+from django.db.models import QuerySet\n+\n+from .models import Product\n+\n+\n+def product_qs_select_for_update() -> QuerySet[Product]:\n+    return Product.objects.order_by(\"pk\").select_for_update(of=([\"self\"]))\n"
        },
        {
          "path": "saleor/product/search.py",
          "status": "modified",
          "diff": "Index: saleor/product/search.py\n===================================================================\n--- saleor/product/search.py\t7b108c3 (parent)\n+++ saleor/product/search.py\t5dc9b64 (commit)\n@@ -6,9 +6,9 @@\n from django.contrib.postgres.search import SearchQuery, SearchRank\n from django.db.models import F, Q, Value, prefetch_related_objects\n \n from ..attribute import AttributeInputType\n-from ..attribute.models import Attribute\n+from ..attribute.models import Attribute, AttributeValue\n from ..core.postgres import FlatConcatSearchVector, NoValidationSearchVector\n from ..core.utils.editorjs import clean_editor_js\n from ..product.models import Product\n \n@@ -212,11 +212,32 @@\n                 weight=\"B\",\n             )\n             for value in values\n         ]\n+    elif input_type in [\n+        AttributeInputType.REFERENCE,\n+        AttributeInputType.SINGLE_REFERENCE,\n+    ]:\n+        # for now only AttributeEntityType.PAGE is supported\n+        search_vectors += [\n+            NoValidationSearchVector(\n+                Value(get_reference_attribute_search_value(value)),\n+                config=\"simple\",\n+                weight=\"B\",\n+            )\n+            for value in values\n+            if value.reference_page_id is not None\n+        ]\n     return search_vectors\n \n \n+def get_reference_attribute_search_value(attribute_value: AttributeValue) -> str:\n+    \"\"\"Get search value for reference attribute.\"\"\"\n+    if attribute_value.reference_page:\n+        return attribute_value.reference_page.title\n+    return \"\"\n+\n+\n def search_products(qs, value):\n     if value:\n         query = SearchQuery(value, search_type=\"websearch\", config=\"simple\")\n         lookup = Q(search_vector=query)\n"
        }
      ]
    },
    {
      "id": "add-reference-filters",
      "sha": "836d01d8429ff250a78abbc5439743c28bc1f772",
      "parentSha": "f3c1a9678d36c934c9295ce557c409cb1279c79f",
      "spec": "Implement reference-based attribute filtering for pages with containsAny/containsAll semantics and update schema, validations, and fixtures.\n\nRequirements\n1) GraphQL input types\n- Add a new input type ContainsFilterInput with two optional fields: containsAny: [String!] and containsAll: [String!]. Describe them as: containsAny = field contains at least one of the specified values, containsAll = contains all of the specified values.\n- Add a new input type ReferenceAttributeWhereInput exposing four optional fields (all of type ContainsFilterInput):\n  - referencedIds: filter by referenced objects using global Relay IDs for Page, Product, and ProductVariant nodes.\n  - pageSlugs: filter by referenced Page slugs.\n  - productSlugs: filter by referenced Product slugs.\n  - productVariantSkus: filter by referenced ProductVariant SKUs.\n- Extend AttributeValuePageInput to include reference: ReferenceAttributeWhereInput (optional), with description \"Filter by reference attribute value.\".\n- Ensure these types appear in the schema and are referenced by PageWhereInput -> attributes[].value.reference.\n\n2) Filtering behavior\n- In page filtering (PageWhere/filters), extend the attribute value filtering pipeline to handle AttributeInputType.REFERENCE. When an attribute with input_type=REFERENCE is filtered via attributes[].value.reference, it must support the following keys (independently or in combination): referencedIds, pageSlugs, productSlugs, productVariantSkus.\n- For each key, support both containsAny and containsAll operators, mutually exclusive per key:\n  - containsAny: return pages having at least one attribute value referencing any of the provided identifiers.\n  - containsAll: return pages having attribute values referencing all provided identifiers (logical AND across the values).\n- Implement the above without requiring the attribute to be unique; pages can have multiple values. Use efficient subqueries (Exists/OuterRef) against AttributeValue and AssignedPageAttributeValue to express both operators.\n- Identifier resolution:\n  - referencedIds: accept a list of global Relay IDs (Page, Product, ProductVariant). Resolve to underlying models and IDs; combine filters for different entity types with OR for containsAny and AND for containsAll.\n  - pageSlugs: resolve to Page by slug.\n  - productSlugs: resolve to Product by slug.\n  - productVariantSkus: resolve to ProductVariant by sku.\n- Scope by attribute when attr_id is provided: only consider AttributeValue rows tied to that attribute. Otherwise, accept any reference values of the given type present on the page.\n\n3) Reusable filtering helpers\n- Introduce reusable helper functions in GraphQL attribute filtering module to build Q expressions using Exists/OuterRef, parameterized by:\n  - db connection name, assigned attribute model (AssignedPageAttributeValue), assigned id field (page_id), AttributeValue reference field (reference_page_id/reference_product_id/reference_variant_id), and identifier field used to match the referenced model (slug/id/sku).\n- Provide separate helpers for the three reference types (pages, products, variants) and one for global object IDs that handles mixed types, returning a combined Q expression that can be AND/OR composed as per containsAll/containsAny rules.\n\n4) Input validation\n- Extend page attribute where input validation to handle reference values:\n  - Reject null or empty reference input (the value for reference must not be null or empty).\n  - For each sub-key (referencedIds/pageSlugs/productSlugs/productVariantSkus), disallow providing both containsAll and containsAny simultaneously. Raise a GraphQLError indicating the offending fields.\n  - Disallow empty lists or null for containsAll/containsAny. Raise a GraphQLError indicating offending fields and that values cannot be null or empty.\n  - If a value.reference filter is used for a non-REFERENCE attribute, raise validation error for incorrect input type.\n\n5) Imports and consistency\n- Update imports for product/page models with explicit modules (e.g., from ...product import models as product_models, from ...page import models as page_models).\n- Adjust GraphQL core type imports to use ..core.types.base.BaseInputObjectType and ..core.types.common.NonNullList to match current code organization.\n\n6) Tests\n- Add end-to-end GraphQL tests under saleor/graphql/page/tests/queries/ to cover:\n  - containsAny and containsAll for pageSlugs, productSlugs, productVariantSkus on a REFERENCE attribute assigned to PageType, verifying counts and that pages with both references satisfy containsAll and any one satisfies containsAny.\n  - containsAny and containsAll for referencedIds using mixed relay IDs for Page/Product/ProductVariant.\n  - Negative validation scenarios: null reference, empty input objects, empty lists for containsAny/containsAll, both operators provided for the same key, use of reference filter on a non-reference attribute.\n- Update an existing test that expects page count from filtering by empty slugs list to reflect the new page fixtures (see below).\n\n7) Fixtures\n- Update page fixtures to create four published pages (add two more to prior two) so baseline page queries without filters return four items. Ensure tests referencing this fixture expect 4 instead of 2 in the relevant case.\n\nAcceptance criteria\n- Schema contains ContainsFilterInput and ReferenceAttributeWhereInput; AttributeValuePageInput includes reference field.\n- Querying pages with attribute value reference filters supports both containsAny and containsAll for the four supported sub-fields and returns expected results.\n- Input validation errors are raised with clear messages according to rules above.\n- All updated and new tests pass, including the page fixture count adjustment.",
      "prompt": "Extend page GraphQL filtering to support reference-type attributes with flexible contains-any/all semantics. Add a reusable input that can express containsAny/containsAll, expose a \"reference\" filter field under attribute values in PageWhereInput, and allow filtering by referenced page slugs, product slugs, variant SKUs, and global Relay IDs. Ensure input validation prevents empty or conflicting operators and that filtering is efficient and correctly scoped to the attribute. Update the schema, page fixtures, and tests so that pages can be filtered using these new reference options and all tests pass.",
      "supplementalFiles": [
        "saleor/page/models.py",
        "saleor/product/models.py",
        "saleor/graphql/utils/filters.py",
        "saleor/graphql/core/filters/__init__.py",
        "saleor/graphql/attribute/types.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/attribute/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/filters.py\n===================================================================\n--- saleor/graphql/attribute/filters.py\tf3c1a96 (parent)\n+++ saleor/graphql/attribute/filters.py\t836d01d (commit)\n@@ -1,13 +1,16 @@\n+from typing import Literal, TypedDict\n+\n import django_filters\n import graphene\n-from django.db.models import Q\n+from django.db.models import Exists, OuterRef, Q, QuerySet\n \n from ...attribute import AttributeInputType\n-from ...attribute.models import Attribute, AttributeValue\n+from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue\n from ...channel.models import Channel\n+from ...page import models as page_models\n from ...permission.utils import has_one_of_permissions\n-from ...product import models\n+from ...product import models as product_models\n from ...product.models import ALL_PRODUCTS_PERMISSIONS\n from ..channel.filters import get_channel_slug_from_filter_data\n from ..core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ..core.enums import MeasurementUnitsEnum\n@@ -30,12 +33,10 @@\n     FilterInputDescriptions,\n     StringFilterInput,\n     WhereInputObjectType,\n )\n-from ..core.types import (\n-    BaseInputObjectType,\n-    NonNullList,\n-)\n+from ..core.types.base import BaseInputObjectType\n+from ..core.types.common import NonNullList\n from ..core.utils import from_global_id_or_error\n from ..utils import get_user_or_app_from_context\n from ..utils.filters import filter_by_ids, filter_slug_list, filter_where_by_value_field\n from .enums import AttributeEntityTypeEnum, AttributeInputTypeEnum, AttributeTypeEnum\n@@ -48,15 +49,17 @@\n     channel = None\n     if channel_slug is not None:\n         channel = Channel.objects.using(qs.db).filter(slug=str(channel_slug)).first()\n     limited_channel_access = False if channel_slug is None else True\n-    product_qs = models.Product.objects.using(qs.db).visible_to_user(\n+    product_qs = product_models.Product.objects.using(qs.db).visible_to_user(\n         requestor, channel, limited_channel_access\n     )\n \n     if field == \"in_category\":\n         _type, category_id = from_global_id_or_error(value, \"Category\")\n-        category = models.Category.objects.using(qs.db).filter(pk=category_id).first()\n+        category = (\n+            product_models.Category.objects.using(qs.db).filter(pk=category_id).first()\n+        )\n \n         if category is None:\n             return qs.none()\n \n@@ -329,4 +332,353 @@\n     class Meta:\n         filterset_class = AttributeValueWhere\n         description = \"Where filtering options for attribute values.\"\n         doc_category = DOC_CATEGORY_ATTRIBUTES\n+\n+\n+CONTAINS_TYPING = dict[Literal[\"contains_any\", \"contains_all\"], list[str]]\n+\n+\n+class SharedContainsFilterParams(TypedDict):\n+    attr_id: int | None\n+    db_connection_name: str\n+    assigned_attr_model: type[AssignedPageAttributeValue]\n+    assigned_id_field_name: Literal[\"page_id\"]\n+    identifier_field_name: Literal[\"slug\", \"id\", \"sku\"]\n+\n+\n+def filter_by_contains_referenced_object_ids(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for objects referencing other entities by global IDs.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to other entities (like: variants, products, pages), identified by\n+    global IDs.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified global IDs will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified global IDs will match.\n+    \"\"\"\n+\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    variant_ids = set()\n+    product_ids = set()\n+    page_ids = set()\n+\n+    for obj_id in contains_any or contains_all or []:\n+        type_, id_ = graphene.Node.from_global_id(obj_id)\n+        if type_ == \"Page\":\n+            page_ids.add(id_)\n+        elif type_ == \"Product\":\n+            product_ids.add(id_)\n+        elif type_ == \"ProductVariant\":\n+            variant_ids.add(id_)\n+\n+    expression = Q()\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"id\",\n+    }\n+    if contains_all:\n+        if page_ids:\n+            expression &= _filter_contains_all_condition(\n+                contains_all=list(page_ids),\n+                referenced_model=page_models.Page,\n+                attr_value_reference_field_name=\"reference_page_id\",\n+                **shared_filter_params,\n+            )\n+        if product_ids:\n+            expression &= _filter_contains_all_condition(\n+                contains_all=list(product_ids),\n+                referenced_model=product_models.Product,\n+                attr_value_reference_field_name=\"reference_product_id\",\n+                **shared_filter_params,\n+            )\n+        if variant_ids:\n+            expression &= _filter_contains_all_condition(\n+                contains_all=list(variant_ids),\n+                referenced_model=product_models.ProductVariant,\n+                attr_value_reference_field_name=\"reference_variant_id\",\n+                **shared_filter_params,\n+            )\n+        return expression\n+\n+    if contains_any:\n+        if page_ids:\n+            expression |= _filter_contains_any_condition(\n+                contains_any=list(page_ids),\n+                referenced_model=page_models.Page,\n+                attr_value_reference_field_name=\"reference_page_id\",\n+                **shared_filter_params,\n+            )\n+\n+        if product_ids:\n+            expression |= _filter_contains_any_condition(\n+                contains_any=list(product_ids),\n+                referenced_model=product_models.Product,\n+                attr_value_reference_field_name=\"reference_product_id\",\n+                **shared_filter_params,\n+            )\n+\n+        if variant_ids:\n+            expression |= _filter_contains_any_condition(\n+                contains_any=list(variant_ids),\n+                referenced_model=product_models.ProductVariant,\n+                attr_value_reference_field_name=\"reference_variant_id\",\n+                **shared_filter_params,\n+            )\n+    return expression\n+\n+\n+def _filter_contains_single_expression(\n+    attr_id: int | None,\n+    db_connection_name: str,\n+    reference_objs: QuerySet[\n+        page_models.Page | product_models.Product | product_models.ProductVariant\n+    ],\n+    attr_value_reference_field_name: Literal[\n+        \"reference_page_id\", \"reference_product_id\", \"reference_variant_id\"\n+    ],\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    single_reference_qs = AttributeValue.objects.using(db_connection_name).filter(\n+        Exists(reference_objs.filter(id=OuterRef(attr_value_reference_field_name))),\n+    )\n+    if attr_id:\n+        attr_query = Attribute.objects.using(db_connection_name).filter(id=attr_id)\n+        single_reference_qs = single_reference_qs.filter(\n+            Exists(attr_query.filter(id=OuterRef(\"attribute_id\"))),\n+        )\n+    assigned_attr_value = assigned_attr_model.objects.using(db_connection_name).filter(\n+        Exists(single_reference_qs.filter(id=OuterRef(\"value_id\"))),\n+        **{str(assigned_id_field_name): OuterRef(\"id\")},\n+    )\n+    return Q(Exists(assigned_attr_value))\n+\n+\n+def _filter_contains_all_condition(\n+    attr_id: int | None,\n+    db_connection_name: str,\n+    contains_all: list[str],\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+    identifier_field_name: Literal[\"slug\", \"id\", \"sku\"],\n+    referenced_model: type[\n+        page_models.Page | product_models.Product | product_models.ProductVariant\n+    ],\n+    attr_value_reference_field_name: Literal[\n+        \"reference_page_id\", \"reference_product_id\", \"reference_variant_id\"\n+    ],\n+):\n+    \"\"\"Build a filter expression that ensures all specified references are present.\n+\n+    Constructs a Q expression that checks for references to all entities from\n+    `referenced_model`, matched using the provided identifiers in `contains_all`.\n+\n+    For each identifier, it resolves the corresponding object using\n+    `identifier_field_name` and adds a subquery to verify the presence\n+    of that reference. The subqueries are combined using logical AND.\n+    \"\"\"\n+\n+    identifiers = contains_all\n+    expression = Q()\n+\n+    for identifier in identifiers:\n+        reference_obj = referenced_model.objects.using(db_connection_name).filter(\n+            **{str(identifier_field_name): identifier}\n+        )\n+        expression &= _filter_contains_single_expression(\n+            attr_id,\n+            db_connection_name,\n+            reference_obj,\n+            attr_value_reference_field_name,\n+            assigned_attr_model,\n+            assigned_id_field_name,\n+        )\n+    return expression\n+\n+\n+def _filter_contains_any_condition(\n+    attr_id: int | None,\n+    db_connection_name: str,\n+    contains_any: list[str],\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+    identifier_field_name: Literal[\"slug\", \"id\", \"sku\"],\n+    referenced_model: type[\n+        page_models.Page | product_models.Product | product_models.ProductVariant\n+    ],\n+    attr_value_reference_field_name: Literal[\n+        \"reference_page_id\", \"reference_product_id\", \"reference_variant_id\"\n+    ],\n+):\n+    \"\"\"Build a filter expression that ensures at least one specified reference is present.\n+\n+    Constructs a Q expression that checks for a reference to any entity from\n+    `referenced_model`, matched using the provided identifiers in `contains_any`.\n+\n+    All matching references are resolved using `identifier_field_name`,\n+    and passed as a single queryset to be checked in a single subquery.\n+\n+    \"\"\"\n+    identifiers = contains_any\n+    reference_objs = referenced_model.objects.using(db_connection_name).filter(\n+        **{f\"{identifier_field_name}__in\": identifiers}\n+    )\n+    return _filter_contains_single_expression(\n+        attr_id,\n+        db_connection_name,\n+        reference_objs,\n+        attr_value_reference_field_name,\n+        assigned_attr_model,\n+        assigned_id_field_name,\n+    )\n+\n+\n+def filter_by_contains_referenced_pages(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for referenced pages.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to pages.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified pages will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified pages will match.\n+    \"\"\"\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"slug\",\n+    }\n+    if contains_all:\n+        return _filter_contains_all_condition(\n+            contains_all=contains_all,\n+            referenced_model=page_models.Page,\n+            attr_value_reference_field_name=\"reference_page_id\",\n+            **shared_filter_params,\n+        )\n+\n+    if contains_any:\n+        return _filter_contains_any_condition(\n+            contains_any=contains_any,\n+            referenced_model=page_models.Page,\n+            attr_value_reference_field_name=\"reference_page_id\",\n+            **shared_filter_params,\n+        )\n+    return Q()\n+\n+\n+def filter_by_contains_referenced_products(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for referenced products.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to products.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified products will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified products will match.\n+    \"\"\"\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"slug\",\n+    }\n+\n+    if contains_all:\n+        return _filter_contains_all_condition(\n+            contains_all=contains_all,\n+            referenced_model=product_models.Product,\n+            attr_value_reference_field_name=\"reference_product_id\",\n+            **shared_filter_params,\n+        )\n+\n+    if contains_any:\n+        return _filter_contains_any_condition(\n+            contains_any=contains_any,\n+            referenced_model=product_models.Product,\n+            attr_value_reference_field_name=\"reference_product_id\",\n+            **shared_filter_params,\n+        )\n+    return Q()\n+\n+\n+def filter_by_contains_referenced_variants(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for referenced product variants.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to product variants.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified variants will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified variants will match.\n+    \"\"\"\n+\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"sku\",\n+    }\n+\n+    if contains_all:\n+        return _filter_contains_all_condition(\n+            contains_all=contains_all,\n+            referenced_model=product_models.ProductVariant,\n+            attr_value_reference_field_name=\"reference_variant_id\",\n+            **shared_filter_params,\n+        )\n+\n+    if contains_any:\n+        return _filter_contains_any_condition(\n+            contains_any=contains_any,\n+            referenced_model=product_models.ProductVariant,\n+            attr_value_reference_field_name=\"reference_variant_id\",\n+            **shared_filter_params,\n+        )\n+    return Q()\n"
        },
        {
          "path": "saleor/graphql/core/filters/where_input.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/filters/where_input.py\n===================================================================\n--- saleor/graphql/core/filters/where_input.py\tf3c1a96 (parent)\n+++ saleor/graphql/core/filters/where_input.py\t836d01d (commit)\n@@ -55,8 +55,10 @@\n     EQ = \"The value equal to.\"\n     ONE_OF = \"The value included in.\"\n     NOT_ONE_OF = \"The value not included in.\"\n     RANGE = \"The value in range.\"\n+    CONTAINS_ALL = \"The field contains all of the specified values.\"\n+    CONTAINS_ANY = \"The field contains at least one of the specified values.\"\n \n \n class StringFilterInput(graphene.InputObjectType):\n     eq = graphene.String(description=FilterInputDescriptions.EQ, required=False)\n@@ -181,4 +183,22 @@\n           Matches objects where the metadata key \"color\" is set to either \"blue\" or \"green\".\n         - `{key: \"status\", value: {eq: \"active\"}}`\n           Matches objects where the metadata key \"status\" is set to \"active\".\n         \"\"\"\n+\n+\n+class ContainsFilterInput(graphene.InputObjectType):\n+    contains_any = NonNullList(\n+        graphene.String,\n+        description=FilterInputDescriptions.CONTAINS_ANY,\n+        required=False,\n+    )\n+    contains_all = NonNullList(\n+        graphene.String,\n+        description=FilterInputDescriptions.CONTAINS_ALL,\n+        required=False,\n+    )\n+\n+    class Meta:\n+        description = (\n+            \"Define the filtering options for fields that can contain multiple values.\"\n+        )\n"
        },
        {
          "path": "saleor/graphql/page/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/filters.py\n===================================================================\n--- saleor/graphql/page/filters.py\tf3c1a96 (parent)\n+++ saleor/graphql/page/filters.py\t836d01d (commit)\n@@ -1,4 +1,6 @@\n+from typing import Literal\n+\n import django_filters\n import graphene\n from django.db.models import Exists, FloatField, OuterRef, Q\n from django.db.models.functions import Cast\n@@ -6,8 +8,15 @@\n \n from ...attribute import AttributeInputType\n from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue\n from ...page import models\n+from ..attribute.filters import (\n+    CONTAINS_TYPING,\n+    filter_by_contains_referenced_object_ids,\n+    filter_by_contains_referenced_pages,\n+    filter_by_contains_referenced_products,\n+    filter_by_contains_referenced_variants,\n+)\n from ..core.context import ChannelQsContext\n from ..core.doc_category import DOC_CATEGORY_PAGES\n from ..core.filters import (\n     FilterInputObjectType,\n@@ -21,8 +30,9 @@\n     MetadataWhereBase,\n     OperationObjectTypeWhereFilter,\n )\n from ..core.filters.where_input import (\n+    ContainsFilterInput,\n     DecimalFilterInput,\n     GlobalIDFilterInput,\n     StringFilterInput,\n     WhereInputObjectType,\n@@ -211,18 +221,130 @@\n         elif attr.input_type == AttributeInputType.DATE_TIME:\n             attr_filter_expression &= filter_by_date_time_attribute(\n                 attr.id, attr_value[\"date_time\"], qs.db\n             )\n+        elif attr.input_type == AttributeInputType.REFERENCE:\n+            attr_filter_expression &= filter_pages_by_reference_attributes(\n+                attr.id, attr_value[\"reference\"], qs.db\n+            )\n     if attr_filter_expression != Q():\n         return qs.filter(attr_filter_expression)\n     return qs.none()\n \n \n+def filter_pages_by_reference_attributes(\n+    attr_id: int | None,\n+    attr_value: dict[\n+        Literal[\n+            \"referenced_ids\", \"page_slugs\", \"product_slugs\", \"product_variant_skus\"\n+        ],\n+        CONTAINS_TYPING,\n+    ],\n+    db_connection_name: str,\n+):\n+    filter_expression = Q()\n+\n+    if \"referenced_ids\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_object_ids(\n+            attr_id,\n+            attr_value[\"referenced_ids\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    if \"page_slugs\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_pages(\n+            attr_id,\n+            attr_value[\"page_slugs\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    if \"product_slugs\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_products(\n+            attr_id,\n+            attr_value[\"product_slugs\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    if \"product_variant_skus\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_variants(\n+            attr_id,\n+            attr_value[\"product_variant_skus\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    return filter_expression\n+\n+\n+def validate_attribute_value_reference_input(\n+    values: list[\n+        dict[\n+            Literal[\n+                \"referenced_ids\", \"page_slugs\", \"product_slugs\", \"product_variant_skus\"\n+            ],\n+            CONTAINS_TYPING,\n+        ]\n+        | None\n+    ],\n+):\n+    \"\"\"Validate the input for reference attributes.\n+\n+    This function checks if the input for reference attributes is valid.\n+    It raises a GraphQLError if the input is invalid.\n+    \"\"\"\n+    duplicated_error = []\n+    empty_input_value_error = set()\n+    for value in values:\n+        if not value:\n+            raise GraphQLError(\n+                message=\"Invalid input for reference attributes. \"\n+                \"Provided 'value' cannot be null or empty.\"\n+            )\n+        for key in value:\n+            single_key_value = value[key]\n+            if (\n+                \"contains_all\" in single_key_value\n+                and \"contains_any\" in single_key_value\n+            ):\n+                duplicated_error.append(key)\n+                continue\n+            if (\n+                \"contains_all\" in single_key_value\n+                and not single_key_value[\"contains_all\"]\n+            ):\n+                empty_input_value_error.add(key)\n+                continue\n+            if (\n+                \"contains_any\" in single_key_value\n+                and not single_key_value[\"contains_any\"]\n+            ):\n+                empty_input_value_error.add(key)\n+\n+    if empty_input_value_error:\n+        raise GraphQLError(\n+            message=(\n+                f\"Invalid input for reference attributes. For fields: {', '.join(empty_input_value_error)}. \"\n+                f\"Provided values cannot be null or empty.\"\n+            )\n+        )\n+    if duplicated_error:\n+        raise GraphQLError(\n+            message=(\n+                f\"Invalid input for reference attributes. For fields: {', '.join(duplicated_error)}. \"\n+                \"Cannot provide both 'containsAll' and 'containsAny' for the same reference filter.\"\n+            )\n+        )\n+\n+\n def validate_attribute_value_input(attributes: list[dict], db_connection_name: str):\n     slug_list = [attr[\"slug\"] for attr in attributes]\n     value_as_empty_list = []\n     value_more_than_one_list = []\n     invalid_input_type_list = []\n+    reference_value_list = []\n     if len(slug_list) != len(set(slug_list)):\n         raise GraphQLError(\n             message=\"Duplicated attribute slugs in attribute 'where' input are not allowed.\"\n         )\n@@ -244,8 +366,10 @@\n             type_specific_value_list[attr[\"slug\"]] = value_key\n         if value[value_key] is None:\n             value_as_empty_list.append(attr[\"slug\"])\n             continue\n+        if value_key == \"reference\":\n+            reference_value_list.append(value[\"reference\"])\n \n     if type_specific_value_list:\n         attribute_input_type_map = Attribute.objects.using(db_connection_name).in_bulk(\n             type_specific_value_list.keys(),\n@@ -264,9 +388,13 @@\n             if \"date_time\" == value_key and input_type != AttributeInputType.DATE_TIME:\n                 invalid_input_type_list.append(attr_slug)\n             if \"boolean\" == value_key and input_type != AttributeInputType.BOOLEAN:\n                 invalid_input_type_list.append(attr_slug)\n+            if \"reference\" == value_key and input_type != AttributeInputType.REFERENCE:\n+                invalid_input_type_list.append(attr_slug)\n \n+    validate_attribute_value_reference_input(reference_value_list)\n+\n     if value_as_empty_list:\n         raise GraphQLError(\n             message=(\n                 f\"Incorrect input for attributes with slugs: {','.join(value_as_empty_list)}. \"\n@@ -288,8 +416,28 @@\n             )\n         )\n \n \n+class ReferenceAttributeWhereInput(BaseInputObjectType):\n+    referenced_ids = ContainsFilterInput(\n+        description=\"Returns objects with a reference pointing to an object identified by the given ID.\",\n+    )\n+    page_slugs = ContainsFilterInput(\n+        description=\"Returns objects with a reference pointing to a page identified by the given slug.\",\n+    )\n+    product_slugs = ContainsFilterInput(\n+        description=(\n+            \"Returns objects with a reference pointing to a product identified by the given slug.\"\n+        )\n+    )\n+    product_variant_skus = ContainsFilterInput(\n+        description=(\n+            \"Returns objects with a reference pointing \"\n+            \"to a product variant identified by the given sku.\"\n+        )\n+    )\n+\n+\n class AttributeValuePageInput(BaseInputObjectType):\n     slug = StringFilterInput(\n         description=\"Filter by slug assigned to AttributeValue.\",\n     )\n@@ -311,8 +459,12 @@\n     boolean = graphene.Boolean(\n         required=False,\n         description=\"Filter by boolean value for attributes of boolean type.\",\n     )\n+    reference = ReferenceAttributeWhereInput(\n+        required=False,\n+        description=(\"Filter by reference attribute value.\"),\n+    )\n \n \n class AttributePageWhereInput(BaseInputObjectType):\n     slug = graphene.String(description=\"Filter by attribute slug.\", required=True)\n"
        },
        {
          "path": "saleor/graphql/page/tests/queries/test_pages.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/queries/test_pages.py\n===================================================================\n--- saleor/graphql/page/tests/queries/test_pages.py\tf3c1a96 (parent)\n+++ saleor/graphql/page/tests/queries/test_pages.py\t836d01d (commit)\n@@ -140,9 +140,9 @@\n     (\"filter_by\", \"pages_count\"),\n     [\n         ({\"slugs\": [\"test-url-1\"]}, 1),\n         ({\"slugs\": [\"test-url-1\", \"test-url-2\"]}, 2),\n-        ({\"slugs\": []}, 2),\n+        ({\"slugs\": []}, 4),\n     ],\n )\n def test_pages_with_filtering(filter_by, pages_count, staff_api_client, page_list):\n     # given\n"
        },
        {
          "path": "saleor/graphql/page/tests/queries/test_pages_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/queries/test_pages_with_where.py\n===================================================================\n--- saleor/graphql/page/tests/queries/test_pages_with_where.py\tf3c1a96 (parent)\n+++ saleor/graphql/page/tests/queries/test_pages_with_where.py\t836d01d (commit)\n@@ -3,10 +3,12 @@\n import graphene\n import pytest\n \n from .....attribute import AttributeInputType\n+from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.models import Page, PageType\n+from ....core.utils import to_global_id_or_none\n from ....tests.utils import get_graphql_content\n \n QUERY_PAGES_WITH_WHERE = \"\"\"\n     query ($where: PageWhereInput) {\n@@ -600,8 +602,640 @@\n     )\n \n \n @pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 2), (\"containsAll\", 1)]\n+)\n+def test_pages_query_with_attribute_value_reference_to_pages(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_page_reference_attribute,\n+):\n+    # given\n+    page_type.page_attributes.add(page_type_page_reference_attribute)\n+\n+    reference_page_1_slug = \"referenced-page-1\"\n+    reference_page_2_slug = \"referenced-page-2\"\n+    referenced_page_1, referenced_page_2 = Page.objects.bulk_create(\n+        [\n+            Page(\n+                title=\"Referenced Page 1\",\n+                slug=reference_page_1_slug,\n+                page_type=page_type,\n+                is_published=True,\n+            ),\n+            Page(\n+                title=\"Referenced Page 2\",\n+                slug=reference_page_2_slug,\n+                page_type=page_type,\n+                is_published=True,\n+            ),\n+        ]\n+    )\n+\n+    attribute_value_1, attribute_value_2 = AttributeValue.objects.bulk_create(\n+        [\n+            AttributeValue(\n+                attribute=page_type_page_reference_attribute,\n+                name=f\"Page {referenced_page_1.pk}\",\n+                slug=f\"page-{referenced_page_1.pk}\",\n+                reference_page=referenced_page_1,\n+            ),\n+            AttributeValue(\n+                attribute=page_type_page_reference_attribute,\n+                name=f\"Page {referenced_page_2.pk}\",\n+                slug=f\"page-{referenced_page_2.pk}\",\n+                reference_page=referenced_page_2,\n+            ),\n+        ]\n+    )\n+    page_with_both_references = page_list[0]\n+    associate_attribute_values_to_instance(\n+        page_with_both_references,\n+        {page_type_page_reference_attribute.pk: [attribute_value_1, attribute_value_2]},\n+    )\n+\n+    page_with_single_reference = page_list[1]\n+    associate_attribute_values_to_instance(\n+        page_with_single_reference,\n+        {page_type_page_reference_attribute.pk: [attribute_value_2]},\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": \"page-reference\",\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"pageSlugs\": {\n+                                filter_type: [\n+                                    reference_page_1_slug,\n+                                    reference_page_2_slug,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 2), (\"containsAll\", 1)]\n+)\n+def test_pages_query_with_attribute_value_reference_to_products(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_product_reference_attribute,\n+    product_list,\n+):\n+    # given\n+    page_type.page_attributes.add(page_type_product_reference_attribute)\n+\n+    first_product = product_list[0]\n+    second_product = product_list[1]\n+\n+    attribute_value_1, attribute_value_2 = AttributeValue.objects.bulk_create(\n+        [\n+            AttributeValue(\n+                attribute=page_type_product_reference_attribute,\n+                name=f\"Product {first_product.pk}\",\n+                slug=f\"product-{first_product.pk}\",\n+                reference_product=first_product,\n+            ),\n+            AttributeValue(\n+                attribute=page_type_product_reference_attribute,\n+                name=f\"Product {second_product.pk}\",\n+                slug=f\"product-{second_product.pk}\",\n+                reference_product=second_product,\n+            ),\n+        ]\n+    )\n+\n+    page_with_both_references = page_list[0]\n+    associate_attribute_values_to_instance(\n+        page_with_both_references,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                attribute_value_1,\n+                attribute_value_2,\n+            ]\n+        },\n+    )\n+\n+    page_with_single_reference = page_list[1]\n+    associate_attribute_values_to_instance(\n+        page_with_single_reference,\n+        {page_type_product_reference_attribute.pk: [attribute_value_2]},\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": \"product-reference\",\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"productSlugs\": {\n+                                filter_type: [first_product.slug, second_product.slug]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+    assert pages_nodes[0][\"node\"][\"id\"] == graphene.Node.to_global_id(\n+        \"Page\", page_list[0].pk\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 2), (\"containsAll\", 1)]\n+)\n+def test_pages_query_with_attribute_value_reference_to_product_variants(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_variant_reference_attribute,\n+    product_variant_list,\n+):\n+    # given\n+    page_type.page_attributes.add(page_type_variant_reference_attribute)\n+\n+    first_variant_sku = \"test-variant-1\"\n+    second_variant_sku = \"test-variant-2\"\n+\n+    first_variant = product_variant_list[0]\n+    first_variant.sku = first_variant_sku\n+    first_variant.save()\n+\n+    second_variant = product_variant_list[1]\n+    second_variant.sku = second_variant_sku\n+    second_variant.save()\n+\n+    attribute_value_1, attribute_value_2 = AttributeValue.objects.bulk_create(\n+        [\n+            AttributeValue(\n+                attribute=page_type_variant_reference_attribute,\n+                name=f\"Variant {first_variant.pk}\",\n+                slug=f\"variant-{first_variant.pk}\",\n+                reference_variant=first_variant,\n+            ),\n+            AttributeValue(\n+                attribute=page_type_variant_reference_attribute,\n+                name=f\"Variant {second_variant.pk}\",\n+                slug=f\"variant-{second_variant.pk}\",\n+                reference_variant=second_variant,\n+            ),\n+        ]\n+    )\n+\n+    page_with_both_references = page_list[0]\n+    associate_attribute_values_to_instance(\n+        page_with_both_references,\n+        {\n+            page_type_variant_reference_attribute.pk: [\n+                attribute_value_1,\n+                attribute_value_2,\n+            ]\n+        },\n+    )\n+\n+    page_with_single_reference = page_list[1]\n+    associate_attribute_values_to_instance(\n+        page_with_single_reference,\n+        {page_type_variant_reference_attribute.pk: [attribute_value_2]},\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": \"variant-reference\",\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"productVariantSkus\": {\n+                                filter_type: [\n+                                    first_variant_sku,\n+                                    second_variant_sku,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+    assert pages_nodes[0][\"node\"][\"id\"] == graphene.Node.to_global_id(\n+        \"Page\", page_list[0].pk\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 3), (\"containsAll\", 2)]\n+)\n+def test_pages_query_with_attribute_value_referenced_page_ids(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_page_reference_attribute,\n+):\n+    # given\n+    page_type.page_attributes.add(\n+        page_type_page_reference_attribute,\n+    )\n+\n+    referenced_first_page, referenced_second_page, referenced_third_page = (\n+        Page.objects.bulk_create(\n+            [\n+                Page(\n+                    title=\"Referenced Page\",\n+                    slug=\"referenced-page\",\n+                    page_type=page_type,\n+                    is_published=True,\n+                ),\n+                Page(\n+                    title=\"Referenced Page\",\n+                    slug=\"referenced-page2\",\n+                    page_type=page_type,\n+                    is_published=True,\n+                ),\n+                Page(\n+                    title=\"Referenced Page\",\n+                    slug=\"referenced-page3\",\n+                    page_type=page_type,\n+                    is_published=True,\n+                ),\n+            ]\n+        )\n+    )\n+\n+    first_attr_value, second_attr_value, third_attr_value = (\n+        AttributeValue.objects.bulk_create(\n+            [\n+                AttributeValue(\n+                    attribute=page_type_page_reference_attribute,\n+                    name=f\"Page {referenced_first_page.pk}\",\n+                    slug=f\"page-{referenced_first_page.pk}\",\n+                    reference_page=referenced_first_page,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_page_reference_attribute,\n+                    name=f\"Page {referenced_second_page.pk}\",\n+                    slug=f\"page-{referenced_second_page.pk}\",\n+                    reference_page=referenced_second_page,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_page_reference_attribute,\n+                    name=f\"Page {referenced_third_page.pk}\",\n+                    slug=f\"page-{referenced_third_page.pk}\",\n+                    reference_page=referenced_third_page,\n+                ),\n+            ]\n+        )\n+    )\n+    fist_page_with_all_ids = page_list[0]\n+    second_page_with_all_ids = page_list[1]\n+    page_with_single_id = page_list[2]\n+    associate_attribute_values_to_instance(\n+        fist_page_with_all_ids,\n+        {\n+            page_type_page_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        second_page_with_all_ids,\n+        {\n+            page_type_page_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_with_single_id,\n+        {page_type_page_reference_attribute.pk: [first_attr_value]},\n+    )\n+\n+    referenced_first_global_id = to_global_id_or_none(referenced_first_page)\n+    referenced_second_global_id = to_global_id_or_none(referenced_second_page)\n+    referenced_third_global_id = to_global_id_or_none(referenced_third_page)\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": page_type_page_reference_attribute.slug,\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"referencedIds\": {\n+                                filter_type: [\n+                                    referenced_first_global_id,\n+                                    referenced_second_global_id,\n+                                    referenced_third_global_id,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(page_list) > len(pages_nodes)\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 3), (\"containsAll\", 2)]\n+)\n+def test_pages_query_with_attribute_value_referenced_variant_ids(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_variant_reference_attribute,\n+    product_variant_list,\n+):\n+    # given\n+    page_type.page_attributes.add(\n+        page_type_variant_reference_attribute,\n+    )\n+\n+    first_variant = product_variant_list[0]\n+    second_variant = product_variant_list[1]\n+    third_variant = product_variant_list[2]\n+\n+    first_attr_value, second_attr_value, third_attr_value = (\n+        AttributeValue.objects.bulk_create(\n+            [\n+                AttributeValue(\n+                    attribute=page_type_variant_reference_attribute,\n+                    name=f\"Variant {first_variant.pk}\",\n+                    slug=f\"variant-{first_variant.pk}\",\n+                    reference_variant=first_variant,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_variant_reference_attribute,\n+                    name=f\"Variant {second_variant.pk}\",\n+                    slug=f\"variant-{second_variant.pk}\",\n+                    reference_variant=second_variant,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_variant_reference_attribute,\n+                    name=f\"Variant {third_variant.pk}\",\n+                    slug=f\"variant-{third_variant.pk}\",\n+                    reference_variant=third_variant,\n+                ),\n+            ]\n+        )\n+    )\n+    fist_page_with_all_ids = page_list[0]\n+    second_page_with_all_ids = page_list[1]\n+    page_with_single_id = page_list[2]\n+    associate_attribute_values_to_instance(\n+        fist_page_with_all_ids,\n+        {\n+            page_type_variant_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        second_page_with_all_ids,\n+        {\n+            page_type_variant_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_with_single_id,\n+        {page_type_variant_reference_attribute.pk: [first_attr_value]},\n+    )\n+    referenced_first_global_id = to_global_id_or_none(first_variant)\n+    referenced_second_global_id = to_global_id_or_none(second_variant)\n+    referenced_third_global_id = to_global_id_or_none(third_variant)\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": page_type_variant_reference_attribute.slug,\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"referencedIds\": {\n+                                filter_type: [\n+                                    referenced_first_global_id,\n+                                    referenced_second_global_id,\n+                                    referenced_third_global_id,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(page_list) > len(pages_nodes)\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 3), (\"containsAll\", 2)]\n+)\n+def test_pages_query_with_attribute_value_referenced_product_ids(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_product_reference_attribute,\n+    product_list,\n+):\n+    # given\n+    page_type.page_attributes.add(\n+        page_type_product_reference_attribute,\n+    )\n+    first_product = product_list[0]\n+    second_product = product_list[1]\n+    third_product = product_list[2]\n+\n+    first_attr_value, second_attr_value, third_attr_value = (\n+        AttributeValue.objects.bulk_create(\n+            [\n+                AttributeValue(\n+                    attribute=page_type_product_reference_attribute,\n+                    name=f\"Product {first_product.pk}\",\n+                    slug=f\"Product-{first_product.pk}\",\n+                    reference_product=first_product,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_product_reference_attribute,\n+                    name=f\"Product {second_product.pk}\",\n+                    slug=f\"product-{second_product.pk}\",\n+                    reference_product=second_product,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_product_reference_attribute,\n+                    name=f\"Product {third_product.pk}\",\n+                    slug=f\"Product-{third_product.pk}\",\n+                    reference_product=third_product,\n+                ),\n+            ]\n+        )\n+    )\n+    fist_page_with_all_ids = page_list[0]\n+    second_page_with_all_ids = page_list[1]\n+    page_with_single_id = page_list[2]\n+    associate_attribute_values_to_instance(\n+        fist_page_with_all_ids,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        second_page_with_all_ids,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_with_single_id,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                first_attr_value,\n+            ],\n+        },\n+    )\n+    referenced_first_global_id = to_global_id_or_none(first_product)\n+    referenced_second_global_id = to_global_id_or_none(second_product)\n+    referenced_third_global_id = to_global_id_or_none(third_product)\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": page_type_product_reference_attribute.slug,\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"referencedIds\": {\n+                                filter_type: [\n+                                    referenced_first_global_id,\n+                                    referenced_second_global_id,\n+                                    referenced_third_global_id,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                },\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(page_list) > len(pages_nodes)\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n     \"attribute_filter\",\n     [\n         # When input receives None\n         [{\"slug\": \"page-size\"}, {\"slug\": \"page-size\"}],\n@@ -658,8 +1292,160 @@\n         [{\"slug\": \"date_time\", \"value\": {\"name\": None}}],\n         [{\"slug\": \"date_time\", \"value\": {\"slug\": None}}],\n         # Date time can't be used with non date time fields\n         [{\"slug\": \"date_time\", \"value\": {\"numeric\": {\"eq\": 1.2}}}],\n+        # Reference attribute\n+        [\n+            {\n+                \"slug\": \"date_time\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"pageSlugs\": {\n+                            \"containsAll\": [\n+                                \"about\",\n+                            ]\n+                        }\n+                    }\n+                },\n+            }\n+        ],\n+        [{\"slug\": \"reference-product\", \"value\": {}}],\n+        [{\"slug\": \"reference-product\", \"value\": {\"reference\": {}}}],\n+        [{\"slug\": \"reference-product\", \"value\": {\"reference\": None}}],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\"pageSlugs\": {\"containsAny\": [], \"containsAll\": []}}\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"productSlugs\": {\"containsAny\": [], \"containsAll\": []}\n+                    }\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"productVariantSkus\": {\"containsAny\": [], \"containsAll\": []}\n+                    }\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"referencedIds\": {\"containsAny\": [], \"containsAll\": []}\n+                    }\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAny\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAny\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAny\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAny\": None}}},\n+            }\n+        ],\n     ],\n )\n def test_pages_query_failed_filter_validation(\n     attribute_filter,\n@@ -671,15 +1457,22 @@\n     boolean_attribute,\n     numeric_attribute_without_unit,\n     date_attribute,\n     date_time_attribute,\n+    page_type_product_reference_attribute,\n ):\n     # given\n     boolean_attribute.type = \"PAGE_TYPE\"\n     boolean_attribute.save()\n     numeric_attribute_without_unit.type = \"PAGE_TYPE\"\n     numeric_attribute_without_unit.save()\n \n+    page_type_product_reference_attribute.slug = \"reference-product\"\n+    page_type_product_reference_attribute.save()\n+\n+    page_type.page_attributes.add(\n+        page_type_product_reference_attribute,\n+    )\n     page_type.page_attributes.add(size_page_attribute)\n     page_type.page_attributes.add(tag_page_attribute)\n     page_type.page_attributes.add(boolean_attribute)\n     page_type.page_attributes.add(numeric_attribute_without_unit)\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\tf3c1a96 (parent)\n+++ saleor/graphql/schema.graphql\t836d01d (commit)\n@@ -13033,10 +13033,46 @@\n   dateTime: DateTimeRangeInput\n \n   \"\"\"Filter by boolean value for attributes of boolean type.\"\"\"\n   boolean: Boolean\n+\n+  \"\"\"Filter by reference attribute value.\"\"\"\n+  reference: ReferenceAttributeWhereInput\n }\n \n+input ReferenceAttributeWhereInput {\n+  \"\"\"\n+  Returns objects with a reference pointing to an object identified by the given ID.\n+  \"\"\"\n+  referencedIds: ContainsFilterInput\n+\n+  \"\"\"\n+  Returns objects with a reference pointing to a page identified by the given slug.\n+  \"\"\"\n+  pageSlugs: ContainsFilterInput\n+\n+  \"\"\"\n+  Returns objects with a reference pointing to a product identified by the given slug.\n+  \"\"\"\n+  productSlugs: ContainsFilterInput\n+\n+  \"\"\"\n+  Returns objects with a reference pointing to a product variant identified by the given sku.\n+  \"\"\"\n+  productVariantSkus: ContainsFilterInput\n+}\n+\n+\"\"\"\n+Define the filtering options for fields that can contain multiple values.\n+\"\"\"\n+input ContainsFilterInput {\n+  \"\"\"The field contains at least one of the specified values.\"\"\"\n+  containsAny: [String!]\n+\n+  \"\"\"The field contains all of the specified values.\"\"\"\n+  containsAll: [String!]\n+}\n+\n type PageTypeCountableConnection @doc(category: \"Pages\") {\n   \"\"\"Pagination data for this connection.\"\"\"\n   pageInfo: PageInfo!\n   edges: [PageTypeCountableEdge!]!\n"
        },
        {
          "path": "saleor/page/tests/fixtures/page.py",
          "status": "modified",
          "diff": "Index: saleor/page/tests/fixtures/page.py\n===================================================================\n--- saleor/page/tests/fixtures/page.py\tf3c1a96 (parent)\n+++ saleor/page/tests/fixtures/page.py\t836d01d (commit)\n@@ -62,9 +62,25 @@\n         \"content\": dummy_editorjs(\"Test content.\"),\n         \"is_published\": True,\n         \"page_type\": page_type,\n     }\n-    pages = Page.objects.bulk_create([Page(**data_1), Page(**data_2)])\n+    data_3 = {\n+        \"slug\": \"test3\",\n+        \"title\": \"Test page3\",\n+        \"content\": dummy_editorjs(\"Test content.\"),\n+        \"is_published\": True,\n+        \"page_type\": page_type,\n+    }\n+    data_4 = {\n+        \"slug\": \"test4\",\n+        \"title\": \"Test page4\",\n+        \"content\": dummy_editorjs(\"Test content.\"),\n+        \"is_published\": True,\n+        \"page_type\": page_type,\n+    }\n+    pages = Page.objects.bulk_create(\n+        [Page(**data_1), Page(**data_2), Page(**data_3), Page(**data_4)]\n+    )\n     return pages\n \n \n @pytest.fixture\n"
        }
      ]
    },
    {
      "id": "add-transaction-typing",
      "sha": "4fbc4ca80e8734e4e30889c6eb7b9742b9449d59",
      "parentSha": "c616f672ccea1a73056486c1ecde42739ed37d53",
      "spec": "Implement static typing and schema validation for transaction-related webhook responses and adjust the payment gateway initialization data flow.\n\n1) Add Pydantic response schemas for transaction events\n- File: saleor/webhook/response_schemas/transaction.py (new)\n  - Implement TransactionSchema base model with fields:\n    - pspReference (alias: pspReference), optional; required unless result is one of OPTIONAL_PSP_REFERENCE_EVENTS; on missing, raise ValueError with: \"Providing `pspReference` is required for {RESULT_UPPER} action result.\"\n    - amount: Decimal; quantize to DEFAULT_DECIMAL_PLACES\n    - time: default to timezone.now; accept ISO 8601 strings and coerce to timezone-aware UTC\n    - externalUrl: HttpUrl, default empty string\n    - message: string, coerce to str, truncate to max length using truncate_transaction_event_message; log warnings on invalid input or truncation\n    - actions: list of allowed actions (CHARGE, REFUND, CANCEL); skip invalid values; normalize to lowercase after validation\n    - result: string; normalize to lowercase after validation\n  - Implement constrained subclasses restricting result values:\n    - TransactionChargeRequestedSchema: result in {CHARGE_SUCCESS, CHARGE_FAILURE}\n    - TransactionCancelRequestedSchema: result in {CANCEL_SUCCESS, CANCEL_FAILURE}\n    - TransactionRefundRequestedSchema: result in {REFUND_SUCCESS, REFUND_FAILURE}\n    - TransactionSessionSchema: result in {AUTHORIZATION_SUCCESS, AUTHORIZATION_FAILURE, AUTHORIZATION_ACTION_REQUIRED, AUTHORIZATION_REQUEST, CHARGE_SUCCESS, CHARGE_FAILURE, CHARGE_ACTION_REQUIRED, CHARGE_REQUEST}; include extra field data: JsonValue that will be returned to storefront\n  - Implement PaymentGatewayInitializeSessionSchema with field data: JsonValue\n\n2) Add shared validator annotations\n- File: saleor/webhook/response_schemas/annotations.py\n  - Add DatetimeUTC to set tzinfo=UTC via AfterValidator\n  - Add OnErrorSkipLiteral using WrapValidator that logs a warning and omits invalid literal values (raise PydanticOmit)\n  - Preserve DefaultIfNone and metadata validators; import necessary pydantic core types and logging\n\n3) Migrate transaction parsing to use schemas\n- File: saleor/payment/utils.py\n  - Define constant SESSION_REQUEST_EVENT_TYPE = \"session-request\"\n  - Remove legacy parse_transaction_event_data and _clean_message helpers\n  - Update parse_transaction_action_data:\n    - If event_is_optional and response lacks both amount and result, only parse pspReference and available actions; if pspReference missing and request_type not in OPTIONAL_PSP_REFERENCE_EVENTS, return (None, \"Providing `pspReference` is required for {REQUEST_TYPE_UPPER}.\") and log warning; otherwise return TransactionRequestResponse with event=None and parsed available actions\n    - Otherwise, select the appropriate schema by request_type:\n      - CHARGE_REQUEST -> TransactionChargeRequestedSchema\n      - REFUND_REQUEST -> TransactionRefundRequestedSchema\n      - CANCEL_REQUEST -> TransactionCancelRequestedSchema\n      - SESSION_REQUEST_EVENT_TYPE -> TransactionSessionSchema\n      - If unsupported request_type, log error and return (None, \"Request type not supported\")\n    - Validate response_data with the schema. On ValidationError:\n      - Log warning\n      - Return (None, truncated_error_message)\n    - On success, construct TransactionRequestResponse with:\n      - psp_reference from model\n      - available_actions from model.actions\n      - event populated from model (psp_reference, type/result, amount, time, external_url, message)\n  - Extract parse_available_actions(available_actions) helper that filters to allowed actions using TransactionAction and returns the filtered list\n  - In create_transaction_event_for_transaction_session, call _get_parsed_transaction_action_data with event_type=SESSION_REQUEST_EVENT_TYPE and event_is_optional=False\n\n4) Adjust PaymentGatewayData to carry storefront JSON value\n- File: saleor/payment/interface.py\n  - Change PaymentGatewayData.data type from dict[Any, Any] | None to JSONValue | None\n\n5) Update webhook plugin to validate and map initialize-session responses\n- File: saleor/plugins/webhook/plugin.py\n  - Validate response_data for PAYMENT_GATEWAY_INITIALIZE_SESSION with PaymentGatewayInitializeSessionSchema\n  - On validation error, set response_data to None and error_msg to str(error)\n  - On success, set PaymentGatewayData.data to response_model.data (the inner \"data\" only)\n\n6) Update GraphQL mutation to return storefront data directly\n- File: saleor/graphql/payment/mutations/transaction/payment_gateway_initialize.py\n  - When building PaymentGatewayConfig list, set data=data_to_return where data_to_return is payment_gateway_response.data (no nested .get(\"data\"))\n  - Maintain NOT_FOUND and INVALID app error handling as currently structured\n\n7) Update and align tests\n- File: saleor/graphql/payment/tests/mutations/test_payment_gateway_initialize.py\n  - Update mocks to pass PaymentGatewayData(app_identifier, data=expected_data) rather than wrapping in {\"data\": expected_data}\n  - Adjust all assertions accordingly across checkout and order variants, including multi-gateway tests\n- File: saleor/plugins/webhook/tests/test_payment_gateway_initialize_session_webhook.py\n  - Mock webhook responses to return {\"data\": expected_data} and assert plugin exposes only the inner data to PaymentGatewayData.data\n- File: saleor/payment/tests/test_utils.py\n  - Import logger from saleor.payment.utils for patching\n  - Where session-based authorization flow is tested, use create_transaction_event_for_transaction_session instead of create_transaction_event_from_request_and_webhook_response\n  - Update expected missing pspReference error assertions to include \"action result.\" and compare with \"in\" containment (not strict equality)\n  - Add test to assert that AUTHORIZATION_REQUEST should not trigger paid/authorize side effects, logs an error once\n  - In tests for same event and different amount scenarios, swap event types from AUTHORIZATION_* to CHARGE_* where appropriate to reflect the new mapping\n  - In tests asserting failure messages arising from validation, compare using containment when messages come from Pydantic validations\n- File: saleor/webhook/tests/response_schemas/test_transaction.py (new)\n  - Add comprehensive tests for all response schemas: valid/invalid time formats, amount coercion, action filtering and normalization, result constraints, missing pspReference behavior, and JSONValue validation for data fields\n\nBehavioral expectations after implementation\n- Transaction webhook responses are rigorously validated; invalid payloads return meaningful, truncated error messages and do not create events\n- Missing pspReference errors read: \"Providing `pspReference` is required for {EVENT_TYPE} action result.\"\n- Available actions are filtered to {charge, refund, cancel} and normalized to lowercase when parsed by schemas\n- time values are coerced to timezone-aware UTC datetimes\n- Payment gateway initialize session webhook responses must be shaped as {\"data\": <json>}; plugin exposes only <json> via PaymentGatewayData.data\n- GraphQL paymentGatewayInitialize returns the PaymentGatewayData.data as-is (JSONValue) without an extra nesting layer",
      "prompt": "Introduce schema-based typing for payment transaction webhook responses and align the gateway initialization data path.\n\nGoals:\n- Validate transaction webhook payloads with strict schemas covering charge, refund, cancel, and session flows, including psp reference requirements, amount, time, external URL, message, available actions, and result types.\n- Ensure missing psp references produce a clear error that mentions the action result, and that timestamps are timezone-aware UTC.\n- For the payment gateway initialize session path, accept a response shaped as {\"data\": <json>} and surface only the inner JSON value to callers.\n- Adjust the GraphQL mutation that aggregates payment gateways so it returns the storefront-facing JSON directly.\n- Update unit tests to match new behavior and message formats, and add tests for the new response schemas.\n\nYou’ll need to add new schema models, replace legacy parsing with validation, update types and message formats, and refactor tests to reflect these changes.",
      "supplementalFiles": [
        "saleor/payment/__init__.py",
        "saleor/payment/models.py",
        "saleor/plugins/manager.py",
        "saleor/plugins/base_plugin.py",
        "saleor/webhook/transport/synchronous/transport.py",
        "saleor/webhook/transport/asynchronous/transport.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/payment/mutations/transaction/payment_gateway_initialize.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/mutations/transaction/payment_gateway_initialize.py\n===================================================================\n--- saleor/graphql/payment/mutations/transaction/payment_gateway_initialize.py\tc616f67 (parent)\n+++ saleor/graphql/payment/mutations/transaction/payment_gateway_initialize.py\t4fbc4ca (commit)\n@@ -89,9 +89,9 @@\n         for identifier in payment_gateways_input_dict:\n             app_identifier = identifier\n             payment_gateway_response = payment_gateways_response_dict.get(identifier)\n             if payment_gateway_response:\n-                response_data = payment_gateway_response.data\n+                data_to_return = payment_gateway_response.data\n                 errors = []\n                 if payment_gateway_response.error:\n                     code = common_types.PaymentGatewayConfigErrorCode.INVALID.value\n                     errors = [\n@@ -102,9 +102,9 @@\n                         }\n                     ]\n \n             else:\n-                response_data = None\n+                data_to_return = None\n                 code = common_types.PaymentGatewayConfigErrorCode.NOT_FOUND.value\n                 msg = (\n                     \"Active app with `HANDLE_PAYMENT` permissions or \"\n                     \"app webhook not found.\"\n@@ -115,9 +115,8 @@\n                         \"message\": msg,\n                         \"code\": code,\n                     }\n                 ]\n-            data_to_return = response_data.get(\"data\") if response_data else None\n             response.append(\n                 PaymentGatewayConfig(\n                     id=app_identifier, data=data_to_return, errors=errors\n                 )\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_payment_gateway_initialize.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_payment_gateway_initialize.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_payment_gateway_initialize.py\tc616f67 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_payment_gateway_initialize.py\t4fbc4ca (commit)\n@@ -56,14 +56,11 @@\n     checkout_info, _ = fetch_checkout_data(checkout_info, plugins_manager, lines)\n     checkout = checkout_info.checkout\n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n-    expected_response = {\"data\": expected_data}\n \n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n \n     variables = {\"id\": to_global_id_or_none(checkout), \"paymentGateways\": None}\n \n@@ -127,14 +124,11 @@\n     # given\n     order = order_with_lines\n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n-    expected_response = {\"data\": expected_data}\n \n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n \n     variables = {\"id\": to_global_id_or_none(order), \"paymentGateways\": None}\n \n@@ -169,14 +163,11 @@\n \n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n     expected_input_data = {\"input\": \"json\"}\n-    expected_response = {\"data\": expected_data}\n \n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n \n     variables = {\n         \"id\": to_global_id_or_none(checkout),\n@@ -221,14 +212,11 @@\n     order = order_with_lines\n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n     expected_input_data = {\"input\": \"json\"}\n-    expected_response = {\"data\": expected_data}\n \n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n \n     variables = {\n         \"id\": to_global_id_or_none(order),\n@@ -272,16 +260,13 @@\n     # given\n     checkout = checkout_with_prices\n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n-    expected_response = {\"data\": expected_data}\n     expected_input_data = {\"input\": \"json\"}\n     excpected_amount = Decimal(30)\n \n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n \n     variables = {\n         \"id\": to_global_id_or_none(checkout),\n@@ -326,15 +311,12 @@\n     # given\n     order = order_with_lines\n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n-    expected_response = {\"data\": expected_data}\n     expected_input_data = {\"input\": \"json\"}\n     excpected_amount = Decimal(30)\n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n     variables = {\n         \"id\": to_global_id_or_none(order),\n         \"amount\": excpected_amount,\n@@ -609,9 +591,8 @@\n     checkout = checkout_with_prices\n     excpected_amount = Decimal(30)\n     first_expected_app_identifier = \"app.id\"\n     first_expected_data = {\"json\": \"data\"}\n-    first_expected_response = {\"data\": first_expected_data}\n     first_expected_input_data = {\"input\": \"json\"}\n \n     second_expected_input_data = {\"input\": \"json2\"}\n     second_error_msg = \"Cannot fetch\"\n@@ -625,9 +606,9 @@\n     )\n \n     mocked_initialize.return_value = [\n         PaymentGatewayData(\n-            app_identifier=first_expected_app_identifier, data=first_expected_response\n+            app_identifier=first_expected_app_identifier, data=first_expected_data\n         ),\n         PaymentGatewayData(\n             app_identifier=second_expected_app_identifier, error=second_error_msg\n         ),\n@@ -716,9 +697,8 @@\n     order = order_with_lines\n     excpected_amount = Decimal(30)\n     first_expected_app_identifier = \"app.id\"\n     first_expected_data = {\"json\": \"data\"}\n-    first_expected_response = {\"data\": first_expected_data}\n     first_expected_input_data = {\"input\": \"json\"}\n \n     second_expected_input_data = {\"input\": \"json2\"}\n     second_error_msg = \"Cannot fetch\"\n@@ -732,9 +712,9 @@\n     )\n \n     mocked_initialize.return_value = [\n         PaymentGatewayData(\n-            app_identifier=first_expected_app_identifier, data=first_expected_response\n+            app_identifier=first_expected_app_identifier, data=first_expected_data\n         ),\n         PaymentGatewayData(\n             app_identifier=second_expected_app_identifier, error=second_error_msg\n         ),\n@@ -822,15 +802,12 @@\n     # given\n     order = order_with_lines\n     expected_app_identifier = \"app.id\"\n     expected_data = {\"json\": \"data\"}\n-    expected_response = {\"data\": expected_data}\n     expected_input_data = {\"input\": \"json\"}\n     excpected_amount = Decimal(\"28.1256977854\")\n     mocked_initialize.return_value = [\n-        PaymentGatewayData(\n-            app_identifier=expected_app_identifier, data=expected_response\n-        )\n+        PaymentGatewayData(app_identifier=expected_app_identifier, data=expected_data)\n     ]\n     variables = {\n         \"id\": to_global_id_or_none(order),\n         \"amount\": excpected_amount,\n"
        },
        {
          "path": "saleor/payment/interface.py",
          "status": "modified",
          "diff": "Index: saleor/payment/interface.py\n===================================================================\n--- saleor/payment/interface.py\tc616f67 (parent)\n+++ saleor/payment/interface.py\t4fbc4ca (commit)\n@@ -146,9 +146,9 @@\n \n @dataclass\n class PaymentGatewayData:\n     app_identifier: str\n-    data: dict[Any, Any] | None = None\n+    data: JSONValue | None = None\n     error: str | None = None\n \n \n @dataclass\n"
        },
        {
          "path": "saleor/payment/tests/test_utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/tests/test_utils.py\n===================================================================\n--- saleor/payment/tests/test_utils.py\tc616f67 (parent)\n+++ saleor/payment/tests/test_utils.py\t4fbc4ca (commit)\n@@ -27,8 +27,9 @@\n     deduplicate_event,\n     get_channel_slug_from_payment,\n     get_correct_event_types_based_on_request_type,\n     get_transaction_event_amount,\n+    logger,\n     parse_transaction_action_data,\n     recalculate_refundable_for_checkout,\n     try_void_or_refund_inactive_payment,\n )\n@@ -565,12 +566,8 @@\n         (\n             TransactionEventType.CANCEL_REQUEST,\n             TransactionEventType.CANCEL_SUCCESS,\n         ),\n-        (\n-            TransactionEventType.AUTHORIZATION_REQUEST,\n-            TransactionEventType.AUTHORIZATION_SUCCESS,\n-        ),\n     ],\n )\n def test_create_transaction_event_from_request_and_webhook_response_with_no_psp_reference_invalid_event(\n     event_type,\n@@ -606,12 +603,15 @@\n     assert request_event.include_in_calculations is False\n     assert transaction.events.count() == event_count + 1\n     assert event.psp_reference is None\n     assert event.transaction_id == transaction.id\n-    error_msg = f\"Providing `pspReference` is required for {result_event_type.upper()}.\"\n-    assert event.message == error_msg\n+    error_msg = (\n+        f\"Providing `pspReference` is required for {result_event_type.upper()} \"\n+        \"action result.\"\n+    )\n+    assert error_msg in event.message\n     assert caplog.records[0].levelno == logging.WARNING\n-    assert caplog.records[0].message == error_msg\n+    assert error_msg in caplog.records[0].message\n \n \n @freeze_time(\"2018-05-31 12:00:01\")\n def test_create_transaction_event_from_request_and_webhook_response_part_event(\n@@ -891,8 +891,9 @@\n     transaction_item_generator,\n     app,\n     order_with_lines,\n     django_capture_on_commit_callbacks,\n+    plugins_manager,\n ):\n     # given\n     order = order_with_lines\n     transaction = transaction_item_generator(order_id=order.pk)\n@@ -915,10 +916,10 @@\n     }\n \n     # when\n     with django_capture_on_commit_callbacks(execute=True):\n-        create_transaction_event_from_request_and_webhook_response(\n-            request_event, app, response_data\n+        create_transaction_event_for_transaction_session(\n+            request_event, app, plugins_manager, response_data\n         )\n \n     # then\n     order.refresh_from_db()\n@@ -928,9 +929,9 @@\n \n \n @freeze_time(\"2018-05-31 12:00:01\")\n def test_create_transaction_event_from_request_updates_order_authorize(\n-    transaction_item_generator, app, order_with_lines\n+    transaction_item_generator, app, order_with_lines, plugins_manager\n ):\n     # given\n     order = order_with_lines\n     transaction = transaction_item_generator(order_id=order.pk)\n@@ -952,10 +953,10 @@\n         \"result\": event_type.upper(),\n     }\n \n     # when\n-    create_transaction_event_from_request_and_webhook_response(\n-        request_event, app, response_data\n+    create_transaction_event_for_transaction_session(\n+        request_event, app, plugins_manager, response_data\n     )\n \n     # then\n     order.refresh_from_db()\n@@ -1061,13 +1062,15 @@\n     mocked_checkout_fully_paid.assert_called_once_with(checkout, webhooks=set())\n     mocked_automatic_checkout_completion_task.assert_not_called()\n \n \n+@patch.object(logger, \"error\")\n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n-def test_create_transaction_event_from_request_when_authorized(\n+def test_create_transaction_event_from_request_when_authorized_logs_warnning(\n     mocked_checkout_fully_paid,\n     mocked_automatic_checkout_completion_task,\n+    mocked_logger,\n     transaction_item_generator,\n     app,\n     checkout_with_prices,\n     django_capture_on_commit_callbacks,\n@@ -1077,11 +1080,12 @@\n \n     channel = checkout.channel\n     assert channel.automatically_complete_fully_paid_checkouts is False\n \n+    request_event_type = TransactionEventType.AUTHORIZATION_REQUEST\n     transaction = transaction_item_generator(checkout_id=checkout.pk)\n     request_event = TransactionEvent.objects.create(\n-        type=TransactionEventType.AUTHORIZATION_REQUEST,\n+        type=request_event_type,\n         amount_value=checkout.total.gross.amount,\n         currency=\"USD\",\n         transaction_id=transaction.id,\n     )\n@@ -1103,12 +1107,16 @@\n             request_event, app, response_data\n         )\n \n     # then\n+    # the `create_transaction_event_from_request_and_webhook_response` should never\n+    # be called for `AUTHORIZATION_REQUEST` event type\n+    assert checkout.authorize_status == CheckoutAuthorizeStatus.NONE\n     checkout.refresh_from_db()\n-    assert checkout.authorize_status == CheckoutAuthorizeStatus.FULL\n     mocked_checkout_fully_paid.assert_not_called()\n     mocked_automatic_checkout_completion_task.assert_not_called()\n+    assert mocked_logger.call_count == 1\n+    assert len(mocked_logger.call_args) == 2\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n@@ -1165,9 +1173,9 @@\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n @patch(\"saleor.plugins.manager.PluginsManager.checkout_fully_paid\")\n-def test_create_transaction_event_from_request_when_authorized_triggers_checkout_completion(\n+def test_create_transaction_event_from_session_when_authorized_triggers_checkout_completion(\n     mocked_checkout_fully_paid,\n     mocked_automatic_checkout_completion_task,\n     transaction_item_generator,\n     app,\n@@ -1204,10 +1212,10 @@\n     }\n \n     # when\n     with django_capture_on_commit_callbacks(execute=True):\n-        create_transaction_event_from_request_and_webhook_response(\n-            request_event, app, response_data\n+        create_transaction_event_for_transaction_session(\n+            request_event, app, plugins_manager, response_data\n         )\n \n     # then\n     checkout.refresh_from_db()\n@@ -1248,11 +1256,12 @@\n     assert failed_event.transaction_id == transaction.id\n \n \n @freeze_time(\"2018-05-31 12:00:01\")\n-def test_create_transaction_event_from_request_and_webhook_response_twice_auth(\n+def test_create_transaction_event_for_transaction_session_twice_auth(\n     transaction_item_generator,\n     app,\n+    plugins_manager,\n ):\n     # given\n     transaction = transaction_item_generator()\n     transaction.events.create(\n@@ -1283,19 +1292,16 @@\n         \"externalUrl\": event_url,\n     }\n \n     # when\n-    failed_event = create_transaction_event_from_request_and_webhook_response(\n-        request_event, app, response_data\n+    failed_event = create_transaction_event_for_transaction_session(\n+        request_event, app, plugins_manager, response_data\n     )\n \n     # then\n     assert TransactionEvent.objects.count() == 3\n-    request_event.refresh_from_db()\n-    assert request_event.psp_reference == expected_psp_reference\n-    assert request_event.include_in_calculations is True\n     assert failed_event\n-    assert failed_event.psp_reference == expected_psp_reference\n+    assert failed_event.psp_reference == request_event.psp_reference\n     assert failed_event.type == TransactionEventType.AUTHORIZATION_FAILURE\n \n \n @pytest.mark.parametrize(\n@@ -1311,9 +1317,9 @@\n ):\n     # given\n     expected_psp_reference = \"psp:122:222\"\n     event_amount = first_event_amount\n-    event_type = TransactionEventType.AUTHORIZATION_SUCCESS\n+    event_type = TransactionEventType.CHARGE_SUCCESS\n     event_time = \"2022-11-18T13:25:58.169685+00:00\"\n     event_url = \"http://localhost:3000/event/ref123\"\n \n     transaction = transaction_item_generator()\n@@ -1324,9 +1330,9 @@\n         psp_reference=expected_psp_reference,\n     )\n \n     request_event = TransactionEvent.objects.create(\n-        type=TransactionEventType.AUTHORIZATION_REQUEST,\n+        type=TransactionEventType.CHARGE_REQUEST,\n         amount_value=second_event_amount,\n         currency=\"USD\",\n         transaction_id=transaction.id,\n     )\n@@ -1408,9 +1414,9 @@\n ):\n     # given\n     expected_psp_reference = \"psp:122:222\"\n     authorize_event_amount = Decimal(12.00)\n-    event_type = TransactionEventType.AUTHORIZATION_SUCCESS\n+    event_type = TransactionEventType.CHARGE_SUCCESS\n     event_time = \"2022-11-18T13:25:58.169685+00:00\"\n     event_url = \"http://localhost:3000/event/ref123\"\n \n     transaction = transaction_item_generator()\n@@ -1422,9 +1428,9 @@\n     )\n \n     second_authorize_event_amount = Decimal(33.00)\n     request_event = TransactionEvent.objects.create(\n-        type=TransactionEventType.AUTHORIZATION_REQUEST,\n+        type=TransactionEventType.CHARGE_REQUEST,\n         amount_value=second_authorize_event_amount,\n         currency=\"USD\",\n         transaction_id=transaction.id,\n     )\n@@ -1448,9 +1454,9 @@\n     assert request_event.psp_reference == expected_psp_reference\n     assert request_event.include_in_calculations is True\n     assert failed_event\n     assert failed_event.psp_reference == expected_psp_reference\n-    assert failed_event.type == TransactionEventType.AUTHORIZATION_FAILURE\n+    assert failed_event.type == TransactionEventType.CHARGE_FAILURE\n \n \n @freeze_time(\"2018-05-31 12:00:01\")\n def test_create_event_from_request_and_webhook_missing_response_calculate_refundable(\n@@ -2221,25 +2227,25 @@\n     (\"response_result\", \"message\"),\n     [\n         (\n             TransactionEventType.AUTHORIZATION_SUCCESS,\n-            \"Providing `pspReference` is required for AUTHORIZATION_SUCCESS.\",\n+            \"Providing `pspReference` is required for AUTHORIZATION_SUCCESS action result.\",\n         ),\n         (\n             TransactionEventType.CHARGE_SUCCESS,\n-            \"Providing `pspReference` is required for CHARGE_SUCCESS.\",\n+            \"Providing `pspReference` is required for CHARGE_SUCCESS action result.\",\n         ),\n         (\n             TransactionEventType.CHARGE_FAILURE,\n             \"Message related to the payment\",\n         ),\n         (\n             TransactionEventType.CHARGE_REQUEST,\n-            \"Providing `pspReference` is required for CHARGE_REQUEST.\",\n+            \"Providing `pspReference` is required for CHARGE_REQUEST action result.\",\n         ),\n         (\n             TransactionEventType.AUTHORIZATION_REQUEST,\n-            \"Providing `pspReference` is required for AUTHORIZATION_REQUEST.\",\n+            \"Providing `pspReference` is required for AUTHORIZATION_REQUEST action result.\",\n         ),\n     ],\n )\n def test_create_transaction_event_for_transaction_session_missing_psp_reference(\n@@ -2273,9 +2279,9 @@\n \n     # then\n     assert response_event.amount_value == expected_amount\n     assert response_event.type == TransactionEventType.CHARGE_FAILURE\n-    assert response_event.message == message\n+    assert message in response_event.message\n     transaction.refresh_from_db()\n     assert transaction.authorized_value == Decimal(\"0\")\n     assert transaction.charged_value == Decimal(\"0\")\n     assert transaction.authorize_pending_value == Decimal(\"0\")\n"
        },
        {
          "path": "saleor/payment/utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/utils.py\n===================================================================\n--- saleor/payment/utils.py\tc616f67 (parent)\n+++ saleor/payment/utils.py\t4fbc4ca (commit)\n@@ -1,5 +1,4 @@\n-import datetime\n import decimal\n import json\n import logging\n from decimal import Decimal\n@@ -12,8 +11,9 @@\n from django.db import IntegrityError, transaction\n from django.db.models import Q\n from django.template.defaultfilters import truncatechars\n from django.utils import timezone\n+from pydantic import ValidationError\n \n from ..account.models import User\n from ..app.models import App\n from ..channel import TransactionFlowStrategy\n@@ -36,8 +36,14 @@\n     update_order_authorize_data,\n     updates_amounts_for_order,\n )\n from ..plugins.manager import PluginsManager, get_plugins_manager\n+from ..webhook.response_schemas.transaction import (\n+    TransactionCancelRequestedSchema,\n+    TransactionChargeRequestedSchema,\n+    TransactionRefundRequestedSchema,\n+    TransactionSessionSchema,\n+)\n from . import (\n     OPTIONAL_PSP_REFERENCE_EVENTS,\n     ChargeStatus,\n     GatewayError,\n@@ -74,8 +80,9 @@\n ALLOWED_GATEWAY_KINDS = {choices[0] for choices in TransactionKind.CHOICES}\n TRANSACTION_EVENT_MSG_MAX_LENGTH: int = TransactionEvent._meta.get_field(  # type: ignore[assignment]\n     \"message\"\n ).max_length\n+SESSION_REQUEST_EVENT_TYPE = \"session-request\"\n \n \n def _recalculate_last_refund_success_for_transaction(\n     transaction_item: TransactionItem,\n@@ -840,104 +847,8 @@\n         logger.warning(missing_msg, \"amount\")\n         error_field_msg.append(missing_msg % \"amount\")\n \n \n-def parse_transaction_event_data(\n-    event_data: dict,\n-    parsed_event_data: dict,\n-    error_field_msg: list[str],\n-    psp_reference: str | None,\n-    request_type: str,\n-    event_is_optional: bool = True,\n-):\n-    if (\n-        event_is_optional\n-        and event_data.get(\"amount\") is None\n-        and not event_data.get(\"result\")\n-    ):\n-        return\n-    missing_msg = (\n-        \"Missing value for field: %s in response of transaction action webhook.\"\n-    )\n-    invalid_msg = (\n-        \"Incorrect value for field: %s, value: %s in \"\n-        \"response of transaction action webhook.\"\n-    )\n-\n-    parsed_event_data[\"psp_reference\"] = psp_reference\n-\n-    possible_event_types = {\n-        str_to_enum(event_result): event_result\n-        for event_result in get_correct_event_types_based_on_request_type(request_type)\n-    }\n-\n-    result = event_data.get(\"result\")\n-    if result:\n-        if result in possible_event_types:\n-            parsed_event_data[\"type\"] = possible_event_types[result]\n-        else:\n-            possible_types = \",\".join(possible_event_types.keys())\n-            msg = (\n-                \"Incorrect value: %s for field: `result` in the response. Request: %s \"\n-                \"can accept only types: %s\"\n-            )\n-            logger.warning(msg, result, request_type.upper(), possible_types)\n-            error_field_msg.append(msg % (result, request_type.upper(), possible_types))\n-    else:\n-        logger.warning(missing_msg, \"result\")\n-        error_field_msg.append(missing_msg % \"result\")\n-\n-    parsed_event_data[\"message\"] = _clean_message(event_data)\n-\n-    amount_data = event_data.get(\"amount\")\n-    parse_transaction_event_amount(\n-        amount_data,\n-        parsed_event_data=parsed_event_data,\n-        error_field_msg=error_field_msg,\n-        invalid_msg=invalid_msg,\n-        missing_msg=missing_msg,\n-    )\n-\n-    if event_time_data := event_data.get(\"time\"):\n-        try:\n-            parsed_event_data[\"time\"] = (\n-                datetime.datetime.fromisoformat(event_time_data).replace(\n-                    tzinfo=datetime.UTC\n-                )\n-                if event_time_data\n-                else None\n-            )\n-        except ValueError:\n-            logger.warning(invalid_msg, \"time\", event_time_data)\n-            error_field_msg.append(invalid_msg % (\"time\", event_time_data))\n-    else:\n-        parsed_event_data[\"time\"] = timezone.now()\n-\n-    parsed_event_data[\"external_url\"] = event_data.get(\"externalUrl\", \"\")\n-\n-\n-def _clean_message(event_data):\n-    message = event_data.get(\"message\") or \"\"\n-    try:\n-        message = str(message)\n-    except (UnicodeEncodeError, TypeError, ValueError):\n-        invalid_err_msg = (\n-            \"Incorrect value for field: %s in response of transaction action webhook.\"\n-        )\n-        logger.warning(invalid_err_msg, \"message\")\n-        message = \"\"\n-\n-    if message and len(message) > TRANSACTION_EVENT_MSG_MAX_LENGTH:\n-        message = truncate_transaction_event_message(message)\n-        field_limit_exceeded_msg = (\n-            \"Value for field: %s in response of transaction action webhook \"\n-            \"exceeds the character field limit. Message has been truncated.\"\n-        )\n-        logger.warning(field_limit_exceeded_msg, \"message\")\n-\n-    return message\n-\n-\n error_msg = str\n \n \n def parse_transaction_action_data(\n@@ -950,59 +861,90 @@\n     It takes the recieved response from sync webhook and\n     returns TransactionRequestResponse with all details.\n     If unable to parse, None will be returned.\n     \"\"\"\n-    psp_reference: str = response_data.get(\"pspReference\")\n-    available_actions = response_data.get(\"actions\", None)\n-    if available_actions is not None:\n-        possible_actions = {\n-            str_to_enum(event_action): event_action\n-            for event_action, _ in TransactionAction.CHOICES\n-        }\n-        available_actions = [\n-            possible_actions[action]\n-            for action in available_actions\n-            if action in possible_actions\n-        ]\n-\n-    parsed_event_data: dict = {}\n-    error_field_msg: list[str] = []\n-    parse_transaction_event_data(\n-        event_data=response_data,\n-        parsed_event_data=parsed_event_data,\n-        error_field_msg=error_field_msg,\n-        psp_reference=psp_reference,\n-        request_type=request_type,\n-        event_is_optional=event_is_optional,\n+    skip_data_parsing = (\n+        event_is_optional\n+        and response_data.get(\"amount\") is None\n+        and not response_data.get(\"result\")\n     )\n+    if skip_data_parsing:\n+        psp_reference = response_data.get(\"pspReference\")\n+        if not psp_reference and request_type not in OPTIONAL_PSP_REFERENCE_EVENTS:\n+            msg = f\"Providing `pspReference` is required for {request_type.upper()}.\"\n+            logger.warning(msg)\n+            return None, msg\n+        return (\n+            TransactionRequestResponse(\n+                psp_reference=psp_reference,\n+                available_actions=parse_available_actions(\n+                    response_data.get(\"actions\", None)\n+                ),\n+                event=None,\n+            ),\n+            None,\n+        )\n \n-    if error_field_msg:\n-        # error field msg can contain details of the value returned by payment app\n-        # which means that we need to confirm that we don't exceed the field limit.\n-        msg = \"\\n\".join(error_field_msg)\n-        msg = truncate_transaction_event_message(msg)\n-        return None, msg\n+    response_data_model = None\n+    request_type_to_schema_map = {\n+        TransactionEventType.CHARGE_REQUEST: TransactionChargeRequestedSchema,\n+        TransactionEventType.REFUND_REQUEST: TransactionRefundRequestedSchema,\n+        TransactionEventType.CANCEL_REQUEST: TransactionCancelRequestedSchema,\n+        SESSION_REQUEST_EVENT_TYPE: TransactionSessionSchema,\n+    }\n \n-    request_event_type = parsed_event_data.get(\"type\", request_type)\n-    if not psp_reference and request_event_type not in OPTIONAL_PSP_REFERENCE_EVENTS:\n-        msg = f\"Providing `pspReference` is required for {request_event_type.upper()}.\"\n-        logger.warning(msg)\n+    request_schema = request_type_to_schema_map.get(request_type)\n+    if not request_schema:\n+        logger.error(\n+            \"Request type %s not supported for parsing transaction action data.\",\n+            request_type,\n+            extra={\"request_type\": request_type},\n+        )\n+        return None, \"Request type not supported\"\n+\n+    try:\n+        response_data_model = (\n+            request_schema.model_validate(response_data)  # type: ignore[attr-defined]\n+        )\n+    except ValidationError as error:\n+        error_msg = str(error)\n+        logger.warning(error_msg)\n+        msg = truncate_transaction_event_message(error_msg)\n         return None, msg\n \n     return (\n         TransactionRequestResponse(\n-            psp_reference=psp_reference,\n-            available_actions=available_actions,\n+            psp_reference=response_data_model.psp_reference,\n+            available_actions=response_data_model.actions,\n             event=(\n-                TransactionRequestEventResponse(**parsed_event_data)\n-                if parsed_event_data\n-                else None\n+                TransactionRequestEventResponse(\n+                    psp_reference=response_data_model.psp_reference,\n+                    type=response_data_model.result,\n+                    amount=response_data_model.amount,\n+                    time=response_data_model.time,\n+                    external_url=str(response_data_model.external_url),\n+                    message=response_data_model.message,\n+                )\n             ),\n         ),\n         None,\n     )\n \n \n+def parse_available_actions(available_actions):\n+    if available_actions is not None:\n+        possible_actions = {\n+            str_to_enum(event_action): event_action\n+            for event_action, _ in TransactionAction.CHOICES\n+        }\n+        available_actions = [\n+            possible_actions[action]\n+            for action in available_actions\n+            if action in possible_actions\n+        ]\n+    return available_actions\n+\n+\n def truncate_transaction_event_message(message: str):\n     return truncatechars(message, TRANSACTION_EVENT_MSG_MAX_LENGTH)\n \n \n@@ -1216,13 +1158,11 @@\n     app: App,\n     manager: \"PluginsManager\",\n     transaction_webhook_response: dict[str, Any] | None = None,\n ):\n-    request_event_type = \"session-request\"\n-\n     transaction_request_response, error_msg = _get_parsed_transaction_action_data(\n         transaction_webhook_response=transaction_webhook_response,\n-        event_type=request_event_type,\n+        event_type=SESSION_REQUEST_EVENT_TYPE,\n         event_is_optional=False,\n     )\n     if not transaction_request_response or not transaction_request_response.event:\n         return create_failed_transaction_event(request_event, cause=error_msg or \"\")\n"
        },
        {
          "path": "saleor/plugins/webhook/plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/plugin.py\n===================================================================\n--- saleor/plugins/webhook/plugin.py\tc616f67 (parent)\n+++ saleor/plugins/webhook/plugin.py\t4fbc4ca (commit)\n@@ -90,8 +90,11 @@\n     generate_thumbnail_payload,\n     generate_transaction_session_payload,\n     generate_translation_payload,\n )\n+from ...webhook.response_schemas.transaction import (\n+    PaymentGatewayInitializeSessionSchema,\n+)\n from ...webhook.transport.asynchronous.transport import (\n     WebhookPayloadData,\n     send_webhook_request_async,\n     trigger_webhooks_async,\n@@ -3129,11 +3132,22 @@\n         )\n         error_msg = None\n         if response_data is None:\n             error_msg = \"Unable to process a payment gateway response.\"\n+\n+        response_data_model = None\n+        if response_data:\n+            try:\n+                response_data_model = (\n+                    PaymentGatewayInitializeSessionSchema.model_validate(response_data)\n+                )\n+            except ValidationError as e:\n+                response_data = None\n+                error_msg = str(e)\n+\n         response_gateway[webhook.app.identifier] = PaymentGatewayData(\n             app_identifier=webhook.app.identifier,\n-            data=response_data,\n+            data=response_data_model.data if response_data_model else None,\n             error=error_msg,\n         )\n \n     def payment_gateway_initialize_session(\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/test_payment_gateway_initialize_session_webhook.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/tests/test_payment_gateway_initialize_session_webhook.py\n===================================================================\n--- saleor/plugins/webhook/tests/test_payment_gateway_initialize_session_webhook.py\tc616f67 (parent)\n+++ saleor/plugins/webhook/tests/test_payment_gateway_initialize_session_webhook.py\t4fbc4ca (commit)\n@@ -94,9 +94,11 @@\n     mock_request, webhook_plugin, webhook_app, checkout, permission_manage_payments\n ):\n     # given\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -129,9 +131,11 @@\n ):\n     # given\n     data = {\"some\": \"request-data\"}\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -166,9 +170,11 @@\n     mock_request, webhook_plugin, webhook_app, checkout, permission_manage_payments\n ):\n     # given\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -203,9 +209,11 @@\n ):\n     # given\n     data = {\"some\": \"request-data\"}\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -273,9 +281,11 @@\n     mock_request, webhook_plugin, webhook_app, order, permission_manage_payments\n ):\n     # given\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -308,9 +318,11 @@\n ):\n     # given\n     data = {\"some\": \"request-data\"}\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -345,9 +357,11 @@\n     mock_request, webhook_plugin, webhook_app, order, permission_manage_payments\n ):\n     # given\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n@@ -383,9 +397,11 @@\n ):\n     # given\n     data = {\"some\": \"request-data\"}\n     expected_data = {\"some\": \"json data\"}\n-    mock_request.return_value = expected_data\n+    mock_request.return_value = {\n+        \"data\": expected_data,\n+    }\n     plugin = webhook_plugin()\n \n     webhook_app.identifier = \"app.identifier\"\n     webhook_app.save()\n"
        },
        {
          "path": "saleor/webhook/response_schemas/annotations.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/response_schemas/annotations.py\n===================================================================\n--- saleor/webhook/response_schemas/annotations.py\tc616f67 (parent)\n+++ saleor/webhook/response_schemas/annotations.py\t4fbc4ca (commit)\n@@ -1,14 +1,21 @@\n+import logging\n+from datetime import UTC, datetime\n from typing import Annotated, Any, TypeVar\n \n from pydantic import (\n+    AfterValidator,\n     BeforeValidator,\n+    ValidationError,\n+    ValidatorFunctionWrapHandler,\n+    WrapValidator,\n )\n-from pydantic_core import PydanticUseDefault\n+from pydantic_core import PydanticOmit, PydanticUseDefault\n \n from ...core.utils.metadata_manager import metadata_is_valid\n \n M = TypeVar(\"M\")\n+logger = logging.getLogger(__name__)\n \n \n def skip_invalid_metadata(value: M) -> M:\n     if not metadata_is_valid(value):\n@@ -26,4 +33,17 @@\n \n \n T = TypeVar(\"T\")\n DefaultIfNone = Annotated[T, BeforeValidator(default_if_none)]\n+\n+DatetimeUTC = Annotated[datetime, AfterValidator(lambda v: v.replace(tzinfo=UTC))]\n+\n+\n+def skip_invalid_literal(value: T, handler: ValidatorFunctionWrapHandler) -> T:\n+    try:\n+        return handler(value)\n+    except ValidationError as err:\n+        logger.warning(\"Skipping invalid literal value: %s\", err)\n+        raise PydanticOmit() from err\n+\n+\n+OnErrorSkipLiteral = Annotated[T, WrapValidator(skip_invalid_literal)]\n"
        },
        {
          "path": "saleor/webhook/response_schemas/transaction.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/transaction.py\n===================================================================\n--- saleor/webhook/response_schemas/transaction.py\tc616f67 (parent)\n+++ saleor/webhook/response_schemas/transaction.py\t4fbc4ca (commit)\n@@ -0,0 +1,217 @@\n+import logging\n+from datetime import datetime\n+from decimal import Decimal\n+from enum import Enum\n+from typing import Annotated, Any, Literal\n+\n+from django.conf import settings\n+from django.utils import timezone\n+from pydantic import (\n+    BaseModel,\n+    Field,\n+    HttpUrl,\n+    JsonValue,\n+    field_validator,\n+    model_validator,\n+)\n+\n+from ...graphql.core.utils import str_to_enum\n+from ...payment import (\n+    OPTIONAL_PSP_REFERENCE_EVENTS,\n+    TransactionAction,\n+    TransactionEventType,\n+)\n+from .annotations import DatetimeUTC, DefaultIfNone, OnErrorSkipLiteral\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+TransactionActionEnum = Enum(  # type: ignore[misc]\n+    \"TransactionActionEnum\",\n+    [(str_to_enum(value), value) for value, _ in TransactionAction.CHOICES],\n+)\n+\n+\n+class TransactionSchema(BaseModel):\n+    psp_reference: Annotated[\n+        DefaultIfNone[str],\n+        Field(\n+            validation_alias=\"pspReference\",\n+            default=None,\n+            description=(\n+                \"Psp reference received from payment provider. Optional for the following results: \"\n+                + \", \".join([event.upper() for event in OPTIONAL_PSP_REFERENCE_EVENTS])\n+            ),\n+        ),\n+    ]\n+    amount: Annotated[\n+        Decimal, Field(description=\"Decimal amount of the processed action\")\n+    ]\n+    time: Annotated[\n+        DefaultIfNone[DatetimeUTC],\n+        Field(\n+            description=\"Time of the action in ISO 8601 format\",\n+            default_factory=timezone.now,\n+        ),\n+    ]\n+    external_url: Annotated[\n+        DefaultIfNone[HttpUrl],\n+        Field(\n+            validation_alias=\"externalUrl\",\n+            description=\"External url with action details\",\n+            default=\"\",\n+        ),\n+    ]\n+    message: Annotated[\n+        DefaultIfNone[str],\n+        Field(\n+            description=\"Message related to the action. The maximum length is 512 characters; any text exceeding this limit will be truncated\",\n+            default=\"\",\n+        ),\n+    ]\n+    actions: (  # type: ignore[name-defined]\n+        Annotated[\n+            list[\n+                OnErrorSkipLiteral[\n+                    Literal[\n+                        TransactionActionEnum.CHARGE.name,\n+                        TransactionActionEnum.REFUND.name,\n+                        TransactionActionEnum.CANCEL.name,\n+                    ]\n+                ]\n+            ],\n+            Field(description=\"List of actions available for the transaction.\"),\n+        ]\n+        | None\n+    ) = None\n+    result: Annotated[\n+        str,\n+        Field(description=\"Result of the action\"),\n+    ]\n+\n+    @model_validator(mode=\"after\")\n+    def clean_psp_reference(self):\n+        if not self.psp_reference and self.result not in OPTIONAL_PSP_REFERENCE_EVENTS:\n+            error_msg = f\"Providing `pspReference` is required for {self.result.upper()} action result.\"\n+            raise ValueError(error_msg)\n+        return self\n+\n+    @field_validator(\"amount\", mode=\"after\")\n+    @classmethod\n+    def clean_amount(cls, amount: Decimal) -> Decimal:\n+        amount = amount.quantize(Decimal(10) ** (-settings.DEFAULT_DECIMAL_PLACES))\n+        return amount\n+\n+    @field_validator(\"time\", mode=\"before\")\n+    @classmethod\n+    def clean_time(cls, time: Any) -> datetime | None:\n+        # pydantic do not support all ISO 8601 formats so in case of string\n+        # we need to parse it manually; different types are handled by pydantic\n+        if isinstance(time, str):\n+            try:\n+                time = datetime.fromisoformat(time)\n+            except ValueError as e:\n+                raise ValueError(\n+                    \"Invalid value for field 'time': {time}. Expected ISO 8601 format.\"\n+                ) from e\n+\n+        return time\n+\n+    @field_validator(\"message\", mode=\"before\")\n+    @classmethod\n+    def clean_message(cls, value: Any):\n+        from ...payment.utils import (\n+            TRANSACTION_EVENT_MSG_MAX_LENGTH,\n+            truncate_transaction_event_message,\n+        )\n+\n+        message = value or \"\"\n+        try:\n+            message = str(message)\n+        except (UnicodeEncodeError, TypeError, ValueError):\n+            invalid_err_msg = \"Incorrect value for field: %s in response of transaction action webhook.\"\n+            logger.warning(invalid_err_msg, \"message\")\n+            message = \"\"\n+\n+        if message and len(message) > TRANSACTION_EVENT_MSG_MAX_LENGTH:\n+            message = truncate_transaction_event_message(message)\n+            field_limit_exceeded_msg = (\n+                \"Value for field: %s in response of transaction action webhook \"\n+                \"exceeds the character field limit. Message has been truncated.\"\n+            )\n+            logger.warning(field_limit_exceeded_msg, \"message\")\n+\n+        return message\n+\n+    @field_validator(\"actions\", mode=\"after\")\n+    @classmethod\n+    def clean_actions(cls, actions: list[str] | None) -> list[str] | None:\n+        return [action.lower() for action in actions] if actions else actions\n+\n+    @field_validator(\"result\", mode=\"after\")\n+    @classmethod\n+    def clean_result(cls, result: str) -> str:\n+        return result.lower()\n+\n+\n+TransactionEventTypeEnum = Enum(  # type: ignore[misc]\n+    \"TransactionEventTypeEnum\",\n+    [(str_to_enum(value), value) for value, _ in TransactionEventType.CHOICES],\n+)\n+\n+\n+class TransactionChargeRequestedSchema(TransactionSchema):\n+    result: Annotated[  # type: ignore[name-defined]\n+        Literal[\n+            TransactionEventTypeEnum.CHARGE_SUCCESS.name,\n+            TransactionEventTypeEnum.CHARGE_FAILURE.name,\n+        ],\n+        Field(description=\"Result of the action\"),\n+    ]\n+\n+\n+class TransactionCancelRequestedSchema(TransactionSchema):\n+    result: Annotated[  # type: ignore[name-defined]\n+        Literal[\n+            TransactionEventTypeEnum.CANCEL_SUCCESS.name,\n+            TransactionEventTypeEnum.CANCEL_FAILURE.name,\n+        ],\n+        Field(description=\"Result of the action\"),\n+    ]\n+\n+\n+class TransactionRefundRequestedSchema(TransactionSchema):\n+    result: Annotated[  # type: ignore[name-defined]\n+        Literal[\n+            TransactionEventTypeEnum.REFUND_SUCCESS.name,\n+            TransactionEventTypeEnum.REFUND_FAILURE.name,\n+        ],\n+        Field(description=\"Result of the action\"),\n+    ]\n+\n+\n+class TransactionSessionSchema(TransactionSchema):\n+    result: Annotated[  # type: ignore[name-defined]\n+        Literal[\n+            TransactionEventTypeEnum.AUTHORIZATION_SUCCESS.name,\n+            TransactionEventTypeEnum.AUTHORIZATION_FAILURE.name,\n+            TransactionEventTypeEnum.AUTHORIZATION_ACTION_REQUIRED.name,\n+            TransactionEventTypeEnum.AUTHORIZATION_REQUEST.name,\n+            TransactionEventTypeEnum.CHARGE_SUCCESS.name,\n+            TransactionEventTypeEnum.CHARGE_FAILURE.name,\n+            TransactionEventTypeEnum.CHARGE_ACTION_REQUIRED.name,\n+            TransactionEventTypeEnum.CHARGE_REQUEST.name,\n+        ],\n+        Field(description=\"Result of the action\"),\n+    ]\n+    data: Annotated[\n+        DefaultIfNone[JsonValue],\n+        Field(\n+            description=\"The JSON data that will be returned to storefront\",\n+            default=None,\n+        ),\n+    ]\n+\n+\n+class PaymentGatewayInitializeSessionSchema(BaseModel):\n+    data: JsonValue\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_transaction.py",
          "status": "added",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_transaction.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_transaction.py\tc616f67 (parent)\n+++ saleor/webhook/tests/response_schemas/test_transaction.py\t4fbc4ca (commit)\n@@ -0,0 +1,612 @@\n+import math\n+from datetime import UTC, datetime\n+from decimal import Decimal\n+\n+import pytest\n+from django.utils import timezone\n+from freezegun import freeze_time\n+from pydantic import ValidationError\n+\n+from ....payment import TransactionAction, TransactionEventType\n+from ...response_schemas.transaction import (\n+    PaymentGatewayInitializeSessionSchema,\n+    TransactionCancelRequestedSchema,\n+    TransactionChargeRequestedSchema,\n+    TransactionRefundRequestedSchema,\n+    TransactionSchema,\n+    TransactionSessionSchema,\n+)\n+\n+\n+def test_transaction_schema_valid_full_data():\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+    }\n+\n+    # when\n+    transaction = TransactionSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.psp_reference == data[\"pspReference\"]\n+    assert transaction.amount == data[\"amount\"]\n+    assert transaction.time.isoformat() == data[\"time\"]\n+    assert str(transaction.external_url) == data[\"externalUrl\"]\n+    assert transaction.message == data[\"message\"]\n+    assert transaction.actions == [action.lower() for action in data.get(\"actions\")]\n+    assert transaction.result == data[\"result\"].lower()\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # Only required fields with values\n+        {\n+            \"pspReference\": None,\n+            \"amount\": Decimal(\"100.50\"),\n+            \"time\": None,\n+            \"externalUrl\": None,\n+            \"message\": None,\n+            \"actions\": None,\n+            \"result\": TransactionEventType.CHARGE_ACTION_REQUIRED.upper(),\n+        },\n+        # Only required fields with values\n+        {\n+            \"amount\": Decimal(\"100.50\"),\n+            \"result\": TransactionEventType.CHARGE_ACTION_REQUIRED.upper(),\n+        },\n+    ],\n+)\n+@freeze_time(\"2023-01-01T12:00:00+00:00\")\n+def test_transaction_schema_valid_only_required_fields(data):\n+    # when\n+    transaction = TransactionSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.psp_reference is None\n+    assert transaction.amount == data[\"amount\"]\n+    assert transaction.time.isoformat() == timezone.now().isoformat()\n+    assert str(transaction.external_url) == \"\"\n+    assert transaction.message == \"\"\n+    assert transaction.actions is None\n+    assert transaction.result == data[\"result\"].lower()\n+\n+\n+@pytest.mark.parametrize(\n+    \"amount\",\n+    [Decimal(\"100.50\"), 100.50, 100, \"100.50\"],\n+)\n+def test_transaction_schema_with_various_amount_types(amount):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": amount,\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+    }\n+\n+    # when\n+    transaction = TransactionSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.amount == Decimal(str(amount))\n+\n+\n+@pytest.mark.parametrize(\n+    (\"time\", \"time_parser\"),\n+    [\n+        # ISO 8601 format with timezone\n+        (\"2023-01-01T12:00:00+00:00\", datetime.fromisoformat),\n+        # ISO 8601 format without timezone\n+        (\"2023-01-01T12:00:00\", datetime.fromisoformat),\n+        # ISO 8601 format with milliseconds\n+        (\"2023-01-01T12:00:00.123+00:00\", datetime.fromisoformat),\n+        # ISO 8601 format with week-based date\n+        (\"2023-W01-1T12:00:00\", datetime.fromisoformat),\n+        # Time as integer\n+        (1672531200, datetime.fromtimestamp),\n+        # No time provided (should use current time)\n+        (None, None),\n+    ],\n+)\n+@freeze_time(\"2023-01-01T12:00:00+00:00\")\n+def test_transaction_schema_time_valid(time, time_parser):\n+    # given\n+    data = {\n+        \"pspReference\": \"123\",\n+        \"amount\": Decimal(\"100.00\"),\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+        \"time\": time,\n+    }\n+\n+    # when\n+    transaction = TransactionSchema.model_validate(data)\n+\n+    # then\n+    time = data.get(\"time\")\n+    parsed_time = time_parser(time) if time else timezone.now()\n+    assert transaction.time == parsed_time.replace(tzinfo=UTC)\n+\n+\n+@pytest.mark.parametrize(\n+    (\"actions\", \"expected_actions\"),\n+    [\n+        # Valid actions\n+        (\n+            [\n+                TransactionAction.CHARGE.upper(),\n+                TransactionAction.REFUND.upper(),\n+                TransactionAction.CANCEL.upper(),\n+            ],\n+            [\n+                TransactionAction.CHARGE,\n+                TransactionAction.REFUND,\n+                TransactionAction.CANCEL,\n+            ],\n+        ),\n+        # Just one action\n+        (\n+            [TransactionAction.CANCEL.upper()],\n+            [TransactionAction.CANCEL],\n+        ),\n+        # Invalid actions (should skip invalid ones)\n+        (\n+            [\"INVALID\", TransactionAction.REFUND.upper()],\n+            [TransactionAction.REFUND],\n+        ),\n+        # Empty actions list\n+        (\n+            [],\n+            [],\n+        ),\n+        # None actions\n+        (\n+            None,\n+            None,\n+        ),\n+    ],\n+)\n+def test_transaction_schema_actions_validation(actions, expected_actions):\n+    # given\n+    data = {\n+        \"pspReference\": \"123\",\n+        \"amount\": Decimal(\"100.00\"),\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+        \"actions\": actions,\n+    }\n+\n+    # when\n+    transaction = TransactionSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.actions == expected_actions\n+\n+\n+@pytest.mark.parametrize(\n+    (\"data\", \"invalid_field\"),\n+    [\n+        # Time as a string value\n+        (\n+            {\n+                \"pspReference\": \"123\",\n+                \"amount\": Decimal(\"100.00\"),\n+                \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+                \"time\": \"invalid-time\",\n+            },\n+            \"time\",\n+        ),\n+        # Invalid external URL\n+        (\n+            {\n+                \"amount\": \"100.50\",\n+                \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+                \"externalUrl\": \"invalid-url\",\n+            },\n+            \"externalUrl\",\n+        ),\n+        # Infinitive amount\n+        (\n+            {\n+                \"pspReference\": \"123\",\n+                \"amount\": math.inf,\n+                \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+            },\n+            \"amount\",\n+        ),\n+    ],\n+)\n+def test_transaction_schema_invalid(data, invalid_field):\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (invalid_field,)\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.AUTHORIZATION_SUCCESS,\n+        TransactionEventType.CHARGE_SUCCESS,\n+        TransactionEventType.CANCEL_SUCCESS,\n+        TransactionEventType.REFUND_SUCCESS,\n+        TransactionEventType.CHARGE_BACK,\n+        TransactionEventType.REFUND_REVERSE,\n+    ],\n+)\n+def test_transaction_schema_time_missing_psp_reference(result):\n+    # given\n+    data = {\n+        \"amount\": Decimal(\"100.00\"),\n+        \"result\": result.upper(),\n+    }\n+\n+    # when/then\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionSchema.model_validate(data)\n+\n+    assert len(exc_info.value.errors()) == 1\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.CHARGE_SUCCESS,\n+        TransactionEventType.CHARGE_FAILURE,\n+    ],\n+)\n+def test_transaction_charge_requested_schema_valid(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    transaction = TransactionChargeRequestedSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.result == result\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.CANCEL_FAILURE,\n+        TransactionEventType.REFUND_FAILURE,\n+        TransactionEventType.CANCEL_SUCCESS,\n+        TransactionEventType.REFUND_SUCCESS,\n+    ],\n+)\n+def test_transaction_charge_requested_schema_invalid(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionChargeRequestedSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (\"result\",)\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.CANCEL_SUCCESS,\n+        TransactionEventType.CANCEL_FAILURE,\n+    ],\n+)\n+def test_transaction_cancel_requested_schema_valid(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    transaction = TransactionCancelRequestedSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.result == result\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.CHARGE_FAILURE,\n+        TransactionEventType.REFUND_FAILURE,\n+        TransactionEventType.CHARGE_SUCCESS,\n+        TransactionEventType.REFUND_SUCCESS,\n+    ],\n+)\n+def test_transaction_cancel_requested_schema_invalid(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionCancelRequestedSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (\"result\",)\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.REFUND_SUCCESS,\n+        TransactionEventType.REFUND_FAILURE,\n+    ],\n+)\n+def test_transaction_refund_requested_schema_valid(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    transaction = TransactionRefundRequestedSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.result == result\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.CHARGE_FAILURE,\n+        TransactionEventType.CANCEL_FAILURE,\n+        TransactionEventType.CHARGE_SUCCESS,\n+        TransactionEventType.CANCEL_SUCCESS,\n+    ],\n+)\n+def test_transaction_refund_requested_schema_invalid(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionRefundRequestedSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (\"result\",)\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.AUTHORIZATION_SUCCESS,\n+        TransactionEventType.AUTHORIZATION_FAILURE,\n+        TransactionEventType.AUTHORIZATION_ACTION_REQUIRED,\n+        TransactionEventType.AUTHORIZATION_REQUEST,\n+        TransactionEventType.CHARGE_SUCCESS,\n+        TransactionEventType.CHARGE_FAILURE,\n+        TransactionEventType.CHARGE_ACTION_REQUIRED,\n+        TransactionEventType.CHARGE_REQUEST,\n+    ],\n+)\n+def test_transaction_session_schema_valid_result(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"time\": \"2023-01-01T12:00:00+00:00\",\n+        \"externalUrl\": \"https://example.com/\",\n+        \"message\": \"Transaction completed successfully.\",\n+        \"actions\": [TransactionAction.CHARGE.upper(), TransactionAction.REFUND.upper()],\n+        \"result\": result.upper(),\n+        \"data\": \"test-data\",\n+    }\n+\n+    # when\n+    transaction = TransactionSessionSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.result == result\n+\n+\n+@pytest.mark.parametrize(\n+    \"result\",\n+    [\n+        TransactionEventType.REFUND_FAILURE,\n+        TransactionEventType.CANCEL_FAILURE,\n+        TransactionEventType.REFUND_SUCCESS,\n+        TransactionEventType.CANCEL_SUCCESS,\n+    ],\n+)\n+def test_transaction_session_schema_invalid_result(result):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"result\": result.upper(),\n+    }\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionSessionSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (\"result\",)\n+\n+\n+@pytest.mark.parametrize(\n+    \"data_value\",\n+    [\n+        # Valid data\n+        {\"key\": \"value\", \"another_key\": \"another_value\"},\n+        # Empty data\n+        {},\n+        # Data with special characters\n+        {\"key\": \"!@#$%^&*()_+\"},\n+        # Data with nested structure\n+        {\"nested\": {\"key\": \"value\"}},\n+        # Data with list\n+        {\"list\": [\"item1\", \"item2\", \"item3\"]},\n+        # Data as None\n+        None,\n+        # Data as string\n+        \"string_data\",\n+        # Data as integer\n+        123,\n+    ],\n+)\n+def test_transaction_session_schema_valid_data(data_value):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"result\": TransactionEventType.AUTHORIZATION_SUCCESS.upper(),\n+        \"data\": data_value,\n+    }\n+\n+    # when\n+    transaction = TransactionSessionSchema.model_validate(data)\n+\n+    # then\n+    assert transaction.data == data_value\n+\n+\n+@pytest.mark.parametrize(\n+    \"data_value\",\n+    [\n+        # Non-serializable object\n+        object(),\n+        # Set - not JSON serializable\n+        {1, 2, 3},\n+        # Function\n+        lambda x: x,\n+        # File handle\n+        open,\n+    ],\n+)\n+def test_transaction_session_schema_invalid_data(data_value):\n+    # given\n+    data = {\n+        \"pspReference\": \"psp-123\",\n+        \"amount\": Decimal(\"100.50\"),\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+        \"data\": data_value,\n+    }\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        TransactionSessionSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (\"data\",)\n+\n+\n+@pytest.mark.parametrize(\n+    \"data_value\",\n+    [\n+        # Valid data\n+        {\"key\": \"value\", \"another_key\": \"another_value\"},\n+        # Empty data\n+        {},\n+        # Data with special characters\n+        {\"key\": \"!@#$%^&*()_+\"},\n+        # Data with nested structure\n+        {\"nested\": {\"key\": \"value\"}},\n+        # Data with list\n+        {\"list\": [\"item1\", \"item2\", \"item3\"]},\n+        # Data as None\n+        None,\n+        # Data as string\n+        \"string_data\",\n+        # Data as integer\n+        123,\n+    ],\n+)\n+def test_payment_gateway_initialize_schema_valid_data(data_value):\n+    # given\n+    data = {\n+        \"data\": data_value,\n+    }\n+\n+    # when\n+    response = PaymentGatewayInitializeSessionSchema.model_validate(data)\n+\n+    # then\n+    assert response.data == data_value\n+\n+\n+@pytest.mark.parametrize(\n+    \"data_value\",\n+    [\n+        # Non-serializable object\n+        object(),\n+        # Set - not JSON serializable\n+        {1, 2, 3},\n+        # Function\n+        lambda x: x,\n+        # File handle\n+        open,\n+    ],\n+)\n+def test_payment_gateway_initialize_schema_invalid_data(data_value):\n+    # given\n+    data = {\n+        \"data\": data_value,\n+    }\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        PaymentGatewayInitializeSessionSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"] == (\"data\",)\n"
        }
      ]
    },
    {
      "id": "apply-instance-tracker",
      "sha": "e27fd5fdab2ed195a56fdc54bce81d12d9dd6a8a",
      "parentSha": "e5fe824ab4c02ebd911ce8e7f450b2763d6886d8",
      "spec": "Implement change tracking for the product variant update mutation and remove legacy comparison utilities.\n\nMake the following changes:\n\n1) Add tracked fields constant\n- File: saleor/graphql/product/mutations/utils.py\n- Add a module-level constant named PRODUCT_VARIANT_UPDATE_FIELDS with the exact set of fields to track as strings:\n  {\"external_reference\", \"is_preorder\", \"metadata\", \"name\", \"preorder_end_date\", \"preorder_global_threshold\", \"private_metadata\", \"quantity_limit_per_customer\", \"sku\", \"track_inventory\", \"weight\"}.\n\n2) Refactor ProductVariantUpdate to use InstanceTracker and return attribute_modified from clean_input\n- File: saleor/graphql/product/mutations/product_variant/product_variant_update.py\n- Imports:\n  - Add: from typing import cast\n  - Add: from .....core.utils.update_mutation_manager import InstanceTracker\n  - Add: from ..utils import PRODUCT_VARIANT_UPDATE_FIELDS\n- Class-level constant:\n  - Add: FIELDS_TO_TRACK = list(PRODUCT_VARIANT_UPDATE_FIELDS)\n- clean_input:\n  - Change to return a tuple: (cleaned_input, attribute_modified).\n  - After cleaner.clean_weight and cleaner.clean_quantity_limit, call cls.clean_attributes(cleaned_input, instance) and store its boolean return as attribute_modified.\n  - If \"sku\" in cleaned_input, normalize with clean_variant_sku.\n  - Run cleaner.clean_preorder_settings(cleaned_input).\n  - Return cleaned_input, attribute_modified.\n- _save_variant_instance(instance, modified_instance_fields):\n  - Keep behavior; ensure it receives a list of modified field names and calls instance.save(update_fields=[\"updated_at\"] + modified_instance_fields).\n- _save:\n  - Update signature to (instance_tracker: InstanceTracker, cleaned_input, attribute_modified) and return tuple[bool, bool] -> (variant_modified, metadata_modified).\n  - Use instance = cast(models.ProductVariant, instance_tracker.instance).\n  - Determine modified_instance_fields = instance_tracker.get_modified_fields().\n  - Compute metadata_modified = (\"metadata\" in modified_instance_fields) or (\"private_metadata\" in modified_instance_fields).\n  - Within traced_atomic_transaction():\n    - If modified_instance_fields is non-empty, call cls._save_variant_instance and set refresh_product_search_index if \"sku\" or \"name\" modified.\n    - If attribute_modified is True, get attributes_data = cleaned_input.get(\"attributes\") and call AttributeAssignmentMixin.save(instance, attributes_data). Also set refresh_product_search_index = True.\n    - If refresh_product_search_index is True: set instance.product.search_index_dirty = True and include [\"updated_at\", \"search_index_dirty\"] in product_update_fields; otherwise, product_update_fields = []. If product.default_variant is not set, set it and append \"default_variant\" to product_update_fields. If product_update_fields is non-empty, save product with update_fields=product_update_fields.\n    - Return bool(modified_instance_fields), metadata_modified.\n- perform_mutation:\n  - After obtaining instance (existing variant), instantiate instance_tracker = InstanceTracker(instance, cls.FIELDS_TO_TRACK).\n  - Update to use the new clean_input: cleaned_input, attribute_modified = cls.clean_input(info, instance, input).\n  - Handle metadata via cls.handle_metadata(instance, cleaned_input) before construct_instance.\n  - Update the instance in place via cls.construct_instance(instance, cleaned_input) (do not reassign to a new instance).\n  - Call cls.clean_instance(info, instance).\n  - Call variant_modified, metadata_modified = cls._save(instance_tracker, cleaned_input, attribute_modified).\n  - Save m2m and call _post_save_action(info, instance, variant_modified, attribute_modified, metadata_modified) accordingly.\n  - Return cls.success_response(instance).\n- Ensure no references remain to serialize_for_comparison(), comparison_fields, or diff_instance_data_fields in ProductVariantUpdate.\n\n3) Remove legacy comparison helpers from ProductVariant model\n- File: saleor/product/models.py\n- Remove imports: copy, model_to_dict (if no longer needed elsewhere in the file).\n- Remove the ProductVariant.comparison_fields @property and ProductVariant.serialize_for_comparison() methods entirely.\n\n4) Update tests to new behavior\n- File: saleor/graphql/product/tests/mutations/test_product_variant_update.py\n- Remove the old tests that rely on QUERY_UPDATE_VARIANT_CHANGING_FIELDS and changed_fields diffs.\n- Add two tests:\n  a) test_update_product_variant_nothing_changed\n     - Patch ProductVariantUpdate.call_event and ProductVariantUpdate._save_variant_instance.\n     - Prepare a variant with values for name, sku, external_reference, metadata/private_metadata, preorder settings, track_inventory, weight, and quantity_limit_per_customer.\n     - Build a ProductVariantInput payload using snake_to_camel_case over ProductVariantInput._meta.fields to match all input keys, with values matching the current variant state and attributes unchanged.\n     - Send ProductVariantUpdate mutation; assert no errors, and assert call_event and _save_variant_instance were not called.\n  b) test_update_product_variant_emit_event\n     - Similar setup, but send inputs one-by-one that each introduce a change (attributes with new values, sku/name changes, toggling trackInventory, modifying weight, preorder settings, quantityLimitPerCustomer, metadata/privateMetadata, externalReference).\n     - For each single-field change, assert no errors and that call_event was called. For non-variant-instance changes (attributes), assert _save_variant_instance was not called; for variant instance field changes, assert _save_variant_instance was called.\n\n5) Minor import formatting consistency\n- File: saleor/graphql/product/mutations/product_variant/product_variant_create.py\n- Split the attribute.utils import to multi-line tuple form as follows:\n  from ....attribute.utils import (\n      AttributeAssignmentMixin,\n      AttrValuesInput,\n  )\n\n6) No behavior change elsewhere\n- Do not modify AttributeAssignmentMixin.clean/save logic; ProductVariantUpdate.clean_attributes already returns a boolean if input modifies attributes (via has_input_modified_attribute_values) and triggers duplicate value validation only when modified.\n\nAcceptance criteria:\n- Updating a variant with identical input should not save the variant instance, should not emit events, and should not call _save_variant_instance.\n- Updating only attributes should not invoke _save_variant_instance but should call AttributeAssignmentMixin.save and emit the product_variant_updated event; product.search_index_dirty is set.\n- Updating any tracked instance field should save only the modified fields plus updated_at, set search_index_dirty when name/sku changed, and emit events. Metadata updates should trigger product_variant_metadata_updated.\n- All tests in saleor/graphql/product/tests/mutations/test_product_variant_update.py pass, and removed legacy compare-based tests are gone.",
      "prompt": "Refactor the product variant update mutation so it only writes and emits events when something actually changed. Use a central list of tracked fields and a change-tracking helper to detect modifications. When only attributes change, update attributes without saving the variant instance; when tracked fields change, save only those fields. Detect metadata changes to emit the dedicated metadata event. Remove the old model-level comparison helpers. Update tests to assert that no writes or events occur when input matches current state, and that events occur for each single-field change, saving the variant instance only when its own fields changed.",
      "supplementalFiles": [
        "saleor/core/utils/update_mutation_manager.py",
        "saleor/graphql/core/mutations.py",
        "saleor/graphql/attribute/utils.py",
        "saleor/graphql/product/mutations/product_variant/product_variant_cleaner.py",
        "saleor/graphql/order/mutations/draft_order_update.py",
        "saleor/graphql/product/mutations/product/product_update.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_create.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_create.py\te5fe824 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_create.py\te27fd5f (commit)\n@@ -8,9 +8,12 @@\n from .....product import models\n from .....product.error_codes import ProductErrorCode\n from .....product.utils.variants import generate_and_set_variant_name\n from ....attribute.types import AttributeValueInput\n-from ....attribute.utils import AttributeAssignmentMixin, AttrValuesInput\n+from ....attribute.utils import (\n+    AttributeAssignmentMixin,\n+    AttrValuesInput,\n+)\n from ....channel import ChannelContext\n from ....core import ResolveInfo\n from ....core.doc_category import DOC_CATEGORY_PRODUCTS\n from ....core.mutations import DeprecatedModelMutation\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_update.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_update.py\te5fe824 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_update.py\te27fd5f (commit)\n@@ -1,9 +1,12 @@\n+from typing import cast\n+\n import graphene\n from django.core.exceptions import ValidationError\n \n from .....attribute import models as attribute_models\n from .....core.tracing import traced_atomic_transaction\n+from .....core.utils.update_mutation_manager import InstanceTracker\n from .....discount.utils.promotion import mark_active_catalogue_promotion_rules_as_dirty\n from .....permission.enums import ProductPermissions\n from .....product import models\n from .....product.error_codes import ProductErrorCode\n@@ -22,8 +25,9 @@\n from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...types import ProductVariant\n from ...utils import clean_variant_sku, get_used_variants_attribute_values\n+from ..utils import PRODUCT_VARIANT_UPDATE_FIELDS\n from . import product_variant_cleaner as cleaner\n from .product_variant_create import ProductVariantInput\n \n T_INPUT_MAP = list[tuple[attribute_models.Attribute, AttrValuesInput]]\n@@ -54,8 +58,10 @@\n         errors_mapping = {\"price_amount\": \"price\"}\n         support_meta_field = True\n         support_private_meta_field = True\n \n+    FIELDS_TO_TRACK = list(PRODUCT_VARIANT_UPDATE_FIELDS)\n+\n     @classmethod\n     def get_instance(cls, info: ResolveInfo, **data) -> models.ProductVariant | None:\n         \"\"\"Prefetch related fields that are needed to process the mutation.\n \n@@ -109,14 +115,14 @@\n         cleaned_input = super().clean_input(info, instance, data, **kwargs)\n \n         cleaner.clean_weight(cleaned_input)\n         cleaner.clean_quantity_limit(cleaned_input)\n-        cls.clean_attributes(cleaned_input, instance)\n+        attribute_modified = cls.clean_attributes(cleaned_input, instance)\n         if \"sku\" in cleaned_input:\n             cleaned_input[\"sku\"] = clean_variant_sku(cleaned_input.get(\"sku\"))\n         cleaner.clean_preorder_settings(cleaned_input)\n \n-        return cleaned_input\n+        return cleaned_input, attribute_modified\n \n     @classmethod\n     def clean_attributes(cls, cleaned_input: dict, instance: models.ProductVariant):\n         attribute_modified = False\n@@ -182,31 +188,44 @@\n         if track_inventory is not None:\n             instance.track_inventory = track_inventory\n \n     @classmethod\n-    def _save_variant_instance(cls, instance, changed_fields):\n-        update_fields = [\"updated_at\"] + changed_fields\n+    def _save_variant_instance(cls, instance, modified_instance_fields):\n+        update_fields = [\"updated_at\"] + modified_instance_fields\n         instance.save(update_fields=update_fields)\n \n     @classmethod\n     def _save(\n-        cls, info: ResolveInfo, instance, cleaned_input, changed_fields\n-    ) -> tuple[bool, bool, bool]:\n-        metadata_changed = (\n-            \"metadata\" in changed_fields or \"private_metadata\" in changed_fields\n+        cls,\n+        instance_tracker: InstanceTracker,\n+        cleaned_input,\n+        attribute_modified: bool,\n+    ) -> tuple[bool, bool]:\n+        instance = cast(models.ProductVariant, instance_tracker.instance)\n+        modified_instance_fields = instance_tracker.get_modified_fields()\n+        metadata_modified = (\n+            \"metadata\" in modified_instance_fields\n+            or \"private_metadata\" in modified_instance_fields\n         )\n \n         refresh_product_search_index = False\n         with traced_atomic_transaction():\n-            if changed_fields:\n-                cls._save_variant_instance(instance, changed_fields)\n-                if \"sku\" in changed_fields or \"name\" in changed_fields:\n+            # handle product variant\n+            if modified_instance_fields:\n+                cls._save_variant_instance(instance, modified_instance_fields)\n+                if (\n+                    \"sku\" in modified_instance_fields\n+                    or \"name\" in modified_instance_fields\n+                ):\n                     refresh_product_search_index = True\n \n-            if attributes := cleaned_input.get(\"attributes\"):\n-                AttributeAssignmentMixin.save(instance, attributes)\n+            # handle attributes\n+            if attribute_modified:\n+                attributes_data = cleaned_input.get(\"attributes\")\n+                AttributeAssignmentMixin.save(instance, attributes_data)\n                 refresh_product_search_index = True\n \n+            # handle product\n             if refresh_product_search_index:\n                 instance.product.search_index_dirty = True\n                 product_update_fields = [\"updated_at\", \"search_index_dirty\"]\n             else:\n@@ -216,9 +235,9 @@\n                 product_update_fields.append(\"default_variant\")\n             if product_update_fields:\n                 instance.product.save(update_fields=product_update_fields)\n \n-            return bool(changed_fields), bool(attributes), metadata_changed\n+            return bool(modified_instance_fields), metadata_modified\n \n     @classmethod\n     def construct_instance(cls, instance, cleaned_input) -> models.ProductVariant:\n         instance = super().construct_instance(instance, cleaned_input)\n@@ -292,29 +311,27 @@\n         )\n         instance = cls.get_instance(\n             info, id=id, sku=sku, external_reference=external_reference, input=input\n         )\n-        old_instance_data = instance.serialize_for_comparison()  # type: ignore[union-attr]\n-        cleaned_input = cls.clean_input(info, instance, input)  # type: ignore[arg-type]\n+        instance = cast(models.ProductVariant, instance)\n+        instance_tracker = InstanceTracker(instance, cls.FIELDS_TO_TRACK)\n \n+        cleaned_input, attribute_modified = cls.clean_input(info, instance, input)\n+\n         cls.handle_metadata(instance, cleaned_input)\n \n-        instance = cls.construct_instance(instance, cleaned_input)\n-\n+        cls.construct_instance(instance, cleaned_input)\n         cls.clean_instance(info, instance)\n-        new_instance_data = instance.serialize_for_comparison()\n \n-        changed_fields = cls.diff_instance_data_fields(\n-            instance.comparison_fields,\n-            old_instance_data,\n-            new_instance_data,\n+        variant_modified, metadata_modified = cls._save(\n+            instance_tracker, cleaned_input, attribute_modified\n         )\n-\n-        variant_modified, attributes_modified, metadata_modified = cls._save(\n-            info, instance, cleaned_input, changed_fields\n-        )\n         cls._save_m2m(info, instance, cleaned_input)\n         cls._post_save_action(\n-            info, instance, variant_modified, attributes_modified, metadata_modified\n+            info,\n+            instance,\n+            variant_modified,\n+            attribute_modified,\n+            metadata_modified,\n         )\n \n         return cls.success_response(instance)\n"
        },
        {
          "path": "saleor/graphql/product/mutations/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/utils.py\n===================================================================\n--- saleor/graphql/product/mutations/utils.py\te5fe824 (parent)\n+++ saleor/graphql/product/mutations/utils.py\te27fd5f (commit)\n@@ -1,9 +1,23 @@\n from django.db.models import Q\n \n from ....tax.models import TaxClass\n \n+PRODUCT_VARIANT_UPDATE_FIELDS = {\n+    \"external_reference\",\n+    \"is_preorder\",\n+    \"metadata\",\n+    \"name\",\n+    \"preorder_end_date\",\n+    \"preorder_global_threshold\",\n+    \"private_metadata\",\n+    \"quantity_limit_per_customer\",\n+    \"sku\",\n+    \"track_inventory\",\n+    \"weight\",\n+}\n \n+\n def clean_tax_code(cleaned_input: dict):\n     \"\"\"Clean deprecated `taxCode` field.\n \n     This function provides backwards compatibility for the `taxCode` input field. If the\n"
        },
        {
          "path": "saleor/graphql/product/tests/mutations/test_product_variant_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/mutations/test_product_variant_update.py\n===================================================================\n--- saleor/graphql/product/tests/mutations/test_product_variant_update.py\te5fe824 (parent)\n+++ saleor/graphql/product/tests/mutations/test_product_variant_update.py\te27fd5f (commit)\n@@ -1,20 +1,22 @@\n import datetime\n import json\n-from unittest.mock import ANY, call, patch\n+from unittest.mock import ANY, patch\n from uuid import uuid4\n \n import graphene\n import pytest\n from django.conf import settings\n from django.utils.text import slugify\n+from measurement.measures import Weight\n \n from .....attribute import AttributeInputType\n from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n-from .....discount.utils.promotion import mark_active_catalogue_promotion_rules_as_dirty\n from .....product.error_codes import ProductErrorCode\n+from ....core.utils import snake_to_camel_case\n from ....tests.utils import get_graphql_content\n+from ...mutations.product_variant.product_variant_create import ProductVariantInput\n \n \n def test_product_variant_update_with_new_attributes(\n     staff_api_client, permission_manage_products, product, size_attribute\n@@ -164,225 +166,8 @@\n     )\n     product_variant_created_webhook_mock.assert_not_called()\n \n \n-QUERY_UPDATE_VARIANT_CHANGING_FIELDS = \"\"\"\n-        mutation updateVariant (\n-            $id: ID!\n-            $sku: String!\n-            $quantityLimitPerCustomer: Int!\n-            $trackInventory: Boolean!\n-            $externalReference: String\n-            $metadata: [MetadataInput!]\n-            $privateMetadata: [MetadataInput!]\n-            $preorder: PreorderSettingsInput\n-            $attributes: [AttributeValueInput!]) {\n-                productVariantUpdate(\n-                    id: $id,\n-                    input: {\n-                        sku: $sku,\n-                        trackInventory: $trackInventory,\n-                        attributes: $attributes,\n-                        externalReference: $externalReference\n-                        quantityLimitPerCustomer: $quantityLimitPerCustomer,\n-                        metadata: $metadata,\n-                        preorder: $preorder,\n-                        privateMetadata: $privateMetadata,\n-                    }) {\n-                    productVariant {\n-                        name\n-                        sku\n-                        quantityLimitPerCustomer\n-                        externalReference\n-                        channelListings {\n-                            channel {\n-                                slug\n-                            }\n-                        }\n-                        metadata {\n-                            key\n-                            value\n-                        }\n-                        privateMetadata {\n-                            key\n-                            value\n-                        }\n-                    }\n-                    errors {\n-                      field\n-                      message\n-                      attributes\n-                      code}\n-                }\n-            }\n-    \"\"\"\n-\n-\n-@pytest.mark.parametrize(\n-    (\"fields\", \"changed_fields\"),\n-    [\n-        ({\"sku\": 1234}, [\"sku\"]),\n-        ({\"metadata\": [{\"key\": \"test_key1\", \"value\": \"test_value2\"}]}, [\"metadata\"]),\n-        ({\"trackInventory\": False}, [\"track_inventory\"]),\n-        ({\"quantityLimitPerCustomer\": 5}, [\"quantity_limit_per_customer\"]),\n-        (\n-            {\"preorder\": {\"globalThreshold\": 11, \"endDate\": \"2024-12-03T00:00Z\"}},\n-            [\"preorder_end_date\", \"preorder_global_threshold\"],\n-        ),\n-        (\n-            {\"preorder\": {\"globalThreshold\": 10, \"endDate\": \"2024-12-03T00:00Z\"}},\n-            [\"preorder_end_date\"],\n-        ),\n-        (\n-            {\"preorder\": {\"globalThreshold\": 11, \"endDate\": \"2024-12-02T00:00Z\"}},\n-            [\"preorder_global_threshold\"],\n-        ),\n-        ({\"externalReference\": \"test-ext-ref2\"}, [\"external_reference\"]),\n-        (\n-            {\"sku\": 1234, \"trackInventory\": False, \"externalReference\": \"test-ext-ref\"},\n-            [\"sku\", \"track_inventory\"],\n-        ),\n-    ],\n-)\n-@patch(\n-    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate.call_event\"\n-)\n-@patch(\n-    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate._save_variant_instance\"\n-)\n-def test_update_product_variant_update_fields_when_necessary(\n-    save_variant_mock,\n-    call_event_mock,\n-    staff_api_client,\n-    product,\n-    permission_manage_products,\n-    fields,\n-    changed_fields,\n-):\n-    # given\n-    variant = product.variants.first()\n-    quantity_limit = 9\n-    external_reference = \"test-ext-ref\"\n-    variant_name = variant.attributes.first().values.first().name\n-    variant_sku = \"123\"\n-    product.default_variant = variant\n-    product.save(update_fields=[\"default_variant\"])\n-    variant.name = variant_name\n-    variant.metadata = {\"test_key1\": \"test_value1\"}\n-    variant.private_metadata = {\"private_key1\": \"private_value_1\"}\n-    variant.external_reference = external_reference\n-    variant.quantity_limit_per_customer = quantity_limit\n-    variant.track_inventory = True\n-    variant.is_preorder = True\n-    variant.preorder_global_threshold = 10\n-    variant.preorder_end_date = \"2024-12-02T00:00Z\"\n-    variant.save()\n-    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.pk)\n-\n-    variables = {\n-        \"id\": variant_id,\n-        \"sku\": variant_sku,\n-        \"trackInventory\": True,\n-        \"quantityLimitPerCustomer\": quantity_limit,\n-        \"externalReference\": external_reference,\n-        \"metadata\": [{\"key\": \"test_key1\", \"value\": \"test_value1\"}],\n-        \"privateMetadata\": [{\"key\": \"private_key1\", \"value\": \"private_value_1\"}],\n-    }\n-\n-    for field, value in fields.items():\n-        variables[field] = value\n-\n-    # when\n-    response = staff_api_client.post_graphql(\n-        QUERY_UPDATE_VARIANT_CHANGING_FIELDS,\n-        variables,\n-        permissions=[permission_manage_products],\n-    )\n-\n-    # then\n-    variant.refresh_from_db()\n-    get_graphql_content(response)\n-    save_variant_mock.assert_called_once_with(variant, changed_fields)\n-    call_event_mock.assert_has_calls(\n-        [\n-            call(ANY, variant),\n-            call(mark_active_catalogue_promotion_rules_as_dirty, ANY),\n-        ]\n-    )\n-\n-\n-@pytest.mark.parametrize(\n-    \"field_values\",\n-    [\n-        [\"sku\", 123],\n-        [\"metadata\", [{\"key\": \"test_key1\", \"value\": \"test_value1\"}]],\n-        [\"trackInventory\", True],\n-        [\"quantityLimitPerCustomer\", 9],\n-        [\"preorder\", {\"globalThreshold\": 10, \"endDate\": \"2024-12-02T00:00Z\"}],\n-        [\"externalReference\", \"test-ext-ref\"],\n-    ],\n-)\n-@patch(\n-    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate.call_event\"\n-)\n-@patch(\n-    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate._save_variant_instance\"\n-)\n-def test_update_product_variant_skip_updating_fields_when_unchanged(\n-    save_variant_mock,\n-    call_event_mock,\n-    staff_api_client,\n-    product,\n-    permission_manage_products,\n-    field_values,\n-):\n-    # given\n-    variant = product.variants.first()\n-    quantity_limit = 9\n-    external_reference = \"test-ext-ref\"\n-    variant_name = variant.attributes.first().values.first().name\n-    variant_sku = \"123\"\n-    product.default_variant = variant\n-    product.save(update_fields=[\"default_variant\"])\n-    variant.name = variant_name\n-    variant.is_preorder = True\n-    variant.preorder_global_threshold = 10\n-    variant.preorder_end_date = \"2024-12-02T00:00Z\"\n-    variant.metadata = {\"test_key1\": \"test_value1\"}\n-    variant.private_metadata = {\"private_key1\": \"private_value_1\"}\n-    variant.external_reference = external_reference\n-    variant.quantity_limit_per_customer = quantity_limit\n-    variant.track_inventory = True\n-    variant.save()\n-    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.pk)\n-\n-    variables = {\n-        \"id\": variant_id,\n-        \"sku\": variant_sku,\n-        \"trackInventory\": True,\n-        \"quantityLimitPerCustomer\": quantity_limit,\n-        \"externalReference\": external_reference,\n-        \"metadata\": [{\"key\": \"test_key1\", \"value\": \"test_value1\"}],\n-        \"privateMetadata\": [{\"key\": \"private_key1\", \"value\": \"private_value_1\"}],\n-    }\n-\n-    field, value = field_values\n-    variables[field] = value\n-\n-    # when\n-    response = staff_api_client.post_graphql(\n-        QUERY_UPDATE_VARIANT_CHANGING_FIELDS,\n-        variables,\n-        permissions=[permission_manage_products],\n-    )\n-\n-    # then\n-    variant.refresh_from_db()\n-    get_graphql_content(response)\n-    save_variant_mock.assert_not_called()\n-    call_event_mock.assert_not_called()\n-\n-\n def test_update_product_variant_marks_prices_as_dirty(\n     staff_api_client,\n     product,\n     size_attribute,\n@@ -2811,4 +2596,187 @@\n     # - product_variant_metadata_updated should  run - metadata value changed\n     # no empty event emitted\n     product_variant_updated_webhook_mock.assert_called_once()\n     product_variant_metadata_updated_webhook_mock.assert_called_once()\n+\n+\n+PRODUCT_VARIANT_UPDATE_MUTATION = \"\"\"\n+mutation ProductVariantUpdate($id: ID!, $input: ProductVariantInput!) {\n+  productVariantUpdate(id: $id, input: $input) {\n+    errors {\n+      field\n+      code\n+      message\n+    }\n+    productVariant {\n+      id\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\n+    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate.call_event\"\n+)\n+@patch(\n+    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate._save_variant_instance\"\n+)\n+def test_update_product_variant_nothing_changed(\n+    save_variant_mock,\n+    call_event_mock,\n+    staff_api_client,\n+    product_with_variant_with_two_attributes,\n+    permission_manage_products,\n+    color_attribute,\n+    size_attribute,\n+):\n+    # given\n+    staff_api_client.user.user_permissions.add(permission_manage_products)\n+    product = product_with_variant_with_two_attributes\n+    variant = product.variants.first()\n+\n+    variant.name = \"some_name\"\n+    variant.sku = \"some_sku\"\n+    variant.external_reference = \"some-ext-ref\"\n+    key = \"some_key\"\n+    value = \"some_value\"\n+    variant.metadata = {key: value}\n+    variant.private_metadata = {key: value}\n+    variant.is_preorder = True\n+    variant.preorder_global_threshold = 10\n+    variant.preorder_end_date = \"2024-12-02T00:00Z\"\n+    variant.track_inventory = True\n+    variant.weight = Weight(kg=10)\n+    variant.quantity_limit_per_customer = 10\n+    variant.save()\n+\n+    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.pk)\n+    color_attribute_id = graphene.Node.to_global_id(\"Attribute\", color_attribute.pk)\n+    size_attribute_id = graphene.Node.to_global_id(\"Attribute\", size_attribute.pk)\n+\n+    attribute_slug_1 = variant.attributes.first().values.first().slug\n+    attribute_slug_2 = variant.attributes.last().values.first().slug\n+\n+    input_fields = [\n+        snake_to_camel_case(key) for key in ProductVariantInput._meta.fields.keys()\n+    ]\n+\n+    input = {\n+        \"attributes\": [\n+            {\"id\": color_attribute_id, \"values\": [attribute_slug_1]},\n+            {\"id\": size_attribute_id, \"values\": [attribute_slug_2]},\n+        ],\n+        \"sku\": variant.sku,\n+        \"name\": variant.name,\n+        \"trackInventory\": variant.track_inventory,\n+        \"weight\": 10,\n+        \"preorder\": {\n+            \"globalThreshold\": variant.preorder_global_threshold,\n+            \"endDate\": variant.preorder_end_date,\n+        },\n+        \"quantityLimitPerCustomer\": variant.quantity_limit_per_customer,\n+        \"metadata\": [{\"key\": key, \"value\": value}],\n+        \"privateMetadata\": [{\"key\": key, \"value\": value}],\n+        \"externalReference\": variant.external_reference,\n+    }\n+    assert set(input_fields) == set(input.keys())\n+\n+    variables = {\"id\": variant_id, \"input\": input}\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        PRODUCT_VARIANT_UPDATE_MUTATION,\n+        variables,\n+    )\n+    content = get_graphql_content(response)\n+\n+    # then\n+    assert not content[\"data\"][\"productVariantUpdate\"][\"errors\"]\n+    variant.refresh_from_db()\n+    call_event_mock.assert_not_called()\n+    save_variant_mock.assert_not_called()\n+\n+\n+@patch(\n+    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate.call_event\"\n+)\n+@patch(\n+    \"saleor.graphql.product.mutations.product_variant.ProductVariantUpdate._save_variant_instance\"\n+)\n+def test_update_product_variant_emit_event(\n+    save_variant_mock,\n+    call_event_mock,\n+    staff_api_client,\n+    product_with_variant_with_two_attributes,\n+    permission_manage_products,\n+    color_attribute,\n+    size_attribute,\n+):\n+    # given\n+    staff_api_client.user.user_permissions.add(permission_manage_products)\n+    product = product_with_variant_with_two_attributes\n+    variant = product.variants.first()\n+\n+    variant.name = \"some_name\"\n+    variant.sku = \"some_sku\"\n+    variant.external_reference = \"some-ext-ref\"\n+    key = \"some_key\"\n+    value = \"some_value\"\n+    variant.metadata = {key: value}\n+    variant.private_metadata = {key: value}\n+    variant.is_preorder = True\n+    variant.preorder_global_threshold = 10\n+    variant.preorder_end_date = \"2024-12-02T00:00Z\"\n+    variant.track_inventory = True\n+    variant.weight = Weight(kg=10)\n+    variant.quantity_limit_per_customer = 10\n+    variant.save()\n+\n+    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.pk)\n+    color_attribute_id = graphene.Node.to_global_id(\"Attribute\", color_attribute.pk)\n+    size_attribute_id = graphene.Node.to_global_id(\"Attribute\", size_attribute.pk)\n+\n+    input_fields = [\n+        snake_to_camel_case(key) for key in ProductVariantInput._meta.fields.keys()\n+    ]\n+\n+    input = {\n+        \"attributes\": [\n+            {\"id\": color_attribute_id, \"values\": [\"new_color\"]},\n+            {\"id\": size_attribute_id, \"values\": [\"new_size\"]},\n+        ],\n+        \"sku\": variant.sku + \"_new\",\n+        \"name\": variant.name + \"_new\",\n+        \"trackInventory\": not variant.track_inventory,\n+        \"weight\": 11,\n+        \"preorder\": {\n+            \"globalThreshold\": variant.preorder_global_threshold + 1,\n+            \"endDate\": \"2024-12-03T00:00Z\",\n+        },\n+        \"quantityLimitPerCustomer\": variant.quantity_limit_per_customer + 1,\n+        \"metadata\": [{\"key\": key + \"_new\", \"value\": value + \"_new\"}],\n+        \"privateMetadata\": [{\"key\": key + \"_new\", \"value\": value + \"_new\"}],\n+        \"externalReference\": variant.external_reference + \"_new\",\n+    }\n+    assert set(input_fields) == set(input.keys())\n+\n+    # fields making changes to related models (other than variant)\n+    non_variant_instance_fields = [\"attributes\"]\n+\n+    for key, value in input.items():\n+        variables = {\"id\": variant_id, \"input\": {key: value}}\n+\n+        # when\n+        response = staff_api_client.post_graphql(\n+            PRODUCT_VARIANT_UPDATE_MUTATION,\n+            variables,\n+        )\n+        content = get_graphql_content(response)\n+\n+        # then\n+        assert not content[\"data\"][\"productVariantUpdate\"][\"errors\"]\n+        call_event_mock.assert_called()\n+        call_event_mock.reset_mock()\n+        if key not in non_variant_instance_fields:\n+            save_variant_mock.assert_called()\n+            save_variant_mock.reset_mock()\n"
        },
        {
          "path": "saleor/product/models.py",
          "status": "modified",
          "diff": "Index: saleor/product/models.py\n===================================================================\n--- saleor/product/models.py\te5fe824 (parent)\n+++ saleor/product/models.py\te27fd5f (commit)\n@@ -1,5 +1,4 @@\n-import copy\n import datetime\n from collections.abc import Iterable\n from decimal import Decimal\n from typing import Optional\n@@ -11,9 +10,8 @@\n from django.contrib.postgres.search import SearchVectorField\n from django.core.validators import MinValueValidator\n from django.db import models, transaction\n from django.db.models import JSONField, TextField\n-from django.forms.models import model_to_dict\n from django.urls import reverse\n from django.utils import timezone\n from django_measurement.models import MeasurementField\n from measurement.measures import Weight\n@@ -458,28 +456,9 @@\n         return self.is_preorder and (\n             self.preorder_end_date is None or timezone.now() <= self.preorder_end_date\n         )\n \n-    @property\n-    def comparison_fields(self):\n-        return [\n-            \"sku\",\n-            \"name\",\n-            \"track_inventory\",\n-            \"is_preorder\",\n-            \"quantity_limit_per_customer\",\n-            \"weight\",\n-            \"external_reference\",\n-            \"metadata\",\n-            \"private_metadata\",\n-            \"preorder_end_date\",\n-            \"preorder_global_threshold\",\n-        ]\n \n-    def serialize_for_comparison(self):\n-        return copy.deepcopy(model_to_dict(self, fields=self.comparison_fields))\n-\n-\n class ProductVariantTranslation(Translation):\n     product_variant = models.ForeignKey(\n         ProductVariant, related_name=\"translations\", on_delete=models.CASCADE\n     )\n"
        }
      ]
    },
    {
      "id": "attribute-channel-context",
      "sha": "94492e45d9d2ae7c074ffe4ff8e6346d22edb442",
      "parentSha": "5d692d80e2c822729fe66dc4d16b21eb8c183297",
      "spec": "Implement channel-aware context for attribute-related GraphQL types, resolvers, and mutations, and align dependent modules (product/page/translations/subscriptions) with the ChannelContext pattern.\n\nScope and requirements:\n\n1) Wrap attribute nodes and querysets in channel context\n- In saleor/graphql/attribute/schema.py:\n  - Wrap the attributes list queryset in ChannelQsContext before returning through create_connection_slice.\n  - For resolve_attribute, wrap the resolved model in ChannelContext(node=attribute, channel_slug=None); return None if not found.\n\n2) Use channel-aware GraphQL types for attributes and values\n- In saleor/graphql/attribute/types.py:\n  - Change AttributeValue to inherit from ChannelContextType[AttributeValue] and set Meta.default_resolver = ChannelContextType.resolver_with_context.\n  - Update all AttributeValue field resolvers to accept ChannelContext[models.AttributeValue] as root, refer to root.node, and propagate root.channel_slug when wrapping referenced objects or building File/IDs. Ensure TranslationField for AttributeValue uses resolver=ChannelContextType.resolve_translation.\n  - Change Attribute to inherit from ChannelContextType[Attribute] and set Meta.default_resolver = ChannelContextType.resolver_with_context.\n  - Update Attribute resolvers (choices, valueRequired, visibility flags, storefrontSearchPosition, availableInGrid, withChoices, productTypes, productVariantTypes) to accept ChannelContext[models.Attribute] as root and use root.node for data access. For choices, wrap the underlying AttributeValue queryset with ChannelQsContext(channel_slug=root.channel_slug) and pass that through filter_connection_queryset and create_connection_slice.\n  - Change SelectedAttribute to subclass ChannelContextTypeForObjectType so its fields can accept ChannelContext-wrapped attribute/value nodes.\n\n3) Update attribute mutations to return ChannelContext-wrapped payloads\n- In saleor/graphql/attribute/mutations/attribute_create.py and attribute_update.py: return AttributeCreate/Update(attribute=ChannelContext(instance, None)).\n- In attribute_reorder_values.py: return AttributeReorderValues(attribute=ChannelContext(attribute, None)).\n- In attribute_delete.py: override success_response to set response.attribute = ChannelContext(instance, None).\n- In attribute_value_create.py: return attribute and attributeValue wrapped with ChannelContext(..., None) in the mutation response.\n- In attribute_value_delete.py and attribute_value_update.py: override success_response to set response.attribute = ChannelContext(instance.attribute, None) and response.attributeValue = ChannelContext(instance, None).\n- In attribute_bulk_create.py and attribute_bulk_update.py: in get_results(), when not rejecting everything, wrap each data[\"instance\"] in ChannelContext(instance, None) before building AttributeBulkCreate/UpdateResult.\n\n4) Align translations and subscriptions with ChannelContext\n- In saleor/graphql/translations/mutations/attribute_translate.py: after perform_mutation, set response.attribute = ChannelContext(response.attribute, None).\n- In saleor/graphql/translations/mutations/attribute_value_translate.py: after perform_mutation, set response.attributeValue = ChannelContext(response.attributeValue, None).\n- In saleor/graphql/translations/types.py: resolve_attribute on AttributeTranslatableContent and resolve_attribute_value on AttributeValueTranslatableContent should return ChannelContext(node=<model>, channel_slug=None).\n- In saleor/graphql/webhook/subscription_types.py: wrap resolved attribute and attribute_value in ChannelContext for subscription payload resolvers.\n\n5) Page and Product integrations for SelectedAttribute\n- In saleor/graphql/page/types.py:\n  - For PageType.resolve_attributes connections, wrap queryset with ChannelQsContext before create_connection_slice.\n  - For Page.resolve_attributes and Page.resolve_attribute, map the loaded structures into SelectedAttribute objects with attribute and values wrapped in ChannelContext(..., None); handle both staff and storefront paths.\n- In saleor/graphql/product/types/products.py:\n  - ProductVariant.resolve_attributes: return a list of SelectedAttribute instances; for ALL scope, always wrap attribute and each value in ChannelContext(channel_slug=root.channel_slug). For the filtered scopes (VARIANT_SELECTION / NOT_VARIANT_SELECTION), compute which attributes to include, then return SelectedAttribute with ChannelContext-wrapped attribute and values, using root.channel_slug.\n  - Product.resolve_attribute: from loaded attribute dicts, find the one matching slug, and return SelectedAttribute with attribute and values wrapped in ChannelContext(channel_slug=root.channel_slug), or None if not found.\n  - Product.resolve_attributes: map the loaded attribute dicts into a list of SelectedAttribute with attribute and values wrapped in ChannelContext(channel_slug=root.channel_slug) for both staff and storefront paths, preserving None when loaders return None.\n  - ProductType.resolve_product_attributes, resolve_variant_attributes, and resolve_assigned_variant_attributes_details: return attributes or attribute objects wrapped in ChannelContext(None) as appropriate; where a connection over attributes is returned, wrap queryset with ChannelQsContext before slicing.\n\n6) Permission decorator compatibility\n- In saleor/graphql/decorators.py (check_attribute_required_permissions): adjust the internal check_perms to accept root: ChannelContext[Attribute], then unwrap attribute = root.node before checking attribute.type and permissions.\n\n7) Core typing and context support\n- In saleor/graphql/core/context.py: update ChannelContext to be a dataclass subclass of BaseContext[N] without the Model bound. Ensure its signature is ChannelContext(node, channel_slug: str | None).\n- In saleor/graphql/core/types/context.py:\n  - Introduce Generic type parameters for ChannelContextTypeForObjectType and BaseObjectType inheritance so it can be used for non-model container types as needed; keep its resolver_with_context to delegate to get_default_resolver on root.node.\n  - Move resolve_id implementation into ChannelContextType (the subclass that also inherits ModelObjectType[T]); keep is_type_of logic to unwrap ChannelContext roots and compare concrete model classes.\n  - Ensure TranslationField resolvers use ChannelContextType.resolve_translation.\n\n8) Metadata mutation channel context opt-in\n- In saleor/graphql/meta/mutations/base.py: include attribute_models.Attribute and attribute_models.AttributeValue in the union of instances that use channel context when deciding whether to set use_channel_context.\n\n9) Tests alignment\n- Update attribute query tests to use a richer attribute query that still validates behavior under the ChannelContext wrapping. Ensure tests don’t rely on direct model resolver roots and continue to validate fields like translation, withChoices, productTypes/productVariantTypes connections, and value choice fields. Keep response shapes unchanged for clients.\n\nAcceptance criteria:\n- All attribute GraphQL types and resolvers operate on ChannelContext-wrapped roots, and connections accept ChannelQsContext-wrapped querysets.\n- Mutations, translations, and subscription payloads consistently return ChannelContext-wrapped attribute/attributeValue nodes.\n- Page and Product resolvers that expose attribute data return SelectedAttribute with ChannelContext-wrapped attribute and values, and connections over attributes use ChannelQsContext.\n- Permission checks on attributes work when root is ChannelContext[Attribute].\n- Metadata mutation logic treats Attribute and AttributeValue as channel-context-aware.\n- All existing GraphQL API field names and response shapes for clients remain the same; internal wrapping is transparent to API consumers.\n- Unit and integration tests for attributes, pages, products, translations, and subscriptions pass using the channel-aware types.\n",
      "prompt": "Introduce channel-aware behavior to all attribute-related GraphQL functionality. Update the attribute types and their resolvers to operate on channel-wrapped roots and querysets so that channel-specific data and translations resolve correctly. Ensure all attribute mutations, queries, translations, and subscriptions return ChannelContext-wrapped attribute and attribute value nodes. Align page and product attribute resolvers to emit SelectedAttribute objects whose attribute and values are channel-wrapped, and make attribute connections use a channel-aware queryset wrapper. Update permission checks and metadata mutations so they work with channel-wrapped attribute nodes. Keep the public GraphQL API schema and field names stable while changing the internal resolution to be channel-aware, and update tests accordingly.",
      "supplementalFiles": [
        "saleor/graphql/core/connection.py",
        "saleor/graphql/core/types/base.py",
        "saleor/graphql/core/types/model.py",
        "saleor/graphql/attribute/dataloaders.py",
        "saleor/graphql/page/dataloaders.py",
        "saleor/graphql/translations/resolvers.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/attribute/mutations/attribute_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_bulk_create.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_bulk_create.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_bulk_create.py\t94492e4 (commit)\n@@ -13,8 +13,9 @@\n from ....permission.enums import PageTypePermissions, ProductTypePermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ....webhook.utils import get_webhooks_for_event\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ...core.enums import ErrorPolicyEnum\n from ...core.mutations import BaseMutation, DeprecatedModelMutation\n from ...core.types import AttributeBulkCreateError, BaseObjectType, NonNullList\n@@ -196,15 +197,23 @@\n \n def get_results(\n     instances_data_with_errors_list: list[dict], reject_everything: bool = False\n ) -> list[AttributeBulkCreateResult]:\n-    return [\n-        AttributeBulkCreateResult(\n-            attribute=None if reject_everything else data.get(\"instance\"),\n-            errors=data.get(\"errors\"),\n+    results = []\n+    for data in instances_data_with_errors_list:\n+        if reject_everything:\n+            attribute = None\n+        else:\n+            attribute = data.get(\"instance\")\n+            if attribute:\n+                attribute = ChannelContext(attribute, None)\n+        results.append(\n+            AttributeBulkCreateResult(\n+                attribute=attribute,\n+                errors=data.get(\"errors\"),\n+            )\n         )\n-        for data in instances_data_with_errors_list\n-    ]\n+    return results\n \n \n class AttributeBulkCreate(BaseMutation):\n     count = graphene.Int(\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_bulk_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_bulk_update.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_bulk_update.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_bulk_update.py\t94492e4 (commit)\n@@ -13,8 +13,9 @@\n from ....core.tracing import traced_atomic_transaction\n from ....permission.enums import PageTypePermissions, ProductTypePermissions\n from ....webhook.utils import get_webhooks_for_event\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ...core.enums import ErrorPolicyEnum\n from ...core.mutations import BaseMutation, DeprecatedModelMutation\n from ...core.types import (\n@@ -51,15 +52,23 @@\n \n def get_results(\n     instances_data_with_errors_list: list[dict], reject_everything: bool = False\n ) -> list[AttributeBulkUpdateResult]:\n-    return [\n-        AttributeBulkUpdateResult(\n-            attribute=None if reject_everything else data.get(\"instance\"),\n-            errors=data.get(\"errors\"),\n+    results = []\n+    for data in instances_data_with_errors_list:\n+        if reject_everything:\n+            attribute = None\n+        else:\n+            attribute = data.get(\"instance\")\n+            if attribute:\n+                attribute = ChannelContext(attribute, None)\n+        results.append(\n+            AttributeBulkUpdateResult(\n+                attribute=attribute,\n+                errors=data.get(\"errors\"),\n+            )\n         )\n-        for data in instances_data_with_errors_list\n-    ]\n+    return results\n \n \n class AttributeBulkUpdateInput(BaseInputObjectType):\n     id = graphene.ID(description=\"ID of an attribute to update.\", required=False)\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_create.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_create.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_create.py\t94492e4 (commit)\n@@ -7,8 +7,9 @@\n from ....core.exceptions import PermissionDenied\n from ....permission.enums import PageTypePermissions, ProductTypePermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.descriptions import DEPRECATED_IN_3X_INPUT\n from ...core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ...core.enums import MeasurementUnitsEnum\n from ...core.fields import JSONString\n@@ -173,9 +174,9 @@\n         instance.save()\n         cls._save_m2m(info, instance, cleaned_input)\n         cls.post_save_action(info, instance, cleaned_input)\n         # Return the attribute that was created\n-        return AttributeCreate(attribute=instance)\n+        return AttributeCreate(attribute=ChannelContext(instance, None))\n \n     @classmethod\n     def post_save_action(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_delete.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_delete.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_delete.py\t94492e4 (commit)\n@@ -3,8 +3,9 @@\n from ....attribute import models as models\n from ....permission.enums import ProductTypePermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.mutations import ModelDeleteMutation, ModelWithExtRefMutation\n from ...core.types import AttributeError\n from ...core.utils import WebhookEventInfo\n from ...plugins.dataloaders import get_plugin_manager_promise\n@@ -33,7 +34,13 @@\n             ),\n         ]\n \n     @classmethod\n+    def success_response(cls, instance):\n+        response = super().success_response(instance)\n+        response.attribute = ChannelContext(instance, None)\n+        return response\n+\n+    @classmethod\n     def post_save_action(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n         cls.call_event(manager.attribute_deleted, instance)\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_reorder_values.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_reorder_values.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_reorder_values.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_reorder_values.py\t94492e4 (commit)\n@@ -6,8 +6,9 @@\n from ....core.tracing import traced_atomic_transaction\n from ....permission.enums import ProductTypePermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ...core.inputs import ReorderInput\n from ...core.mutations import BaseMutation\n from ...core.types import AttributeError, NonNullList\n@@ -99,5 +100,5 @@\n         for value in events_list:\n             cls.call_event(manager.attribute_value_updated, value)\n         cls.call_event(manager.attribute_updated, attribute)\n \n-        return AttributeReorderValues(attribute=attribute)\n+        return AttributeReorderValues(attribute=ChannelContext(attribute, None))\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_update.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_update.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_update.py\t94492e4 (commit)\n@@ -5,8 +5,9 @@\n from ....attribute.error_codes import AttributeErrorCode\n from ....permission.enums import ProductTypePermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.descriptions import DEPRECATED_IN_3X_INPUT\n from ...core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ...core.enums import MeasurementUnitsEnum\n from ...core.mutations import ModelWithExtRefMutation\n@@ -151,9 +152,9 @@\n         cls._save_m2m(info, instance, cleaned_input)\n         cls.post_save_action(info, instance, cleaned_input)\n \n         # Return the attribute that was created\n-        return AttributeUpdate(attribute=instance)\n+        return AttributeUpdate(attribute=ChannelContext(instance, None))\n \n     @classmethod\n     def post_save_action(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_value_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_value_create.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_value_create.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_value_create.py\t94492e4 (commit)\n@@ -7,8 +7,9 @@\n from ....core.utils import generate_unique_slug\n from ....permission.enums import ProductPermissions\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.mutations import DeprecatedModelMutation\n from ...core.types import AttributeError\n from ...core.utils import WebhookEventInfo\n from ...plugins.dataloaders import get_plugin_manager_promise\n@@ -102,9 +103,12 @@\n \n         instance.save()\n         cls._save_m2m(info, instance, cleaned_input)\n         cls.post_save_action(info, instance, cleaned_input)\n-        return AttributeValueCreate(attribute=attribute, attributeValue=instance)\n+        return AttributeValueCreate(\n+            attribute=ChannelContext(attribute, None),\n+            attributeValue=ChannelContext(instance, None),\n+        )\n \n     @classmethod\n     def post_save_action(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_value_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_value_delete.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_value_delete.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_value_delete.py\t94492e4 (commit)\n@@ -5,8 +5,9 @@\n from ....permission.enums import ProductTypePermissions\n from ....product import models as product_models\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.mutations import ModelDeleteMutation, ModelWithExtRefMutation\n from ...core.types import AttributeError\n from ...core.utils import WebhookEventInfo\n from ...plugins.dataloaders import get_plugin_manager_promise\n@@ -71,6 +72,7 @@\n \n     @classmethod\n     def success_response(cls, instance):\n         response = super().success_response(instance)\n-        response.attribute = instance.attribute\n+        response.attribute = ChannelContext(instance.attribute, None)\n+        response.attributeValue = ChannelContext(instance, None)\n         return response\n"
        },
        {
          "path": "saleor/graphql/attribute/mutations/attribute_value_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/mutations/attribute_value_update.py\n===================================================================\n--- saleor/graphql/attribute/mutations/attribute_value_update.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/mutations/attribute_value_update.py\t94492e4 (commit)\n@@ -6,8 +6,9 @@\n from ....permission.enums import ProductTypePermissions\n from ....product import models as product_models\n from ....webhook.event_types import WebhookEventAsyncType\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.mutations import ModelWithExtRefMutation\n from ...core.types import AttributeError\n from ...core.utils import WebhookEventInfo\n from ...plugins.dataloaders import get_plugin_manager_promise\n@@ -86,9 +87,10 @@\n \n     @classmethod\n     def success_response(cls, instance):\n         response = super().success_response(instance)\n-        response.attribute = instance.attribute\n+        response.attribute = ChannelContext(instance.attribute, None)\n+        response.attributeValue = ChannelContext(instance, None)\n         return response\n \n     @classmethod\n     def post_save_action(cls, info: ResolveInfo, instance, cleaned_input):\n"
        },
        {
          "path": "saleor/graphql/attribute/schema.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/schema.py\n===================================================================\n--- saleor/graphql/attribute/schema.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/schema.py\t94492e4 (commit)\n@@ -2,8 +2,9 @@\n \n from ...attribute import models\n from ..core import ResolveInfo\n from ..core.connection import create_connection_slice, filter_connection_queryset\n+from ..core.context import ChannelContext, ChannelQsContext\n from ..core.descriptions import DEPRECATED_IN_3X_INPUT\n from ..core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ..core.fields import BaseField, FilterConnectionField\n from ..core.utils.resolvers import resolve_by_global_id_slug_or_ext_ref\n@@ -68,16 +69,20 @@\n             qs, kwargs, info.context, allow_replica=info.context.allow_replica\n         )\n         if search:\n             qs = filter_attribute_search(qs, None, search)\n+        qs = ChannelQsContext(qs=qs, channel_slug=None)\n         return create_connection_slice(qs, info, kwargs, AttributeCountableConnection)\n \n     def resolve_attribute(\n         self, info: ResolveInfo, *, id=None, slug=None, external_reference=None\n     ):\n-        return resolve_by_global_id_slug_or_ext_ref(\n+        attribute = resolve_by_global_id_slug_or_ext_ref(\n             info, models.Attribute, id, slug, external_reference\n         )\n+        if attribute:\n+            return ChannelContext(node=attribute, channel_slug=None)\n+        return None\n \n \n class AttributeMutations(graphene.ObjectType):\n     # attribute mutations\n"
        },
        {
          "path": "saleor/graphql/attribute/tests/queries/test_attribute_query.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/tests/queries/test_attribute_query.py\n===================================================================\n--- saleor/graphql/attribute/tests/queries/test_attribute_query.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/tests/queries/test_attribute_query.py\t94492e4 (commit)\n@@ -63,38 +63,58 @@\n     )\n \n \n QUERY_ATTRIBUTE = \"\"\"\n-    query($id: ID!, $query: String) {\n-        attribute(id: $id) {\n-            id\n-            slug\n-            name\n-            inputType\n-            entityType\n-            type\n-            unit\n-            choices(first: 10, filter: {search: $query}) {\n-                edges {\n-                    node {\n-                        slug\n-                        inputType\n-                        value\n-                        file {\n-                            url\n-                            contentType\n-                        }\n-                    }\n-                }\n-            }\n-            valueRequired\n-            visibleInStorefront\n-            filterableInStorefront\n-            filterableInDashboard\n-            availableInGrid\n-            storefrontSearchPosition\n+query ($id: ID!, $query: String) {\n+  attribute(id: $id) {\n+    id\n+    slug\n+    name\n+    inputType\n+    entityType\n+    type\n+    unit\n+    choices(first: 10, filter: {search: $query}) {\n+      edges {\n+        node {\n+          slug\n+          inputType\n+          value\n+          file {\n+            url\n+            contentType\n+          }\n         }\n+      }\n     }\n+    valueRequired\n+    visibleInStorefront\n+    filterableInStorefront\n+    filterableInDashboard\n+    availableInGrid\n+    storefrontSearchPosition\n+    translation(languageCode: PL) {\n+      id\n+      name\n+    }\n+    withChoices\n+    productTypes(first: 1) {\n+      edges {\n+        node {\n+          id\n+        }\n+      }\n+    }\n+    productVariantTypes(first: 1) {\n+      edges {\n+        node {\n+          id\n+        }\n+      }\n+    }\n+    externalReference\n+  }\n+}\n \"\"\"\n \n \n def test_get_single_product_attribute_by_staff(\n@@ -416,11 +436,13 @@\n             \"node\": {\n                 \"slug\": value.slug,\n                 \"value\": value.value,\n                 \"inputType\": value.input_type.upper(),\n-                \"file\": {\"url\": value.file_url, \"contentType\": value.content_type}\n-                if value.file_url\n-                else None,\n+                \"file\": (\n+                    {\"url\": value.file_url, \"contentType\": value.content_type}\n+                    if value.file_url\n+                    else None\n+                ),\n             }\n         }\n         attribute_value_data.append(data)\n \n@@ -438,12 +460,32 @@\n                     slug\n                     choices(first: 10) {\n                         edges {\n                             node {\n+                            id\n+                            name\n+                            slug\n+                            inputType\n+                            value\n+                            file {\n+                                url\n+                                contentType\n+                            }\n+                            translation(languageCode: PL) {\n                                 id\n                                 name\n-                                slug\n+                                translatableContent {\n+                                id\n+                                }\n                             }\n+                            reference\n+                            richText\n+                            plainText\n+                            boolean\n+                            date\n+                            dateTime\n+                            externalReference\n+                            }\n                         }\n                     }\n                 }\n             }\n"
        },
        {
          "path": "saleor/graphql/attribute/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/types.py\n===================================================================\n--- saleor/graphql/attribute/types.py\t5d692d8 (parent)\n+++ saleor/graphql/attribute/types.py\t94492e4 (commit)\n@@ -12,9 +12,13 @@\n     CountableConnection,\n     create_connection_slice,\n     filter_connection_queryset,\n )\n-from ..core.context import ChannelContext, get_database_connection_name\n+from ..core.context import (\n+    ChannelContext,\n+    ChannelQsContext,\n+    get_database_connection_name,\n+)\n from ..core.descriptions import (\n     ADDED_IN_322,\n     DEFAULT_DEPRECATION_REASON,\n     DEPRECATED_IN_3X_INPUT,\n@@ -29,11 +33,11 @@\n     DateRangeInput,\n     DateTimeRangeInput,\n     File,\n     IntRangeInput,\n-    ModelObjectType,\n     NonNullList,\n )\n+from ..core.types.context import ChannelContextType, ChannelContextTypeForObjectType\n from ..decorators import check_attribute_required_permissions\n from ..meta.types import ObjectWithMetadata\n from ..page.dataloaders import PageByIdLoader\n from ..product.dataloaders.products import ProductByIdLoader, ProductVariantByIdLoader\n@@ -58,15 +62,17 @@\n         return None\n     return reference_pk\n \n \n-class AttributeValue(ModelObjectType[models.AttributeValue]):\n+class AttributeValue(ChannelContextType[models.AttributeValue]):\n     id = graphene.GlobalID(required=True, description=\"The ID of the attribute value.\")\n     name = graphene.String(description=AttributeValueDescriptions.NAME)\n     slug = graphene.String(description=AttributeValueDescriptions.SLUG)\n     value = graphene.String(description=AttributeValueDescriptions.VALUE)\n     translation = TranslationField(\n-        AttributeValueTranslation, type_name=\"attribute value\"\n+        AttributeValueTranslation,\n+        type_name=\"attribute value\",\n+        resolver=ChannelContextType.resolve_translation,\n     )\n     input_type = AttributeInputTypeEnum(description=AttributeDescriptions.INPUT_TYPE)\n     reference = graphene.ID(description=\"The ID of the referenced object.\")\n     referenced_object = graphene.Field(\n@@ -95,24 +101,29 @@\n         required=False,\n     )\n \n     class Meta:\n+        default_resolver = ChannelContextType.resolver_with_context\n         description = \"Represents a value of an attribute.\"\n         interfaces = [graphene.relay.Node]\n         model = models.AttributeValue\n \n     @staticmethod\n-    def resolve_referenced_object(root: models.AttributeValue, info: ResolveInfo):\n+    def resolve_referenced_object(\n+        root: ChannelContext[models.AttributeValue], info: ResolveInfo\n+    ):\n+        attr_value = root.node\n+\n         def prepare_referenced_object(attribute):\n             if not attribute:\n                 return None\n-            reference_pk = get_reference_pk(attribute, root)\n+            reference_pk = get_reference_pk(attribute, attr_value)\n \n             if reference_pk is None:\n                 return None\n \n             def wrap_with_channel_context(_object):\n-                return ChannelContext(node=_object, channel_slug=None)\n+                return ChannelContext(node=_object, channel_slug=root.channel_slug)\n \n             if attribute.entity_type == AttributeEntityType.PRODUCT:\n                 return (\n                     ProductByIdLoader(info.context)\n@@ -130,63 +141,78 @@\n             return None\n \n         return (\n             AttributesByAttributeId(info.context)\n-            .load(root.attribute_id)\n+            .load(attr_value.attribute_id)\n             .then(prepare_referenced_object)\n         )\n \n-    @staticmethod\n-    def resolve_input_type(root: models.AttributeValue, info: ResolveInfo):\n+    def resolve_input_type(\n+        root: ChannelContext[models.AttributeValue], info: ResolveInfo\n+    ):\n+        attr_value = root.node\n         return (\n             AttributesByAttributeId(info.context)\n-            .load(root.attribute_id)\n+            .load(attr_value.attribute_id)\n             .then(lambda attribute: attribute.input_type)\n         )\n \n     @staticmethod\n-    def resolve_file(root: models.AttributeValue, _info: ResolveInfo) -> None | File:\n-        if not root.file_url:\n+    def resolve_file(\n+        root: ChannelContext[models.AttributeValue], _info: ResolveInfo\n+    ) -> None | File:\n+        attr_value = root.node\n+        if not attr_value.file_url:\n             return None\n-        return File(url=root.file_url, content_type=root.content_type)\n+        return File(url=attr_value.file_url, content_type=attr_value.content_type)\n \n     @staticmethod\n-    def resolve_reference(root: models.AttributeValue, info: ResolveInfo):\n+    def resolve_reference(\n+        root: ChannelContext[models.AttributeValue], info: ResolveInfo\n+    ):\n+        attr_value = root.node\n+\n         def prepare_reference(attribute) -> None | str:\n-            reference_pk = get_reference_pk(attribute, root)\n+            reference_pk = get_reference_pk(attribute, attr_value)\n             if reference_pk is None:\n                 return None\n             return graphene.Node.to_global_id(attribute.entity_type, reference_pk)\n \n         return (\n             AttributesByAttributeId(info.context)\n-            .load(root.attribute_id)\n+            .load(attr_value.attribute_id)\n             .then(prepare_reference)\n         )\n \n     @staticmethod\n-    def resolve_date_time(root: models.AttributeValue, info: ResolveInfo):\n+    def resolve_date_time(\n+        root: ChannelContext[models.AttributeValue], info: ResolveInfo\n+    ):\n+        attr_value = root.node\n+\n         def _resolve_date(attribute):\n             if attribute.input_type == AttributeInputType.DATE_TIME:\n-                return root.date_time\n+                return attr_value.date_time\n             return None\n \n         return (\n             AttributesByAttributeId(info.context)\n-            .load(root.attribute_id)\n+            .load(attr_value.attribute_id)\n             .then(_resolve_date)\n         )\n \n     @staticmethod\n-    def resolve_date(root: models.AttributeValue, info: ResolveInfo):\n+    def resolve_date(root: ChannelContext[models.AttributeValue], info: ResolveInfo):\n+        attr_value = root.node\n+\n         def _resolve_date(attribute):\n             if attribute.input_type == AttributeInputType.DATE:\n-                return root.date_time\n+                return attr_value.date_time\n             return None\n \n         return (\n             AttributesByAttributeId(info.context)\n-            .load(root.attribute_id)\n+            .load(attr_value.attribute_id)\n             .then(_resolve_date)\n         )\n \n \n@@ -195,9 +221,9 @@\n         doc_category = DOC_CATEGORY_ATTRIBUTES\n         node = AttributeValue\n \n \n-class Attribute(ModelObjectType[models.Attribute]):\n+class Attribute(ChannelContextType[models.Attribute]):\n     id = graphene.GlobalID(required=True, description=\"The ID of the attribute.\")\n     input_type = AttributeInputTypeEnum(description=AttributeDescriptions.INPUT_TYPE)\n     entity_type = AttributeEntityTypeEnum(\n         description=AttributeDescriptions.ENTITY_TYPE, required=False\n@@ -278,9 +304,13 @@\n         ),\n         required=True,\n         deprecation_reason=DEFAULT_DEPRECATION_REASON,\n     )\n-    translation = TranslationField(AttributeTranslation, type_name=\"attribute\")\n+    translation = TranslationField(\n+        AttributeTranslation,\n+        type_name=\"attribute\",\n+        resolver=ChannelContextType.resolve_translation,\n+    )\n     with_choices = graphene.Boolean(\n         description=AttributeDescriptions.WITH_CHOICES, required=True\n     )\n     product_types = ConnectionField(\n@@ -303,77 +333,100 @@\n         required=False,\n     )\n \n     class Meta:\n+        default_resolver = ChannelContextType.resolver_with_context\n         description = (\n             \"Custom attribute of a product. Attributes can be assigned to products and \"\n             \"variants at the product type level.\"\n         )\n         interfaces = [graphene.relay.Node, ObjectWithMetadata]\n         model = models.Attribute\n \n     @staticmethod\n-    def resolve_choices(root: models.Attribute, info: ResolveInfo, **kwargs):\n-        if root.input_type in AttributeInputType.TYPES_WITH_CHOICES:\n-            qs = root.values.using(get_database_connection_name(info.context)).all()\n+    def resolve_choices(\n+        root: ChannelContext[models.Attribute], info: ResolveInfo, **kwargs\n+    ):\n+        attr = root.node\n+        if attr.input_type in AttributeInputType.TYPES_WITH_CHOICES:\n+            qs = attr.values.using(get_database_connection_name(info.context)).all()\n         else:\n             qs = models.AttributeValue.objects.none()\n \n-        qs = filter_connection_queryset(\n-            qs, kwargs, allow_replica=info.context.allow_replica\n+        channel_context_qs = ChannelQsContext(qs=qs, channel_slug=root.channel_slug)\n+        channel_context_qs = filter_connection_queryset(\n+            channel_context_qs, kwargs, allow_replica=info.context.allow_replica\n         )\n         return create_connection_slice(\n-            qs, info, kwargs, AttributeValueCountableConnection\n+            channel_context_qs, info, kwargs, AttributeValueCountableConnection\n         )\n \n     @staticmethod\n     @check_attribute_required_permissions()\n-    def resolve_value_required(root: models.Attribute, _info: ResolveInfo):\n-        return root.value_required\n+    def resolve_value_required(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.value_required\n \n     @staticmethod\n     @check_attribute_required_permissions()\n-    def resolve_visible_in_storefront(root: models.Attribute, _info: ResolveInfo):\n-        return root.visible_in_storefront\n+    def resolve_visible_in_storefront(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.visible_in_storefront\n \n     @staticmethod\n     @check_attribute_required_permissions()\n-    def resolve_filterable_in_storefront(root: models.Attribute, _info: ResolveInfo):\n-        return root.filterable_in_storefront\n+    def resolve_filterable_in_storefront(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.filterable_in_storefront\n \n     @staticmethod\n     @check_attribute_required_permissions()\n-    def resolve_filterable_in_dashboard(root: models.Attribute, _info: ResolveInfo):\n-        return root.filterable_in_dashboard\n+    def resolve_filterable_in_dashboard(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.filterable_in_dashboard\n \n     @staticmethod\n     @check_attribute_required_permissions()\n-    def resolve_storefront_search_position(root: models.Attribute, _info: ResolveInfo):\n-        return root.storefront_search_position\n+    def resolve_storefront_search_position(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.storefront_search_position\n \n     @staticmethod\n     @check_attribute_required_permissions()\n-    def resolve_available_in_grid(root: models.Attribute, _info: ResolveInfo):\n-        return root.available_in_grid\n+    def resolve_available_in_grid(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.available_in_grid\n \n     @staticmethod\n-    def resolve_with_choices(root: models.Attribute, _info: ResolveInfo):\n-        return root.input_type in AttributeInputType.TYPES_WITH_CHOICES\n+    def resolve_with_choices(\n+        root: ChannelContext[models.Attribute], _info: ResolveInfo\n+    ):\n+        return root.node.input_type in AttributeInputType.TYPES_WITH_CHOICES\n \n     @staticmethod\n-    def resolve_product_types(root: models.Attribute, info: ResolveInfo, **kwargs):\n+    def resolve_product_types(\n+        root: ChannelContext[models.Attribute], info: ResolveInfo, **kwargs\n+    ):\n         from ..product.types import ProductTypeCountableConnection\n \n-        qs = root.product_types.using(get_database_connection_name(info.context)).all()\n+        qs = root.node.product_types.using(\n+            get_database_connection_name(info.context)\n+        ).all()\n         return create_connection_slice(qs, info, kwargs, ProductTypeCountableConnection)\n \n     @staticmethod\n     def resolve_product_variant_types(\n-        root: models.Attribute, info: ResolveInfo, **kwargs\n+        root: ChannelContext[models.Attribute], info: ResolveInfo, **kwargs\n     ):\n         from ..product.types import ProductTypeCountableConnection\n \n-        qs = root.product_variant_types.using(\n+        qs = root.node.product_variant_types.using(\n             get_database_connection_name(info.context)\n         ).all()\n         return create_connection_slice(qs, info, kwargs, ProductTypeCountableConnection)\n \n@@ -404,9 +457,9 @@\n         )\n         doc_category = DOC_CATEGORY_ATTRIBUTES\n \n \n-class SelectedAttribute(BaseObjectType):\n+class SelectedAttribute(ChannelContextTypeForObjectType):\n     attribute = graphene.Field(\n         Attribute,\n         default_value=None,\n         description=AttributeDescriptions.NAME,\n"
        },
        {
          "path": "saleor/graphql/core/context.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/context.py\n===================================================================\n--- saleor/graphql/core/context.py\t5d692d8 (parent)\n+++ saleor/graphql/core/context.py\t94492e4 (commit)\n@@ -3,9 +3,8 @@\n from typing import TYPE_CHECKING, Any, Generic, TypeVar\n \n from django.conf import settings\n from django.db.models import QuerySet\n-from django.db.models.base import Model\n from django.http import HttpRequest\n from django.utils.functional import empty\n \n if TYPE_CHECKING:\n@@ -84,13 +83,10 @@\n         self.node = node\n         self.allow_sync_webhooks = allow_sync_webhooks\n \n \n-C = TypeVar(\"C\", bound=Model)\n-\n-\n @dataclass\n-class ChannelContext(BaseContext[C]):\n+class ChannelContext(BaseContext[N]):\n     channel_slug: str | None\n \n \n @dataclass\n"
        },
        {
          "path": "saleor/graphql/core/types/context.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/types/context.py\n===================================================================\n--- saleor/graphql/core/types/context.py\t5d692d8 (parent)\n+++ saleor/graphql/core/types/context.py\t94492e4 (commit)\n@@ -1,48 +1,52 @@\n-from typing import TypeVar, cast\n+from typing import Generic, TypeVar, cast\n \n from django.db.models import Model\n from graphene.types.resolver import get_default_resolver\n \n from ...translations.resolvers import resolve_translation\n from .. import ResolveInfo\n from ..context import ChannelContext\n+from .base import BaseObjectType\n from .model import ModelObjectType\n \n-T = TypeVar(\"T\", bound=Model)\n+N = TypeVar(\"N\", bound=Model)\n \n \n-class ChannelContextTypeForObjectType(ModelObjectType[T]):\n+class ChannelContextTypeForObjectType(Generic[N], BaseObjectType):\n     \"\"\"A Graphene type that supports resolvers' root as ChannelContext objects.\"\"\"\n \n     class Meta:\n         abstract = True\n \n     @staticmethod\n     def resolver_with_context(\n-        attname, default_value, root: ChannelContext, info: ResolveInfo, **args\n+        attname, default_value, root: ChannelContext[N], info: ResolveInfo, **args\n     ):\n         resolver = get_default_resolver()\n         return resolver(attname, default_value, root.node, info, **args)\n \n     @staticmethod\n-    def resolve_id(root: ChannelContext[T], _info: ResolveInfo):\n-        return root.node.pk\n-\n-    @staticmethod\n     def resolve_translation(\n-        root: ChannelContext[T], info: ResolveInfo, *, language_code\n+        root: ChannelContext[N], info: ResolveInfo, *, language_code\n     ):\n         # Resolver for TranslationField; needs to be manually specified.\n         return resolve_translation(root.node, info, language_code=language_code)\n \n \n-class ChannelContextType(ChannelContextTypeForObjectType[T]):\n+T = TypeVar(\"T\", bound=Model)\n+\n+\n+class ChannelContextType(ChannelContextTypeForObjectType[T], ModelObjectType[T]):\n     \"\"\"A Graphene type that supports resolvers' root as ChannelContext objects.\"\"\"\n \n     class Meta:\n         abstract = True\n \n+    @staticmethod\n+    def resolve_id(root: ChannelContext[T], _info: ResolveInfo):\n+        return root.node.pk\n+\n     @classmethod\n     def is_type_of(cls, root: ChannelContext[T] | T, _info: ResolveInfo) -> bool:\n         # Unwrap node from ChannelContext if it didn't happen already\n         if isinstance(root, ChannelContext):\n@@ -54,6 +58,5 @@\n         if cls._meta.model._meta.proxy:\n             model = root._meta.model\n         else:\n             model = cast(type[Model], root._meta.model._meta.concrete_model)\n-\n         return model == cls._meta.model\n"
        },
        {
          "path": "saleor/graphql/decorators.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/decorators.py\n===================================================================\n--- saleor/graphql/decorators.py\t5d692d8 (parent)\n+++ saleor/graphql/decorators.py\t94492e4 (commit)\n@@ -4,8 +4,9 @@\n \n from graphene import ResolveInfo\n \n from ..attribute import AttributeType\n+from ..attribute.models import Attribute\n from ..core.exceptions import PermissionDenied\n from ..permission.auth_filters import is_app, is_staff_user\n from ..permission.enums import (\n     BasePermissionEnum,\n@@ -18,8 +19,9 @@\n     has_one_of_permissions,\n     one_of_permissions_or_auth_filter_required,\n )\n from ..permission.utils import permission_required as core_permission_required\n+from .core.context import ChannelContext\n from .utils import get_user_or_app_from_context\n \n \n def context(f):\n@@ -118,9 +120,10 @@\n     As an attribute can belong to the product or to the page,\n     different permissions need to be checked.\n     \"\"\"\n \n-    def check_perms(context, attribute):\n+    def check_perms(context, root: ChannelContext[Attribute]):\n+        attribute = root.node\n         requestor = get_user_or_app_from_context(context)\n         permissions: list[BasePermissionEnum]\n         if attribute.type == AttributeType.PAGE_TYPE:\n             permissions = [\n"
        },
        {
          "path": "saleor/graphql/meta/mutations/base.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/meta/mutations/base.py\n===================================================================\n--- saleor/graphql/meta/mutations/base.py\t5d692d8 (parent)\n+++ saleor/graphql/meta/mutations/base.py\t94492e4 (commit)\n@@ -1,8 +1,9 @@\n import graphene\n from django.core.exceptions import ValidationError\n from graphql.error.base import GraphQLError\n \n+from ....attribute import models as attribute_models\n from ....checkout import models as checkout_models\n from ....core import models\n from ....core.db.connection import allow_writer\n from ....core.error_codes import MetadataErrorCode\n@@ -255,10 +256,13 @@\n             | product_models.Collection\n             | product_models.Product\n             | product_models.ProductVariant\n             | shipping_models.ShippingMethod\n-            | shipping_models.ShippingZone,\n+            | shipping_models.ShippingZone\n+            | attribute_models.Attribute\n+            | attribute_models.AttributeValue,\n         )\n+\n         use_channel_context = use_channel_context or (\n             # For old sales migrated into promotions\n             isinstance(instance, Promotion) and instance.old_sale_id\n         )\n"
        },
        {
          "path": "saleor/graphql/page/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/types.py\n===================================================================\n--- saleor/graphql/page/types.py\t5d692d8 (parent)\n+++ saleor/graphql/page/types.py\t94492e4 (commit)\n@@ -14,9 +14,13 @@\n     CountableConnection,\n     create_connection_slice,\n     filter_connection_queryset,\n )\n-from ..core.context import get_database_connection_name\n+from ..core.context import (\n+    ChannelContext,\n+    ChannelQsContext,\n+    get_database_connection_name,\n+)\n from ..core.descriptions import DEPRECATED_IN_3X_INPUT, RICH_CONTENT\n from ..core.doc_category import DOC_CATEGORY_PAGES\n from ..core.federation import federated_entity, resolve_federation_references\n from ..core.fields import FilterConnectionField, JSONString, PermissionsField\n@@ -84,17 +88,26 @@\n         return models.PageType\n \n     @staticmethod\n     def resolve_attributes(root: models.PageType, info: ResolveInfo):\n+        def wrap_with_channel_context(attributes):\n+            return [ChannelContext(attribute, None) for attribute in attributes]\n+\n         requestor = get_user_or_app_from_context(info.context)\n         if (\n             requestor\n             and requestor.is_active\n             and requestor.has_perm(PagePermissions.MANAGE_PAGES)\n         ):\n-            return PageAttributesAllByPageTypeIdLoader(info.context).load(root.pk)\n-        return PageAttributesVisibleInStorefrontByPageTypeIdLoader(info.context).load(\n-            root.pk\n+            return (\n+                PageAttributesAllByPageTypeIdLoader(info.context)\n+                .load(root.pk)\n+                .then(wrap_with_channel_context)\n+            )\n+        return (\n+            PageAttributesVisibleInStorefrontByPageTypeIdLoader(info.context)\n+            .load(root.pk)\n+            .then(wrap_with_channel_context)\n         )\n \n     @staticmethod\n     def resolve_available_attributes(\n@@ -107,8 +120,9 @@\n             qs, kwargs, info.context, allow_replica=info.context.allow_replica\n         )\n         if search:\n             qs = filter_attribute_search(qs, None, search)\n+        qs = ChannelQsContext(qs=qs, channel_slug=None)\n         return create_connection_slice(qs, info, kwargs, AttributeCountableConnection)\n \n     @staticmethod\n     def resolve_has_pages(root: models.PageType, info: ResolveInfo):\n@@ -199,33 +213,70 @@\n         return content if content is not None else {}\n \n     @staticmethod\n     def resolve_attributes(root: models.Page, info: ResolveInfo):\n+        def wrap_with_channel_context(\n+            attributes: list[dict[str, list]] | None,\n+        ) -> list[SelectedAttribute] | None:\n+            if attributes is None:\n+                return None\n+            return [\n+                SelectedAttribute(\n+                    attribute=ChannelContext(attribute[\"attribute\"], None),\n+                    values=[\n+                        ChannelContext(value, None) for value in attribute[\"values\"]\n+                    ],\n+                )\n+                for attribute in attributes\n+            ]\n+\n         requestor = get_user_or_app_from_context(info.context)\n         if (\n             requestor\n             and requestor.is_active\n             and requestor.has_perm(PagePermissions.MANAGE_PAGES)\n         ):\n-            return SelectedAttributesAllByPageIdLoader(info.context).load(root.id)\n-        return SelectedAttributesVisibleInStorefrontPageIdLoader(info.context).load(\n-            root.id\n+            return (\n+                SelectedAttributesAllByPageIdLoader(info.context)\n+                .load(root.id)\n+                .then(wrap_with_channel_context)\n+            )\n+        return (\n+            SelectedAttributesVisibleInStorefrontPageIdLoader(info.context)\n+            .load(root.id)\n+            .then(wrap_with_channel_context)\n         )\n \n     @staticmethod\n     def resolve_attribute(root: models.Page, info: ResolveInfo, slug: str):\n+        def wrap_with_channel_context(\n+            attribute_data: dict[str, dict | list[dict]] | None,\n+        ) -> SelectedAttribute | None:\n+            if attribute_data is None:\n+                return None\n+            return SelectedAttribute(\n+                attribute=ChannelContext(attribute_data[\"attribute\"], None),\n+                values=[\n+                    ChannelContext(value, None) for value in attribute_data[\"values\"]\n+                ],\n+            )\n+\n         requestor = get_user_or_app_from_context(info.context)\n         if (\n             requestor\n             and requestor.is_active\n             and requestor.has_perm(PagePermissions.MANAGE_PAGES)\n         ):\n-            return SelectedAttributeAllByPageIdAttributeSlugLoader(info.context).load(\n-                (root.id, slug)\n+            return (\n+                SelectedAttributeAllByPageIdAttributeSlugLoader(info.context)\n+                .load((root.id, slug))\n+                .then(wrap_with_channel_context)\n             )\n-        return SelectedAttributeVisibleInStorefrontPageIdAttributeSlugLoader(\n-            info.context\n-        ).load((root.id, slug))\n+        return (\n+            SelectedAttributeVisibleInStorefrontPageIdAttributeSlugLoader(info.context)\n+            .load((root.id, slug))\n+            .then(wrap_with_channel_context)\n+        )\n \n \n class PageCountableConnection(CountableConnection):\n     class Meta:\n"
        },
        {
          "path": "saleor/graphql/product/types/products.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/types/products.py\n===================================================================\n--- saleor/graphql/product/types/products.py\t5d692d8 (parent)\n+++ saleor/graphql/product/types/products.py\t94492e4 (commit)\n@@ -1,8 +1,9 @@\n import sys\n from collections import defaultdict\n from dataclasses import asdict\n from decimal import Decimal\n+from typing import cast\n \n import graphene\n from graphene import relay\n from promise import Promise\n@@ -583,29 +584,57 @@\n         root: ChannelContext[models.ProductVariant],\n         info,\n         variant_selection: str | None = None,\n     ):\n-        def apply_variant_selection_filter(selected_attributes):\n+        def apply_variant_selection_filter(\n+            selected_attributes,\n+        ) -> list[SelectedAttribute]:\n             if not variant_selection or variant_selection == VariantAttributeScope.ALL:\n-                return selected_attributes\n+                return [\n+                    SelectedAttribute(\n+                        attribute=ChannelContext(\n+                            selected_att[\"attribute\"], root.channel_slug\n+                        ),\n+                        values=[\n+                            ChannelContext(value, root.channel_slug)\n+                            for value in selected_att[\"values\"]\n+                        ],\n+                    )\n+                    for selected_att in selected_attributes\n+                ]\n             attributes = [\n                 (selected_att[\"attribute\"], selected_att[\"variant_selection\"])\n                 for selected_att in selected_attributes\n             ]\n+            attributes = cast(list[tuple[attribute_models.Attribute, bool]], attributes)\n             variant_selection_attrs = [\n                 attr for attr, _ in get_variant_selection_attributes(attributes)\n             ]\n \n             if variant_selection == VariantAttributeScope.VARIANT_SELECTION:\n-                return [\n-                    selected_attribute\n-                    for selected_attribute in selected_attributes\n-                    if selected_attribute[\"attribute\"] in variant_selection_attrs\n+                attributes_to_return = [\n+                    selected_att\n+                    for selected_att in selected_attributes\n+                    if selected_att[\"attribute\"] in variant_selection_attrs\n                 ]\n+            else:\n+                attributes_to_return = [\n+                    selected_att\n+                    for selected_att in selected_attributes\n+                    if selected_att[\"attribute\"] not in variant_selection_attrs\n+                ]\n+\n             return [\n-                selected_attribute\n-                for selected_attribute in selected_attributes\n-                if selected_attribute[\"attribute\"] not in variant_selection_attrs\n+                SelectedAttribute(\n+                    attribute=ChannelContext(\n+                        selected_att[\"attribute\"], root.channel_slug\n+                    ),\n+                    values=[\n+                        ChannelContext(value, root.channel_slug)\n+                        for value in selected_att[\"values\"]\n+                    ],\n+                )\n+                for selected_att in attributes_to_return\n             ]\n \n         return (\n             SelectedAttributesByProductVariantIdLoader(info.context)\n@@ -1302,15 +1331,36 @@\n \n     @staticmethod\n     def resolve_attribute(root: ChannelContext[models.Product], info, slug):\n         def get_selected_attribute_by_slug(\n-            attributes: list[SelectedAttribute],\n+            attributes: (\n+                list[\n+                    dict[\n+                        str,\n+                        attribute_models.Attribute\n+                        | list[attribute_models.AttributeValue],\n+                    ]\n+                ]\n+                | None\n+            ),\n         ) -> SelectedAttribute | None:\n-            return next(\n-                (atr for atr in attributes if atr[\"attribute\"].slug == slug),\n-                None,\n-            )\n+            if attributes is None:\n+                return None\n \n+            for atr in attributes:\n+                attribute = atr[\"attribute\"]\n+                attribute = cast(attribute_models.Attribute, attribute)\n+                if attribute.slug == slug:\n+                    values = atr[\"values\"]\n+                    values = cast(list[attribute_models.AttributeValue], values)\n+                    return SelectedAttribute(\n+                        attribute=ChannelContext(attribute, root.channel_slug),\n+                        values=[\n+                            ChannelContext(value, root.channel_slug) for value in values\n+                        ],\n+                    )\n+            return None\n+\n         requestor = get_user_or_app_from_context(info.context)\n         if (\n             requestor\n             and requestor.is_active\n@@ -1328,20 +1378,55 @@\n         )\n \n     @staticmethod\n     def resolve_attributes(root: ChannelContext[models.Product], info):\n+        def wrap_with_channel_context(\n+            attributes: (\n+                list[\n+                    dict[\n+                        str,\n+                        attribute_models.Attribute\n+                        | list[attribute_models.AttributeValue],\n+                    ]\n+                ]\n+                | None\n+            ),\n+        ) -> list[SelectedAttribute] | None:\n+            if attributes is None:\n+                return None\n+\n+            response = []\n+            for attr_data in attributes:\n+                attribute = attr_data[\"attribute\"]\n+                attribute = cast(attribute_models.Attribute, attribute)\n+                values = attr_data[\"values\"]\n+                values = cast(list[attribute_models.AttributeValue], values)\n+                response.append(\n+                    SelectedAttribute(\n+                        attribute=ChannelContext(attribute, root.channel_slug),\n+                        values=[\n+                            ChannelContext(value, root.channel_slug) for value in values\n+                        ],\n+                    )\n+                )\n+            return response\n+\n         requestor = get_user_or_app_from_context(info.context)\n         if (\n             requestor\n             and requestor.is_active\n             and requestor.has_perm(ProductPermissions.MANAGE_PRODUCTS)\n         ):\n-            return SelectedAttributesAllByProductIdLoader(info.context).load(\n-                root.node.id\n+            return (\n+                SelectedAttributesAllByProductIdLoader(info.context)\n+                .load(root.node.id)\n+                .then(wrap_with_channel_context)\n             )\n-        return SelectedAttributesVisibleInStorefrontByProductIdLoader(\n-            info.context\n-        ).load(root.node.id)\n+        return (\n+            SelectedAttributesVisibleInStorefrontByProductIdLoader(info.context)\n+            .load(root.node.id)\n+            .then(wrap_with_channel_context)\n+        )\n \n     @staticmethod\n     def resolve_media_by_id(root: ChannelContext[models.Product], info, *, id):\n         _type, pk = from_global_id_or_error(id, ProductMedia)\n@@ -1786,9 +1871,9 @@\n \n     @staticmethod\n     def resolve_product_attributes(root: models.ProductType, info):\n         def unpack_attributes(attributes):\n-            return [attr for attr, *_ in attributes]\n+            return [ChannelContext(attr, None) for attr, *_ in attributes]\n \n         requestor = get_user_or_app_from_context(info.context)\n         if (\n             requestor\n@@ -1814,14 +1899,16 @@\n         variant_selection: str | None = None,\n     ):\n         def apply_variant_selection_filter(attributes):\n             if not variant_selection or variant_selection == VariantAttributeScope.ALL:\n-                return [attr for attr, *_ in attributes]\n+                return [ChannelContext(attr, None) for attr, *_ in attributes]\n             variant_selection_attrs = get_variant_selection_attributes(attributes)\n             if variant_selection == VariantAttributeScope.VARIANT_SELECTION:\n-                return [attr for attr, *_ in variant_selection_attrs]\n+                return [\n+                    ChannelContext(attr, None) for attr, *_ in variant_selection_attrs\n+                ]\n             return [\n-                attr\n+                ChannelContext(attr, None)\n                 for attr, variant_selection in attributes\n                 if (attr, variant_selection) not in variant_selection_attrs\n             ]\n \n@@ -1851,19 +1938,28 @@\n     ):\n         def apply_variant_selection_filter(attributes):\n             if not variant_selection or variant_selection == VariantAttributeScope.ALL:\n                 return [\n-                    {\"attribute\": attr, \"variant_selection\": variant_selection}\n+                    {\n+                        \"attribute\": ChannelContext(attr, None),\n+                        \"variant_selection\": variant_selection,\n+                    }\n                     for attr, variant_selection in attributes\n                 ]\n             variant_selection_attrs = get_variant_selection_attributes(attributes)\n             if variant_selection == VariantAttributeScope.VARIANT_SELECTION:\n                 return [\n-                    {\"attribute\": attr, \"variant_selection\": variant_selection}\n+                    {\n+                        \"attribute\": ChannelContext(attr, None),\n+                        \"variant_selection\": variant_selection,\n+                    }\n                     for attr, variant_selection in variant_selection_attrs\n                 ]\n             return [\n-                {\"attribute\": attr, \"variant_selection\": variant_selection}\n+                {\n+                    \"attribute\": ChannelContext(attr, None),\n+                    \"variant_selection\": variant_selection,\n+                }\n                 for attr, variant_selection in attributes\n                 if (attr, variant_selection) not in variant_selection_attrs\n             ]\n \n@@ -1921,8 +2017,9 @@\n             qs, kwargs, info.context, allow_replica=info.context.allow_replica\n         )\n         if search:\n             qs = filter_attribute_search(qs, None, search)\n+        qs = ChannelQsContext(qs=qs, channel_slug=None)\n         return create_connection_slice(qs, info, kwargs, AttributeCountableConnection)\n \n     @staticmethod\n     def resolve_weight(root: models.ProductType, _info):\n"
        },
        {
          "path": "saleor/graphql/translations/mutations/attribute_translate.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/translations/mutations/attribute_translate.py\n===================================================================\n--- saleor/graphql/translations/mutations/attribute_translate.py\t5d692d8 (parent)\n+++ saleor/graphql/translations/mutations/attribute_translate.py\t94492e4 (commit)\n@@ -2,8 +2,9 @@\n \n from ....attribute import models as attribute_models\n from ....permission.enums import SitePermissions\n from ...attribute.types import Attribute\n+from ...core.context import ChannelContext\n from ...core.enums import LanguageCodeEnum\n from ...core.types import TranslationError\n from .utils import BaseTranslateMutation, NameTranslationInput\n \n@@ -28,4 +29,10 @@\n         object_type = Attribute\n         error_type_class = TranslationError\n         error_type_field = \"translation_errors\"\n         permissions = (SitePermissions.MANAGE_TRANSLATIONS,)\n+\n+    @classmethod\n+    def perform_mutation(cls, *args, **kwargs):\n+        response = super().perform_mutation(*args, **kwargs)\n+        response.attribute = ChannelContext(response.attribute, None)\n+        return response\n"
        },
        {
          "path": "saleor/graphql/translations/mutations/attribute_value_translate.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/translations/mutations/attribute_value_translate.py\n===================================================================\n--- saleor/graphql/translations/mutations/attribute_value_translate.py\t5d692d8 (parent)\n+++ saleor/graphql/translations/mutations/attribute_value_translate.py\t94492e4 (commit)\n@@ -5,8 +5,9 @@\n from ....attribute import models as attribute_models\n from ....core.utils.editorjs import clean_editor_js\n from ....permission.enums import SitePermissions\n from ...attribute.types import AttributeValue\n+from ...core.context import ChannelContext\n from ...core.descriptions import RICH_CONTENT\n from ...core.enums import LanguageCodeEnum\n from ...core.fields import JSONString\n from ...core.types import TranslationError\n@@ -49,4 +50,10 @@\n                 )\n             elif instance.attribute.input_type == AttributeInputType.PLAIN_TEXT:\n                 input_data[\"name\"] = truncatechars(input_data[\"plain_text\"], 250)\n         return input_data\n+\n+    @classmethod\n+    def perform_mutation(cls, *args, **kwargs):\n+        response = super().perform_mutation(*args, **kwargs)\n+        response.attributeValue = ChannelContext(response.attributeValue, None)\n+        return response\n"
        },
        {
          "path": "saleor/graphql/translations/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/translations/types.py\n===================================================================\n--- saleor/graphql/translations/types.py\t5d692d8 (parent)\n+++ saleor/graphql/translations/types.py\t94492e4 (commit)\n@@ -20,13 +20,9 @@\n from ...shipping import models as shipping_models\n from ...site import models as site_models\n from ..attribute.dataloaders import AttributesByAttributeId, AttributeValueByIdLoader\n from ..core.context import ChannelContext, get_database_connection_name\n-from ..core.descriptions import (\n-    ADDED_IN_321,\n-    DEPRECATED_IN_3X_TYPE,\n-    RICH_CONTENT,\n-)\n+from ..core.descriptions import ADDED_IN_321, DEPRECATED_IN_3X_TYPE, RICH_CONTENT\n from ..core.enums import LanguageCodeEnum\n from ..core.fields import JSONString, PermissionsField\n from ..core.tracing import traced_resolver\n from ..core.types import LanguageDisplay, ModelObjectType, NonNullList\n@@ -172,9 +168,9 @@\n         )\n \n     @staticmethod\n     def resolve_attribute(root: attribute_models.Attribute, _info):\n-        return root\n+        return ChannelContext(node=root, channel_slug=None)\n \n     @staticmethod\n     def resolve_attribute_id(root: attribute_models.Attribute, _info):\n         return graphene.Node.to_global_id(\"Attribute\", root.id)\n@@ -218,9 +214,9 @@\n         )\n \n     @staticmethod\n     def resolve_attribute_value(root: attribute_models.AttributeValue, _info):\n-        return root\n+        return ChannelContext(node=root, channel_slug=None)\n \n     @staticmethod\n     def resolve_attribute(root: attribute_models.AttributeValue, info):\n         return AttributesByAttributeId(info.context).load(root.attribute_id)\n"
        },
        {
          "path": "saleor/graphql/webhook/subscription_types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/subscription_types.py\n===================================================================\n--- saleor/graphql/webhook/subscription_types.py\t5d692d8 (parent)\n+++ saleor/graphql/webhook/subscription_types.py\t94492e4 (commit)\n@@ -359,9 +359,9 @@\n \n     @staticmethod\n     def resolve_attribute(root, _info: ResolveInfo):\n         _, attribute = root\n-        return attribute\n+        return ChannelContext(attribute, None)\n \n \n class AttributeCreated(SubscriptionObjectType, AttributeBase):\n     class Meta:\n@@ -394,10 +394,10 @@\n     )\n \n     @staticmethod\n     def resolve_attribute_value(root, _info: ResolveInfo):\n-        _, attribute = root\n-        return attribute\n+        _, attribute_value = root\n+        return ChannelContext(attribute_value, None)\n \n \n class AttributeValueCreated(SubscriptionObjectType, AttributeValueBase):\n     class Meta:\n"
        }
      ]
    },
    {
      "id": "block-shipping-webhooks",
      "sha": "4da98aa85df1be00674a119105640ca56e41a238",
      "parentSha": "9280e058a89585647dfac6c8047523871332d841",
      "spec": "Implement a feature to block synchronous shipping webhooks and external shipping method calls during bulk checkout queries and to denormalize shipping method data in the checkout.\n\nScope and behavior:\n- Add an opt-in flag on CheckoutInfo to control external calls\n  - Introduce a boolean flag allow_sync_webhooks (default True) on saleor/checkout/fetch.py:CheckoutInfo.\n  - When allow_sync_webhooks is False:\n    - Do not call any external shipping webhooks (SHIPPING_LIST_METHODS_FOR_CHECKOUT, CHECKOUT_FILTER_SHIPPING_METHODS) or plugin-based external shipping methods.\n    - When resolving the currently set external shipping method, construct it from the checkout’s denormalized fields (shipping_method_name and undiscounted_base_shipping_price) without external lookups.\n\n- Replace property-based shipping accessors with method-based ones and cache results\n  - Replace CheckoutInfo.all_shipping_methods cached_property with a method get_all_shipping_methods().\n    - Cache built-in methods in _cached_built_in_shipping_methods and external methods in _cached_external_shipping_methods.\n    - If allow_sync_webhooks is False, only return built-in methods and never call manager for external methods or excluded shipping methods.\n    - If allow_sync_webhooks is True, combine built-in and external methods and apply manager.excluded_shipping_methods_for_checkout, then compute active flags.\n  - Replace CheckoutInfo.delivery_method_info property with method get_delivery_method_info().\n    - If an external shipping method is selected and allow_sync_webhooks is True, resolve it from get_all_shipping_methods(); otherwise, construct it from denormalized fields.\n    - After producing a ShippingMethodData, update checkout’s denormalized fields if they don’t match using a helper (see below), then return DeliveryMethodBase via get_delivery_method_info().\n  - Add update_delivery_method_lists_for_checkout_info.reset to clear the two caches (_cached_built_in_shipping_methods/_cached_external_shipping_methods) instead of deleting a cached property.\n\n- Split built-in and external methods fetching helpers and update call signatures\n  - Implement get_available_built_in_shipping_methods_for_checkout_info(checkout_info) which computes valid internal methods using checkout_info and the subtotal (derived from base_calculations), replacing get_valid_internal_shipping_method_list_for_checkout_info and using a new helper in utils (below).\n  - Implement get_external_shipping_methods_for_checkout_info(checkout_info) to fetch external methods via PluginsManager only when allowed.\n  - Refactor get_all_shipping_methods_list(checkout_info) to chain the two above.\n\n- Denormalize shipping method name and base shipping price on checkout\n  - In CheckoutInfo, implement a helper _update_denormalized_shipping_method_fields(delivery_method: ShippingMethodData|Warehouse) that updates:\n    - shipping_method_name based on ShippingMethodData.name (or None if Warehouse/collection point), and\n    - undiscounted_base_shipping_price_amount based on ShippingMethodData.price quantized to checkout currency.\n  - Persist the changes with allow_writer() if any field changes.\n\n- Update checkout shipping method assignment/removal utilities to manage denormalized fields\n  - In saleor/checkout/utils.py:\n    - Implement _assign_undiscounted_base_shipping_price_to_checkout(checkout, shipping_method_data) to set undiscounted_base_shipping_price_amount when price changes; return list of updated fields.\n    - Implement _remove_undiscounted_base_shipping_price(checkout) to zero out undiscounted_base_shipping_price_amount when present; return list of updated fields.\n    - Update assign_external_shipping_to_checkout and assign_built_in_shipping_to_checkout to call _assign_undiscounted_base_shipping_price_to_checkout before changing IDs/names.\n    - Update remove_delivery_method_from_checkout and assign_collection_point_to_checkout to call _remove_undiscounted_base_shipping_price.\n  - Refactor get_valid_internal_shipping_methods_for_checkout into get_valid_internal_shipping_methods_for_checkout_info(checkout_info, subtotal) to consume checkout_info fields directly (lines, shipping address, channel listings, database connection name) instead of separate parameters.\n\n- Adjust calculations behavior around undiscounted prices\n  - In saleor/checkout/calculations.py:\n    - Remove update_undiscounted_prices() function and rename _update_undiscounted_unit_price_for_lines to update_undiscounted_unit_price_for_lines.\n    - In _fetch_checkout_prices_if_expired, call update_undiscounted_unit_price_for_lines(lines) (no shipping base price assignment here) and proceed with prior unit price updates and discount objects creation.\n\n- Propagate allow_sync_webhooks in GraphQL resolvers and use new accessors\n  - In saleor/graphql/checkout/types.py:\n    - In Checkout resolvers for shippingMethod, shippingMethods, availableShippingMethods, shippingPrice, subtotalPrice, totalPrice, status/balance, and line-level unit/total price calculations, set checkout_info.allow_sync_webhooks = root.allow_sync_webhooks before computing or fetching methods.\n    - Replace usages of checkout_info.delivery_method_info and checkout_info.all_shipping_methods with checkout_info.get_delivery_method_info() and checkout_info.get_all_shipping_methods().\n  - In mutations and other GraphQL modules using delivery method info (e.g., checkout_lines_add.py, checkout_shipping_address_update.py, mutations/utils.py), update call sites to use get_delivery_method_info().\n  - Update saleor/graphql/webhook/resolvers.py to call the new get_all_shipping_methods_list(checkout_info) signature without extra parameters.\n\n- Update other integrations to the new access pattern\n  - Replace all remaining internal uses of checkout_info.delivery_method_info with get_delivery_method_info() in:\n    - saleor/checkout/actions.py, base_calculations.py, checkout_cleaner.py, complete_checkout.py.\n    - saleor/payment/gateways/adyen/utils/common.py when building shipping line item data.\n    - saleor/plugins/avatax/__init__.py for address validation and shipping line price extraction.\n    - saleor/tax/calculations/checkout.py for shipping price tax class and tax rate.\n\n- Tests and observable behavior\n  - Add tests ensuring that when querying checkouts connection (bulk), no synchronous shipping webhooks or external shipping method calls are made and only built-in methods are returned. Validate that the denormalized external shipping method fields on checkout are used to resolve the delivery method with correct name/id/price without triggering network calls.\n  - Update existing tests to use get_delivery_method_info() and get_all_shipping_methods() instead of properties and to assert undiscounted_base_shipping_price_amount updates where applicable (e.g., during assignment/removal and when reusing the same method).\n  - Update tests in webhook plugin area to query a single checkout by ID rather than the connection where necessary and keep assertions for shipping method lists.\n\n- Documentation\n  - Update CHANGELOG to state that queries checkouts, checkoutLines, and me.checkouts no longer trigger external shipping method fetches (SHIPPING_LIST_METHODS_FOR_CHECKOUT) or exclusion filtering (CHECKOUT_FILTER_SHIPPING_METHODS).\n\nAcceptance criteria:\n- Bulk checkout queries never trigger synchronous shipping webhooks or external shipping method plugins; only built-in shipping methods are returned.\n- Delivery method resolution for an external shipping method uses the denormalized name and base price on checkout without external calls when allow_sync_webhooks is False.\n- New get_all_shipping_methods() and get_delivery_method_info() methods are used consistently throughout the codebase and respect allow_sync_webhooks.\n- Denormalized fields (shipping_method_name and undiscounted_base_shipping_price_amount) are updated when assigning shipping methods or when delivery method data is retrieved, and are cleared when switching to collection point or removing delivery method.\n- All updated tests pass and new tests demonstrate the no-webhook behavior.",
      "prompt": "Implement a change to prevent external shipping webhooks and external shipping method lookups from being triggered during bulk checkout queries, while still returning correct shipping data.\n\nAdd a flag on the checkout info context that allows shipping sync webhooks to be skipped. Update the shipping method retrieval and delivery method resolution to rely only on built‑in methods when this flag is disabled and to use denormalized shipping method fields on the checkout for the selected external method. Cache built‑in and external methods separately and clear caches when shipping‑related fields change.\n\nPropagate the flag from GraphQL checkout resolvers (for checkouts connections and related line fields) and update existing resolvers and mutations to use method-based accessors for shipping methods and delivery method info. Ensure checkout utilities update or clear the denormalized shipping method name and base shipping price when assigning/removing delivery methods. Adjust the calculations to stop writing shipping base price there and only update line undiscounted unit prices.\n\nFinally, add tests to confirm that bulk checkout queries do not trigger synchronous shipping webhooks, that only built‑in shipping methods are returned, and that the denormalized external shipping method data is used without network calls when the flag is disabled.",
      "supplementalFiles": [
        "saleor/shipping/interface.py",
        "saleor/plugins/manager.py",
        "saleor/webhook/transport/shipping.py",
        "saleor/checkout/models.py",
        "saleor/core/prices.py",
        "saleor/graphql/context.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t9280e05 (parent)\n+++ CHANGELOG.md\t4da98aa (commit)\n@@ -22,8 +22,9 @@\n - Fix updating `metadata` and `privateMetadata` in `transactionUpdate` - #17261 by @IKarbowiak\n   - The provided data in the input field are merged with the existing one (previously the existing data was overridden by the new one).\n - Fixed `invoiceRequest` no longer throws an error, when only app with webhook `INVOICE_REQUESTED` is installed, without invoice plugin - #17355 by @witoszekdev\n - Queries: `checkouts`, `checkoutLines`, and `me.checkouts` will no longer trigger external calls to calculate taxes: the `CHECKOUT_CALCULATE_TAXES` webhooks and plugins (including AvataxPlugin) - #17268 by @korycins\n+- Queries `checkouts`, `checkoutLines`, and `me.checkouts` will no longer trigger external calls to fetch shipping methods (`SHIPPING_LIST_METHODS_FOR_CHECKOUT`) or to filter the available shipping methods (`CHECKOUT_FILTER_SHIPPING_METHODS`) - #17387 by @korycins\n \n ### GraphQL API\n \n - Add `CheckoutCustomerNoteUpdate` mutation - #16315 by @pitkes22\n"
        },
        {
          "path": "saleor/checkout/actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/actions.py\n===================================================================\n--- saleor/checkout/actions.py\t9280e05 (parent)\n+++ saleor/checkout/actions.py\t4da98aa (commit)\n@@ -83,9 +83,9 @@\n     lines: list[\"CheckoutLineInfo\"],\n     webhook_event_map: dict[str, set[\"Webhook\"]],\n     address: Optional[\"Address\"] = None,\n ):\n-    _ = checkout_info.all_shipping_methods\n+    _ = checkout_info.get_all_shipping_methods()\n \n     # + timedelta(seconds=10) to confirm that triggered webhooks will still have\n     # valid prices. Triggered only when we have active sync tax webhook.\n     if webhook_event_map.get(\n"
        },
        {
          "path": "saleor/checkout/base_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/base_calculations.py\n===================================================================\n--- saleor/checkout/base_calculations.py\t9280e05 (parent)\n+++ saleor/checkout/base_calculations.py\t4da98aa (commit)\n@@ -117,9 +117,9 @@\n ) -> Money:\n     \"\"\"Calculate base (untaxed) undiscounted price for any kind of delivery method.\"\"\"\n     from .fetch import ShippingMethodInfo\n \n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n     currency = checkout_info.checkout.currency\n \n     if not isinstance(delivery_method_info, ShippingMethodInfo):\n         return zero_money(currency)\n"
        },
        {
          "path": "saleor/checkout/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/calculations.py\n===================================================================\n--- saleor/checkout/calculations.py\t9280e05 (parent)\n+++ saleor/checkout/calculations.py\t4da98aa (commit)\n@@ -31,9 +31,9 @@\n     get_tax_calculation_strategy_for_checkout,\n     normalize_tax_rate_for_db,\n     validate_tax_data,\n )\n-from .fetch import ShippingMethodInfo, find_checkout_line_info\n+from .fetch import find_checkout_line_info\n from .models import Checkout\n from .payment_utils import update_checkout_payment_statuses\n \n if TYPE_CHECKING:\n@@ -301,24 +301,9 @@\n     total_price = undiscounted_unit_price * checkout_line_info.line.quantity\n     return quantize_price(total_price, total_price.currency)\n \n \n-def update_undiscounted_prices(\n-    checkout_info: \"CheckoutInfo\", lines: Iterable[\"CheckoutLineInfo\"]\n-):\n-    delivery_method_info = checkout_info.delivery_method_info\n-    if isinstance(delivery_method_info, ShippingMethodInfo):\n-        shipping_method_data = delivery_method_info.delivery_method\n-        checkout_info.checkout.undiscounted_base_shipping_price_amount = (\n-            shipping_method_data.price.amount\n-        )\n-    else:\n-        checkout_info.checkout.undiscounted_base_shipping_price_amount = Decimal(0)\n-\n-    _update_undiscounted_unit_price_for_lines(lines)\n-\n-\n-def _update_undiscounted_unit_price_for_lines(lines: Iterable[\"CheckoutLineInfo\"]):\n+def update_undiscounted_unit_price_for_lines(lines: Iterable[\"CheckoutLineInfo\"]):\n     \"\"\"Update line undiscounted unit price amount.\n \n     Undiscounted unit price stores the denormalized price of the variant.\n     \"\"\"\n@@ -394,9 +379,9 @@\n         checkout_info, lines, database_connection_name\n     )\n \n     lines = cast(list, lines)\n-    update_undiscounted_prices(checkout_info, lines)\n+    update_undiscounted_unit_price_for_lines(lines)\n     update_prior_unit_price_for_lines(lines)\n \n     create_or_update_discount_objects_from_promotion_for_checkout(\n         checkout_info, lines, database_connection_name\n"
        },
        {
          "path": "saleor/checkout/checkout_cleaner.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/checkout_cleaner.py\n===================================================================\n--- saleor/checkout/checkout_cleaner.py\t9280e05 (parent)\n+++ saleor/checkout/checkout_cleaner.py\t4da98aa (commit)\n@@ -23,13 +23,15 @@\n \n def clean_checkout_shipping(\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n-    error_code: type[CheckoutErrorCode]\n-    | type[PaymentErrorCode]\n-    | type[OrderCreateFromCheckoutErrorCode],\n+    error_code: (\n+        type[CheckoutErrorCode]\n+        | type[PaymentErrorCode]\n+        | type[OrderCreateFromCheckoutErrorCode]\n+    ),\n ):\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     if is_shipping_required(lines):\n         if not delivery_method_info.delivery_method:\n             raise ValidationError(\n@@ -62,11 +64,13 @@\n \n \n def clean_billing_address(\n     checkout_info: \"CheckoutInfo\",\n-    error_code: type[CheckoutErrorCode]\n-    | type[PaymentErrorCode]\n-    | type[OrderCreateFromCheckoutErrorCode],\n+    error_code: (\n+        type[CheckoutErrorCode]\n+        | type[PaymentErrorCode]\n+        | type[OrderCreateFromCheckoutErrorCode]\n+    ),\n ):\n     if not checkout_info.billing_address:\n         raise ValidationError(\n             {\n"
        },
        {
          "path": "saleor/checkout/complete_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/complete_checkout.py\n===================================================================\n--- saleor/checkout/complete_checkout.py\t9280e05 (parent)\n+++ saleor/checkout/complete_checkout.py\t4da98aa (commit)\n@@ -177,9 +177,9 @@\n     manager: \"PluginsManager\",\n     lines: list[\"CheckoutLineInfo\"],\n ) -> dict[str, Any]:\n     \"\"\"Fetch, process and return shipping data from checkout.\"\"\"\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n     shipping_address = delivery_method_info.shipping_address\n \n     if (\n         delivery_method_info.store_as_customer_address\n@@ -386,9 +386,9 @@\n         quantity=quantity,\n         is_digital=is_digital,\n         variant=variant,\n         digital_content=variant.digital_content if is_digital and variant else None,\n-        warehouse_pk=checkout_info.delivery_method_info.warehouse_pk,\n+        warehouse_pk=checkout_info.get_delivery_method_info().warehouse_pk,\n         line_discounts=line_discounts,\n     )\n \n     return line_info\n@@ -468,17 +468,17 @@\n         for variant_translation in variants_translation\n     }\n \n     additional_warehouse_lookup = (\n-        checkout_info.delivery_method_info.get_warehouse_filter_lookup()\n+        checkout_info.get_delivery_method_info().get_warehouse_filter_lookup()\n     )\n     check_stock_and_preorder_quantity_bulk(\n         variants,\n         country_code,\n         quantities,\n         checkout_info.channel.slug,\n         global_quantity_limit=None,\n-        delivery_method_info=checkout_info.delivery_method_info,\n+        delivery_method_info=checkout_info.get_delivery_method_info(),\n         additional_filter_lookup=additional_warehouse_lookup,\n         existing_lines=lines,\n         replace=True,\n         check_reservations=True,\n@@ -687,16 +687,16 @@\n     OrderLineDiscount.objects.bulk_create(order_line_discounts)\n \n     country_code = checkout_info.get_country()\n     additional_warehouse_lookup = (\n-        checkout_info.delivery_method_info.get_warehouse_filter_lookup()\n+        checkout_info.get_delivery_method_info().get_warehouse_filter_lookup()\n     )\n     allocate_stocks(\n         order_lines_info,\n         country_code,\n         checkout_info.channel,\n         manager,\n-        checkout_info.delivery_method_info.warehouse_pk,\n+        checkout_info.get_delivery_method_info().warehouse_pk,\n         additional_warehouse_lookup,\n         check_reservations=True,\n         checkout_lines=[line.line for line in checkout_lines],\n     )\n@@ -1138,16 +1138,16 @@\n     reservation_enabled: bool,\n ):\n     country_code = checkout_info.get_country()\n     additional_warehouse_lookup = (\n-        checkout_info.delivery_method_info.get_warehouse_filter_lookup()\n+        checkout_info.get_delivery_method_info().get_warehouse_filter_lookup()\n     )\n     allocate_stocks(\n         order_lines_info,\n         country_code,\n         checkout_info.channel,\n         manager,\n-        checkout_info.delivery_method_info.warehouse_pk,\n+        checkout_info.get_delivery_method_info().warehouse_pk,\n         additional_warehouse_lookup,\n         check_reservations=True,\n         checkout_lines=[line.line for line in checkout_lines],\n     )\n"
        },
        {
          "path": "saleor/checkout/fetch.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/fetch.py\n===================================================================\n--- saleor/checkout/fetch.py\t9280e05 (parent)\n+++ saleor/checkout/fetch.py\t4da98aa (commit)\n@@ -116,25 +116,62 @@\n     voucher_code: Optional[\"VoucherCode\"] = None\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME\n     pregenerated_payloads_for_excluded_shipping_method: dict | None = None\n \n-    @cached_property\n-    def all_shipping_methods(self) -> list[\"ShippingMethodData\"]:\n-        all_methods = get_all_shipping_methods_list(\n-            self,\n-            self.shipping_address,\n-            self.lines,\n-            self.shipping_channel_listings,\n-            self.manager,\n-            self.database_connection_name,\n-        )\n-        # Filter shipping methods using sync webhooks\n-        excluded_methods = self.manager.excluded_shipping_methods_for_checkout(\n-            self.checkout,\n-            self.channel,\n-            all_methods,\n-            self.pregenerated_payloads_for_excluded_shipping_method,\n-        )\n+    allow_sync_webhooks: bool = True\n+    _cached_built_in_shipping_methods: list[ShippingMethodData] | None = None\n+    _cached_external_shipping_methods: list[ShippingMethodData] | None = None\n+\n+    def get_all_shipping_methods(\n+        self,\n+    ) -> list[\"ShippingMethodData\"]:\n+        \"\"\"Return list of all available shipping methods.\n+\n+        If self.allow_sync_webhooks is set to False, any external calls will be skipped.\n+        If self.allow_sync_webhooks is set to True, the external calls like: external\n+        shipping methods or exclude shipping methods will be called.\n+\n+        The fetched values are stored in self object to remove any additional\n+        external/DB calls.\n+        \"\"\"\n+        if (\n+            self._cached_external_shipping_methods is not None\n+            and self._cached_built_in_shipping_methods is not None\n+        ):\n+            return (\n+                self._cached_built_in_shipping_methods\n+                + self._cached_external_shipping_methods\n+            )\n+\n+        if (\n+            not self.allow_sync_webhooks\n+            and self._cached_built_in_shipping_methods is not None\n+        ):\n+            return self._cached_built_in_shipping_methods\n+\n+        if self._cached_built_in_shipping_methods is None:\n+            self._cached_built_in_shipping_methods = (\n+                get_available_built_in_shipping_methods_for_checkout_info(self)\n+            )\n+\n+        if not self.allow_sync_webhooks:\n+            excluded_methods = []\n+            all_methods = self._cached_built_in_shipping_methods\n+        else:\n+            self._cached_external_shipping_methods = (\n+                get_external_shipping_methods_for_checkout_info(self)\n+            )\n+            all_methods = (\n+                self._cached_built_in_shipping_methods\n+                + self._cached_external_shipping_methods\n+            )\n+            # Filter shipping methods using sync webhooks\n+            excluded_methods = self.manager.excluded_shipping_methods_for_checkout(\n+                self.checkout,\n+                self.channel,\n+                all_methods,\n+                self.pregenerated_payloads_for_excluded_shipping_method,\n+            )\n         initialize_shipping_method_active_status(all_methods, excluded_methods)\n         return all_methods\n \n     @cached_property\n@@ -146,10 +183,36 @@\n                 self.lines, self.channel.id, quantity_check=False\n             )\n         )\n \n-    @property\n-    def delivery_method_info(self) -> \"DeliveryMethodBase\":\n+    def _update_denormalized_shipping_method_fields(\n+        self, delivery_method: ShippingMethodData | Warehouse\n+    ):\n+        checkout = self.checkout\n+        fields_to_update = []\n+        if isinstance(delivery_method, ShippingMethodData):\n+            new_shipping_method_name = delivery_method.name\n+            new_shipping_price = delivery_method.price\n+        else:\n+            new_shipping_method_name = None\n+            new_shipping_price = zero_money(checkout.currency)\n+\n+        if checkout.shipping_method_name != new_shipping_method_name:\n+            checkout.shipping_method_name = new_shipping_method_name\n+            fields_to_update.append(\"shipping_method_name\")\n+        current_shipping_price = quantize_price(\n+            checkout.undiscounted_base_shipping_price, checkout.currency\n+        )\n+        new_shipping_price = quantize_price(new_shipping_price, checkout.currency)\n+        if current_shipping_price != new_shipping_price:\n+            checkout.undiscounted_base_shipping_price_amount = new_shipping_price.amount\n+            fields_to_update.append(\"undiscounted_base_shipping_price_amount\")\n+\n+        if fields_to_update:\n+            with allow_writer():\n+                checkout.save(update_fields=fields_to_update)\n+\n+    def get_delivery_method_info(self) -> \"DeliveryMethodBase\":\n         from ..webhook.transport.shipping import convert_to_app_id_with_identifier\n         from .utils import get_external_shipping_id\n \n         delivery_method: ShippingMethodData | Warehouse | None = None\n@@ -167,28 +230,40 @@\n                     self.shipping_method, shipping_channel_listing\n                 )\n \n         elif external_shipping_method_id := get_external_shipping_id(self.checkout):\n-            methods = {method.id: method for method in self.all_shipping_methods}\n-            if method := methods.get(external_shipping_method_id):\n-                delivery_method = method\n+            if self.allow_sync_webhooks:\n+                methods = {\n+                    method.id: method for method in self.get_all_shipping_methods()\n+                }\n+                if method := methods.get(external_shipping_method_id):\n+                    delivery_method = method\n+                else:\n+                    new_shipping_method_id = convert_to_app_id_with_identifier(\n+                        external_shipping_method_id\n+                    )\n+                    if new_shipping_method_id is None:\n+                        delivery_method = None\n+                    else:\n+                        delivery_method = methods.get(new_shipping_method_id)\n             else:\n-                new_shipping_method_id = convert_to_app_id_with_identifier(\n-                    external_shipping_method_id\n+                delivery_method = ShippingMethodData(\n+                    id=get_external_shipping_id(self.checkout),\n+                    name=self.checkout.shipping_method_name or \"\",\n+                    price=self.checkout.undiscounted_base_shipping_price,\n                 )\n-                if new_shipping_method_id is None:\n-                    delivery_method = None\n-                else:\n-                    delivery_method = methods.get(new_shipping_method_id)\n \n         else:\n             delivery_method = self.collection_point\n \n+        if isinstance(delivery_method, ShippingMethodData):\n+            self._update_denormalized_shipping_method_fields(delivery_method)\n+\n         return get_delivery_method_info(delivery_method, self.shipping_address)\n \n     @property\n     def valid_shipping_methods(self) -> list[\"ShippingMethodData\"]:\n-        return [method for method in self.all_shipping_methods if method.active]\n+        return [method for method in self.get_all_shipping_methods() if method.active]\n \n     @property\n     def valid_delivery_methods(\n         self,\n@@ -543,19 +618,15 @@\n     )\n     return checkout_info\n \n \n-def get_valid_internal_shipping_method_list_for_checkout_info(\n+def get_available_built_in_shipping_methods_for_checkout_info(\n     checkout_info: \"CheckoutInfo\",\n-    shipping_address: Optional[\"Address\"],\n-    lines: list[CheckoutLineInfo],\n-    shipping_channel_listings: Iterable[ShippingMethodChannelListing],\n-    database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n ) -> list[\"ShippingMethodData\"]:\n     from . import base_calculations\n-    from .utils import get_valid_internal_shipping_methods_for_checkout\n+    from .utils import get_valid_internal_shipping_methods_for_checkout_info\n \n-    country_code = shipping_address.country.code if shipping_address else None\n+    lines = checkout_info.lines\n \n     subtotal = base_calculations.base_checkout_subtotal(\n         lines,\n         checkout_info.channel,\n@@ -576,40 +647,34 @@\n \n     if not is_shipping_voucher and not is_voucher_for_specific_product:\n         subtotal -= checkout_info.checkout.discount\n \n-    valid_shipping_methods = get_valid_internal_shipping_methods_for_checkout(\n+    valid_shipping_methods = get_valid_internal_shipping_methods_for_checkout_info(\n         checkout_info,\n-        lines,\n         subtotal,\n-        shipping_channel_listings,\n-        country_code=country_code,\n-        database_connection_name=database_connection_name,\n     )\n \n     return valid_shipping_methods\n \n \n+def get_external_shipping_methods_for_checkout_info(\n+    checkout_info,\n+) -> list[ShippingMethodData]:\n+    manager = checkout_info.manager\n+    return manager.list_shipping_methods_for_checkout(\n+        checkout=checkout_info.checkout, channel_slug=checkout_info.channel.slug\n+    )\n+\n+\n def get_all_shipping_methods_list(\n     checkout_info,\n-    shipping_address,\n-    lines,\n-    shipping_channel_listings,\n-    manager,\n-    database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n ):\n     return list(\n         itertools.chain(\n-            get_valid_internal_shipping_method_list_for_checkout_info(\n+            get_available_built_in_shipping_methods_for_checkout_info(\n                 checkout_info,\n-                shipping_address,\n-                lines,\n-                shipping_channel_listings,\n-                database_connection_name=database_connection_name,\n             ),\n-            manager.list_shipping_methods_for_checkout(\n-                checkout=checkout_info.checkout, channel_slug=checkout_info.channel.slug\n-            ),\n+            get_external_shipping_methods_for_checkout_info(checkout_info),\n         )\n     )\n \n \n@@ -631,9 +696,10 @@\n \n     # Clear cached properties if they were already calculated, so they can be\n     # recalculated.\n     try:\n-        del checkout_info.all_shipping_methods\n+        del checkout_info._cached_built_in_shipping_methods\n+        del checkout_info._cached_external_shipping_methods\n     except AttributeError:\n         pass\n \n     try:\n"
        },
        {
          "path": "saleor/checkout/tests/test_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_checkout.py\n===================================================================\n--- saleor/checkout/tests/test_checkout.py\t9280e05 (parent)\n+++ saleor/checkout/tests/test_checkout.py\t4da98aa (commit)\n@@ -30,8 +30,9 @@\n from ...plugins.manager import get_plugins_manager\n from ...product.models import VariantChannelListingPromotionRule\n from ...shipping.interface import ShippingMethodData\n from ...shipping.models import ShippingZone\n+from ...webhook.event_types import WebhookEventSyncType\n from .. import base_calculations, calculations\n from ..fetch import (\n     CheckoutInfo,\n     CheckoutLineInfo,\n@@ -64,24 +65,24 @@\n     checkout.save()\n     manager = get_plugins_manager(allow_replica=False)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n     # no shipping method assigned\n     assert not delivery_method_info.is_valid_delivery_method()\n     shipping_method = shipping_zone.shipping_methods.first()\n     checkout.shipping_method = shipping_method\n     checkout.save()\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert delivery_method_info.is_valid_delivery_method()\n \n     zone = ShippingZone.objects.create(name=\"DE\", countries=[\"DE\"])\n     shipping_method.shipping_zone = zone\n     shipping_method.save()\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert not delivery_method_info.is_method_in_valid_methods(checkout_info)\n \n \n@@ -116,9 +117,9 @@\n \n     manager = get_plugins_manager(allow_replica=False)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert delivery_method_info.is_method_in_valid_methods(checkout_info)\n \n \n@@ -161,16 +162,144 @@\n     lines, _ = fetch_checkout_lines(checkout)\n \n     # when\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     # then\n     assert delivery_method_info.delivery_method.metadata == metadata\n     assert delivery_method_info.delivery_method.description == description\n     assert delivery_method_info.is_method_in_valid_methods(checkout_info)\n \n \n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_delivery_method_external_method_with_not_allowed_webhooks(\n+    mocked_request, checkout_with_item, shipping_app, settings\n+):\n+    # given\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    shipping_method_id = \"abcd\"\n+    shipping_method_name = \"Default shipping\"\n+    graphql_shipping_method_id = graphene.Node.to_global_id(\n+        \"app\", f\"{shipping_app.id}:{shipping_method_id}\"\n+    )\n+\n+    checkout = checkout_with_item\n+    shipping_price = Money(Decimal(10), currency=checkout.currency)\n+\n+    checkout.external_shipping_method_id = graphql_shipping_method_id\n+    checkout.undiscounted_base_shipping_price = shipping_price\n+    checkout.shipping_method_name = shipping_method_name\n+    checkout.save()\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    checkout_info.allow_sync_webhooks = False\n+\n+    # when\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n+\n+    # then\n+    delivery_method = delivery_method_info.delivery_method\n+    assert isinstance(delivery_method, ShippingMethodData)\n+    assert delivery_method.name == shipping_method_name\n+    assert delivery_method.price == shipping_price\n+    assert delivery_method.id == graphql_shipping_method_id\n+    mocked_request.assert_not_called()\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_delivery_method_exclude_shipping_methods_with_not_allowed_webhooks(\n+    mocked_request, checkout_with_item, shipping_app, settings\n+):\n+    # given\n+    webhook = shipping_app.webhooks.get()\n+    webhook.events.create(\n+        event_type=WebhookEventSyncType.CHECKOUT_FILTER_SHIPPING_METHODS\n+    )\n+\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    shipping_method_id = \"abcd\"\n+    shipping_method_name = \"Default shipping\"\n+    graphql_shipping_method_id = graphene.Node.to_global_id(\n+        \"app\", f\"{shipping_app.id}:{shipping_method_id}\"\n+    )\n+\n+    checkout = checkout_with_item\n+    shipping_price = Money(Decimal(10), currency=checkout.currency)\n+\n+    checkout.external_shipping_method_id = graphql_shipping_method_id\n+    checkout.undiscounted_base_shipping_price = shipping_price\n+    checkout.shipping_method_name = shipping_method_name\n+    checkout.save()\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    checkout_info.allow_sync_webhooks = False\n+\n+    # when\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n+\n+    # then\n+    delivery_method = delivery_method_info.delivery_method\n+    assert isinstance(delivery_method, ShippingMethodData)\n+    assert delivery_method.name == shipping_method_name\n+    assert delivery_method.price == shipping_price\n+    assert delivery_method.id == graphql_shipping_method_id\n+    mocked_request.assert_not_called()\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_get_all_shipping_methods_with_external_methods_and_not_allowed_webhooks(\n+    mocked_request, checkout_with_shipping_method, shipping_app, settings\n+):\n+    # given\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+\n+    checkout = checkout_with_shipping_method\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    checkout_info.allow_sync_webhooks = False\n+\n+    # when\n+    shipping_methods = checkout_info.get_all_shipping_methods()\n+\n+    # then\n+    assert all(not shipping_method.is_external for shipping_method in shipping_methods)\n+    mocked_request.assert_not_called()\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_get_all_shipping_methods_with_exclude_shipping_methods_with_not_allowed_webhooks(\n+    mocked_request, checkout_with_shipping_method, shipping_app, settings\n+):\n+    # given\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+\n+    webhook = shipping_app.webhooks.get()\n+    webhook.events.create(\n+        event_type=WebhookEventSyncType.CHECKOUT_FILTER_SHIPPING_METHODS\n+    )\n+\n+    checkout = checkout_with_shipping_method\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    checkout_info.allow_sync_webhooks = False\n+\n+    # when\n+    shipping_methods = checkout_info.get_all_shipping_methods()\n+\n+    # then\n+    assert all(shipping_method.active for shipping_method in shipping_methods)\n+    mocked_request.assert_not_called()\n+\n+\n @pytest.mark.parametrize(\n     \"invalid_metadata\",\n     [\n         (\"invalid\", \"format\", \"tuple\"),\n@@ -223,9 +352,9 @@\n     lines, _ = fetch_checkout_lines(checkout)\n \n     # when\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     # then\n     assert delivery_method_info.delivery_method.metadata == {}\n     assert delivery_method_info.delivery_method.description == description\n@@ -266,9 +395,9 @@\n \n     manager = get_plugins_manager(allow_replica=False)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert delivery_method_info.is_method_in_valid_methods(checkout_info)\n \n \n@@ -306,9 +435,9 @@\n \n     manager = get_plugins_manager(allow_replica=False)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert delivery_method_info.is_method_in_valid_methods(checkout_info)\n \n \n@@ -339,9 +468,9 @@\n \n     manager = get_plugins_manager(allow_replica=False)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert delivery_method_info.is_method_in_valid_methods(checkout_info) is False\n \n \n@@ -352,9 +481,9 @@\n     checkout_info = fetch_checkout_info(checkout, [], manager)\n     clear_delivery_method(checkout_info)\n     checkout.refresh_from_db()\n     assert not checkout.shipping_method\n-    assert isinstance(checkout_info.delivery_method_info, DeliveryMethodBase)\n+    assert isinstance(checkout_info.get_delivery_method_info(), DeliveryMethodBase)\n \n \n @patch.object(CheckoutMetadata, \"save\")\n def test_clear_delivery_method_do_not_update_metadata_when_no_external_shipping(\n@@ -372,9 +501,9 @@\n     # then\n     checkout.refresh_from_db()\n     assert not mocked_metadata_save.called\n     assert not checkout.shipping_method\n-    assert isinstance(checkout_info.delivery_method_info, DeliveryMethodBase)\n+    assert isinstance(checkout_info.get_delivery_method_info(), DeliveryMethodBase)\n \n \n @patch.object(CheckoutMetadata, \"save\")\n def test_clear_delivery_method_update_metadata_when_external_shipping(\n@@ -395,9 +524,9 @@\n     checkout.refresh_from_db()\n     checkout.metadata_storage.refresh_from_db()\n     assert mocked_metadata_save.called\n     assert not checkout.shipping_method\n-    assert isinstance(checkout_info.delivery_method_info, DeliveryMethodBase)\n+    assert isinstance(checkout_info.get_delivery_method_info(), DeliveryMethodBase)\n     assert (\n         PRIVATE_META_APP_SHIPPING_ID not in checkout.metadata_storage.private_metadata\n     )\n \n@@ -1959,9 +2088,9 @@\n         manager=manager,\n         shipping_channel_listings=shipping_method.channel_listings.all(),\n     )\n \n-    all_shipping_methods = checkout_info.all_shipping_methods\n+    all_shipping_methods = checkout_info.get_all_shipping_methods()\n     assert all_shipping_methods == []\n \n     # when\n     shipping_updated_fields = change_shipping_address_in_checkout(\n@@ -1978,9 +2107,9 @@\n     # then\n     assert checkout.shipping_address == address\n     assert checkout.billing_address == address\n     assert checkout_info.shipping_address == address\n-    assert checkout_info.all_shipping_methods\n+    assert checkout_info.get_all_shipping_methods()\n \n \n def test_add_voucher_to_checkout(checkout_with_item, voucher):\n     assert checkout_with_item.voucher_code is None\n@@ -2224,9 +2353,9 @@\n     checkout = checkout_with_item\n     manager = get_plugins_manager(allow_replica=False)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    delivery_method_info = checkout_info.delivery_method_info\n+    delivery_method_info = checkout_info.get_delivery_method_info()\n \n     assert isinstance(delivery_method_info, DeliveryMethodBase)\n     assert not delivery_method_info.is_valid_delivery_method()\n     assert not delivery_method_info.is_local_collection_point\n"
        },
        {
          "path": "saleor/checkout/tests/test_delivery_assignent_to_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_delivery_assignent_to_checkout.py\n===================================================================\n--- saleor/checkout/tests/test_delivery_assignent_to_checkout.py\t9280e05 (parent)\n+++ saleor/checkout/tests/test_delivery_assignent_to_checkout.py\t4da98aa (commit)\n@@ -231,9 +231,13 @@\n def test_assign_built_in_shipping_to_checkout_without_delivery_method(\n     checkout, shipping_method\n ):\n     # given\n-    expected_updated_fields = {\"shipping_method_id\", \"shipping_method_name\"}\n+    expected_updated_fields = {\n+        \"shipping_method_id\",\n+        \"shipping_method_name\",\n+        \"undiscounted_base_shipping_price_amount\",\n+    }\n     shipping_method_data = ShippingMethodData(\n         id=str(shipping_method.id),\n         name=shipping_method.name,\n         price=Money(10, checkout.currency),\n@@ -258,8 +262,9 @@\n         \"shipping_method_id\",\n         \"shipping_method_name\",\n         \"collection_point_id\",\n         \"shipping_address_id\",\n+        \"undiscounted_base_shipping_price_amount\",\n     }\n     shipping_method_data = ShippingMethodData(\n         id=str(shipping_method.id),\n         name=shipping_method.name,\n@@ -286,8 +291,9 @@\n     expected_updated_fields = {\n         \"shipping_method_id\",\n         \"shipping_method_name\",\n         \"external_shipping_method_id\",\n+        \"undiscounted_base_shipping_price_amount\",\n     }\n     shipping_method_data = ShippingMethodData(\n         id=str(shipping_method.id),\n         name=shipping_method.name,\n@@ -319,8 +325,9 @@\n \n     expected_updated_fields = {\n         \"shipping_method_id\",\n         \"shipping_method_name\",\n+        \"undiscounted_base_shipping_price_amount\",\n     }\n \n     # when\n     fields_to_update = assign_built_in_shipping_to_checkout(\n@@ -336,15 +343,17 @@\n def test_assign_built_in_shipping_to_checkout_with_the_same_shipping_method(\n     checkout, shipping_method\n ):\n     # given\n+    shipping_price_amount = Decimal(10)\n     checkout.shipping_method = shipping_method\n     checkout.shipping_method_name = shipping_method.name\n+    checkout.undiscounted_base_shipping_price_amount = shipping_price_amount\n \n     shipping_method_data = ShippingMethodData(\n         id=str(shipping_method.id),\n         name=shipping_method.name,\n-        price=Money(10, checkout.currency),\n+        price=Money(shipping_price_amount, checkout.currency),\n     )\n \n     # when\n     fields_to_update = assign_built_in_shipping_to_checkout(\n"
        },
        {
          "path": "saleor/checkout/utils.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/utils.py\n===================================================================\n--- saleor/checkout/utils.py\t9280e05 (parent)\n+++ saleor/checkout/utils.py\t4da98aa (commit)\n@@ -16,8 +16,9 @@\n from ..account.models import User\n from ..checkout.fetch import update_delivery_method_lists_for_checkout_info\n from ..core.db.connection import allow_writer\n from ..core.exceptions import NonExistingCheckoutLines, ProductNotPublished\n+from ..core.prices import quantize_price\n from ..core.taxes import zero_taxed_money\n from ..core.utils.promo_code import (\n     InvalidPromoCode,\n     promo_code_is_gift_card,\n@@ -528,9 +529,9 @@\n     \"\"\"Calculate discount value for a voucher of shipping type.\"\"\"\n     if not is_shipping_required(lines):\n         msg = \"Your order does not require shipping.\"\n         raise NotApplicable(msg)\n-    shipping_method = checkout_info.delivery_method_info.delivery_method\n+    shipping_method = checkout_info.get_delivery_method_info().delivery_method\n     if not shipping_method:\n         msg = \"Please select a delivery method first.\"\n         raise NotApplicable(msg)\n \n@@ -935,34 +936,37 @@\n         ]\n     )\n \n \n-def get_valid_internal_shipping_methods_for_checkout(\n+def get_valid_internal_shipping_methods_for_checkout_info(\n     checkout_info: \"CheckoutInfo\",\n-    lines: list[\"CheckoutLineInfo\"],\n     subtotal: \"Money\",\n-    shipping_channel_listings: Iterable[\"ShippingMethodChannelListing\"],\n-    country_code: str | None = None,\n-    database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n ) -> list[ShippingMethodData]:\n-    if not is_shipping_required(lines):\n+    if not is_shipping_required(checkout_info.lines):\n         return []\n     if not checkout_info.shipping_address:\n         return []\n \n+    country_code = (\n+        checkout_info.shipping_address.country.code\n+        if checkout_info.shipping_address\n+        else None\n+    )\n+\n     shipping_methods = ShippingMethod.objects.using(\n-        database_connection_name\n+        checkout_info.database_connection_name\n     ).applicable_shipping_methods_for_instance(\n         checkout_info.checkout,\n         channel_id=checkout_info.checkout.channel_id,\n         price=subtotal,\n         shipping_address=checkout_info.shipping_address,\n         country_code=country_code,\n-        lines=lines,\n+        lines=checkout_info.lines,\n     )\n \n     channel_listings_map = {\n-        listing.shipping_method_id: listing for listing in shipping_channel_listings\n+        listing.shipping_method_id: listing\n+        for listing in checkout_info.shipping_channel_listings\n     }\n \n     internal_methods: list[ShippingMethodData] = []\n     for method in shipping_methods:\n@@ -1106,8 +1110,15 @@\n     if field_deleted:\n         metadata.save(update_fields=[\"private_metadata\"])\n \n \n+def _remove_undiscounted_base_shipping_price(checkout: Checkout):\n+    if checkout.undiscounted_base_shipping_price_amount:\n+        checkout.undiscounted_base_shipping_price_amount = Decimal(0)\n+        return [\"undiscounted_base_shipping_price_amount\"]\n+    return []\n+\n+\n def remove_external_shipping_from_checkout(\n     checkout: Checkout, save: bool = False\n ) -> list[str]:\n     fields_to_update = []\n@@ -1149,20 +1160,37 @@\n \n \n def remove_delivery_method_from_checkout(checkout: Checkout) -> list[str]:\n     fields_to_update = []\n+    fields_to_update += _remove_undiscounted_base_shipping_price(checkout)\n     fields_to_update += remove_built_in_shipping_from_checkout(checkout)\n     fields_to_update += remove_click_and_collect_from_checkout(checkout)\n     fields_to_update += remove_external_shipping_from_checkout(checkout)\n     return fields_to_update\n \n \n+def _assign_undiscounted_base_shipping_price_to_checkout(\n+    checkout, shipping_method_data: ShippingMethodData\n+):\n+    current_shipping_price = quantize_price(\n+        checkout.undiscounted_base_shipping_price, checkout.currency\n+    )\n+    new_shipping_price = quantize_price(shipping_method_data.price, checkout.currency)\n+    if current_shipping_price != new_shipping_price:\n+        checkout.undiscounted_base_shipping_price_amount = new_shipping_price.amount\n+        return [\"undiscounted_base_shipping_price_amount\"]\n+    return []\n+\n+\n def assign_external_shipping_to_checkout(\n     checkout: Checkout, external_shipping_method_data: ShippingMethodData\n ) -> list[str]:\n     fields_to_update = []\n     fields_to_update += remove_built_in_shipping_from_checkout(checkout)\n     fields_to_update += remove_click_and_collect_from_checkout(checkout)\n+    fields_to_update += _assign_undiscounted_base_shipping_price_to_checkout(\n+        checkout, external_shipping_method_data\n+    )\n \n     # make sure that we don't have obsolete data for shipping methods stored in\n     # private metadata\n     _remove_external_shipping_from_metadata(checkout=checkout)\n@@ -1182,8 +1210,11 @@\n ) -> list[str]:\n     fields_to_update = []\n     fields_to_update += remove_external_shipping_from_checkout(checkout)\n     fields_to_update += remove_click_and_collect_from_checkout(checkout)\n+    fields_to_update += _assign_undiscounted_base_shipping_price_to_checkout(\n+        checkout, shipping_method_data\n+    )\n \n     if checkout.shipping_method_id != int(shipping_method_data.id):\n         checkout.shipping_method_id = shipping_method_data.id\n         fields_to_update.append(\"shipping_method_id\")\n@@ -1196,8 +1227,9 @@\n def assign_collection_point_to_checkout(\n     checkout, collection_point: Warehouse\n ) -> list[str]:\n     fields_to_update = []\n+    fields_to_update += _remove_undiscounted_base_shipping_price(checkout)\n     fields_to_update += remove_external_shipping_from_checkout(checkout)\n     fields_to_update += remove_built_in_shipping_from_checkout(checkout)\n     if checkout.collection_point_id != collection_point.id:\n         checkout.collection_point_id = collection_point.id\n@@ -1281,9 +1313,9 @@\n \n def get_address_for_checkout_taxes(\n     checkout_info: \"CheckoutInfo\",\n ) -> Optional[\"Address\"]:\n-    shipping_address = checkout_info.delivery_method_info.shipping_address\n+    shipping_address = checkout_info.get_delivery_method_info().shipping_address\n     return shipping_address or checkout_info.billing_address\n \n \n def checkout_info_for_logs(\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_lines_add.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_lines_add.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_lines_add.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_lines_add.py\t4da98aa (commit)\n@@ -161,9 +161,9 @@\n             variants,\n             checkout_lines_data,\n             checkout.get_country(),\n             channel_slug,\n-            checkout_info.delivery_method_info,\n+            checkout_info.get_delivery_method_info(),\n             lines=lines,\n         )\n \n         variants_ids_to_validate = {\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_shipping_address_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\t4da98aa (commit)\n@@ -180,9 +180,9 @@\n                 info,\n                 lines,\n                 country,\n                 checkout_info.channel.slug,\n-                checkout_info.delivery_method_info,\n+                checkout_info.get_delivery_method_info(),\n             )\n \n         update_checkout_shipping_method_if_invalid(checkout_info, lines)\n \n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/utils.py\n===================================================================\n--- saleor/graphql/checkout/mutations/utils.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/mutations/utils.py\t4da98aa (commit)\n@@ -120,9 +120,9 @@\n         clear_delivery_method(checkout_info)\n \n     is_valid = clean_delivery_method(\n         checkout_info=checkout_info,\n-        method=checkout_info.delivery_method_info.delivery_method,\n+        method=checkout_info.get_delivery_method_info().delivery_method,\n     )\n \n     if not is_valid:\n         clear_delivery_method(checkout_info)\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py\t4da98aa (commit)\n@@ -3860,9 +3860,9 @@\n         manager=manager, checkout_info=checkout_info, lines=lines, address=address\n     )\n \n     assert not checkout_info.valid_pick_up_points\n-    assert not checkout_info.delivery_method_info.is_method_in_valid_methods(\n+    assert not checkout_info.get_delivery_method_info().is_method_in_valid_methods(\n         checkout_info\n     )\n \n     payment = payment_dummy\n@@ -4021,9 +4021,9 @@\n         manager=manager, checkout_info=checkout_info, lines=lines, address=address\n     )\n \n     assert not checkout_info.valid_pick_up_points\n-    assert not checkout_info.delivery_method_info.is_method_in_valid_methods(\n+    assert not checkout_info.get_delivery_method_info().is_method_in_valid_methods(\n         checkout_info\n     )\n \n     payment = payment_dummy\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\t4da98aa (commit)\n@@ -3838,9 +3838,9 @@\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     assert not checkout_info.valid_pick_up_points\n-    assert not checkout_info.delivery_method_info.is_method_in_valid_methods(\n+    assert not checkout_info.get_delivery_method_info().is_method_in_valid_methods(\n         checkout_info\n     )\n     # when\n     response = api_client.post_graphql(MUTATION_CHECKOUT_COMPLETE, variables)\n@@ -3978,9 +3978,9 @@\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     assert not checkout_info.valid_pick_up_points\n-    assert not checkout_info.delivery_method_info.is_method_in_valid_methods(\n+    assert not checkout_info.get_delivery_method_info().is_method_in_valid_methods(\n         checkout_info\n     )\n \n     # when\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_delivery_method_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_delivery_method_update.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_delivery_method_update.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_delivery_method_update.py\t4da98aa (commit)\n@@ -2012,8 +2012,9 @@\n     checkout = checkout_with_item\n     checkout.shipping_address = address\n     checkout.external_shipping_method_id = method_id\n     checkout.shipping_method_name = response_shipping_name\n+    checkout.undiscounted_base_shipping_price_amount = Decimal(response_shipping_price)\n     checkout.save()\n \n     # when\n     response = api_client.post_graphql(\n@@ -2214,10 +2215,12 @@\n     api_client,\n ):\n     # given\n     checkout = checkout_with_shipping_method\n-\n     shipping_method = checkout.shipping_method\n+    price = shipping_method.channel_listings.get().price\n+    checkout.undiscounted_base_shipping_price_amount = price.amount\n+    checkout.save()\n \n     # when\n     response = api_client.post_graphql(\n         MUTATION_UPDATE_DELIVERY_METHOD,\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_shipping_method_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_shipping_method_update.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_shipping_method_update.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_shipping_method_update.py\t4da98aa (commit)\n@@ -1044,8 +1044,9 @@\n     checkout = checkout_with_item\n     checkout.shipping_address = address\n     checkout.external_shipping_method_id = method_id\n     checkout.shipping_method_name = response_shipping_name\n+    checkout.undiscounted_base_shipping_price_amount = Decimal(response_shipping_price)\n     checkout.save()\n \n     # when\n     response = api_client.post_graphql(\n@@ -1285,8 +1286,11 @@\n     # given\n     checkout = checkout_with_shipping_method\n \n     shipping_method = checkout.shipping_method\n+    price = shipping_method.channel_listings.get().price\n+    checkout.undiscounted_base_shipping_price_amount = price.amount\n+    checkout.save()\n \n     # when\n     response = api_client.post_graphql(\n         MUTATION_UPDATE_SHIPPING_METHOD,\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py\t4da98aa (commit)\n@@ -2039,9 +2039,9 @@\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     assert not checkout_info.valid_pick_up_points\n-    assert not checkout_info.delivery_method_info.is_method_in_valid_methods(\n+    assert not checkout_info.get_delivery_method_info().is_method_in_valid_methods(\n         checkout_info\n     )\n \n     response = app_api_client.post_graphql(\n@@ -2169,9 +2169,9 @@\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     assert not checkout_info.valid_pick_up_points\n-    assert not checkout_info.delivery_method_info.is_method_in_valid_methods(\n+    assert not checkout_info.get_delivery_method_info().is_method_in_valid_methods(\n         checkout_info\n     )\n \n     response = app_api_client.post_graphql(\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkout.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkout.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/test_checkout.py\t4da98aa (commit)\n@@ -129,9 +129,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n     update_checkout_shipping_method_if_invalid(checkout_info, lines)\n \n     assert checkout.shipping_method is None\n-    assert checkout_info.delivery_method_info.delivery_method is None\n+    assert checkout_info.get_delivery_method_info().delivery_method is None\n \n     # Ensure the checkout's shipping method was saved\n     checkout.refresh_from_db(fields=[\"shipping_method\"])\n     assert checkout.shipping_method is None\n@@ -163,9 +163,9 @@\n     update_checkout_shipping_method_if_invalid(checkout_info, lines)\n \n     # then\n     assert checkout.shipping_method is None\n-    assert checkout_info.delivery_method_info.delivery_method is None\n+    assert checkout_info.get_delivery_method_info().delivery_method is None\n \n     # Ensure the checkout's shipping method was saved\n     checkout.refresh_from_db(fields=[\"shipping_method\"])\n     assert checkout.shipping_method is None\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkouts_query.py",
          "status": "added",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkouts_query.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkouts_query.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/tests/test_checkouts_query.py\t4da98aa (commit)\n@@ -0,0 +1,289 @@\n+from decimal import Decimal\n+from unittest.mock import patch\n+\n+from django.utils import timezone\n+\n+from ....shipping.models import ShippingMethod\n+from ....webhook.event_types import WebhookEventSyncType\n+from ...core.utils import to_global_id_or_none\n+from ...tests.utils import get_graphql_content\n+\n+CHECKOUTS_QUERY = \"\"\"\n+query CheckoutsQuery {\n+  checkouts(first: 1) {\n+    edges {\n+      node {\n+        deliveryMethod {\n+          __typename\n+          ... on ShippingMethod {\n+            id\n+            name\n+            price {\n+              amount\n+            }\n+          }\n+        }\n+        shippingPrice {\n+          gross {\n+            amount\n+          }\n+        }\n+        totalPrice {\n+          gross {\n+            amount\n+          }\n+        }\n+        subtotalPrice {\n+          gross {\n+            amount\n+          }\n+        }\n+        lines {\n+          totalPrice {\n+            gross {\n+              amount\n+            }\n+          }\n+          unitPrice {\n+            gross {\n+              amount\n+            }\n+          }\n+        }\n+        shippingMethods {\n+          id\n+          name\n+          active\n+        }\n+        availableShippingMethods {\n+          id\n+          name\n+          active\n+        }\n+      }\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_query_checkouts_do_not_trigger_external_shipping_webhook_with_flat_rates(\n+    mocked_request,\n+    staff_api_client,\n+    permission_manage_checkouts,\n+    checkout_with_delivery_method_for_external_shipping,\n+    settings,\n+    tax_configuration_flat_rates,\n+    shipping_app,\n+):\n+    # given\n+    webhook = shipping_app.webhooks.get()\n+    assert (\n+        WebhookEventSyncType.SHIPPING_LIST_METHODS_FOR_CHECKOUT\n+        in webhook.events.all().values_list(\"event_type\", flat=True)\n+    )\n+\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    checkout = checkout_with_delivery_method_for_external_shipping\n+    checkout.price_expiration = timezone.now()\n+    checkout.undiscounted_base_shipping_price_amount = Decimal(\"100\")\n+    checkout.save()\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        CHECKOUTS_QUERY,\n+        permissions=[permission_manage_checkouts],\n+    )\n+\n+    # then\n+    data = get_graphql_content(response)[\"data\"][\"checkouts\"][\"edges\"]\n+    assert len(data) == 1\n+    checkout_data = data[0][\"node\"]\n+\n+    shipping_method = ShippingMethod.objects.get()\n+    assert len(checkout_data[\"shippingMethods\"]) == 1\n+    assert checkout_data[\"shippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    assert len(checkout_data[\"availableShippingMethods\"]) == 1\n+    assert checkout_data[\"availableShippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    delivery_method = checkout_data[\"deliveryMethod\"]\n+    assert delivery_method\n+    assert delivery_method[\"id\"] == checkout.external_shipping_method_id\n+    assert delivery_method[\"name\"] == checkout.shipping_method_name\n+    assert (\n+        delivery_method[\"price\"][\"amount\"]\n+        == checkout.undiscounted_base_shipping_price_amount\n+    )\n+    mocked_request.assert_not_called()\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_query_checkouts_do_not_trigger_external_shipping_webhook_with_tax_app(\n+    mocked_request,\n+    staff_api_client,\n+    permission_manage_checkouts,\n+    checkout_with_delivery_method_for_external_shipping,\n+    settings,\n+    tax_configuration_tax_app,\n+    shipping_app,\n+):\n+    # given\n+    webhook = shipping_app.webhooks.get()\n+    assert (\n+        WebhookEventSyncType.SHIPPING_LIST_METHODS_FOR_CHECKOUT\n+        in webhook.events.all().values_list(\"event_type\", flat=True)\n+    )\n+\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    checkout = checkout_with_delivery_method_for_external_shipping\n+    checkout.price_expiration = timezone.now()\n+    checkout.undiscounted_base_shipping_price_amount = Decimal(\"100\")\n+    checkout.save()\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        CHECKOUTS_QUERY,\n+        permissions=[permission_manage_checkouts],\n+    )\n+\n+    # then\n+    data = get_graphql_content(response)[\"data\"][\"checkouts\"][\"edges\"]\n+    assert len(data) == 1\n+    checkout_data = data[0][\"node\"]\n+\n+    shipping_method = ShippingMethod.objects.get()\n+    assert len(checkout_data[\"shippingMethods\"]) == 1\n+    assert checkout_data[\"shippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    assert len(checkout_data[\"availableShippingMethods\"]) == 1\n+    assert checkout_data[\"availableShippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    delivery_method = checkout_data[\"deliveryMethod\"]\n+    assert delivery_method\n+    assert delivery_method[\"id\"] == checkout.external_shipping_method_id\n+    assert delivery_method[\"name\"] == checkout.shipping_method_name\n+    assert (\n+        delivery_method[\"price\"][\"amount\"]\n+        == checkout.undiscounted_base_shipping_price_amount\n+    )\n+    mocked_request.assert_not_called()\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_query_checkouts_do_not_trigger_exclude_shipping_webhooks_with_flat_rates(\n+    mocked_request,\n+    staff_api_client,\n+    permission_manage_checkouts,\n+    checkout_with_delivery_method_for_external_shipping,\n+    settings,\n+    tax_configuration_flat_rates,\n+    shipping_app,\n+):\n+    # given\n+    webhook = shipping_app.webhooks.get()\n+    webhook.events.create(\n+        event_type=WebhookEventSyncType.CHECKOUT_FILTER_SHIPPING_METHODS\n+    )\n+\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    checkout = checkout_with_delivery_method_for_external_shipping\n+    checkout.price_expiration = timezone.now()\n+    checkout.undiscounted_base_shipping_price_amount = Decimal(\"100\")\n+    checkout.save()\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        CHECKOUTS_QUERY,\n+        permissions=[permission_manage_checkouts],\n+    )\n+\n+    # then\n+    data = get_graphql_content(response)[\"data\"][\"checkouts\"][\"edges\"]\n+    assert len(data) == 1\n+    checkout_data = data[0][\"node\"]\n+\n+    shipping_method = ShippingMethod.objects.get()\n+    assert len(checkout_data[\"shippingMethods\"]) == 1\n+    assert checkout_data[\"shippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    assert len(checkout_data[\"availableShippingMethods\"]) == 1\n+    assert checkout_data[\"availableShippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    delivery_method = checkout_data[\"deliveryMethod\"]\n+    assert delivery_method\n+    assert delivery_method[\"id\"] == checkout.external_shipping_method_id\n+    assert delivery_method[\"name\"] == checkout.shipping_method_name\n+    assert (\n+        delivery_method[\"price\"][\"amount\"]\n+        == checkout.undiscounted_base_shipping_price_amount\n+    )\n+    mocked_request.assert_not_called()\n+\n+\n+@patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+def test_query_checkouts_do_not_trigger_exclude_shipping_webhooks_with_tax_app(\n+    mocked_request,\n+    staff_api_client,\n+    permission_manage_checkouts,\n+    checkout_with_delivery_method_for_external_shipping,\n+    settings,\n+    tax_configuration_tax_app,\n+    shipping_app,\n+):\n+    # given\n+    webhook = shipping_app.webhooks.get()\n+    webhook.events.create(\n+        event_type=WebhookEventSyncType.CHECKOUT_FILTER_SHIPPING_METHODS\n+    )\n+\n+    settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+    checkout = checkout_with_delivery_method_for_external_shipping\n+    checkout.price_expiration = timezone.now()\n+    checkout.undiscounted_base_shipping_price_amount = Decimal(\"100\")\n+    checkout.save()\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        CHECKOUTS_QUERY,\n+        permissions=[permission_manage_checkouts],\n+    )\n+\n+    # then\n+    data = get_graphql_content(response)[\"data\"][\"checkouts\"][\"edges\"]\n+    assert len(data) == 1\n+    checkout_data = data[0][\"node\"]\n+\n+    shipping_method = ShippingMethod.objects.get()\n+    assert len(checkout_data[\"shippingMethods\"]) == 1\n+    assert checkout_data[\"shippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    assert len(checkout_data[\"availableShippingMethods\"]) == 1\n+    assert checkout_data[\"availableShippingMethods\"][0][\"id\"] == to_global_id_or_none(\n+        shipping_method\n+    )\n+\n+    delivery_method = checkout_data[\"deliveryMethod\"]\n+    assert delivery_method\n+    assert delivery_method[\"id\"] == checkout.external_shipping_method_id\n+    assert delivery_method[\"name\"] == checkout.shipping_method_name\n+    assert (\n+        delivery_method[\"price\"][\"amount\"]\n+        == checkout.undiscounted_base_shipping_price_amount\n+    )\n+    mocked_request.assert_not_called()\n"
        },
        {
          "path": "saleor/graphql/checkout/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/types.py\n===================================================================\n--- saleor/graphql/checkout/types.py\t9280e05 (parent)\n+++ saleor/graphql/checkout/types.py\t4da98aa (commit)\n@@ -346,8 +346,9 @@\n \n             @allow_writer_in_context(info.context)\n             def calculate_line_unit_price(data):\n                 checkout_info, lines, payloads = data\n+                checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n                 database_connection_name = get_database_connection_name(info.context)\n                 for line_info in lines:\n                     if line_info.line.pk == root.node.pk:\n                         return calculations.checkout_line_unit_price(\n@@ -383,8 +384,9 @@\n         def with_checkout(checkout):\n             checkout_info = CheckoutInfoByCheckoutTokenLoader(info.context).load(\n                 checkout.token\n             )\n+\n             lines = CheckoutLinesInfoByCheckoutTokenLoader(info.context).load(\n                 checkout.token\n             )\n \n@@ -425,8 +427,9 @@\n             checkout, manager = data\n             checkout_info = CheckoutInfoByCheckoutTokenLoader(info.context).load(\n                 checkout.token\n             )\n+\n             lines = CheckoutLinesInfoByCheckoutTokenLoader(info.context).load(\n                 checkout.token\n             )\n             payloads = None\n@@ -437,8 +440,9 @@\n \n             @allow_writer_in_context(info.context)\n             def calculate_line_total_price(data):\n                 checkout_info, lines, payloads = data\n+                checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n                 database_connection_name = get_database_connection_name(info.context)\n                 for line_info in lines:\n                     if line_info.line.pk == root.node.pk:\n                         return calculations.checkout_line_total(\n@@ -953,9 +957,10 @@\n \n     @staticmethod\n     def resolve_shipping_method(root: SyncWebhookControlContext[models.Checkout], info):\n         def with_checkout_info(checkout_info):\n-            delivery_method = checkout_info.delivery_method_info.delivery_method\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+            delivery_method = checkout_info.get_delivery_method_info().delivery_method\n             if not delivery_method or not isinstance(\n                 delivery_method, ShippingMethodData\n             ):\n                 return None\n@@ -974,9 +979,10 @@\n         root: SyncWebhookControlContext[models.Checkout], info: ResolveInfo\n     ):\n         @allow_writer_in_context(info.context)\n         def with_checkout_info(checkout_info):\n-            return checkout_info.all_shipping_methods\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+            return checkout_info.get_all_shipping_methods()\n \n         return (\n             CheckoutInfoByCheckoutTokenLoader(info.context)\n             .load(root.node.token)\n@@ -988,9 +994,10 @@\n         root: SyncWebhookControlContext[models.Checkout], info: ResolveInfo\n     ):\n         @allow_writer_in_context(info.context)\n         def with_checkout_info(checkout_info):\n-            return checkout_info.delivery_method_info.delivery_method\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+            return checkout_info.get_delivery_method_info().delivery_method\n \n         return (\n             CheckoutInfoByCheckoutTokenLoader(info.context)\n             .load(root.node.token)\n@@ -1019,8 +1026,10 @@\n         @allow_writer_in_context(info.context)\n         def calculate_total_price(data):\n             address, lines, checkout_info, manager, payloads = data\n             database_connection_name = get_database_connection_name(info.context)\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+\n             taxed_total = calculations.calculate_checkout_total_with_gift_cards(\n                 manager=manager,\n                 checkout_info=checkout_info,\n                 lines=lines,\n@@ -1043,8 +1052,10 @@\n         @allow_writer_in_context(info.context)\n         def calculate_subtotal_price(data):\n             address, lines, checkout_info, manager, payloads = data\n             database_connection_name = get_database_connection_name(info.context)\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+\n             return calculations.checkout_subtotal(\n                 manager=manager,\n                 checkout_info=checkout_info,\n                 lines=lines,\n@@ -1066,8 +1077,10 @@\n         @allow_writer_in_context(info.context)\n         def calculate_shipping_price(data):\n             address, lines, checkout_info, manager, payloads = data\n             database_connection_name = get_database_connection_name(info.context)\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+\n             return calculations.checkout_shipping_price(\n                 manager=manager,\n                 checkout_info=checkout_info,\n                 lines=lines,\n@@ -1105,8 +1118,10 @@\n         root: SyncWebhookControlContext[models.Checkout], info: ResolveInfo\n     ):\n         @allow_writer_in_context(info.context)\n         def with_checkout_info(checkout_info):\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+\n             return checkout_info.valid_shipping_methods\n \n         return (\n             CheckoutInfoByCheckoutTokenLoader(info.context)\n@@ -1148,9 +1163,9 @@\n         )\n \n         @allow_writer_in_context(info.context)\n         def get_available_payment_gateways(results):\n-            (checkout_info, lines_info) = results\n+            checkout_info, lines_info = results\n             return manager.list_payment_gateways(\n                 currency=root.node.currency,\n                 checkout_info=checkout_info,\n                 checkout_lines=lines_info,\n@@ -1391,8 +1406,10 @@\n         @allow_writer_in_context(info.context)\n         def _resolve_charge_status(data):\n             address, lines, checkout_info, manager, payloads, transactions = data\n             database_connection_name = get_database_connection_name(info.context)\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+\n             fetch_checkout_data(\n                 checkout_info=checkout_info,\n                 manager=manager,\n                 lines=lines,\n@@ -1416,8 +1433,10 @@\n         database_connection_name = get_database_connection_name(info.context)\n \n         def _calculate_total_balance_for_transactions(data):\n             address, lines, checkout_info, manager, payloads, transactions = data\n+            checkout_info.allow_sync_webhooks = root.allow_sync_webhooks\n+\n             taxed_total = calculations.calculate_checkout_total_with_gift_cards(\n                 manager=manager,\n                 checkout_info=checkout_info,\n                 lines=lines,\n"
        },
        {
          "path": "saleor/graphql/webhook/resolvers.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/resolvers.py\n===================================================================\n--- saleor/graphql/webhook/resolvers.py\t9280e05 (parent)\n+++ saleor/graphql/webhook/resolvers.py\t4da98aa (commit)\n@@ -79,11 +79,6 @@\n         database_connection_name=database_connection_name,\n     )\n     all_shipping_methods = get_all_shipping_methods_list(\n         checkout_info,\n-        checkout.shipping_address,\n-        lines,\n-        shipping_channel_listings,\n-        manager,\n-        database_connection_name=database_connection_name,\n     )\n     return all_shipping_methods\n"
        },
        {
          "path": "saleor/payment/gateways/adyen/utils/common.py",
          "status": "modified",
          "diff": "Index: saleor/payment/gateways/adyen/utils/common.py\n===================================================================\n--- saleor/payment/gateways/adyen/utils/common.py\t9280e05 (parent)\n+++ saleor/payment/gateways/adyen/utils/common.py\t4da98aa (commit)\n@@ -244,11 +244,11 @@\n         \"quantity\": 1,\n         \"amountExcludingTax\": price_to_minor_unit(total_net, currency),\n         \"taxPercentage\": tax_percentage_in_adyen_format,\n         \"description\": (\n-            f\"Shipping - {checkout_info.delivery_method_info.delivery_method.name}\"\n+            f\"Shipping - {checkout_info.get_delivery_method_info().delivery_method.name}\"\n         ),\n-        \"id\": f\"Shipping:{checkout_info.delivery_method_info.delivery_method.id}\",\n+        \"id\": f\"Shipping:{checkout_info.get_delivery_method_info().delivery_method.id}\",\n         \"taxAmount\": price_to_minor_unit(tax_amount, currency),\n         \"amountIncludingTax\": price_to_minor_unit(total_gross, currency),\n     }\n \n@@ -301,10 +301,11 @@\n             \"amountIncludingTax\": price_to_minor_unit(unit_gross, currency),\n         }\n         line_items.append(line_data)\n \n-    if checkout_info.delivery_method_info.delivery_method and is_shipping_required(\n-        lines\n+    if (\n+        checkout_info.get_delivery_method_info().delivery_method\n+        and is_shipping_required(lines)\n     ):\n         line_items.append(get_shipping_data(manager, checkout_info, lines))\n \n     payment_data[\"lineItems\"] = line_items\n"
        },
        {
          "path": "saleor/plugins/avatax/__init__.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/__init__.py\n===================================================================\n--- saleor/plugins/avatax/__init__.py\t9280e05 (parent)\n+++ saleor/plugins/avatax/__init__.py\t4da98aa (commit)\n@@ -204,15 +204,15 @@\n     if not lines:\n         return False\n \n     shipping_required = is_shipping_required(lines)\n-    shipping_address = checkout_info.delivery_method_info.shipping_address\n+    shipping_address = checkout_info.get_delivery_method_info().shipping_address\n     address = shipping_address or checkout_info.billing_address\n     return _validate_address_details(\n         shipping_address,\n         shipping_required,\n         address,\n-        checkout_info.delivery_method_info.delivery_method,\n+        checkout_info.get_delivery_method_info().delivery_method,\n     )\n \n \n def taxes_need_new_fetch(data: dict[str, Any], cached_data) -> bool:\n@@ -349,9 +349,9 @@\n             amount=checkout_line_total.amount,\n             ref1=line_info.variant.sku,\n         )\n \n-    delivery_method = checkout_info.delivery_method_info.delivery_method\n+    delivery_method = checkout_info.get_delivery_method_info().delivery_method\n     if delivery_method:\n         price = getattr(delivery_method, \"price\", None)\n         is_shipping_discount = (\n             voucher.type == VoucherType.SHIPPING if voucher else False\n"
        },
        {
          "path": "saleor/plugins/tests/sample_plugins.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/tests/sample_plugins.py\n===================================================================\n--- saleor/plugins/tests/sample_plugins.py\t9280e05 (parent)\n+++ saleor/plugins/tests/sample_plugins.py\t4da98aa (commit)\n@@ -122,9 +122,9 @@\n         address: Optional[\"Address\"],\n         previous_value: TaxedMoney,\n     ):\n         # See if delivery method doesn't trigger infinite recursion\n-        bool(checkout_info.delivery_method_info.delivery_method)\n+        bool(checkout_info.get_delivery_method_info().delivery_method)\n \n         price = Money(\"1.0\", currency=checkout_info.checkout.currency)\n         return TaxedMoney(price, price)\n \n"
        },
        {
          "path": "saleor/plugins/webhook/tests/test_shipping_webhook.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/tests/test_shipping_webhook.py\n===================================================================\n--- saleor/plugins/webhook/tests/test_shipping_webhook.py\t9280e05 (parent)\n+++ saleor/plugins/webhook/tests/test_shipping_webhook.py\t4da98aa (commit)\n@@ -5,8 +5,9 @@\n import graphene\n import pytest\n \n from ....core.models import EventDelivery\n+from ....graphql.core.utils import to_global_id_or_none\n from ....graphql.tests.utils import get_graphql_content\n from ....graphql.webhook.utils import get_subscription_query_hash\n from ....order import OrderStatus\n from ....webhook.const import CACHE_EXCLUDED_SHIPPING_TIME\n@@ -49,25 +50,21 @@\n     }\n \"\"\"\n \n CHECKOUT_QUERY_SHIPPING_METHOD = \"\"\"\n-    query CheckoutsQuery {\n-        checkouts(first: 1) {\n-            edges {\n-                node {\n-                    shippingMethods {\n-                        id\n-                        name\n-                        active\n-                    }\n-                    availableShippingMethods {\n-                        id\n-                        name\n-                        active\n-                    }\n-                }\n-            }\n+    query Checkout($id: ID){\n+      checkout(id: $id) {\n+        shippingMethods {\n+          id\n+          name\n+          active\n         }\n+        availableShippingMethods {\n+          id\n+          name\n+          active\n+        }\n+      }\n     }\n \"\"\"\n \n \n@@ -610,11 +607,14 @@\n         ExcludedShippingMethod(excluded_shipping_method_id, webhook_reason)\n     ]\n     staff_api_client.user.user_permissions.add(permission_manage_checkouts)\n     # when\n-    response = staff_api_client.post_graphql(CHECKOUT_QUERY_SHIPPING_METHOD)\n+    response = staff_api_client.post_graphql(\n+        CHECKOUT_QUERY_SHIPPING_METHOD,\n+        variables={\"id\": to_global_id_or_none(checkout_ready_to_complete)},\n+    )\n     content = get_graphql_content(response)\n-    checkout_data = content[\"data\"][\"checkouts\"][\"edges\"][0][\"node\"]\n+    checkout_data = content[\"data\"][\"checkout\"]\n \n     shipping_methods = checkout_data[\"shippingMethods\"]\n     # then\n     assert len(shipping_methods) == 2\n@@ -650,13 +650,14 @@\n     ]\n \n     staff_api_client.user.user_permissions.add(permission_manage_checkouts)\n     # when\n-    response = staff_api_client.post_graphql(CHECKOUT_QUERY_SHIPPING_METHOD)\n+    response = staff_api_client.post_graphql(\n+        CHECKOUT_QUERY_SHIPPING_METHOD,\n+        variables={\"id\": to_global_id_or_none(checkout_ready_to_complete)},\n+    )\n     content = get_graphql_content(response)\n-    shipping_methods = content[\"data\"][\"checkouts\"][\"edges\"][0][\"node\"][\n-        \"availableShippingMethods\"\n-    ]\n+    shipping_methods = content[\"data\"][\"checkout\"][\"availableShippingMethods\"]\n     # then\n     assert len(shipping_methods) == 1\n     assert shipping_methods[0][\"active\"]\n \n@@ -673,11 +674,14 @@\n     # given\n     mocked_webhook.side_effect = [[], AssertionError(\"called twice.\")]\n     staff_api_client.user.user_permissions.add(permission_manage_checkouts)\n     # when\n-    response = staff_api_client.post_graphql(CHECKOUT_QUERY_SHIPPING_METHOD)\n+    response = staff_api_client.post_graphql(\n+        CHECKOUT_QUERY_SHIPPING_METHOD,\n+        variables={\"id\": to_global_id_or_none(checkout_ready_to_complete)},\n+    )\n     content = get_graphql_content(response)\n-    checkout_data = content[\"data\"][\"checkouts\"][\"edges\"][0][\"node\"]\n+    checkout_data = content[\"data\"][\"checkout\"]\n     # then\n     assert len(checkout_data[\"availableShippingMethods\"]) == 2\n     assert len(checkout_data[\"shippingMethods\"]) == 2\n \n"
        },
        {
          "path": "saleor/tax/calculations/checkout.py",
          "status": "modified",
          "diff": "Index: saleor/tax/calculations/checkout.py\n===================================================================\n--- saleor/tax/calculations/checkout.py\t9280e05 (parent)\n+++ saleor/tax/calculations/checkout.py\t4da98aa (commit)\n@@ -57,9 +57,9 @@\n         line.total_price = line_total_price\n         line.tax_rate = normalize_tax_rate_for_db(tax_rate)\n \n     # Calculate shipping price.\n-    shipping_method = checkout_info.delivery_method_info.delivery_method\n+    shipping_method = checkout_info.get_delivery_method_info().delivery_method\n     tax_class = getattr(shipping_method, \"tax_class\", None)\n     shipping_tax_rate = get_tax_rate_for_tax_class(\n         tax_class,\n         tax_class.country_rates.all() if tax_class else [],\n"
        }
      ]
    },
    {
      "id": "cache-app-token",
      "sha": "d9a97ea25cbf721429d3f438c985d736a10ec6bc",
      "parentSha": "f623ab428821155d90063021fc2b643d4601819a",
      "spec": "Implement persistent caching in the AppByTokenLoader and add tests.\n\nRequired changes:\n1) Modify saleor/graphql/app/dataloaders/app.py\n- Imports:\n  - Add: import hashlib\n  - Add: from dataclasses import dataclass\n  - Add: from django.core.cache import cache\n- Constants and helpers:\n  - Add constant CACHE_TIMEOUT set to 30 days (30 * 60 * 60 * 24).\n  - Add function create_app_cache_key_from_token(token: str) -> str that returns a cache key with prefix \"AppByTokenLoader:\" followed by md5(token.encode(\"utf-8\")).hexdigest().\n  - Add @dataclass TokenInfo with fields:\n    - raw_token: str\n    - _cache_key: str | None = None\n    - property last_4 -> last four characters of raw_token\n    - property cache_key -> lazily computes and memoizes create_app_cache_key_from_token(raw_token)\n- AppByTokenLoader class adjustments:\n  - Add method get_and_cache_app_id(self, token_info: TokenInfo, token_id: int, auth_token: str, app_id: int) -> int | None that:\n    - Attempts cache.get(token_info.cache_key). If present, expect a tuple (cached_app_id, cached_token_id); if token_id equals cached_token_id, return cached_app_id without setting cache again.\n    - Otherwise, verify the token via check_password(token_info.raw_token, auth_token); if valid, cache (app_id, token_id) under token_info.cache_key with CACHE_TIMEOUT and return app_id; else return None.\n  - Add method remove_not_valid_tokens_from_cache(self, last_4s_to_raw_token_map, tokens_found) that deletes any cache entries for TokenInfo instances whose raw_token is not in tokens_found.\n  - Update batch_load(self, keys):\n    - Build last_4s_to_raw_token_map as defaultdict(list) mapping token_last_4 to lists of TokenInfo, not plain strings.\n    - Query AppToken with .filter(token_last_4__in=...) and .values_list(\"auth_token\", \"token_last_4\", \"app_id\", \"id\") (note the inclusion of token id).\n    - Iterate database tokens; for each, iterate TokenInfo instances for matching last_4, skipping raw tokens already processed (deduplicate using a tokens_found set). For each token_info, call get_and_cache_app_id; if it returns a value, add mapping raw_token->app_id to authed_apps and mark raw_token as found.\n    - After iterating DB rows, call remove_not_valid_tokens_from_cache for tokens not found.\n    - Load apps with App.objects.using(...).filter(id__in=authed_apps.values(), is_active=True, removed_at__isnull=True).in_bulk() and return [apps.get(authed_apps.get(key)) for key in keys].\n\n2) Add tests: saleor/graphql/app/tests/test_app_by_token_loader_use_cache.py\n- Create a new test module that patches \"saleor.graphql.app.dataloaders.app.cache\" and uses the existing setup_mock_for_cache fixture (from saleor/tests/fixtures.py) to simulate the cache backend.\n- Add the following tests (all import AppByTokenLoader and create_app_cache_key_from_token from the dataloader module, and use SaleorContext):\n  - test_app_by_token_loader_cache_token_calculation: creates a token for an active app, calls the loader with the raw token, asserts fetched app is correct, and cache contains (app.id, token.id) under the expected cache key.\n  - test_app_by_token_loader_invalid_token: uses a non-existent token, asserts fetched_app is None and cache remains empty.\n  - test_app_by_token_loader_use_cached_app: pre-populates cache with (app.id, token.id), calls the loader, asserts fetched app is correct and cache.set was called only once (the pre-population), not by the loader.\n  - test_app_by_token_loader_cached_app_not_active: marks app inactive, pre-populates cache, calls loader, asserts fetched_app is None and cache still contains the entry (no additional set calls).\n  - test_app_by_token_loader_cached_app_marked_as_removed: sets removed_at on app, pre-populates cache, calls loader, asserts fetched_app is None and cache still contains the entry (no additional set calls).\n  - test_app_by_token_loader_missing_app: deletes the app (cascading tokens), pre-populates cache, calls loader, asserts fetched_app is None, cache entry is deleted by the loader.\n  - test_app_by_token_loader_removed_token: deletes the token (app remains), pre-populates cache, calls loader, asserts fetched_app is None and cache entry is deleted by the loader.\n  - test_app_by_token_loader_one_of_tokens_in_cache: pre-populates cache for token A, creates token B, calls loader with both tokens, asserts both fetched apps are correct and cache.set was called exactly twice (one pre-population, one from loader for token B), and the expected values are in cache for both keys.\n  - test_app_by_token_loader_tokens_with_same_last_4: create two apps with tokens sharing the same last 4, call loader with both tokens, assert each result matches the correct app and both cache entries are set by the loader.\n\nNotes and expectations:\n- Ensure imports for hashlib, dataclasses.dataclass, and django.core.cache.cache are added in the dataloader module.\n- Ensure AppToken query includes the token id in values_list to support cache validation and matching.\n- Cache value must be a tuple (app_id, token_id) and use the helper cache key builder to match tests.\n- Do not re-set cache when a valid cached entry is present and token_id matches.\n- When no matching AppToken is found for a given raw token, delete that token’s cache entry.\n- Respect existing filtering for App retrieval: only is_active=True and removed_at__isnull=True should be returned; cached entries should not alter this behavior.\n- Tests must import and use SaleorContext and the setup_mock_for_cache fixture and patch the cache at module path \"saleor.graphql.app.dataloaders.app.cache\".",
      "prompt": "Add a persistent cache layer for resolving apps by token in the GraphQL AppByTokenLoader. Use a deterministic cache key derived from the provided raw token and store a tuple sufficient to confirm that a cached token still corresponds to the current database token record. On cache hits, avoid revalidating or resetting entries. On misses, validate against the hashed token in the database, then cache the result for a long TTL. If a token or its app no longer exists, proactively remove obsolete cache entries. Ensure that only active, not-removed apps are returned. Provide comprehensive tests that mock the cache backend to verify: caching on first validation, using cache on subsequent requests, correct behavior for inactive and removed apps, pruning cache when an app or token has been deleted, handling mixed cached and uncached tokens, and two different tokens sharing the same last four characters.",
      "supplementalFiles": [
        "saleor/app/models.py",
        "saleor/graphql/core/dataloaders.py",
        "saleor/graphql/app/dataloaders/__init__.py",
        "saleor/graphql/app/dataloaders/utils.py",
        "saleor/graphql/context.py",
        "saleor/tests/fixtures.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/app/dataloaders/app.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/dataloaders/app.py\n===================================================================\n--- saleor/graphql/app/dataloaders/app.py\tf623ab4 (parent)\n+++ saleor/graphql/app/dataloaders/app.py\td9a97ea (commit)\n@@ -1,12 +1,23 @@\n+import hashlib\n from collections import defaultdict\n+from dataclasses import dataclass\n \n from django.contrib.auth.hashers import check_password\n+from django.core.cache import cache\n \n from ....app.models import App, AppToken\n from ...core.dataloaders import DataLoader\n \n+# Cache timeout for the app token loader\n+CACHE_TIMEOUT = 30 * 60 * 60 * 24  # 30 days\n \n+\n+def create_app_cache_key_from_token(token: str) -> str:\n+    \"\"\"Create a cache key for the app based on the token.\"\"\"\n+    return f\"AppByTokenLoader:{hashlib.md5(token.encode('utf-8')).hexdigest()}\"\n+\n+\n class AppByIdLoader(DataLoader[str, App]):\n     context_key = \"app_by_id\"\n \n     def batch_load(self, keys):\n@@ -17,35 +28,89 @@\n         )\n         return [apps.get(key) for key in keys]\n \n \n+@dataclass\n+class TokenInfo:\n+    raw_token: str\n+    _cache_key: str | None = None\n+\n+    @property\n+    def last_4(self) -> str:\n+        return self.raw_token[-4:]\n+\n+    @property\n+    def cache_key(self) -> str:\n+        if self._cache_key is None:\n+            self._cache_key = create_app_cache_key_from_token(self.raw_token)\n+            return self._cache_key\n+        return self._cache_key\n+\n+\n class AppByTokenLoader(DataLoader[str, App]):\n     context_key = \"app_by_token\"\n \n+    def get_and_cache_app_id(\n+        self, token_info: TokenInfo, token_id: int, auth_token: str, app_id: int\n+    ):\n+        \"\"\"Check if the token is valid and return the app ID.\"\"\"\n+        cached_data = cache.get(token_info.cache_key)\n+        if cached_data:\n+            cached_app_id, cached_token_id = cached_data\n+            if token_id == cached_token_id:\n+                return cached_app_id\n+        elif check_password(token_info.raw_token, auth_token):\n+            cache_data = (app_id, token_id)\n+            cache.set(token_info.cache_key, cache_data, CACHE_TIMEOUT)\n+            return app_id\n+        return None\n+\n+    def remove_not_valid_tokens_from_cache(\n+        self, last_4s_to_raw_token_map, tokens_found\n+    ):\n+        \"\"\"Remove tokens from the cache that are not valid.\"\"\"\n+        for token_infos in last_4s_to_raw_token_map.values():\n+            for token_info in token_infos:\n+                if token_info.raw_token not in tokens_found:\n+                    cache.delete(token_info.cache_key)\n+\n     def batch_load(self, keys):\n         last_4s_to_raw_token_map = defaultdict(list)\n+\n         for raw_token in keys:\n-            last_4s_to_raw_token_map[raw_token[-4:]].append(raw_token)\n+            token_info = TokenInfo(raw_token=raw_token)\n+            last_4s_to_raw_token_map[token_info.last_4].append(token_info)\n \n+        # Fetch tokens for keys that are not in the cache and check if they are valid\n+        authed_apps = {}\n         tokens = (\n             AppToken.objects.using(self.database_connection_name)\n             .filter(token_last_4__in=last_4s_to_raw_token_map.keys())\n-            .values_list(\"auth_token\", \"token_last_4\", \"app_id\")\n+            .values_list(\"auth_token\", \"token_last_4\", \"app_id\", \"id\")\n         )\n-        authed_apps = {}\n-        for auth_token, token_last_4, app_id in tokens:\n-            for raw_token in last_4s_to_raw_token_map[token_last_4]:\n-                if check_password(raw_token, auth_token):\n-                    authed_apps[raw_token] = app_id\n+        tokens_found = set()\n+        for auth_token, token_last_4, app_id, token_id in tokens:\n+            for token_info in last_4s_to_raw_token_map[token_last_4]:\n+                if token_info.raw_token in tokens_found:\n+                    # Skip if we already checked this token\n+                    continue\n+                app_id = self.get_and_cache_app_id(\n+                    token_info, token_id, auth_token, app_id\n+                )\n+                if app_id:\n+                    authed_apps[token_info.raw_token] = app_id\n+                    tokens_found.add(token_info.raw_token)\n \n+        # Remove the cache for tokens that are not valid\n+        self.remove_not_valid_tokens_from_cache(last_4s_to_raw_token_map, tokens_found)\n+\n         apps = (\n             App.objects.using(self.database_connection_name)\n             .filter(\n                 id__in=authed_apps.values(), is_active=True, removed_at__isnull=True\n             )\n             .in_bulk()\n         )\n-\n         return [apps.get(authed_apps.get(key)) for key in keys]\n \n \n class ActiveAppByIdLoader(DataLoader):\n"
        },
        {
          "path": "saleor/graphql/app/tests/test_app_by_token_loader_use_cache.py",
          "status": "added",
          "diff": "Index: saleor/graphql/app/tests/test_app_by_token_loader_use_cache.py\n===================================================================\n--- saleor/graphql/app/tests/test_app_by_token_loader_use_cache.py\tf623ab4 (parent)\n+++ saleor/graphql/app/tests/test_app_by_token_loader_use_cache.py\td9a97ea (commit)\n@@ -0,0 +1,301 @@\n+from unittest.mock import patch\n+\n+from django.utils import timezone\n+\n+from ....app.models import App, AppToken\n+from ...context import SaleorContext\n+from ..dataloaders.app import AppByTokenLoader, create_app_cache_key_from_token\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_cache_token_calculation(\n+    mocked_cache, app, setup_mock_for_cache\n+):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    cached_app_id, token_id = mocked_cache.get(expected_cache_key)\n+    assert token.id == token_id\n+    assert fetched_app.id == app.id == cached_app_id\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_invalid_token(mocked_cache, app, setup_mock_for_cache):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    cached_data = mocked_cache.get(expected_cache_key)\n+    assert fetched_app is None\n+    assert cached_data is None\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_use_cached_app(mocked_cache, app, setup_mock_for_cache):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+    mocked_cache.set(expected_cache_key, (app.id, token.id), 123)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    cached_app_id, cached_token_id = mocked_cache.get(expected_cache_key)\n+    assert token.id == cached_token_id\n+    assert fetched_app.id == app.id == cached_app_id\n+    # Check that the cache was set only once during given test section\n+    mocked_cache.set.assert_called_once_with(\n+        expected_cache_key, (app.id, token.id), 123\n+    )\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_cached_app_not_active(\n+    mocked_cache, app, setup_mock_for_cache\n+):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    app.is_active = False\n+    app.save(update_fields=[\"is_active\"])\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+    mocked_cache.set(expected_cache_key, (app.id, token.id), 123)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    cached_app_id, cached_token_id = mocked_cache.get(expected_cache_key)\n+    assert token.id == cached_token_id\n+    assert app.id == cached_app_id\n+    # Check that the app was not fetched from the database\n+    assert fetched_app is None\n+    # Check that the cache was set only once during given test section\n+    mocked_cache.set.assert_called_once_with(\n+        expected_cache_key, (app.id, token.id), 123\n+    )\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_cached_app_marked_as_removed(\n+    mocked_cache, app, setup_mock_for_cache\n+):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    app.removed_at = timezone.now()\n+    app.save(update_fields=[\"removed_at\"])\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+    mocked_cache.set(expected_cache_key, (app.id, token.id), 123)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    cached_app_id, cached_token_id = mocked_cache.get(expected_cache_key)\n+    assert token.id == cached_token_id\n+    assert app.id == cached_app_id\n+    # Check that the app was not fetched from the database\n+    assert fetched_app is None\n+    # Check that the cache was set only once during given test section\n+    mocked_cache.set.assert_called_once_with(\n+        expected_cache_key, (app.id, token.id), 123\n+    )\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_missing_app(mocked_cache, app, setup_mock_for_cache):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    deleted_app_id = app.id\n+    app.delete()\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+    mocked_cache.set(expected_cache_key, (deleted_app_id, token.id), 123)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    # Check that the app was removed from the database\n+    assert not App.objects.exists()\n+    # Check that the app was not fetched from the database\n+    assert fetched_app is None\n+    # Check that the cache was set only once during given test section\n+    mocked_cache.set.assert_called_once_with(\n+        expected_cache_key, (deleted_app_id, token.id), 123\n+    )\n+    # Check if the token was removed from the cache\n+    assert mocked_cache.get(expected_cache_key) is None\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_removed_token(mocked_cache, app, setup_mock_for_cache):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    token_id = token.id\n+    token.delete()\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+    mocked_cache.set(expected_cache_key, (app.id, token_id), 123)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token])\n+    fetched_app = loaded_apps[0]\n+\n+    # then\n+    # Check that the token was removed from the database\n+    assert not AppToken.objects.exists()\n+    # Check that the app was not fetched from the database\n+    assert fetched_app is None\n+    # Check that the cache was set only once during given test section\n+    mocked_cache.set.assert_called_once_with(\n+        expected_cache_key, (app.id, token_id), 123\n+    )\n+    # Check if the token was removed from the cache\n+    assert mocked_cache.get(expected_cache_key) is None\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_one_of_tokens_in_cache(\n+    mocked_cache, app, setup_mock_for_cache\n+):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+    mocked_cache.set(expected_cache_key, (app.id, token.id), 123)\n+\n+    raw_token2 = \"test_token2\"\n+    token2, _ = app.tokens.create(\n+        name=\"test_token2\",\n+        auth_token=raw_token2,\n+    )\n+    expected_cache_key2 = create_app_cache_key_from_token(raw_token2)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token, raw_token2])\n+    fetched_app = loaded_apps[0]\n+    fetched_app2 = loaded_apps[1]\n+\n+    # then\n+    cached_app_id, cached_token_id = mocked_cache.get(expected_cache_key)\n+    assert token.id == cached_token_id\n+    assert fetched_app.id == app.id == cached_app_id\n+    cached_app_id2, cached_token_id2 = mocked_cache.get(expected_cache_key2)\n+    assert token2.id == cached_token_id2\n+    assert fetched_app2.id == app.id == cached_app_id2\n+    # Check that the cache was set once during given test section and second time inside dataloader\n+    assert mocked_cache.set.call_count == 2\n+\n+\n+@patch(\"saleor.graphql.app.dataloaders.app.cache\")\n+def test_app_by_token_loader_tokens_with_same_last_4(\n+    mocked_cache, app, app_with_token, setup_mock_for_cache\n+):\n+    # given\n+    dummy_cache = {}\n+    setup_mock_for_cache(dummy_cache, mocked_cache)\n+    raw_token = \"test_token1234\"\n+    token, _ = app.tokens.create(\n+        name=\"test_token\",\n+        auth_token=raw_token,\n+    )\n+    expected_cache_key = create_app_cache_key_from_token(raw_token)\n+\n+    app2 = app_with_token\n+    raw_token2 = \"test2_token1234\"\n+    token2, _ = app2.tokens.create(\n+        name=\"test_token2\",\n+        auth_token=raw_token2,\n+    )\n+    expected_cache_key2 = create_app_cache_key_from_token(raw_token2)\n+\n+    # when\n+    context = SaleorContext()\n+    app_by_token_loader = AppByTokenLoader(context)\n+    loaded_apps = app_by_token_loader.batch_load([raw_token, raw_token2])\n+    fetched_app = loaded_apps[0]\n+    fetched_app2 = loaded_apps[1]\n+\n+    # then\n+    assert token.token_last_4 == token2.token_last_4\n+    cached_app_id, cached_token_id = mocked_cache.get(expected_cache_key)\n+    assert token.id == cached_token_id\n+    assert fetched_app.id == app.id == cached_app_id\n+    cached_app_id2, cached_token_id2 = mocked_cache.get(expected_cache_key2)\n+    assert token2.id == cached_token_id2\n+    assert fetched_app2.id == app2.id == cached_app_id2\n+    # Check that the cache was set once during given test section and second time inside dataloader\n+    assert mocked_cache.set.call_count == 2\n"
        }
      ]
    },
    {
      "id": "denorm-product-type",
      "sha": "968881fb364baf02c39e725a7f0703fd91fc8398",
      "parentSha": "663543eaf563e773983e2482b667c45bc540d54b",
      "spec": "Implement denormalized product_type_id on OrderLine and ensure it is populated in all order creation flows, plus backfilled via a Celery migration task.\n\nScope\n- Model/migrations: add the field and a post-migrate triggered task to backfill.\n- Order creation flows: populate product_type_id whenever lines are created.\n- Admin/bulk flows: populate product_type_id efficiently during bulk operations.\n- Celery config: ensure tasks for this migration series are discovered.\n- Tests (already provided in repo) will validate field population across flows.\n\nRequirements\n1) Add nullable, denormalized field on OrderLine\n- File: saleor/order/models.py\n  - Add IntegerField product_type_id (null=True, blank=True) on OrderLine with a comment indicating it is denormalized.\n\n2) Add database migrations for the new field and for triggering the population task\n- File: saleor/order/migrations/0209_orderline_product_type_id.py\n  - Add product_type_id IntegerField to orderline model, nullable and blank.\n- File: saleor/order/migrations/0210_populated_order_line_product_type_id.py\n  - On post_migrate (sender=order app), enqueue an asynchronous Celery task to populate product_type_id for existing rows.\n  - The forward migration should connect a post_migrate signal and call the Celery task (no reverse code).\n\n3) Implement a Celery task to backfill product_type_id in batches\n- File: saleor/order/migrations/tasks/saleor3_22.py\n  - Define ORDER_LINE_PRODUCT_ID_BATCH_SIZE = 250.\n  - Implement a Celery task populate_order_line_product_type_id_task(line_pk=None) which:\n    - Selects OrderLine rows with pk >= starting pk, where variant is not null and product_type_id is null, ordered by pk ascending, limited to the batch size.\n    - Builds a mapping: variant_id -> product_id (from ProductVariant), then product_id -> product_type_id (from Product), then variant_id -> product_type_id.\n    - Locks selected order lines (select_for_update) within a transaction, sets line.product_type_id where available, and bulk_update only the product_type_id field.\n    - If the batch is non-empty, recursively enqueue the next batch with the last processed pk.\n  - Ensure the task runs with writer access enabled according to the project's DB access policy (consistent with existing task patterns).\n\n4) Update Celery autodiscovery to load the new migration task namespace\n- File: saleor/celeryconf.py\n  - Update app.autodiscover_tasks for migration tasks to use related_name=\"saleor3_22\".\n\n5) Populate product_type_id in all order-line creation paths\n- Checkout to order conversion:\n  - File: saleor/checkout/complete_checkout.py\n    - In _create_line_for_order, when instantiating OrderLine, set product_type_id from the checkout_line_info.product.product_type_id.\n- Draft/unconfirmed order flow (utility used by order mutations):\n  - File: saleor/order/utils.py\n    - In create_order_line (used by add_variant_to_order and order lines create), set product_type_id from product.product_type_id for the selected variant’s product.\n- Random data generation for orders (dev utilities):\n  - File: saleor/core/utils/random_data.py\n    - In _get_new_order_line, set product_type_id from product.product_type.id.\n\n6) Populate product_type_id in order bulk create\n- File: saleor/graphql/order/bulk_mutations/order_bulk_create.py\n  - Import Product along with ProductVariant.\n  - Before line creation, compute product_ids for all variants and build a product_id -> product_type_id map; store it in object_storage.\n  - When creating each OrderLine in the mutation, set product_type_id using the precomputed map for the variant’s product_id.\n\n7) Tests coverage (already provided in repo)\n- The following tests should pass, asserting product_type_id is set on order lines created via:\n  - Checkout completion with payments\n  - Checkout completion with transactions\n  - Draft order create\n  - Order lines create (for DRAFT and UNCONFIRMED orders)\n  - Order bulk create\n\nAcceptance criteria\n- Running migrations adds product_type_id and schedules the backfill task on post-migrate.\n- New orders and lines created via checkout completion, draft order creation, order lines creation, and order bulk create have product_type_id set to the corresponding product’s product_type_id.\n- The backfill task updates existing lines with non-null variants and null product_type_id in batches until completion.\n- Celery autodiscovery picks up the new tasks module (saleor3_22) so the backfill task can run.\n- All provided tests related to this feature pass.",
      "prompt": "Add a denormalized product type reference to order lines and ensure it’s correctly set across all order creation paths.\n\nSpecifically:\n- Add a new nullable integer field on order lines for the product type ID.\n- Backfill existing rows with a Celery task that processes lines in batches and schedules itself until complete, and trigger it after migrations.\n- Ensure the new field is set whenever order lines are created: during checkout completion, draft/unconfirmed order line creation, random data generation for orders, and order bulk creation.\n- Update Celery autodiscovery so the migration task is discoverable.\n\nThe solution should pass tests that verify product_type_id is set for all order lines created via checkout completion, draft order creation, order lines creation, and order bulk create, and that the post-migrate process enqueues the backfill task.",
      "supplementalFiles": [
        "saleor/graphql/order/mutations/order_lines_create.py",
        "saleor/graphql/checkout/mutations/checkout_complete.py",
        "saleor/product/models.py",
        "saleor/core/db/connection.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/celeryconf.py",
          "status": "modified",
          "diff": "Index: saleor/celeryconf.py\n===================================================================\n--- saleor/celeryconf.py\t663543e (parent)\n+++ saleor/celeryconf.py\t968881f (commit)\n@@ -36,8 +36,8 @@\n app.autodiscover_tasks(\n     packages=[\n         \"saleor.order.migrations.tasks\",\n     ],\n-    related_name=\"saleor3_21\",\n+    related_name=\"saleor3_22\",\n )\n app.autodiscover_tasks(lambda: discover_plugins_modules(settings.PLUGINS))\n app.autodiscover_tasks(related_name=\"search_tasks\")\n"
        },
        {
          "path": "saleor/checkout/complete_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/complete_checkout.py\n===================================================================\n--- saleor/checkout/complete_checkout.py\t663543e (parent)\n+++ saleor/checkout/complete_checkout.py\t968881f (commit)\n@@ -372,8 +372,9 @@\n         translated_product_name=translated_product_name,\n         translated_variant_name=translated_variant_name,\n         product_sku=variant.sku,\n         product_variant_id=variant.get_global_id(),\n+        product_type_id=checkout_line_info.product.product_type_id,\n         is_shipping_required=variant.is_shipping_required(),\n         is_gift_card=variant.is_gift_card(),\n         quantity=quantity,\n         variant=variant,\n"
        },
        {
          "path": "saleor/core/utils/random_data.py",
          "status": "modified",
          "diff": "Index: saleor/core/utils/random_data.py\n===================================================================\n--- saleor/core/utils/random_data.py\t663543e (parent)\n+++ saleor/core/utils/random_data.py\t968881f (commit)\n@@ -717,8 +717,9 @@\n         order=order,\n         product_name=str(product),\n         variant_name=str(variant),\n         product_sku=variant.sku,\n+        product_type_id=product.product_type.id,\n         product_variant_id=variant.get_global_id(),\n         is_shipping_required=variant.is_shipping_required(),\n         is_gift_card=variant.is_gift_card(),\n         quantity=quantity,\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py\t663543e (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_payment.py\t968881f (commit)\n@@ -5941,4 +5941,53 @@\n \n     order = Order.objects.first()\n     assert order.user_email == checkout.email\n     assert order.user.email == checkout.user.email\n+\n+\n+def test_checkout_complete_sets_product_type_id_for_all_order_lines(\n+    user_api_client,\n+    checkout_ready_to_complete,\n+    payment_dummy,\n+    address,\n+):\n+    # given\n+    checkout = checkout_ready_to_complete\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+\n+    variant_id_to_product_type_id_map = {\n+        line.variant.id: line.product_type.id for line in lines\n+    }\n+\n+    total = calculations.checkout_total(\n+        manager=manager, checkout_info=checkout_info, lines=lines, address=address\n+    )\n+    payment = payment_dummy\n+    payment.is_active = True\n+    payment.order = None\n+    payment.total = total.gross.amount\n+    payment.currency = total.gross.currency\n+    payment.checkout = checkout\n+    payment.save()\n+    assert not payment.transactions.exists()\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(checkout),\n+        \"redirectUrl\": \"https://www.example.com\",\n+    }\n+\n+    # when\n+    response = user_api_client.post_graphql(MUTATION_CHECKOUT_COMPLETE, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkoutComplete\"]\n+    assert not data[\"errors\"]\n+\n+    order = Order.objects.first()\n+    for line in order.lines.all():\n+        assert (\n+            line.product_type_id == variant_id_to_product_type_id_map[line.variant_id]\n+        )\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\t663543e (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\t968881f (commit)\n@@ -5420,4 +5420,53 @@\n \n     order = Order.objects.first()\n     assert order.user_email == checkout.email\n     assert order.user.email == checkout.user.email\n+\n+\n+def test_checkout_complete_sets_product_type_id_for_all_order_lines(\n+    user_api_client,\n+    checkout_ready_to_complete,\n+    address,\n+    address_usa,\n+    shipping_method,\n+    transaction_events_generator,\n+    transaction_item_generator,\n+    customer_user,\n+):\n+    # given\n+    checkout = prepare_checkout_for_test(\n+        checkout_ready_to_complete,\n+        address,\n+        address_usa,\n+        shipping_method,\n+        transaction_item_generator,\n+        transaction_events_generator,\n+        user=customer_user,\n+        save_billing_address=True,\n+        save_shipping_address=True,\n+    )\n+\n+    lines, _ = fetch_checkout_lines(checkout)\n+\n+    variant_id_to_product_type_id_map = {\n+        line.variant.id: line.product_type.id for line in lines\n+    }\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(checkout),\n+        \"redirectUrl\": \"https://www.example.com\",\n+    }\n+\n+    # when\n+    response = user_api_client.post_graphql(MUTATION_CHECKOUT_COMPLETE, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkoutComplete\"]\n+    assert not data[\"errors\"]\n+\n+    order = Order.objects.first()\n+    for line in order.lines.all():\n+        assert (\n+            line.product_type_id == variant_id_to_product_type_id_map[line.variant_id]\n+        )\n"
        },
        {
          "path": "saleor/graphql/order/bulk_mutations/order_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/bulk_mutations/order_bulk_create.py\n===================================================================\n--- saleor/graphql/order/bulk_mutations/order_bulk_create.py\t663543e (parent)\n+++ saleor/graphql/order/bulk_mutations/order_bulk_create.py\t968881f (commit)\n@@ -46,9 +46,9 @@\n from ....order.utils import update_order_display_gross_prices, updates_amounts_for_order\n from ....payment import TransactionEventType\n from ....payment.models import TransactionEvent, TransactionItem\n from ....permission.enums import OrderPermissions\n-from ....product.models import ProductVariant\n+from ....product.models import Product, ProductVariant\n from ....shipping.models import ShippingMethod, ShippingMethodChannelListing\n from ....tax.models import TaxClass, TaxConfiguration\n from ....warehouse.management import stock_bulk_update\n from ....warehouse.models import Stock, Warehouse\n@@ -799,8 +799,14 @@\n         gift_cards = GiftCard.objects.filter(code__in=identifiers.gift_card_codes.keys)\n         orders = Order.objects.filter(\n             external_reference__in=identifiers.order_external_references.keys\n         )\n+        product_ids = {variant.product_id for variant in variants}\n+        product_id_to_product_type_id_map = dict(\n+            Product.objects.filter(pk__in=product_ids).values_list(\n+                \"id\", \"product_type_id\"\n+            )\n+        )\n \n         # Create dictionary\n         object_storage: dict[str, Any] = {}\n         for user in users:\n@@ -841,8 +847,12 @@\n \n         for object in [*warehouses, *shipping_methods, *tax_classes, *apps]:\n             object_storage[f\"{object.__class__.__name__}.id.{object.pk}\"] = object\n \n+        object_storage[\"product_id_to_product_type_id_map\"] = (\n+            product_id_to_product_type_id_map\n+        )\n+\n         return object_storage\n \n     @classmethod\n     def is_datetime_valid(cls, date: datetime.datetime) -> bool:\n@@ -1755,12 +1765,17 @@\n                     path=f\"lines.{index}.created_at\",\n                     code=OrderBulkCreateErrorCode.FUTURE_DATE,\n                 )\n             )\n-\n+        product_type_id = None\n+        if variant:\n+            product_type_id = object_storage.get(\n+                \"product_id_to_product_type_id_map\"\n+            ).get(variant.product_id)\n         order_line = OrderLine(\n             order=order_data.order,\n             variant=variant,\n+            product_type_id=product_type_id,\n             product_name=order_line_input.get(\"product_name\") or variant.product.name,\n             variant_name=order_line_input.get(\"variant_name\")\n             or (variant.name if variant else \"\"),\n             translated_product_name=order_line_input.get(\"translated_product_name\")\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_draft_order_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_draft_order_create.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_draft_order_create.py\t663543e (parent)\n+++ saleor/graphql/order/tests/mutations/test_draft_order_create.py\t968881f (commit)\n@@ -4112,4 +4112,46 @@\n \n     order = Order.objects.get(id=order_pk)\n \n     assert order.language_code == \"pl\"\n+\n+\n+def test_draft_order_create_sets_product_type_id_for_order_line(\n+    app_api_client,\n+    permission_manage_orders,\n+    customer_user,\n+    product_available_in_many_channels,\n+    channel_PLN,\n+):\n+    # given\n+    variant = product_available_in_many_channels.variants.first()\n+    query = DRAFT_ORDER_CREATE_MUTATION\n+\n+    user_id = graphene.Node.to_global_id(\"User\", customer_user.id)\n+    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.id)\n+\n+    expected_product_type_id = variant.product.product_type_id\n+\n+    variant_list = [\n+        {\"variantId\": variant_id, \"quantity\": 2},\n+    ]\n+    channel_id = graphene.Node.to_global_id(\"Channel\", channel_PLN.id)\n+\n+    variables = {\n+        \"input\": {\n+            \"user\": user_id,\n+            \"lines\": variant_list,\n+            \"channelId\": channel_id,\n+        }\n+    }\n+\n+    # when\n+    response = app_api_client.post_graphql(\n+        query, variables, permissions=(permission_manage_orders,)\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert not content[\"data\"][\"draftOrderCreate\"][\"errors\"]\n+\n+    order_line = OrderLine.objects.first()\n+    assert order_line.product_type_id == expected_product_type_id\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_bulk_create.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_bulk_create.py\t663543e (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_bulk_create.py\t968881f (commit)\n@@ -577,8 +577,9 @@\n     assert db_order.lines.first() == db_order_line\n     assert (\n         db_order.lines_count == len(order_bulk_input[\"lines\"]) == db_order.lines.count()\n     )\n+    assert db_order_line.product_type_id == variant.product.product_type_id\n \n \n def test_order_bulk_create_unit_discount_mismatched_discount(\n     staff_api_client,\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_lines_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_lines_create.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_lines_create.py\t663543e (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_lines_create.py\t968881f (commit)\n@@ -2184,4 +2184,38 @@\n     # then\n     line.refresh_from_db()\n     assert line.quantity == old_quantity + extra_quantity\n     assert line.draft_base_price_expire_at is None\n+\n+\n+@pytest.mark.parametrize(\"status\", [OrderStatus.DRAFT, OrderStatus.UNCONFIRMED])\n+def test_order_lines_create_sets_product_type_id_for_order_line(\n+    status,\n+    order,\n+    permission_group_manage_orders,\n+    staff_api_client,\n+    variant_with_many_stocks,\n+):\n+    # given\n+    query = ORDER_LINES_CREATE_MUTATION\n+    order.status = status\n+    order.save(update_fields=[\"status\"])\n+    variant = variant_with_many_stocks\n+\n+    quantity = 1\n+    order_id = graphene.Node.to_global_id(\"Order\", order.id)\n+    variant_id = graphene.Node.to_global_id(\"ProductVariant\", variant.id)\n+    variables = {\"orderId\": order_id, \"variantId\": variant_id, \"quantity\": quantity}\n+\n+    expected_product_type_id = variant.product.product_type_id\n+\n+    # when\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    response = staff_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert not content[\"data\"][\"orderLinesCreate\"][\"errors\"]\n+\n+    order.refresh_from_db()\n+    assert len(order.lines.all()) == 1\n+    assert order.lines.first().product_type_id == expected_product_type_id\n"
        },
        {
          "path": "saleor/order/migrations/0209_orderline_product_type_id.py",
          "status": "added",
          "diff": "Index: saleor/order/migrations/0209_orderline_product_type_id.py\n===================================================================\n--- saleor/order/migrations/0209_orderline_product_type_id.py\t663543e (parent)\n+++ saleor/order/migrations/0209_orderline_product_type_id.py\t968881f (commit)\n@@ -0,0 +1,17 @@\n+# Generated by Django 5.2.1 on 2025-06-03 11:22\n+\n+from django.db import migrations, models\n+\n+\n+class Migration(migrations.Migration):\n+    dependencies = [\n+        (\"order\", \"0208_order_lines_count_idx\"),\n+    ]\n+\n+    operations = [\n+        migrations.AddField(\n+            model_name=\"orderline\",\n+            name=\"product_type_id\",\n+            field=models.IntegerField(blank=True, null=True),\n+        ),\n+    ]\n"
        },
        {
          "path": "saleor/order/migrations/0210_populated_order_line_product_type_id.py",
          "status": "added",
          "diff": "Index: saleor/order/migrations/0210_populated_order_line_product_type_id.py\n===================================================================\n--- saleor/order/migrations/0210_populated_order_line_product_type_id.py\t663543e (parent)\n+++ saleor/order/migrations/0210_populated_order_line_product_type_id.py\t968881f (commit)\n@@ -0,0 +1,26 @@\n+from django.apps import apps as registry\n+from django.db import migrations\n+from django.db.models.signals import post_migrate\n+\n+from .tasks.saleor3_22 import populate_order_line_product_type_id_task\n+\n+\n+def populate_order_line_product_id(apps, _schema_editor):\n+    def on_migrations_complete(sender=None, **kwargs):\n+        populate_order_line_product_type_id_task.delay()\n+\n+    sender = registry.get_app_config(\"order\")\n+    post_migrate.connect(on_migrations_complete, weak=False, sender=sender)\n+\n+\n+class Migration(migrations.Migration):\n+    dependencies = [\n+        (\"order\", \"0209_orderline_product_type_id\"),\n+    ]\n+\n+    operations = [\n+        migrations.RunPython(\n+            populate_order_line_product_id,\n+            reverse_code=migrations.RunPython.noop,\n+        )\n+    ]\n"
        },
        {
          "path": "saleor/order/migrations/tasks/saleor3_22.py",
          "status": "added",
          "diff": "Index: saleor/order/migrations/tasks/saleor3_22.py\n===================================================================\n--- saleor/order/migrations/tasks/saleor3_22.py\t663543e (parent)\n+++ saleor/order/migrations/tasks/saleor3_22.py\t968881f (commit)\n@@ -0,0 +1,55 @@\n+from django.db import transaction\n+\n+from ....celeryconf import app\n+from ....core.db.connection import allow_writer\n+from ....product.models import Product, ProductVariant\n+from ...models import OrderLine\n+\n+ORDER_LINE_PRODUCT_ID_BATCH_SIZE = 250\n+\n+\n+@app.task\n+@allow_writer()\n+def populate_order_line_product_type_id_task(line_pk=None):\n+    \"\"\"Populate product id for order lines.\"\"\"\n+    if line_pk is None:\n+        line_pk = 0\n+    lines = OrderLine.objects.filter(\n+        pk__gte=line_pk, variant__isnull=False, product_type_id__isnull=True\n+    )\n+    qs = lines.order_by(\"pk\")\n+\n+    line_id_with_variant_id = qs.values_list(\"pk\", \"variant_id\")[\n+        :ORDER_LINE_PRODUCT_ID_BATCH_SIZE\n+    ]\n+\n+    variant_id_to_product_id = dict(\n+        ProductVariant.objects.filter(\n+            pk__in=[variant_id for _, variant_id in line_id_with_variant_id]\n+        ).values_list(\"id\", \"product_id\")\n+    )\n+\n+    product_id_to_product_type_id_map = dict(\n+        Product.objects.filter(pk__in=variant_id_to_product_id.values()).values_list(\n+            \"id\", \"product_type_id\"\n+        )\n+    )\n+    variant_id_to_product_type_id = {\n+        variant_id: product_id_to_product_type_id_map[product_id]\n+        for variant_id, product_id in variant_id_to_product_id.items()\n+    }\n+\n+    line_pks = [line_id for (line_id, _) in line_id_with_variant_id]\n+    if line_pks:\n+        lines = OrderLine.objects.filter(pk__in=line_pks).order_by(\"pk\")\n+        with transaction.atomic():\n+            to_save = []\n+            _lines_lock = list(lines.select_for_update(of=([\"self\"])))\n+            for line in lines:\n+                product_type_id = variant_id_to_product_type_id.get(line.variant_id)\n+                if not product_type_id:\n+                    continue\n+                line.product_type_id = product_type_id\n+                to_save.append(line)\n+            OrderLine.objects.bulk_update(to_save, [\"product_type_id\"])\n+        populate_order_line_product_type_id_task.delay(line_pks[-1])\n"
        },
        {
          "path": "saleor/order/models.py",
          "status": "modified",
          "diff": "Index: saleor/order/models.py\n===================================================================\n--- saleor/order/models.py\t663543e (parent)\n+++ saleor/order/models.py\t968881f (commit)\n@@ -570,8 +570,12 @@\n     translated_variant_name = models.CharField(max_length=255, default=\"\", blank=True)\n     product_sku = models.CharField(max_length=255, null=True, blank=True)\n     # str with GraphQL ID used as fallback when product SKU is not available\n     product_variant_id = models.CharField(max_length=255, null=True, blank=True)\n+\n+    # denormalized product type id\n+    product_type_id = models.IntegerField(null=True, blank=True)\n+\n     is_shipping_required = models.BooleanField()\n     is_gift_card = models.BooleanField()\n     quantity = models.IntegerField(validators=[MinValueValidator(1)])\n     quantity_fulfilled = models.IntegerField(\n"
        },
        {
          "path": "saleor/order/utils.py",
          "status": "modified",
          "diff": "Index: saleor/order/utils.py\n===================================================================\n--- saleor/order/utils.py\t663543e (parent)\n+++ saleor/order/utils.py\t968881f (commit)\n@@ -306,8 +306,9 @@\n         translated_variant_name=translated_variant_name,\n         product_sku=variant.sku,\n         product_variant_id=variant.get_global_id(),\n         is_shipping_required=variant.is_shipping_required(),\n+        product_type_id=product.product_type_id,\n         is_gift_card=variant.is_gift_card(),\n         quantity=quantity,\n         unit_price=unit_price,\n         undiscounted_unit_price=undiscounted_unit_price,\n"
        }
      ]
    },
    {
      "id": "extend-app-extensions",
      "sha": "b546041c458c4411243949f7a75de7aebfd5fdb8",
      "parentSha": "7d9754447eef0f490bdb1292d69249ae1461a450",
      "spec": "Implement App Extension options and widget support across models, validations, installation, and GraphQL.\n\n1) Model and types\n- saleor/app/types.py:\n  - Add AppExtensionHttpMethod with GET and POST and CHOICES.\n  - Extend AppExtensionTarget with WIDGET and add to CHOICES.\n  - Extend AppExtensionMount with new *_DETAILS_WIDGETS and related *_WIDGETS constants used in the diff and add them to CHOICES (e.g., collection_details_widgets, gift_card_details_widgets, customer_details_widgets, product_details_widgets, order_details_widgets, draft_order_details_widgets, voucher_details_widgets, etc.).\n- saleor/app/models.py:\n  - Add http_target_method: models.CharField(choices=AppExtensionHttpMethod.CHOICES, null=True, blank=False) to AppExtension.\n- Create a new migration saleor/app/migrations/0032_appextension_http_target_method_and_more.py:\n  - Add the http_target_method field to AppExtension.\n  - Alter AppExtension.mount choices to include all new *_WIDGETS mounts.\n  - Alter AppExtension.target choices to include WIDGET and keep POPUP, APP_PAGE, NEW_TAB; set default to POPUP.\n\n2) Validators and manifest cleaning\n- saleor/app/validators.py:\n  - Add Pydantic-based AppExtensionOptions model with two optional fields:\n    - new_tab_target (validation_alias='newTabTarget') and widget_target (validation_alias='widgetTarget'), each having an inner model with a required 'method' that must be one of GET or POST.\n  - Ensure only one of newTabTarget or widgetTarget is allowed; raise ValueError if both are present.\n  - Add validation helpers to ensure method is either GET or POST.\n- saleor/app/manifest_validations.py:\n  - Import django.conf.settings, urllib.parse.urlparse, and PydanticValidationError as needed.\n  - Update _clean_extension_url to:\n    - Require manifest_data['tokenTargetUrl'] to be present; raise ValidationError if missing.\n    - For NEW_TAB and WIDGET targets: if options specify POST (newTabTarget.method == 'POST' or widgetTarget.method == 'POST'):\n      - If settings.ENABLE_SSL is True, require extension URL to start with https.\n      - Require extension URL hostname to match the hostname of tokenTargetUrl.\n    - Maintain existing relative path handling: APP_PAGE allows relative path; APP_PAGE forbids absolute protocol URLs; POPUP validates as standard URL if absolute; NEW_TAB must not be relative.\n  - Add _clean_extension_options(extension, errors):\n    - Validate extension['options'] using AppExtensionOptions.model_validate.\n    - Enforce that widgetTarget options only appear when target == WIDGET, and newTabTarget options only when target == NEW_TAB; otherwise append ValidationError to errors['extensions'].\n    - Normalize extension['options'] to snake_case field names via model_dump(exclude_none=True), resulting in keys 'new_tab_target' or 'widget_target'.\n  - In _clean_extensions, invoke _clean_extension_options after URL and permissions checks.\n\n3) Installation flow\n- saleor/app/installation_utils.py:\n  - When creating AppExtension instances from manifest_data['extensions'], read normalized snake_case options:\n    - options = extension_data.get('options', {})\n    - new_tab_target = options.get('new_tab_target')\n    - widget_target = options.get('widget_target')\n    - Determine http_target_method from whichever option dict is present by extracting its 'method' (if present), otherwise None.\n  - Pass http_target_method=http_target_method to AppExtension.objects.create.\n\n4) GraphQL API exposure\n- saleor/graphql/app/types.py:\n  - Import AppExtensionHttpMethod and add a BaseEnum HttpMethod (GET, POST).\n  - Define types:\n    - WidgetTargetOptions { method: HttpMethod! }\n    - NewTabTargetOptions { method: HttpMethod! }\n    - AppExtensionOptionsWidget { widgetTarget: WidgetTargetOptions }\n    - AppExtensionOptionsNewTab { newTabTarget: NewTabTargetOptions }\n    - Union AppExtensionPossibleOptions = AppExtensionOptionsWidget | AppExtensionOptionsNewTab\n  - Extend the AppExtension GraphQL type with a nullable field options: AppExtensionPossibleOptions (with description stating added in 3.22).\n  - Implement resolve_options(root, info):\n    - If root.target == WIDGET, return AppExtensionOptionsWidget with widgetTarget.method from root.http_target_method.\n    - If root.target == NEW_TAB, return AppExtensionOptionsNewTab with newTabTarget.method from root.http_target_method.\n    - Otherwise return None.\n- saleor/graphql/schema.graphql:\n  - Regenerate schema to include:\n    - WIDGET in AppExtensionTargetEnum.\n    - New *_WIDGETS values in AppExtensionMountEnum.\n    - New enum HttpMethod with POST and GET.\n    - New union AppExtensionPossibleOptions and the two concrete AppExtensionOptions* types and their nested *TargetOptions with method field.\n    - Add options field to AppExtension type with the \"Added in Saleor 3.22\" note.\n\n5) Tests and expected behavior (ensure these pass against your implementation)\n- saleor/app/tests/test_installation_utils.py:\n  - Existing tests for creating extensions should still pass and now assert http_target_method is None by default.\n  - Tests creating WIDGET/NEW_TAB with options should persist http_target_method and reflect the specified method.\n  - For NEW_TAB with POST: URL must be https when ENABLE_SSL True and must match tokenTargetUrl hostname; violations raise ValidationError and bubble to \"Incorrect value for field: url.\".\n- saleor/app/tests/test_validators.py:\n  - NEW_TAB with relative URL should be invalid.\n  - New parameterized tests validate AppExtensionOptions behavior: only one of newTabTarget/widgetTarget allowed; methods limited to GET or POST; normalization to snake_case after cleaning; and target-option mismatch errors.\n  - _clean_extension_url requires tokenTargetUrl; when settings.ENABLE_SSL is False, http URLs are acceptable.\n- saleor/graphql/app/tests/queries/test_app_extension.py and .../test_app_extensions.py:\n  - options should appear in query results for WIDGET/NEW_TAB targets with method mapped through HttpMethod.\n- saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py:\n  - Ensure validations for extension URL are compatible with the new rules (absolute URL for NEW_TAB, and when POST + SSL enabled, same-origin and https conditions apply). Update expected absolute URL in tests accordingly.\n\n6) Changelog\n- CHANGELOG.md: add a line indicating widgets and options support, new WIDGET target, and options field for NEW_TAB and WIDGET, with a link to docs placeholder as in the diff.\n\n7) Post-implementation steps\n- Run makemigrations to confirm the migration file name and content match the spec.\n- Apply migrations and regenerate the GraphQL schema (schema.graphql) to include the new enums, types, union, and field.\n",
      "prompt": "Enhance the App Extensions system to support widget targets and per-target options. Add a new WIDGET target and additional widget mount points. Validate extension options in the manifest so that only one of newTabTarget or widgetTarget can be provided, each with a GET or POST method, and normalize options to the internal structure. Enforce that POST-based NEW_TAB and WIDGET extensions use https when SSL is enabled and that their URLs are same-origin with the app’s token target URL. Persist the chosen HTTP method for an extension in a flat database field and expose the options via the GraphQL API with a typed union. Update validations, installation logic, and GraphQL types accordingly so queries return the options and tests pass. Finally, update the changelog and regenerate the schema.",
      "supplementalFiles": [
        "saleor/graphql/app/enums.py",
        "saleor/graphql/app/resolvers.py",
        "saleor/graphql/app/filters.py",
        "saleor/graphql/app/mutations/app_fetch_manifest.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t7d97544 (parent)\n+++ CHANGELOG.md\tb546041 (commit)\n@@ -31,8 +31,9 @@\n - Fix PAGE_DELETE webhook to include pageType in payload - #17697 by @Jennyyyy0212 and @CherineCho2016\n - Stripe Plugin has been deprecated. It will be removed in the future. Please use [the Stripe App](https://docs.saleor.io/developer/app-store/apps/stripe/overview) instead\n - App Extensions: Added new allowed extension target: NEW_TAB. Once handled in the Dashboard, an extension will be able to open a link in new tab\n - App Extensions: New mount points for Dashboard categories, collections, gift cards, draft orders, discounts, vouchers, pages, pages types and menus\n+- App Extensions: Now mount point types have been added, meant to be used as widgets. Additionally, a new target `WIDGET` has been added. For `NEW_TAB` and `WIDGET` targets, new field `options`. See [docs](todo) to learn more\n - Changed logging settings of failed requests to reduce logs amount in production:\n \n   - Downgraded the \"A query had an error\" log from INFO to DEBUG level.\n   - Increased the `django.request` logger's level to ERROR, to reduce the number of WARNING logs for failed GraphQL or 404 requests.\n"
        },
        {
          "path": "saleor/app/installation_utils.py",
          "status": "modified",
          "diff": "Index: saleor/app/installation_utils.py\n===================================================================\n--- saleor/app/installation_utils.py\t7d97544 (parent)\n+++ saleor/app/installation_utils.py\tb546041 (commit)\n@@ -230,14 +230,37 @@\n     )\n \n     app.permissions.set(app_installation.permissions.all())\n     for extension_data in manifest_data.get(\"extensions\", []):\n+        # Manifest is already \"clean\" so values are snake case\n+        options = extension_data.get(\"options\", {})\n+        new_tab_target = options.get(\"new_tab_target\")\n+        widget_target = options.get(\"widget_target\")\n+\n+        # Ensure proper extraction of the method values from the options\n+        http_target_method = None\n+\n+        if (\n+            new_tab_target\n+            and isinstance(new_tab_target, dict)\n+            and \"method\" in new_tab_target\n+        ):\n+            http_target_method = new_tab_target[\"method\"]\n+\n+        if (\n+            widget_target\n+            and isinstance(widget_target, dict)\n+            and \"method\" in widget_target\n+        ):\n+            http_target_method = widget_target[\"method\"]\n+\n         extension = AppExtension.objects.create(\n             app=app,\n             label=extension_data.get(\"label\"),\n             url=extension_data.get(\"url\"),\n             mount=extension_data.get(\"mount\"),\n             target=extension_data.get(\"target\", AppExtensionTarget.POPUP),\n+            http_target_method=http_target_method,\n         )\n         extension.permissions.set(extension_data.get(\"permissions\", []))\n \n     webhooks = Webhook.objects.bulk_create(\n"
        },
        {
          "path": "saleor/app/manifest_validations.py",
          "status": "modified",
          "diff": "Index: saleor/app/manifest_validations.py\n===================================================================\n--- saleor/app/manifest_validations.py\t7d97544 (parent)\n+++ saleor/app/manifest_validations.py\tb546041 (commit)\n@@ -1,11 +1,14 @@\n import logging\n from collections import defaultdict\n from collections.abc import Iterable\n+from urllib.parse import urlparse\n \n+from django.conf import settings\n from django.core.exceptions import ValidationError\n from django.db.models import Value\n from django.db.models.functions import Concat\n+from pydantic import ValidationError as PydanticValidationError\n from semantic_version import NpmSpec, Version\n from semantic_version.base import Range\n \n from .. import __version__\n@@ -21,9 +24,9 @@\n from ..webhook.validators import custom_headers_validator\n from .error_codes import AppErrorCode\n from .models import App\n from .types import AppExtensionMount, AppExtensionTarget\n-from .validators import AppURLValidator, brand_validator\n+from .validators import AppExtensionOptions, AppURLValidator, brand_validator\n \n logger = logging.getLogger(__name__)\n \n T_ERRORS = dict[str, list[ValidationError]]\n@@ -70,14 +73,40 @@\n     - url cannot start with protocol when target == \"APP_PAGE\"\n     \"\"\"\n     extension_url = extension[\"url\"]\n     target = extension.get(\"target\") or AppExtensionTarget.POPUP\n+\n+    # Assume app URL is the one that originally received the token.\n+    app_url = manifest_data.get(\"tokenTargetUrl\")\n+\n+    new_tab_method_post = (\n+        extension.get(\"options\", {}).get(\"newTabTarget\", {}).get(\"method\") == \"POST\"\n+    )\n+    widget_method_post = (\n+        extension.get(\"options\", {}).get(\"widgetTarget\", {}).get(\"method\") == \"POST\"\n+    )\n+\n+    if not app_url:\n+        raise ValidationError(\"Manifest is invalid, token_target_url is missing\")\n+\n     if extension_url.startswith(\"/\"):\n         _clean_extension_url_with_only_path(manifest_data, target, extension_url)\n     elif target == AppExtensionTarget.APP_PAGE:\n         msg = \"Url cannot start with protocol when target == APP_PAGE\"\n         logger.warning(msg)\n         raise ValidationError(msg)\n+    elif (target == AppExtensionTarget.NEW_TAB and new_tab_method_post) or (\n+        target == AppExtensionTarget.WIDGET and widget_method_post\n+    ):\n+        parsed_app_url = urlparse(app_url)\n+        parsed_extension_url = urlparse(extension_url)\n+\n+        if parsed_extension_url.scheme != \"https\" and settings.ENABLE_SSL:\n+            raise ValidationError(\"Extension must start with https\")\n+\n+        if parsed_app_url.hostname != parsed_extension_url.hostname:\n+            raise ValidationError(\"Extension URL must match App URL\")\n+\n     else:\n         _clean_app_url(extension_url)\n \n \n@@ -205,10 +234,44 @@\n             )\n         )\n \n \n+def _clean_extension_options(extension, errors):\n+    \"\"\"Validate the options field in an extension.\"\"\"\n+    options = extension.get(\"options\", {})\n+    try:\n+        validated_options = AppExtensionOptions.model_validate(options)\n+\n+        if (\n+            validated_options.widget_target\n+            and extension.get(\"target\") != AppExtensionTarget.WIDGET\n+        ):\n+            raise ValidationError(\n+                \"widgetTarget options must be set only on WIDGET target\"\n+            )\n+\n+        if (\n+            validated_options.new_tab_target\n+            and extension.get(\"target\") != AppExtensionTarget.NEW_TAB\n+        ):\n+            raise ValidationError(\n+                \"newTabTarget options must be set only on NEW_TAB target\"\n+            )\n+\n+        # Update the extension with the validated options\n+        extension[\"options\"] = validated_options.model_dump(exclude_none=True)\n+    except (ValidationError, PydanticValidationError) as e:\n+        errors[\"extensions\"].append(\n+            ValidationError(\n+                f\"Invalid options field: {str(e)}\",\n+                code=AppErrorCode.INVALID.value,\n+            )\n+        )\n+\n+\n def _clean_extensions(manifest_data, app_permissions, errors):\n     extensions = manifest_data.get(\"extensions\", [])\n+\n     for extension in extensions:\n         if \"target\" not in extension:\n             extension[\"target\"] = AppExtensionTarget.POPUP\n         else:\n@@ -227,9 +290,11 @@\n             )\n \n         _clean_extension_permissions(extension, app_permissions, errors)\n \n+        _clean_extension_options(extension, errors)\n \n+\n def _clean_webhooks(manifest_data, errors):\n     webhooks = manifest_data.get(\"webhooks\", [])\n \n     async_types = {\n"
        },
        {
          "path": "saleor/app/migrations/0032_appextension_http_target_method_and_more.py",
          "status": "added",
          "diff": "Index: saleor/app/migrations/0032_appextension_http_target_method_and_more.py\n===================================================================\n--- saleor/app/migrations/0032_appextension_http_target_method_and_more.py\t7d97544 (parent)\n+++ saleor/app/migrations/0032_appextension_http_target_method_and_more.py\tb546041 (commit)\n@@ -0,0 +1,124 @@\n+# Generated by Django 5.2.1 on 2025-06-13 10:02\n+\n+from django.db import migrations, models\n+\n+\n+class Migration(migrations.Migration):\n+    dependencies = [\n+        (\"app\", \"0031_alter_appextension_mount_alter_appextension_target\"),\n+    ]\n+\n+    operations = [\n+        migrations.AddField(\n+            model_name=\"appextension\",\n+            name=\"http_target_method\",\n+            field=models.CharField(\n+                choices=[(\"GET\", \"GET\"), (\"POST\", \"POST\")], null=True\n+            ),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"appextension\",\n+            name=\"mount\",\n+            field=models.CharField(\n+                choices=[\n+                    (\"category_overview_create\", \"category_overview_create\"),\n+                    (\n+                        \"category_overview_more_actions\",\n+                        \"category_overview_more_actions\",\n+                    ),\n+                    (\"category_details_more_actions\", \"category_details_more_actions\"),\n+                    (\"collection_overview_create\", \"collection_overview_create\"),\n+                    (\n+                        \"collection_overview_more_actions\",\n+                        \"collection_overview_more_actions\",\n+                    ),\n+                    (\n+                        \"collection_details_more_actions\",\n+                        \"collection_details_more_actions\",\n+                    ),\n+                    (\"collection_details_widgets\", \"collection_details_widgets\"),\n+                    (\"gift_card_overview_create\", \"gift_card_overview_create\"),\n+                    (\n+                        \"gift_card_overview_more_actions\",\n+                        \"gift_card_overview_more_actions\",\n+                    ),\n+                    (\n+                        \"gift_card_details_more_actions\",\n+                        \"gift_card_details_more_actions\",\n+                    ),\n+                    (\"gift_card_details_widgets\", \"gift_card_details_widgets\"),\n+                    (\"customer_overview_create\", \"customer_overview_create\"),\n+                    (\n+                        \"customer_overview_more_actions\",\n+                        \"customer_overview_more_actions\",\n+                    ),\n+                    (\"customer_details_more_actions\", \"customer_details_more_actions\"),\n+                    (\"customer_details_widgets\", \"customer_details_widgets\"),\n+                    (\"product_overview_create\", \"product_overview_create\"),\n+                    (\"product_overview_more_actions\", \"product_overview_more_actions\"),\n+                    (\"product_details_more_actions\", \"product_details_more_actions\"),\n+                    (\"product_details_widgets\", \"product_details_widgets\"),\n+                    (\"navigation_catalog\", \"navigation_catalog\"),\n+                    (\"navigation_orders\", \"navigation_orders\"),\n+                    (\"navigation_customers\", \"navigation_customers\"),\n+                    (\"navigation_discounts\", \"navigation_discounts\"),\n+                    (\"navigation_translations\", \"navigation_translations\"),\n+                    (\"navigation_pages\", \"navigation_pages\"),\n+                    (\"order_details_more_actions\", \"order_details_more_actions\"),\n+                    (\"order_overview_create\", \"order_overview_create\"),\n+                    (\"order_overview_more_actions\", \"order_overview_more_actions\"),\n+                    (\"order_details_widgets\", \"order_details_widgets\"),\n+                    (\n+                        \"draft_order_details_more_actions\",\n+                        \"draft_order_details_more_actions\",\n+                    ),\n+                    (\"draft_order_overview_create\", \"draft_order_overview_create\"),\n+                    (\n+                        \"draft_order_overview_more_actions\",\n+                        \"draft_order_overview_more_actions\",\n+                    ),\n+                    (\"draft_order_details_widgets\", \"draft_order_details_widgets\"),\n+                    (\"discount_details_more_actions\", \"discount_details_more_actions\"),\n+                    (\"discount_overview_create\", \"discount_overview_create\"),\n+                    (\n+                        \"discount_overview_more_actions\",\n+                        \"discount_overview_more_actions\",\n+                    ),\n+                    (\"voucher_details_more_actions\", \"voucher_details_more_actions\"),\n+                    (\"voucher_overview_create\", \"voucher_overview_create\"),\n+                    (\"voucher_overview_more_actions\", \"voucher_overview_more_actions\"),\n+                    (\"voucher_details_widgets\", \"voucher_details_widgets\"),\n+                    (\"page_details_more_actions\", \"page_details_more_actions\"),\n+                    (\"page_overview_create\", \"page_overview_create\"),\n+                    (\"page_overview_more_actions\", \"page_overview_more_actions\"),\n+                    (\"page_type_overview_create\", \"page_type_overview_create\"),\n+                    (\n+                        \"page_type_overview_more_actions\",\n+                        \"page_type_overview_more_actions\",\n+                    ),\n+                    (\n+                        \"page_type_details_more_actions\",\n+                        \"page_type_details_more_actions\",\n+                    ),\n+                    (\"menu_overview_create\", \"menu_overview_create\"),\n+                    (\"menu_overview_more_actions\", \"menu_overview_more_actions\"),\n+                    (\"menu_details_more_actions\", \"menu_details_more_actions\"),\n+                ],\n+                max_length=256,\n+            ),\n+        ),\n+        migrations.AlterField(\n+            model_name=\"appextension\",\n+            name=\"target\",\n+            field=models.CharField(\n+                choices=[\n+                    (\"popup\", \"popup\"),\n+                    (\"app_page\", \"app_page\"),\n+                    (\"new_tab\", \"new_tab\"),\n+                    (\"widget\", \"widget\"),\n+                ],\n+                default=\"popup\",\n+                max_length=128,\n+            ),\n+        ),\n+    ]\n"
        },
        {
          "path": "saleor/app/models.py",
          "status": "modified",
          "diff": "Index: saleor/app/models.py\n===================================================================\n--- saleor/app/models.py\t7d97544 (parent)\n+++ saleor/app/models.py\tb546041 (commit)\n@@ -10,9 +10,14 @@\n from ..core.models import Job, ModelWithMetadata\n from ..permission.enums import AppPermission, BasePermissionEnum\n from ..permission.models import Permission\n from ..webhook.event_types import WebhookEventAsyncType, WebhookEventSyncType\n-from .types import AppExtensionMount, AppExtensionTarget, AppType\n+from .types import (\n+    AppExtensionHttpMethod,\n+    AppExtensionMount,\n+    AppExtensionTarget,\n+    AppType,\n+)\n \n \n class AppQueryset(models.QuerySet[\"App\"]):\n     def for_event_type(self, event_type: str):\n@@ -162,8 +167,13 @@\n         Permission,\n         blank=True,\n         help_text=\"Specific permissions for this app extension.\",\n     )\n+    http_target_method = models.CharField(\n+        blank=False,\n+        null=True,\n+        choices=AppExtensionHttpMethod.CHOICES,\n+    )\n \n \n class AppInstallation(Job):\n     uuid = models.UUIDField(unique=True, default=uuid4)\n"
        },
        {
          "path": "saleor/app/tests/test_installation_utils.py",
          "status": "modified",
          "diff": "Index: saleor/app/tests/test_installation_utils.py\n===================================================================\n--- saleor/app/tests/test_installation_utils.py\t7d97544 (parent)\n+++ saleor/app/tests/test_installation_utils.py\tb546041 (commit)\n@@ -273,15 +273,17 @@\n ):\n     # given\n     label = \"Create product with app\"\n     url = \"http://127.0.0.1:8080/app-extension\"\n+    options: dict = {}\n     app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\", \"MANAGE_ORDERS\"]\n     app_manifest[\"extensions\"] = [\n         {\n             \"label\": label,\n             \"url\": url,\n             \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n             \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"options\": options,\n         }\n     ]\n     mocked_get_response = Mock()\n     mocked_get_response.json.return_value = app_manifest\n@@ -304,10 +306,59 @@\n     assert app_extension.url == url\n     assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n     assert app_extension.target == AppExtensionTarget.POPUP\n     assert list(app_extension.permissions.all()) == [permission_manage_products]\n+    assert app_extension.http_target_method is None\n \n \n+def test_install_app_with_extension_widget(\n+    app_manifest,\n+    app_installation,\n+    monkeypatch,\n+    permission_manage_products,\n+    permission_manage_orders,\n+):\n+    # given\n+    label = \"Create product with app\"\n+    url = \"https://example.com/app-extension\"\n+    options = {\"widgetTarget\": {\"method\": \"POST\"}}\n+    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\", \"MANAGE_ORDERS\"]\n+    app_manifest[\"tokenTargetUrl\"] = \"https://example.com/install\"\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"label\": label,\n+            \"url\": url,\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"target\": \"WIDGET\",\n+            \"options\": options,\n+        }\n+    ]\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n+\n+    app_installation.permissions.set(\n+        [permission_manage_products, permission_manage_orders]\n+    )\n+\n+    # when\n+    app, _ = install_app(app_installation, activate=True)\n+\n+    # then\n+    assert App.objects.get().id == app.id\n+    app_extension = app.extensions.get()\n+\n+    assert app_extension.label == label\n+    assert app_extension.url == url\n+    assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n+    assert app_extension.target == AppExtensionTarget.WIDGET\n+    assert list(app_extension.permissions.all()) == [permission_manage_products]\n+    assert app_extension.http_target_method == \"POST\"\n+\n+\n @pytest.mark.parametrize(\n     (\"app_permissions\", \"extension_permissions\"),\n     [\n         ([], [\"MANAGE_PRODUCTS\"]),\n@@ -344,8 +395,128 @@\n     with pytest.raises(ValidationError):\n         install_app(app_installation, activate=True)\n \n \n+def test_install_app_with_extension_new_tab_target(\n+    app_manifest,\n+    app_installation,\n+    monkeypatch,\n+    permission_manage_products,\n+):\n+    # given\n+    label = \"Open in new tab\"\n+    url = \"http://127.0.0.1:8080/app-extension\"\n+    options = {\"newTabTarget\": {\"method\": \"GET\"}}\n+    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"label\": label,\n+            \"url\": url,\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"options\": options,\n+            \"target\": \"NEW_TAB\",\n+        }\n+    ]\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n+\n+    app_installation.permissions.set([permission_manage_products])\n+\n+    # when\n+    app, _ = install_app(app_installation, activate=True)\n+\n+    # then\n+    assert App.objects.get().id == app.id\n+    app_extension = app.extensions.get()\n+    assert app_extension.label == label\n+    assert app_extension.url == url\n+    assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n+    assert app_extension.target == \"new_tab\"\n+    assert list(app_extension.permissions.all()) == [permission_manage_products]\n+    assert app_extension.http_target_method == \"GET\"\n+\n+\n+def test_install_app_with_extension_new_tab_target_post_url_non_https(\n+    app_manifest,\n+    app_installation,\n+    monkeypatch,\n+    permission_manage_products,\n+):\n+    # given\n+    label = \"Open in new tab\"\n+    # Non-https url is prohibited\n+    url = \"http://extenal-url.com\"\n+    options = {\"newTabTarget\": {\"method\": \"POST\"}}\n+    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"label\": label,\n+            \"url\": url,\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"options\": options,\n+            \"target\": \"NEW_TAB\",\n+        }\n+    ]\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n+\n+    app_installation.permissions.set([permission_manage_products])\n+\n+    # when\n+    # then\n+    with pytest.raises(ValidationError) as error:\n+        app, _ = install_app(app_installation, activate=True)\n+\n+    assert error.value.messages[0] == \"Incorrect value for field: url.\"\n+\n+\n+def test_install_app_with_extension_new_tab_target_post_url_other_than_app(\n+    app_manifest,\n+    app_installation,\n+    monkeypatch,\n+    permission_manage_products,\n+):\n+    # given\n+    label = \"Open in new tab\"\n+    # Url other than app's URL is prohibited\n+    url = \"https://extenal-url.com\"\n+    app_manifest[\"tokenTargetUrl\"] = \"https://app-url.com\"\n+    options = {\"newTabTarget\": {\"method\": \"POST\"}}\n+    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"label\": label,\n+            \"url\": url,\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"options\": options,\n+            \"target\": \"NEW_TAB\",\n+        }\n+    ]\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n+\n+    app_installation.permissions.set([permission_manage_products])\n+\n+    # when\n+    # then\n+    with pytest.raises(ValidationError) as error:\n+        app, _ = install_app(app_installation, activate=True)\n+\n+    assert error.value.messages[0] == \"Incorrect value for field: url.\"\n+\n+\n @pytest.mark.parametrize(\n     \"url\",\n     [\n         \"http:/127.0.0.1:8080/app\",\n@@ -451,8 +622,92 @@\n     with pytest.raises(ValidationError):\n         install_app(app_installation, activate=True)\n \n \n+@pytest.mark.parametrize(\n+    \"incorrect_options\",\n+    [\n+        {\"newTabTarget\": {\"method\": \"INVALID\"}},\n+        {\"newTabTarget\": {}},\n+        {\"newTabTarget\": \"invalid\"},\n+        {\"widgetTarget\": {\"method\": \"INVALID\"}},\n+        {\"widgetTarget\": {}},\n+        {\"widgetTarget\": \"invalid\"},\n+    ],\n+)\n+def test_install_app_extension_incorrect_options(\n+    incorrect_options, app_manifest, app_installation, monkeypatch\n+):\n+    # given\n+    label = \"Create product with app\"\n+    url = \"http://127.0.0.1:8080/app-extension\"\n+    app_manifest[\"permissions\"] = []\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"label\": label,\n+            \"url\": url,\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"target\": \"POPUP\",\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"options\": incorrect_options,\n+        }\n+    ]\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n+\n+    # when & then\n+    with pytest.raises(ValidationError):\n+        install_app(app_installation, activate=True)\n+\n+\n+def test_install_app_with_extension_post_method(\n+    app_manifest,\n+    app_installation,\n+    monkeypatch,\n+    permission_manage_products,\n+):\n+    # given\n+    label = \"Create product with app\"\n+    url = \"https://example.com/extension\"  # extension url must be under the same origin as app\n+    options = {\"newTabTarget\": {\"method\": \"POST\"}}\n+    app_manifest[\"tokenTargetUrl\"] = \"https://example.com/install\"\n+    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"label\": label,\n+            \"url\": url,\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"options\": options,\n+            \"target\": \"NEW_TAB\",\n+        }\n+    ]\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n+\n+    app_installation.permissions.set([permission_manage_products])\n+\n+    # when\n+    app, _ = install_app(app_installation, activate=True)\n+\n+    # then\n+    assert App.objects.get().id == app.id\n+    app_extension = app.extensions.get()\n+\n+    assert app_extension.label == label\n+    assert app_extension.url == url\n+    assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n+    assert app_extension.target == AppExtensionTarget.NEW_TAB\n+    assert list(app_extension.permissions.all()) == [permission_manage_products]\n+    assert app_extension.http_target_method == \"POST\"\n+\n+\n def test_install_app_with_webhook(\n     app_manifest, app_manifest_webhook, app_installation, monkeypatch\n ):\n     # given\n"
        },
        {
          "path": "saleor/app/tests/test_validators.py",
          "status": "modified",
          "diff": "Index: saleor/app/tests/test_validators.py\n===================================================================\n--- saleor/app/tests/test_validators.py\t7d97544 (parent)\n+++ saleor/app/tests/test_validators.py\tb546041 (commit)\n@@ -1,12 +1,16 @@\n import pytest\n from django.core.exceptions import ValidationError\n \n from ... import __version__\n-from ...app.validators import AppURLValidator\n+from ...app.validators import (\n+    AppExtensionOptions,\n+    AppURLValidator,\n+)\n from ..error_codes import AppErrorCode\n from ..manifest_validations import (\n     _clean_author,\n+    _clean_extension_options,\n     _clean_extension_url,\n     _clean_required_saleor_version,\n     _parse_version,\n )\n@@ -102,4 +106,302 @@\n     with pytest.raises(ValidationError) as error:\n         _clean_extension_url(extension, app_manifest)\n \n     assert error.value.message == \"NEW_TAB target should be absolute path\"\n+\n+\n+@pytest.mark.parametrize(\n+    (\"extension\", \"manifest\", \"should_raise\"),\n+    [\n+        # url starts with /, target APP_PAGE, appUrl provided\n+        (\n+            {\"url\": \"/page\", \"target\": AppExtensionTarget.APP_PAGE},\n+            {\n+                \"tokenTargetUrl\": \"https://app.example.com\",\n+                \"appUrl\": \"https://app.example.com\",\n+            },\n+            False,\n+        ),\n+        # url starts with /, target NEW_TAB, should raise\n+        (\n+            {\"url\": \"/tab\", \"target\": AppExtensionTarget.NEW_TAB},\n+            {\n+                \"tokenTargetUrl\": \"https://app.example.com\",\n+                \"appUrl\": \"https://app.example.com\",\n+            },\n+            True,\n+        ),\n+        # url starts with protocol, target APP_PAGE, should raise\n+        (\n+            {\n+                \"url\": \"https://app.example.com/page\",\n+                \"target\": AppExtensionTarget.APP_PAGE,\n+            },\n+            {\"tokenTargetUrl\": \"https://app.example.com\"},\n+            True,\n+        ),\n+        # url starts with protocol, target NEW_TAB, method POST, valid host\n+        (\n+            {\n+                \"url\": \"https://app.example.com/page\",\n+                \"target\": AppExtensionTarget.NEW_TAB,\n+                \"options\": {\"newTabTarget\": {\"method\": \"POST\"}},\n+            },\n+            {\"tokenTargetUrl\": \"https://app.example.com\"},\n+            False,\n+        ),\n+        # url starts with protocol, target NEW_TAB, method POST, invalid host\n+        (\n+            {\n+                \"url\": \"https://other.com/page\",\n+                \"target\": AppExtensionTarget.NEW_TAB,\n+                \"options\": {\"newTabTarget\": {\"method\": \"POST\"}},\n+            },\n+            {\"tokenTargetUrl\": \"https://app.example.com\"},\n+            True,\n+        ),\n+        # url is valid absolute, target POPUP\n+        (\n+            {\"url\": \"https://app.example.com/page\", \"target\": AppExtensionTarget.POPUP},\n+            {\"tokenTargetUrl\": \"https://app.example.com\"},\n+            False,\n+        ),\n+    ],\n+)\n+def test_clean_extension_url(extension, manifest, should_raise):\n+    if should_raise:\n+        with pytest.raises(ValidationError):\n+            _clean_extension_url(extension, manifest)\n+\n+    else:\n+        _clean_extension_url(extension, manifest)\n+\n+\n+def test_clean_extension_url_https_only(settings):\n+    settings.ENABLE_SSL = True\n+\n+    with pytest.raises(ValidationError):\n+        _clean_extension_url(\n+            {\n+                \"url\": \"http://app.example.com/page\",\n+                \"target\": AppExtensionTarget.NEW_TAB,\n+                \"options\": {\"newTabTarget\": {\"method\": \"POST\"}},\n+            },\n+            {\n+                \"tokenTargetUrl\": \"https://app.example.com\",\n+                \"appUrl\": \"https://app.example.com\",\n+            },\n+        )\n+\n+\n+def test_clean_extension_url_http_if_SSL_disabled(settings):\n+    settings.ENABLE_SSL = False\n+\n+    result = _clean_extension_url(\n+        {\"url\": \"http://app.example.com/page\", \"target\": AppExtensionTarget.NEW_TAB},\n+        {\n+            \"tokenTargetUrl\": \"https://app.example.com\",\n+            \"appUrl\": \"https://app.example.com\",\n+        },\n+    )\n+\n+    assert result is None\n+\n+\n+def test_app_extension_options_accepts_only_one():\n+    parsed = AppExtensionOptions().model_validate({\"widgetTarget\": {\"method\": \"GET\"}})\n+\n+    assert parsed.new_tab_target is None\n+    assert parsed.widget_target is not None\n+\n+    parsed = AppExtensionOptions().model_validate({\"newTabTarget\": {\"method\": \"GET\"}})\n+\n+    assert parsed.new_tab_target is not None\n+    assert parsed.widget_target is None\n+\n+    with pytest.raises(\n+        ValueError, match=\"Only one of 'newTabTarget' or 'widgetTarget' can be set.\"\n+    ):\n+        AppExtensionOptions.model_validate(\n+            {\n+                \"newTabTarget\": {\"method\": \"GET\"},\n+                \"widgetTarget\": {\"method\": \"GET\"},\n+            }\n+        )\n+\n+    parsed = AppExtensionOptions().model_validate({})\n+\n+    assert parsed.new_tab_target is None\n+    assert parsed.widget_target is None\n+\n+\n+@pytest.mark.parametrize(\n+    (\"app_url\", \"extension_url\", \"should_raise\"),\n+    [\n+        (None, \"/some-path\", True),  # Test missing token_target_url\n+        (\"https://example.com\", \"/some-path\", False),  # Test valid token_target_url\n+    ],\n+)\n+def test_clean_extension_url_token_target_url(app_url, extension_url, should_raise):\n+    # Given\n+    extension = {\"url\": extension_url, \"target\": \"APP_PAGE\"}\n+    manifest_data = {\"tokenTargetUrl\": app_url, \"appUrl\": \"https://example.com\"}\n+\n+    # When & Then\n+    if should_raise:\n+        with pytest.raises(ValidationError, match=\"token_target_url is missing\"):\n+            _clean_extension_url(extension, manifest_data)\n+    else:\n+        # Should not raise ValidationError\n+        _clean_extension_url(extension, manifest_data)\n+\n+\n+def test_clean_extension_options_valid_widget_options():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.WIDGET,\n+        \"options\": {\"widgetTarget\": {\"method\": \"POST\"}},\n+    }\n+    errors = {\"extensions\": []}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" in errors\n+    assert len(errors[\"extensions\"]) == 0\n+    assert \"options\" in extension\n+    assert \"widget_target\" in extension[\"options\"]\n+    assert extension[\"options\"][\"widget_target\"][\"method\"] == \"POST\"\n+\n+\n+def test_clean_extension_options_valid_new_tab_options():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.NEW_TAB,\n+        \"options\": {\"newTabTarget\": {\"method\": \"GET\"}},\n+    }\n+    errors = {\"extensions\": []}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" in errors\n+    assert len(errors[\"extensions\"]) == 0\n+    assert \"options\" in extension\n+    assert \"new_tab_target\" in extension[\"options\"]\n+    assert extension[\"options\"][\"new_tab_target\"][\"method\"] == \"GET\"\n+\n+\n+def test_clean_extension_options_both_targets():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.NEW_TAB,\n+        \"options\": {\n+            \"newTabTarget\": {\"method\": \"GET\"},\n+            \"widgetTarget\": {\"method\": \"POST\"},\n+        },\n+    }\n+    errors = {\"extensions\": []}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" in errors\n+    assert len(errors[\"extensions\"]) == 1\n+    assert (\n+        \"Only one of 'newTabTarget' or 'widgetTarget'\"\n+        in errors[\"extensions\"][0].message\n+    )\n+\n+\n+def test_clean_extension_options_widget_target_with_wrong_target():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.NEW_TAB,\n+        \"options\": {\"widgetTarget\": {\"method\": \"POST\"}},\n+    }\n+    errors = {\"extensions\": []}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" in errors\n+    assert len(errors[\"extensions\"]) == 1\n+    assert (\n+        \"widgetTarget options must be set only on WIDGET target\"\n+        in errors[\"extensions\"][0].message\n+    )\n+\n+\n+def test_clean_extension_options_new_tab_target_with_wrong_target():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.WIDGET,\n+        \"options\": {\"newTabTarget\": {\"method\": \"GET\"}},\n+    }\n+    errors = {\"extensions\": []}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" in errors\n+    assert len(errors[\"extensions\"]) == 1\n+    assert (\n+        \"newTabTarget options must be set only on NEW_TAB target\"\n+        in errors[\"extensions\"][0].message\n+    )\n+\n+\n+def test_clean_extension_options_invalid_options():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.WIDGET,\n+        \"options\": {\n+            \"widgetTarget\": {\n+                \"method\": \"INVALID_METHOD\"  # Only POST and GET are valid\n+            }\n+        },\n+    }\n+    errors = {\"extensions\": []}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" in errors\n+    assert len(errors[\"extensions\"]) == 1\n+    assert \"Invalid options field\" in errors[\"extensions\"][0].message\n+\n+\n+def test_clean_extension_options_empty():\n+    # Given\n+    extension = {\"target\": AppExtensionTarget.WIDGET, \"options\": {}}\n+    errors = {}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" not in errors\n+    assert \"options\" in extension\n+    assert extension[\"options\"] == {}\n+\n+\n+def test_clean_extension_options_no_options():\n+    # Given\n+    extension = {\n+        \"target\": AppExtensionTarget.WIDGET,\n+    }\n+    errors = {}\n+\n+    # When\n+    _clean_extension_options(extension, errors)\n+\n+    # Then\n+    assert \"extensions\" not in errors\n+    assert \"options\" in extension\n+    assert extension[\"options\"] == {}\n"
        },
        {
          "path": "saleor/app/types.py",
          "status": "modified",
          "diff": "Index: saleor/app/types.py\n===================================================================\n--- saleor/app/types.py\t7d97544 (parent)\n+++ saleor/app/types.py\tb546041 (commit)\n@@ -14,20 +14,24 @@\n \n     COLLECTION_OVERVIEW_CREATE = \"collection_overview_create\"\n     COLLECTION_OVERVIEW_MORE_ACTIONS = \"collection_overview_more_actions\"\n     COLLECTION_DETAILS_MORE_ACTIONS = \"collection_details_more_actions\"\n+    COLLECTION_DETAILS_WIDGETS = \"collection_details_widgets\"\n \n     GIFT_CARD_OVERVIEW_CREATE = \"gift_card_overview_create\"\n     GIFT_CARD_OVERVIEW_MORE_ACTIONS = \"gift_card_overview_more_actions\"\n     GIFT_CARD_DETAILS_MORE_ACTIONS = \"gift_card_details_more_actions\"\n+    GIFT_CARD_DETAILS_WIDGETS = \"gift_card_details_widgets\"\n \n     CUSTOMER_OVERVIEW_CREATE = \"customer_overview_create\"\n     CUSTOMER_OVERVIEW_MORE_ACTIONS = \"customer_overview_more_actions\"\n     CUSTOMER_DETAILS_MORE_ACTIONS = \"customer_details_more_actions\"\n+    CUSTOMER_DETAILS_WIDGETS = \"customer_details_widgets\"\n \n     PRODUCT_OVERVIEW_CREATE = \"product_overview_create\"\n     PRODUCT_OVERVIEW_MORE_ACTIONS = \"product_overview_more_actions\"\n     PRODUCT_DETAILS_MORE_ACTIONS = \"product_details_more_actions\"\n+    PRODUCT_DETAILS_WIDGETS = \"product_details_widgets\"\n \n     NAVIGATION_CATALOG = \"navigation_catalog\"\n     NAVIGATION_ORDERS = \"navigation_orders\"\n     NAVIGATION_CUSTOMERS = \"navigation_customers\"\n@@ -37,20 +41,23 @@\n \n     ORDER_DETAILS_MORE_ACTIONS = \"order_details_more_actions\"\n     ORDER_OVERVIEW_CREATE = \"order_overview_create\"\n     ORDER_OVERVIEW_MORE_ACTIONS = \"order_overview_more_actions\"\n+    ORDER_DETAILS_WIDGETS = \"order_details_widgets\"\n \n     DRAFT_ORDER_DETAILS_MORE_ACTIONS = \"draft_order_details_more_actions\"\n     DRAFT_ORDER_OVERVIEW_CREATE = \"draft_order_overview_create\"\n     DRAFT_ORDER_OVERVIEW_MORE_ACTIONS = \"draft_order_overview_more_actions\"\n+    DRAFT_ORDER_DETAILS_WIDGETS = \"draft_order_details_widgets\"\n \n     DISCOUNT_DETAILS_MORE_ACTIONS = \"discount_details_more_actions\"\n     DISCOUNT_OVERVIEW_CREATE = \"discount_overview_create\"\n     DISCOUNT_OVERVIEW_MORE_ACTIONS = \"discount_overview_more_actions\"\n \n     VOUCHER_DETAILS_MORE_ACTIONS = \"voucher_details_more_actions\"\n     VOUCHER_OVERVIEW_CREATE = \"voucher_overview_create\"\n     VOUCHER_OVERVIEW_MORE_ACTIONS = \"voucher_overview_more_actions\"\n+    VOUCHER_DETAILS_WIDGETS = \"voucher_details_widgets\"\n \n     PAGE_DETAILS_MORE_ACTIONS = \"page_details_more_actions\"\n     PAGE_OVERVIEW_CREATE = \"page_overview_create\"\n     PAGE_OVERVIEW_MORE_ACTIONS = \"page_overview_more_actions\"\n@@ -69,17 +76,21 @@\n         (CATEGORY_DETAILS_MORE_ACTIONS, \"category_details_more_actions\"),\n         (COLLECTION_OVERVIEW_CREATE, \"collection_overview_create\"),\n         (COLLECTION_OVERVIEW_MORE_ACTIONS, \"collection_overview_more_actions\"),\n         (COLLECTION_DETAILS_MORE_ACTIONS, \"collection_details_more_actions\"),\n+        (COLLECTION_DETAILS_WIDGETS, \"collection_details_widgets\"),\n         (GIFT_CARD_OVERVIEW_CREATE, \"gift_card_overview_create\"),\n         (GIFT_CARD_OVERVIEW_MORE_ACTIONS, \"gift_card_overview_more_actions\"),\n         (GIFT_CARD_DETAILS_MORE_ACTIONS, \"gift_card_details_more_actions\"),\n+        (GIFT_CARD_DETAILS_WIDGETS, \"gift_card_details_widgets\"),\n         (CUSTOMER_OVERVIEW_CREATE, \"customer_overview_create\"),\n         (CUSTOMER_OVERVIEW_MORE_ACTIONS, \"customer_overview_more_actions\"),\n         (CUSTOMER_DETAILS_MORE_ACTIONS, \"customer_details_more_actions\"),\n+        (CUSTOMER_DETAILS_WIDGETS, \"customer_details_widgets\"),\n         (PRODUCT_OVERVIEW_CREATE, \"product_overview_create\"),\n         (PRODUCT_OVERVIEW_MORE_ACTIONS, \"product_overview_more_actions\"),\n         (PRODUCT_DETAILS_MORE_ACTIONS, \"product_details_more_actions\"),\n+        (PRODUCT_DETAILS_WIDGETS, \"product_details_widgets\"),\n         (NAVIGATION_CATALOG, \"navigation_catalog\"),\n         (NAVIGATION_ORDERS, \"navigation_orders\"),\n         (NAVIGATION_CUSTOMERS, \"navigation_customers\"),\n         (NAVIGATION_DISCOUNTS, \"navigation_discounts\"),\n@@ -87,17 +98,20 @@\n         (NAVIGATION_PAGES, \"navigation_pages\"),\n         (ORDER_DETAILS_MORE_ACTIONS, \"order_details_more_actions\"),\n         (ORDER_OVERVIEW_CREATE, \"order_overview_create\"),\n         (ORDER_OVERVIEW_MORE_ACTIONS, \"order_overview_more_actions\"),\n+        (ORDER_DETAILS_WIDGETS, \"order_details_widgets\"),\n         (DRAFT_ORDER_DETAILS_MORE_ACTIONS, \"draft_order_details_more_actions\"),\n         (DRAFT_ORDER_OVERVIEW_CREATE, \"draft_order_overview_create\"),\n         (DRAFT_ORDER_OVERVIEW_MORE_ACTIONS, \"draft_order_overview_more_actions\"),\n+        (DRAFT_ORDER_DETAILS_WIDGETS, \"draft_order_details_widgets\"),\n         (DISCOUNT_DETAILS_MORE_ACTIONS, \"discount_details_more_actions\"),\n         (DISCOUNT_OVERVIEW_CREATE, \"discount_overview_create\"),\n         (DISCOUNT_OVERVIEW_MORE_ACTIONS, \"discount_overview_more_actions\"),\n         (VOUCHER_DETAILS_MORE_ACTIONS, \"voucher_details_more_actions\"),\n         (VOUCHER_OVERVIEW_CREATE, \"voucher_overview_create\"),\n         (VOUCHER_OVERVIEW_MORE_ACTIONS, \"voucher_overview_more_actions\"),\n+        (VOUCHER_DETAILS_WIDGETS, \"voucher_details_widgets\"),\n         (PAGE_DETAILS_MORE_ACTIONS, \"page_details_more_actions\"),\n         (PAGE_OVERVIEW_CREATE, \"page_overview_create\"),\n         (PAGE_OVERVIEW_MORE_ACTIONS, \"page_overview_more_actions\"),\n         (PAGE_TYPE_OVERVIEW_CREATE, \"page_type_overview_create\"),\n@@ -118,6 +132,24 @@\n \n     POPUP = \"popup\"\n     APP_PAGE = \"app_page\"\n     NEW_TAB = \"new_tab\"\n+    WIDGET = \"widget\"\n \n-    CHOICES = [(POPUP, \"popup\"), (APP_PAGE, \"app_page\"), (NEW_TAB, \"new_tab\")]\n+    CHOICES = [\n+        (POPUP, \"popup\"),\n+        (APP_PAGE, \"app_page\"),\n+        (NEW_TAB, \"new_tab\"),\n+        (WIDGET, \"widget\"),\n+    ]\n+\n+\n+class AppExtensionHttpMethod:\n+    \"\"\"HTTP methods available for app extensions.\n+\n+    Represents available HTTPS methods for frontend to work with extension (WIDGET and NEW_TAB)\n+    \"\"\"\n+\n+    GET = \"GET\"\n+    POST = \"POST\"\n+\n+    CHOICES = [(\"GET\", \"GET\"), (\"POST\", \"POST\")]\n"
        },
        {
          "path": "saleor/app/validators.py",
          "status": "modified",
          "diff": "Index: saleor/app/validators.py\n===================================================================\n--- saleor/app/validators.py\t7d97544 (parent)\n+++ saleor/app/validators.py\tb546041 (commit)\n@@ -1,12 +1,15 @@\n import mimetypes\n import re\n+from typing import Annotated, Literal\n \n from django.core.exceptions import ValidationError\n from django.core.validators import URLValidator\n+from pydantic import BaseModel, Field, field_validator, model_validator\n \n from ..thumbnail import ICON_MIME_TYPES\n from .error_codes import AppErrorCode\n+from .types import AppExtensionHttpMethod\n \n \n class AppURLValidator(URLValidator):\n     validator = URLValidator\n@@ -43,4 +46,59 @@\n         raise ValidationError(\n             \"Invalid file type for field: logo.default.\",\n             code=AppErrorCode.INVALID_URL_FORMAT.value,\n         )\n+\n+\n+def validate_POST_or_GET_http_method(value):\n+    \"\"\"Validate that the HTTP method is either GET or POST.\"\"\"\n+    if value not in [\n+        AppExtensionHttpMethod.GET,\n+        AppExtensionHttpMethod.POST,\n+    ]:\n+        raise ValueError(\n+            f\"Method must be either {AppExtensionHttpMethod.GET} or {AppExtensionHttpMethod.POST}\"\n+        )\n+    return value\n+\n+\n+class NewTabTargetOptions(BaseModel):\n+    method: Literal[\"GET\", \"POST\"]\n+\n+    @field_validator(\"method\")\n+    def validate_method(cls, value):\n+        return validate_POST_or_GET_http_method(value)\n+\n+\n+class WidgetTargetOptions(BaseModel):\n+    method: Literal[\"GET\", \"POST\"]\n+\n+    @field_validator(\"method\")\n+    def validate_method(cls, value):\n+        return validate_POST_or_GET_http_method(value)\n+\n+\n+class AppExtensionOptions(BaseModel):\n+    new_tab_target: Annotated[\n+        NewTabTargetOptions | None,\n+        Field(\n+            validation_alias=\"newTabTarget\",\n+            description=\"Settings for extension target NEW_TAB\",\n+        ),\n+    ] = None\n+    widget_target: Annotated[\n+        WidgetTargetOptions | None,\n+        Field(\n+            validation_alias=\"widgetTarget\",\n+            description=\"Settings for extension target WIDGET\",\n+        ),\n+    ] = None\n+\n+    @model_validator(mode=\"after\")\n+    def validate_either_or(cls, values):\n+        new_tab = values.new_tab_target\n+        widget = values.widget_target\n+\n+        if new_tab and widget:\n+            raise ValueError(\"Only one of 'newTabTarget' or 'widgetTarget' can be set.\")\n+\n+        return values\n"
        },
        {
          "path": "saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py\n===================================================================\n--- saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py\t7d97544 (parent)\n+++ saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py\tb546041 (commit)\n@@ -438,9 +438,9 @@\n         (\"/app\", AppExtensionTargetEnum.APP_PAGE.name, \"\"),\n         (\"/app\", AppExtensionTargetEnum.APP_PAGE.name, \"https://www.example.com/app\"),\n         (\"/app\", AppExtensionTargetEnum.POPUP.name, \"https://www.example.com/app\"),\n         (\n-            \"https://app-absolute-url.com\",\n+            \"https://www.example.com/app/form\",\n             AppExtensionTargetEnum.NEW_TAB.name,\n             \"https://www.example.com/app\",\n         ),\n     ],\n"
        },
        {
          "path": "saleor/graphql/app/tests/queries/test_app_extension.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/queries/test_app_extension.py\n===================================================================\n--- saleor/graphql/app/tests/queries/test_app_extension.py\t7d97544 (parent)\n+++ saleor/graphql/app/tests/queries/test_app_extension.py\tb546041 (commit)\n@@ -1,8 +1,8 @@\n import graphene\n \n from .....app.models import AppExtension\n-from .....app.types import AppExtensionMount\n+from .....app.types import AppExtensionMount, AppExtensionTarget\n from .....core.jwt import jwt_decode\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n QUERY_APP_EXTENSION = \"\"\"\n@@ -16,8 +16,21 @@\n         accessToken\n         permissions{\n             code\n         }\n+        options {\n+          ... on AppExtensionOptionsWidget{\n+            widgetTarget {\n+              method\n+            }\n+          }\n+          ...on AppExtensionOptionsNewTab {\n+            newTabTarget{\n+              method\n+            }\n+          }\n+\n+        }\n     }\n }\n \"\"\"\n \n@@ -28,8 +41,10 @@\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n         mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        http_target_method=\"POST\",\n+        target=AppExtensionTarget.WIDGET,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -52,9 +67,11 @@\n     assert len(extension_data[\"permissions\"]) == 1\n     permission_code = extension_data[\"permissions\"][0][\"code\"].lower()\n     assert app_extension.permissions.first().codename == permission_code\n \n+    assert extension_data[\"options\"][\"widgetTarget\"][\"method\"] == \"POST\"\n \n+\n def test_app_extension_by_app(app, app_api_client, permission_manage_products):\n     # given\n     app_extension = AppExtension.objects.create(\n         app=app,\n"
        },
        {
          "path": "saleor/graphql/app/tests/queries/test_app_extensions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/queries/test_app_extensions.py\n===================================================================\n--- saleor/graphql/app/tests/queries/test_app_extensions.py\t7d97544 (parent)\n+++ saleor/graphql/app/tests/queries/test_app_extensions.py\tb546041 (commit)\n@@ -16,8 +16,21 @@\n         mount\n         target\n         id\n         accessToken\n+        options {\n+          ... on AppExtensionOptionsWidget{\n+            widgetTarget {\n+              method\n+            }\n+          }\n+          ...on AppExtensionOptionsNewTab {\n+            newTabTarget{\n+              method\n+            }\n+          }\n+\n+        }\n         permissions{\n           code\n         }\n       }\n@@ -33,8 +46,10 @@\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n         mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        http_target_method=\"POST\",\n+        target=AppExtensionTarget.WIDGET,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     variables = {}\n \n@@ -65,9 +80,11 @@\n     assert extension_data[\"accessToken\"]\n     decode_token = jwt_decode(extension_data[\"accessToken\"])\n     decode_token[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n \n+    assert extension_data[\"options\"][\"widgetTarget\"][\"method\"] == \"POST\"\n \n+\n def test_app_extensions_app_not_active(\n     staff_api_client, app, permission_manage_products\n ):\n     # given\n"
        },
        {
          "path": "saleor/graphql/app/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/types.py\n===================================================================\n--- saleor/graphql/app/types.py\t7d97544 (parent)\n+++ saleor/graphql/app/types.py\tb546041 (commit)\n@@ -3,9 +3,9 @@\n \n import graphene\n \n from ...app import models\n-from ...app.types import AppExtensionTarget\n+from ...app.types import AppExtensionHttpMethod, AppExtensionTarget\n from ...core.exceptions import PermissionDenied\n from ...core.jwt import JWT_THIRDPARTY_ACCESS_TYPE\n from ...core.utils import build_absolute_uri\n from ...permission.auth_filters import AuthorizationFilters\n@@ -26,13 +26,14 @@\n from ..core import ResolveInfo, SaleorContext\n from ..core.connection import CountableConnection\n from ..core.context import get_database_connection_name\n from ..core.dataloaders import DataLoader\n-from ..core.descriptions import ADDED_IN_319, ADDED_IN_321\n+from ..core.descriptions import ADDED_IN_319, ADDED_IN_321, ADDED_IN_322\n from ..core.doc_category import DOC_CATEGORY_APPS\n from ..core.federation import federated_entity, resolve_federation_references\n from ..core.scalars import DateTime\n from ..core.types import (\n+    BaseEnum,\n     BaseObjectType,\n     IconThumbnailField,\n     Job,\n     ModelObjectType,\n@@ -136,8 +137,66 @@\n         \"\"\"Return an extension URL.\"\"\"\n         return resolve_app_extension_url(root)\n \n \n+class HttpMethod(BaseEnum):\n+    POST = AppExtensionHttpMethod.POST\n+    GET = AppExtensionHttpMethod.GET\n+\n+\n+class NewTabTargetOptions(BaseObjectType):\n+    method = graphene.Field(\n+        HttpMethod,\n+        required=True,\n+        description=\"HTTP method for New Tab target (GET or POST)\",\n+    )\n+\n+    class Meta:\n+        description = \"Represents the NEW_TAB target options for an app extension.\"\n+        doc_category = DOC_CATEGORY_APPS\n+\n+\n+class WidgetTargetOptions(BaseObjectType):\n+    method = graphene.Field(\n+        HttpMethod,\n+        required=True,\n+        description=\"HTTP method for Widget target (GET or POST)\",\n+    )\n+\n+    class Meta:\n+        description = \"Represents the WIDGET target options for an app extension.\"\n+        doc_category = DOC_CATEGORY_APPS\n+\n+\n+class AppExtensionOptionsWidget(BaseObjectType):\n+    widget_target = graphene.Field(\n+        WidgetTargetOptions,\n+        description=\"Options for displaying a Widget\",\n+        required=False,\n+    )\n+\n+    class Meta:\n+        description = \"Represents the options for an app extension.\"\n+        doc_category = DOC_CATEGORY_APPS\n+\n+\n+class AppExtensionOptionsNewTab(BaseObjectType):\n+    new_tab_target = graphene.Field(\n+        NewTabTargetOptions,\n+        description=\"Options controlling behavior of the NEW_TAB extension target\",\n+        required=False,\n+    )\n+\n+    class Meta:\n+        description = \"Represents the options for an app extension.\"\n+        doc_category = DOC_CATEGORY_APPS\n+\n+\n+class AppExtensionPossibleOptions(graphene.Union):\n+    class Meta:\n+        types = (AppExtensionOptionsWidget, AppExtensionOptionsNewTab)\n+\n+\n class AppExtension(AppManifestExtension, ModelObjectType[models.AppExtension]):\n     id = graphene.GlobalID(required=True, description=\"The ID of the app extension.\")\n     app = graphene.Field(\n         \"saleor.graphql.app.types.App\",\n@@ -146,8 +205,12 @@\n     )\n     access_token = graphene.String(\n         description=\"JWT token used to authenticate by third-party app extension.\"\n     )\n+    options = graphene.Field(\n+        AppExtensionPossibleOptions,\n+        description=\"App extension options.\" + ADDED_IN_322,\n+    )\n \n     class Meta:\n         description = \"Represents app data.\"\n         interfaces = [graphene.relay.Node]\n@@ -200,9 +263,25 @@\n             return resolve_access_token_for_app_extension(info, root, app)\n \n         return AppByIdLoader(info.context).load(root.app_id).then(_resolve_access_token)\n \n+    @staticmethod\n+    def resolve_options(root: models.AppExtension, _info: ResolveInfo):\n+        http_method = root.http_target_method\n \n+        if root.target == AppExtensionTarget.WIDGET:\n+            return AppExtensionOptionsWidget(\n+                widget_target=WidgetTargetOptions(method=http_method),\n+            )\n+\n+        if root.target == AppExtensionTarget.NEW_TAB:\n+            return AppExtensionOptionsNewTab(\n+                new_tab_target=NewTabTargetOptions(method=http_method),\n+            )\n+\n+        return None\n+\n+\n class AppExtensionCountableConnection(CountableConnection):\n     class Meta:\n         doc_category = DOC_CATEGORY_APPS\n         node = AppExtension\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\t7d97544 (parent)\n+++ saleor/graphql/schema.graphql\tb546041 (commit)\n@@ -2941,8 +2941,15 @@\n   app: App!\n \n   \"\"\"JWT token used to authenticate by third-party app extension.\"\"\"\n   accessToken: String\n+\n+  \"\"\"\n+  App extension options.\n+  \n+  Added in Saleor 3.22.\n+  \"\"\"\n+  options: AppExtensionPossibleOptions\n }\n \n \"\"\"All places where app extension can be mounted.\"\"\"\n enum AppExtensionMountEnum @doc(category: \"Apps\") {\n@@ -2951,17 +2958,21 @@\n   CATEGORY_DETAILS_MORE_ACTIONS\n   COLLECTION_OVERVIEW_CREATE\n   COLLECTION_OVERVIEW_MORE_ACTIONS\n   COLLECTION_DETAILS_MORE_ACTIONS\n+  COLLECTION_DETAILS_WIDGETS\n   GIFT_CARD_OVERVIEW_CREATE\n   GIFT_CARD_OVERVIEW_MORE_ACTIONS\n   GIFT_CARD_DETAILS_MORE_ACTIONS\n+  GIFT_CARD_DETAILS_WIDGETS\n   CUSTOMER_OVERVIEW_CREATE\n   CUSTOMER_OVERVIEW_MORE_ACTIONS\n   CUSTOMER_DETAILS_MORE_ACTIONS\n+  CUSTOMER_DETAILS_WIDGETS\n   PRODUCT_OVERVIEW_CREATE\n   PRODUCT_OVERVIEW_MORE_ACTIONS\n   PRODUCT_DETAILS_MORE_ACTIONS\n+  PRODUCT_DETAILS_WIDGETS\n   NAVIGATION_CATALOG\n   NAVIGATION_ORDERS\n   NAVIGATION_CUSTOMERS\n   NAVIGATION_DISCOUNTS\n@@ -2969,17 +2980,20 @@\n   NAVIGATION_PAGES\n   ORDER_DETAILS_MORE_ACTIONS\n   ORDER_OVERVIEW_CREATE\n   ORDER_OVERVIEW_MORE_ACTIONS\n+  ORDER_DETAILS_WIDGETS\n   DRAFT_ORDER_DETAILS_MORE_ACTIONS\n   DRAFT_ORDER_OVERVIEW_CREATE\n   DRAFT_ORDER_OVERVIEW_MORE_ACTIONS\n+  DRAFT_ORDER_DETAILS_WIDGETS\n   DISCOUNT_DETAILS_MORE_ACTIONS\n   DISCOUNT_OVERVIEW_CREATE\n   DISCOUNT_OVERVIEW_MORE_ACTIONS\n   VOUCHER_DETAILS_MORE_ACTIONS\n   VOUCHER_OVERVIEW_CREATE\n   VOUCHER_OVERVIEW_MORE_ACTIONS\n+  VOUCHER_DETAILS_WIDGETS\n   PAGE_DETAILS_MORE_ACTIONS\n   PAGE_OVERVIEW_CREATE\n   PAGE_OVERVIEW_MORE_ACTIONS\n   PAGE_TYPE_OVERVIEW_CREATE\n@@ -2999,10 +3013,42 @@\n enum AppExtensionTargetEnum @doc(category: \"Apps\") {\n   POPUP\n   APP_PAGE\n   NEW_TAB\n+  WIDGET\n }\n \n+union AppExtensionPossibleOptions = AppExtensionOptionsWidget | AppExtensionOptionsNewTab\n+\n+\"\"\"Represents the options for an app extension.\"\"\"\n+type AppExtensionOptionsWidget @doc(category: \"Apps\") {\n+  \"\"\"Options for displaying a Widget\"\"\"\n+  widgetTarget: WidgetTargetOptions\n+}\n+\n+\"\"\"Represents the WIDGET target options for an app extension.\"\"\"\n+type WidgetTargetOptions @doc(category: \"Apps\") {\n+  \"\"\"HTTP method for Widget target (GET or POST)\"\"\"\n+  method: HttpMethod!\n+}\n+\n+enum HttpMethod {\n+  POST\n+  GET\n+}\n+\n+\"\"\"Represents the options for an app extension.\"\"\"\n+type AppExtensionOptionsNewTab @doc(category: \"Apps\") {\n+  \"\"\"Options controlling behavior of the NEW_TAB extension target\"\"\"\n+  newTabTarget: NewTabTargetOptions\n+}\n+\n+\"\"\"Represents the NEW_TAB target options for an app extension.\"\"\"\n+type NewTabTargetOptions @doc(category: \"Apps\") {\n+  \"\"\"HTTP method for New Tab target (GET or POST)\"\"\"\n+  method: HttpMethod!\n+}\n+\n \"\"\"Represents the app's brand data.\"\"\"\n type AppBrand @doc(category: \"Apps\") {\n   \"\"\"App's logos details.\"\"\"\n   logo: AppBrandLogo!\n"
        }
      ]
    },
    {
      "id": "extend-order-search",
      "sha": "4815c54985113204e8370c0d86451c89ad69ad65",
      "parentSha": "d7bef8c489af1c6006dd2faa6047a69e0bb9dd48",
      "spec": "- Extend order search coverage\n  - Update saleor/order/search.py:\n    - In prepare_order_search_vector_value(order, *, already_prefetched=False):\n      - Prefetch additional relations: \"invoices\" and \"events\", in addition to existing: \"user\", \"billing_address\", \"shipping_address\", \"payments\", \"discounts\", \"lines\", \"payment_transactions__events\".\n      - Build search_vectors including:\n        - Order number as string (weight A).\n        - Order GraphQL global ID (graphene.Node.to_global_id(\"Order\", order.id)) with weight A.\n        - Existing fields: user_email, user.email, user.first_name, user.last_name (weight A where applicable).\n        - Customer note content if present (weight B).\n        - Billing and shipping address vectors via generate_address_search_vector_value with weight B.\n        - External reference if present (weight B).\n        - Existing payments, discounts, lines, transactions vectors.\n        - New: up to settings.SEARCH_ORDERS_MAX_INDEXED_INVOICES most recent invoices (order by created_at desc), include GraphQL global IDs (Invoice) with weight D.\n        - New: up to settings.SEARCH_ORDERS_MAX_INDEXED_EVENTS most recent note-related order events (types NOTE_ADDED, NOTE_UPDATED), include parameters[\"message\"] values (weight D).\n    - Add helpers in the same module:\n      - generate_order_invoices_search_vector_value(order) that returns a list of NoValidationSearchVector with Invoice global IDs (weight D), limited by SEARCH_ORDERS_MAX_INDEXED_INVOICES.\n      - generate_order_events_search_vector_value(order) that filters note events (NOTE_ADDED, NOTE_UPDATED), extracts the message from parameters, and returns a list of NoValidationSearchVector (weight D), limited by SEARCH_ORDERS_MAX_INDEXED_EVENTS.\n    - Keep search_orders using SearchQuery(value, search_type=\"websearch\", config=\"simple\").\n- Refresh order search vector on side-effectful mutations\n  - saleor/graphql/invoice/mutations/invoice_create.py: After creating the invoice and emitting events, call update_order_search_vector(order) to refresh search_vector.\n  - saleor/graphql/invoice/mutations/invoice_delete.py: Use the order before permission check (order = invoice.order) and call update_order_search_vector(order) after deletion and event emission.\n  - saleor/graphql/order/mutations/order_note_add.py: After creating the note event and calling call_event_by_order_status, call update_order_search_vector(order).\n  - saleor/graphql/order/mutations/order_note_update.py: After updating the note event and calling call_event_by_order_status, call update_order_search_vector(order). Ensure the queryset used to fetch the event is restricted to NOTE_ADDED and NOTE_UPDATED types.\n- Improve order search backfill task for scalability and safety\n  - saleor/core/search_tasks.py:\n    - Define ORDER_BATCH_SIZE = 100.\n    - Change set_order_search_document_values signature to:\n      set_order_search_document_values(update_all: bool = False, database_connection_name: str = settings.DATABASE_CONNECTION_REPLICA_NAME, updated_count: int = 0, order_number: int = 0) -> None.\n    - If update_all is False, process only orders where search_vector is None; otherwise process orders with number >= order_number.\n    - Query only the next ORDER_BATCH_SIZE order numbers ordered by number asc from the specified database connection and log \"No orders to update.\" when none.\n    - In allow_writer() context, refetch the batch by number from the writer, prefetch all relations used by prepare_order_search_vector_value (including payment_transactions__events, invoices, events), order by pk.\n    - Wrap updates in transaction.atomic() and use select_for_update(of=([\"self\"])) on the batch queryset to lock the rows. Compute and bulk update search_vector using set_search_vector_values.\n    - Schedule the next batch with set_order_search_document_values.delay(update_all, database_connection_name, updated_count, order_number=last_number). Stop when the fetched numbers count is < ORDER_BATCH_SIZE.\n- Standardize account address search vectors\n  - saleor/account/search.py: In generate_address_search_vector_value(address, weight=\"A\"), pass config=\"simple\" to each NoValidationSearchVector instantiation (including the initial multi-value vector and all conditionally appended vectors such as company_name, country_area, city, city_area, street_address_2, postal_code, phone). Keep weight usage unchanged.\n- Add settings to cap indexing scope\n  - saleor/settings.py: Define SEARCH_ORDERS_MAX_INDEXED_INVOICES = 20 and SEARCH_ORDERS_MAX_INDEXED_EVENTS = 50 alongside existing SEARCH_ORDERS_ caps.\n- Backfill existing orders via migration\n  - Add a migration under saleor/order/migrations (depending on the latest order migration) that on post_migrate enqueues set_order_search_document_values.delay() to fill search_vector for existing orders. Use the order app config as sender to avoid running for other apps.\n- Tests and small fixes\n  - Move and expand order search tests from saleor/graphql/order/tests/queries/test_orders.py into a new module saleor/graphql/order/tests/queries/test_orders_search.py covering searches by: discounts (name/translated), emails and user names, combined name, empty string, payment PSP references, product SKU/name/variant name, order global ID, invoice global ID, note event messages, partial customer_note, billing/shipping address fields and country code/name, and external_reference (including partial matches). Ensure tests update orders' search_vector before assertions.\n  - In saleor/graphql/invoice/tests/test_invoice_create.py and test_invoice_delete.py, refresh the order from DB and assert order.search_vector is set after performing the mutation.\n  - In saleor/checkout/tests/test_checkout_complete.py, refresh the order from DB before event assertions in the affected tests to avoid stale data.\n- Changelog\n  - Update CHANGELOG.md to document the expanded order search: by order ID, invoice IDs, messages from order events, customer note content, and external reference.\n",
      "prompt": "Enhance the order search experience so staff can find orders using more signals. Extend the order search index to include the order’s global ID, invoice IDs, messages from note-related order events, customer note content, and the order’s external reference, in addition to the existing data points. Ensure the index is refreshed automatically when invoices are created or deleted and when order notes are added or updated. Make the background job that backfills order search indices robust and scalable by processing orders in small, ordered batches with row locks and by supporting both partial (missing only) and full updates. Standardize address-based search to use a simple text search configuration. Add settings to cap how many invoices and note events are indexed per order. Trigger a background reindex after migrations. Update and reorganize tests to cover the new search behaviors.",
      "supplementalFiles": [
        "saleor/core/postgres.py",
        "saleor/order/models.py",
        "saleor/order/events.py",
        "saleor/invoice/models.py",
        "saleor/graphql/order/mutations/order_note_common.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\td7bef8c (parent)\n+++ CHANGELOG.md\t4815c54 (commit)\n@@ -23,8 +23,14 @@\n     - Filter by order metadata.\n     - Filter by order by associated lines metadata.\n     - Filter by the product type of related order lines.\n - Extend the `Page` type with an `attribute` field. Adds support for querying a specific attribute on a page by `slug`, returning the matching attribute and its assigned values, or null if no match is found.\n+- Enhanced order search options. Orders can now be searched using:\n+  - The order's ID\n+  - IDs of invoices linked to the order\n+  - Messages from related order events\n+  - The content of customer note\n+  - The order external reference\n \n ### Webhooks\n \n ### Other changes\n"
        },
        {
          "path": "saleor/account/search.py",
          "status": "modified",
          "diff": "Index: saleor/account/search.py\n===================================================================\n--- saleor/account/search.py\td7bef8c (parent)\n+++ saleor/account/search.py\t4815c54 (commit)\n@@ -71,38 +71,53 @@\n             Value(address.last_name),\n             Value(address.street_address_1),\n             Value(address.country.name),\n             Value(address.country.code),\n+            config=\"simple\",\n             weight=weight,\n-        )\n+        ),\n     ]\n     if address.company_name:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.company_name), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.company_name), config=\"simple\", weight=weight\n+            )\n         )\n     if address.country_area:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.country_area), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.country_area), config=\"simple\", weight=weight\n+            )\n         )\n     if address.city:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.city), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.city), config=\"simple\", weight=weight\n+            )\n         )\n     if address.city_area:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.city_area), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.city_area), config=\"simple\", weight=weight\n+            )\n         )\n     if address.street_address_2:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.street_address_2), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.street_address_2), config=\"simple\", weight=weight\n+            )\n         )\n     if address.postal_code:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.postal_code), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.postal_code), config=\"simple\", weight=weight\n+            )\n         )\n     if address.phone:\n         search_vectors.append(\n-            NoValidationSearchVector(Value(address.phone.as_e164), weight=weight)\n+            NoValidationSearchVector(\n+                Value(address.phone.as_e164), config=\"simple\", weight=weight\n+            )\n         )\n     return search_vectors\n \n \n"
        },
        {
          "path": "saleor/checkout/tests/test_checkout_complete.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_checkout_complete.py\n===================================================================\n--- saleor/checkout/tests/test_checkout_complete.py\td7bef8c (parent)\n+++ saleor/checkout/tests/test_checkout_complete.py\t4815c54 (commit)\n@@ -91,8 +91,9 @@\n             app=None,\n             manager=manager,\n         )\n \n+    order.refresh_from_db()\n     (\n         order_placed_event,\n         payment_captured_event,\n         order_fully_paid_event,\n@@ -255,8 +256,9 @@\n             app=None,\n             manager=manager,\n         )\n \n+    order.refresh_from_db()\n     (\n         order_placed_event,\n         payment_captured_event,\n         order_fully_paid_event,\n@@ -414,8 +416,9 @@\n             app=None,\n             manager=manager,\n         )\n \n+    order.refresh_from_db()\n     (\n         order_placed_event,\n         payment_authorized_event,\n         order_confirmed_event,\n@@ -530,8 +533,9 @@\n             app=None,\n             manager=manager,\n         )\n \n+    order.refresh_from_db()\n     (\n         order_placed_event,\n         payment_captured_event,\n         order_confirmed_event,\n@@ -1307,8 +1311,9 @@\n             user=customer_user,\n             app=app,\n         )\n \n+    order.refresh_from_db()\n     (\n         order_marked_as_paid,\n         order_placed_event,\n         order_fully_paid,\n"
        },
        {
          "path": "saleor/core/search_tasks.py",
          "status": "modified",
          "diff": "Index: saleor/core/search_tasks.py\n===================================================================\n--- saleor/core/search_tasks.py\td7bef8c (parent)\n+++ saleor/core/search_tasks.py\t4815c54 (commit)\n@@ -1,6 +1,9 @@\n+from typing import Any\n+\n from celery.utils.log import get_task_logger\n from django.conf import settings\n+from django.db import transaction\n \n from ..account.models import User\n from ..account.search import prepare_user_search_document_value\n from ..celeryconf import app\n@@ -15,8 +18,10 @@\n from .postgres import FlatConcatSearchVector\n \n task_logger = get_task_logger(__name__)\n \n+ORDER_BATCH_SIZE = 100\n+\n BATCH_SIZE = 500\n # Based on local testing, 500 should be a good balance between performance\n # total time and memory usage. Should be tested after some time and adjusted by\n # running the task on different thresholds and measure memory usage, total time\n@@ -52,41 +57,66 @@\n     set_user_search_document_values.delay(updated_count)\n \n \n @app.task\n-def set_order_search_document_values(updated_count: int = 0) -> None:\n-    orders = list(\n-        Order.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME)\n-        .filter(search_vector=None)\n-        .prefetch_related(\n-            \"user\",\n-            \"billing_address\",\n-            \"shipping_address\",\n-            \"payments\",\n-            \"discounts\",\n-            \"lines\",\n-        )\n-        .order_by(\"-number\")[:BATCH_SIZE]\n+def set_order_search_document_values(\n+    update_all: bool = False,\n+    database_connection_name: str = settings.DATABASE_CONNECTION_REPLICA_NAME,\n+    updated_count: int = 0,\n+    order_number: int = 0,\n+) -> None:\n+    \"\"\"Update search document values for orders.\n+\n+    If `update_all` is False, it will update only orders with search_vector=None.\n+    \"\"\"\n+    lookup: dict[str, Any] = {\"number__gte\": order_number}\n+    if not update_all:\n+        lookup[\"search_vector\"] = None\n+\n+    orders_qs = (\n+        Order.objects.using(database_connection_name)\n+        .filter(**lookup)\n+        .order_by(\"number\")\n     )\n \n-    if not orders:\n+    numbers = list(orders_qs.values_list(\"number\", flat=True)[:ORDER_BATCH_SIZE])\n+    if not numbers:\n         task_logger.info(\"No orders to update.\")\n         return\n \n     with allow_writer():\n-        updated_count += set_search_vector_values(\n-            orders, prepare_order_search_vector_value\n+        orders = (\n+            Order.objects.filter(number__in=numbers)\n+            .prefetch_related(\n+                \"user\",\n+                \"billing_address\",\n+                \"shipping_address\",\n+                \"payments\",\n+                \"discounts\",\n+                \"lines\",\n+                \"payment_transactions__events\",\n+                \"invoices\",\n+                \"events\",\n+            )\n+            .order_by(\"pk\")\n         )\n+        with transaction.atomic():\n+            _orders_lock = list(orders.select_for_update(of=([\"self\"])))\n+            updated_count += set_search_vector_values(\n+                list(orders), prepare_order_search_vector_value\n+            )\n \n     task_logger.info(\"Updated %d orders\", updated_count)\n \n-    if len(orders) < BATCH_SIZE:\n+    if len(numbers) < ORDER_BATCH_SIZE:\n         task_logger.info(\"Setting order search document values finished.\")\n         return\n \n     del orders\n \n-    set_order_search_document_values.delay(updated_count)\n+    set_order_search_document_values.delay(\n+        update_all, database_connection_name, updated_count, order_number=numbers[-1]\n+    )\n \n \n @app.task\n def set_product_search_document_values(updated_count: int = 0) -> None:\n"
        },
        {
          "path": "saleor/graphql/invoice/mutations/invoice_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/invoice/mutations/invoice_create.py\n===================================================================\n--- saleor/graphql/invoice/mutations/invoice_create.py\td7bef8c (parent)\n+++ saleor/graphql/invoice/mutations/invoice_create.py\t4815c54 (commit)\n@@ -4,8 +4,9 @@\n from ....core import JobStatus\n from ....invoice import events, models\n from ....invoice.error_codes import InvoiceErrorCode\n from ....order import events as order_events\n+from ....order.search import update_order_search_vector\n from ....permission.enums import OrderPermissions\n from ...app.dataloaders import get_app_promise\n from ...core import ResolveInfo\n from ...core.doc_category import DOC_CATEGORY_ORDERS\n@@ -133,5 +134,6 @@\n             user=info.context.user,\n             app=app,\n             invoice_number=cleaned_input[\"number\"],\n         )\n+        update_order_search_vector(order)\n         return InvoiceCreate(invoice=invoice)\n"
        },
        {
          "path": "saleor/graphql/invoice/mutations/invoice_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/invoice/mutations/invoice_delete.py\n===================================================================\n--- saleor/graphql/invoice/mutations/invoice_delete.py\td7bef8c (parent)\n+++ saleor/graphql/invoice/mutations/invoice_delete.py\t4815c54 (commit)\n@@ -1,7 +1,8 @@\n import graphene\n \n from ....invoice import events, models\n+from ....order.search import update_order_search_vector\n from ....permission.enums import OrderPermissions\n from ...app.dataloaders import get_app_promise\n from ...core import ResolveInfo\n from ...core.mutations import ModelDeleteMutation\n@@ -23,11 +24,13 @@\n \n     @classmethod\n     def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n         invoice = cls.get_instance(info, **data)\n-        cls.check_channel_permissions(info, [invoice.order.channel_id])\n+        order = invoice.order\n+        cls.check_channel_permissions(info, [order.channel_id])\n         response = super().perform_mutation(_root, info, **data)\n         app = get_app_promise(info.context).get()\n         events.invoice_deleted_event(\n             user=info.context.user, app=app, invoice_id=invoice.pk\n         )\n+        update_order_search_vector(order)\n         return response\n"
        },
        {
          "path": "saleor/graphql/invoice/tests/test_invoice_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/invoice/tests/test_invoice_create.py\n===================================================================\n--- saleor/graphql/invoice/tests/test_invoice_create.py\td7bef8c (parent)\n+++ saleor/graphql/invoice/tests/test_invoice_create.py\t4815c54 (commit)\n@@ -88,8 +88,10 @@\n         order=order,\n         user=staff_api_client.user,\n         parameters__invoice_number=number,\n     ).exists()\n+    order.refresh_from_db()\n+    assert order.search_vector\n \n \n def test_create_invoice_by_user_no_channel_access(\n     staff_api_client, permission_group_all_perms_channel_USD_only, order, channel_PLN\n@@ -160,8 +162,10 @@\n         user=None,\n         app=app_api_client.app,\n         parameters__invoice_number=number,\n     ).exists()\n+    order.refresh_from_db()\n+    assert order.search_vector\n \n \n def test_create_invoice_no_billing_address(\n     staff_api_client, permission_group_manage_orders, order\n"
        },
        {
          "path": "saleor/graphql/invoice/tests/test_invoice_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/invoice/tests/test_invoice_delete.py\n===================================================================\n--- saleor/graphql/invoice/tests/test_invoice_delete.py\td7bef8c (parent)\n+++ saleor/graphql/invoice/tests/test_invoice_delete.py\t4815c54 (commit)\n@@ -37,8 +37,10 @@\n         type=InvoiceEvents.DELETED,\n         user=staff_api_client.user,\n         parameters__invoice_id=invoice.id,\n     ).exists()\n+    order.refresh_from_db()\n+    assert order.search_vector\n \n \n def test_invoice_delete_by_user_no_channel_access(\n     staff_api_client, permission_group_all_perms_channel_USD_only, order, channel_PLN\n@@ -78,8 +80,10 @@\n         user=None,\n         app=app_api_client.app,\n         parameters__invoice_id=invoice.id,\n     ).exists()\n+    order.refresh_from_db()\n+    assert order.search_vector\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.invoice_delete\")\n def test_invoice_delete_invalid_id(\n"
        },
        {
          "path": "saleor/graphql/order/mutations/order_note_add.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/order_note_add.py\n===================================================================\n--- saleor/graphql/order/mutations/order_note_add.py\td7bef8c (parent)\n+++ saleor/graphql/order/mutations/order_note_add.py\t4815c54 (commit)\n@@ -1,8 +1,9 @@\n import graphene\n from django.db import transaction\n \n from ....order import error_codes, events\n+from ....order.search import update_order_search_vector\n from ....permission.enums import OrderPermissions\n from ...app.dataloaders import get_app_promise\n from ...core import ResolveInfo\n from ...core.context import SyncWebhookControlContext\n@@ -57,8 +58,9 @@\n                 app=app,\n                 message=cleaned_input[\"message\"],\n             )\n             call_event_by_order_status(order, manager)\n+            update_order_search_vector(order)\n         return OrderNoteAdd(\n             order=SyncWebhookControlContext(order),\n             event=SyncWebhookControlContext(event),\n         )\n"
        },
        {
          "path": "saleor/graphql/order/mutations/order_note_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/order_note_update.py\n===================================================================\n--- saleor/graphql/order/mutations/order_note_update.py\td7bef8c (parent)\n+++ saleor/graphql/order/mutations/order_note_update.py\t4815c54 (commit)\n@@ -1,8 +1,9 @@\n import graphene\n from django.db import transaction\n \n from ....order import OrderEvents, error_codes, events, models\n+from ....order.search import update_order_search_vector\n from ....permission.enums import OrderPermissions\n from ...app.dataloaders import get_app_promise\n from ...core import ResolveInfo\n from ...core.context import SyncWebhookControlContext\n@@ -63,8 +64,9 @@\n                 message=cleaned_input[\"message\"],\n                 related_event=order_event_to_update,\n             )\n             call_event_by_order_status(order, manager)\n+            update_order_search_vector(order)\n         return OrderNoteUpdate(\n             order=SyncWebhookControlContext(order),\n             event=SyncWebhookControlContext(event),\n         )\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_note_add.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_note_add.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_note_add.py\td7bef8c (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_note_add.py\t4815c54 (commit)\n@@ -67,8 +67,9 @@\n     order_updated_webhook_mock.assert_called_once_with(order, webhooks=set())\n \n     order.refresh_from_db()\n     assert order.status == OrderStatus.UNFULFILLED\n+    assert order.search_vector\n \n     # Ensure the correct order event was created\n     event = order.events.get()\n     assert event.type == order_events.OrderEvents.NOTE_ADDED\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_note_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_note_update.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_note_update.py\td7bef8c (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_note_update.py\t4815c54 (commit)\n@@ -78,8 +78,9 @@\n     order_updated_webhook_mock.assert_called_once_with(order, webhooks=set())\n \n     order.refresh_from_db()\n     assert order.status == OrderStatus.UNFULFILLED\n+    assert order.search_vector\n \n     assert OrderEvent.objects.filter(order=order).count() == 2\n     new_note = OrderEvent.objects.filter(order=order).exclude(pk=note.pk).get()\n     assert new_note.type == OrderEvents.NOTE_UPDATED\n"
        },
        {
          "path": "saleor/graphql/order/tests/queries/test_orders.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/queries/test_orders.py\n===================================================================\n--- saleor/graphql/order/tests/queries/test_orders.py\td7bef8c (parent)\n+++ saleor/graphql/order/tests/queries/test_orders.py\t4815c54 (commit)\n@@ -1,20 +1,13 @@\n from decimal import Decimal\n from unittest.mock import patch\n \n-import pytest\n-from prices import Money, TaxedMoney\n-\n-from .....core.postgres import FlatConcatSearchVector\n-from .....discount.models import OrderDiscount\n from .....order import OrderStatus\n from .....order.events import (\n     draft_order_created_from_replace_event,\n     fulfillment_fulfilled_items_event,\n     order_added_products_event,\n )\n-from .....order.models import Order, Payment\n-from .....order.search import prepare_order_search_vector_value\n from .....plugins.manager import PluginsManager\n from .....tax.calculations.order import update_order_prices_with_flat_rates\n from ....tests.utils import get_graphql_content\n from .shared_query_fragments import ORDER_FRAGMENT_WITH_WEBHOOK_RELATED_FIELDS\n@@ -259,127 +252,4 @@\n     order_with_lines.refresh_from_db()\n     assert not order_with_lines.should_refresh_prices\n     assert order_with_lines.total_gross_amount != Decimal(0)\n     mocked_webhook_handler.assert_not_called()\n-\n-\n-ORDERS_QUERY_WITH_SEARCH = \"\"\"\n-  query ($search: String) {\n-    orders(first: 10, search:$search) {\n-      totalCount\n-      edges {\n-        node {\n-          id\n-        }\n-      }\n-    }\n-  }\n-\"\"\"\n-\n-\n-@pytest.mark.parametrize(\n-    (\"search_value\", \"count\"),\n-    [\n-        (\"discount name\", 2),\n-        (\"Some other\", 1),\n-        (\"translated\", 1),\n-        (\"test@mirumee.com\", 1),\n-        (\"Leslie\", 1),\n-        (\"Wade\", 1),\n-        (\"\", 3),\n-        (\"ExternalID\", 1),\n-        (\"SKU_A\", 1),\n-    ],\n-)\n-def test_orders_query_with_search(\n-    search_value,\n-    count,\n-    staff_api_client,\n-    permission_group_manage_orders,\n-    customer_user,\n-    channel_USD,\n-    product,\n-    variant,\n-):\n-    # given\n-    orders = Order.objects.bulk_create(\n-        [\n-            Order(\n-                user=customer_user,\n-                user_email=\"test@mirumee.com\",\n-                channel=channel_USD,\n-                lines_count=0,\n-            ),\n-            Order(\n-                user_email=\"user_email1@example.com\",\n-                channel=channel_USD,\n-                lines_count=0,\n-            ),\n-            Order(\n-                user_email=\"user_email2@example.com\",\n-                channel=channel_USD,\n-                lines_count=0,\n-            ),\n-        ]\n-    )\n-\n-    OrderDiscount.objects.bulk_create(\n-        [\n-            OrderDiscount(\n-                order=orders[0],\n-                name=\"Some discount name\",\n-                value=Decimal(\"1\"),\n-                amount_value=Decimal(\"1\"),\n-                translated_name=\"translated\",\n-            ),\n-            OrderDiscount(\n-                order=orders[2],\n-                name=\"Some other discount name\",\n-                value=Decimal(\"10\"),\n-                amount_value=Decimal(\"10\"),\n-                translated_name=\"PL_name\",\n-            ),\n-        ]\n-    )\n-    order_with_payment = orders[1]\n-    payment = Payment.objects.create(\n-        order=order_with_payment, psp_reference=\"ExternalID\"\n-    )\n-    payment.transactions.create(gateway_response={}, is_success=True)\n-\n-    order_with_orderline = orders[2]\n-    channel = order_with_orderline.channel\n-    channel_listing = variant.channel_listings.get(channel=channel)\n-    net = variant.get_price(channel_listing)\n-    currency = net.currency\n-    gross = Money(amount=net.amount * Decimal(1.23), currency=currency)\n-    unit_price = TaxedMoney(net=net, gross=gross)\n-    order_with_orderline.lines.create(\n-        product_name=str(product),\n-        variant_name=str(variant),\n-        product_sku=variant.sku,\n-        product_variant_id=variant.get_global_id(),\n-        is_shipping_required=variant.is_shipping_required(),\n-        is_gift_card=variant.is_gift_card(),\n-        quantity=3,\n-        variant=variant,\n-        unit_price=unit_price,\n-        total_price=unit_price * 3,\n-        undiscounted_unit_price=unit_price,\n-        undiscounted_total_price=unit_price * 3,\n-        tax_rate=Decimal(\"0.23\"),\n-    )\n-    for order in orders:\n-        order.search_vector = FlatConcatSearchVector(\n-            *prepare_order_search_vector_value(order)\n-        )\n-    Order.objects.bulk_update(orders, [\"search_vector\"])\n-\n-    variables = {\"search\": search_value}\n-    permission_group_manage_orders.user_set.add(staff_api_client.user)\n-\n-    # when\n-    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n-\n-    # then\n-    content = get_graphql_content(response)\n-    assert content[\"data\"][\"orders\"][\"totalCount\"] == count\n"
        },
        {
          "path": "saleor/graphql/order/tests/queries/test_orders_search.py",
          "status": "added",
          "diff": "Index: saleor/graphql/order/tests/queries/test_orders_search.py\n===================================================================\n--- saleor/graphql/order/tests/queries/test_orders_search.py\td7bef8c (parent)\n+++ saleor/graphql/order/tests/queries/test_orders_search.py\t4815c54 (commit)\n@@ -0,0 +1,536 @@\n+from decimal import Decimal\n+\n+import graphene\n+import pytest\n+from prices import Money, TaxedMoney\n+\n+from .....core.postgres import FlatConcatSearchVector\n+from .....discount.models import OrderDiscount\n+from .....invoice.models import Invoice\n+from .....order import OrderEvents\n+from .....order.models import Order, Payment\n+from .....order.search import prepare_order_search_vector_value\n+from ....tests.utils import get_graphql_content\n+\n+ORDERS_QUERY_WITH_SEARCH = \"\"\"\n+  query ($search: String) {\n+    orders(first: 10, search:$search) {\n+      totalCount\n+      edges {\n+        node {\n+          id\n+          number\n+        }\n+      }\n+    }\n+  }\n+\"\"\"\n+\n+\n+def update_orders_search_vector(orders):\n+    for order in orders:\n+        order.search_vector = FlatConcatSearchVector(\n+            *prepare_order_search_vector_value(order)\n+        )\n+    Order.objects.bulk_update(orders, [\"search_vector\"])\n+\n+\n+@pytest.mark.parametrize(\n+    (\"search_value\", \"count\"),\n+    [\n+        (\"discount name\", 2),\n+        (\"Some other\", 1),\n+        (\"translated\", 1),\n+        (\"test@mirumee.com\", 1),\n+        (\"Leslie\", 1),\n+        (\"Wade\", 1),\n+        (\"Leslie Wade\", 1),\n+        (\"\", 3),\n+        (\"ExternalID\", 1),\n+        (\"SKU_A\", 1),\n+    ],\n+)\n+def test_orders_query_with_search(\n+    search_value,\n+    count,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    customer_user,\n+    channel_USD,\n+    product,\n+    variant,\n+):\n+    # given\n+    orders = Order.objects.bulk_create(\n+        [\n+            Order(\n+                user=customer_user,\n+                user_email=\"test@mirumee.com\",\n+                channel=channel_USD,\n+                lines_count=0,\n+            ),\n+            Order(\n+                user_email=\"user_email1@example.com\",\n+                channel=channel_USD,\n+                lines_count=0,\n+            ),\n+            Order(\n+                user_email=\"user_email2@example.com\",\n+                channel=channel_USD,\n+                lines_count=0,\n+            ),\n+        ]\n+    )\n+\n+    OrderDiscount.objects.bulk_create(\n+        [\n+            OrderDiscount(\n+                order=orders[0],\n+                name=\"Some discount name\",\n+                value=Decimal(\"1\"),\n+                amount_value=Decimal(\"1\"),\n+                translated_name=\"translated\",\n+            ),\n+            OrderDiscount(\n+                order=orders[2],\n+                name=\"Some other discount name\",\n+                value=Decimal(\"10\"),\n+                amount_value=Decimal(\"10\"),\n+                translated_name=\"PL_name\",\n+            ),\n+        ]\n+    )\n+    order_with_payment = orders[1]\n+    payment = Payment.objects.create(\n+        order=order_with_payment, psp_reference=\"ExternalID\"\n+    )\n+    payment.transactions.create(gateway_response={}, is_success=True)\n+\n+    order_with_orderline = orders[2]\n+    channel = order_with_orderline.channel\n+    channel_listing = variant.channel_listings.get(channel=channel)\n+    net = variant.get_price(channel_listing)\n+    currency = net.currency\n+    gross = Money(amount=net.amount * Decimal(1.23), currency=currency)\n+    unit_price = TaxedMoney(net=net, gross=gross)\n+    order_with_orderline.lines.create(\n+        product_name=str(product),\n+        variant_name=str(variant),\n+        product_sku=variant.sku,\n+        product_variant_id=variant.get_global_id(),\n+        is_shipping_required=variant.is_shipping_required(),\n+        is_gift_card=variant.is_gift_card(),\n+        quantity=3,\n+        variant=variant,\n+        unit_price=unit_price,\n+        total_price=unit_price * 3,\n+        undiscounted_unit_price=unit_price,\n+        undiscounted_total_price=unit_price * 3,\n+        tax_rate=Decimal(\"0.23\"),\n+    )\n+\n+    update_orders_search_vector(orders)\n+\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == count\n+\n+\n+def test_orders_query_with_search_by_order_id(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+):\n+    # given\n+    update_orders_search_vector(order_list)\n+\n+    search_value = graphene.Node.to_global_id(\"Order\", order_list[1].pk)\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == 1\n+    assert content[\"data\"][\"orders\"][\"edges\"][0][\"node\"][\"id\"] == search_value\n+\n+\n+def test_orders_query_with_search_by_invoice_id(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+):\n+    # given\n+    invoices = Invoice.objects.bulk_create(\n+        [Invoice(order=order, number=f\"INV-{order.pk}\") for order in order_list]\n+    )\n+    update_orders_search_vector(order_list)\n+\n+    search_value = graphene.Node.to_global_id(\"Invoice\", invoices[2].pk)\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == 1\n+    assert content[\"data\"][\"orders\"][\"edges\"][0][\"node\"][\n+        \"id\"\n+    ] == graphene.Node.to_global_id(\"Order\", order_list[2].pk)\n+\n+\n+def test_orders_query_with_search_by_order_event_message(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+):\n+    # given\n+    event_message = \"Special event message for search\"\n+    order = order_list[0]\n+    order.events.create(\n+        type=OrderEvents.NOTE_ADDED,\n+        user=None,\n+        parameters={\"message\": event_message},\n+    )\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": \"Special event message\"}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == 1\n+    assert content[\"data\"][\"orders\"][\"edges\"][0][\"node\"][\n+        \"id\"\n+    ] == graphene.Node.to_global_id(\"Order\", order_list[0].pk)\n+\n+\n+@pytest.mark.parametrize(\n+    (\"search_value\", \"expected_count\"),\n+    [\n+        (\"match in\", 1),\n+        (\"note\", 2),\n+        (\"partial\", 1),\n+        (\"unrelated\", 0),\n+    ],\n+)\n+def test_orders_query_with_search_by_partial_customer_note(\n+    search_value,\n+    expected_count,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+):\n+    # given\n+    notes = [\n+        \"This is a match in the customer note\",\n+        \"This note has a partial match\",\n+        \"\",\n+    ]\n+    for order, note in zip(order_list, notes, strict=True):\n+        order.customer_note = note\n+\n+    Order.objects.bulk_update(order_list, [\"customer_note\"])\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == expected_count\n+\n+\n+def test_orders_query_with_search_by_product_name(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    product,\n+    variant,\n+):\n+    # given\n+    order = order_list[0]\n+    channel = order.channel\n+    channel_listing = variant.channel_listings.get(channel=channel)\n+    net = variant.get_price(channel_listing)\n+    currency = net.currency\n+    gross = Money(amount=net.amount * Decimal(1.23), currency=currency)\n+    unit_price = TaxedMoney(net=net, gross=gross)\n+    product_name = str(product)\n+    order.lines.create(\n+        product_name=product_name,\n+        variant_name=str(variant),\n+        product_sku=variant.sku,\n+        product_variant_id=variant.get_global_id(),\n+        is_shipping_required=variant.is_shipping_required(),\n+        is_gift_card=variant.is_gift_card(),\n+        quantity=2,\n+        variant=variant,\n+        unit_price=unit_price,\n+        total_price=unit_price * 2,\n+        undiscounted_unit_price=unit_price,\n+        undiscounted_total_price=unit_price * 2,\n+        tax_rate=Decimal(\"0.23\"),\n+    )\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": product_name}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == 1\n+    assert content[\"data\"][\"orders\"][\"edges\"][0][\"node\"][\n+        \"id\"\n+    ] == graphene.Node.to_global_id(\"Order\", order.pk)\n+\n+\n+def test_orders_query_with_search_by_variant_name(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    product,\n+    variant,\n+):\n+    # given\n+    order = order_list[1]\n+    channel = order.channel\n+    channel_listing = variant.channel_listings.get(channel=channel)\n+    net = variant.get_price(channel_listing)\n+    currency = net.currency\n+    gross = Money(amount=net.amount * Decimal(1.23), currency=currency)\n+    unit_price = TaxedMoney(net=net, gross=gross)\n+    variant_name = str(variant)\n+    order.lines.create(\n+        product_name=str(product),\n+        variant_name=variant_name,\n+        product_sku=variant.sku,\n+        product_variant_id=variant.get_global_id(),\n+        is_shipping_required=variant.is_shipping_required(),\n+        is_gift_card=variant.is_gift_card(),\n+        quantity=1,\n+        variant=variant,\n+        unit_price=unit_price,\n+        total_price=unit_price,\n+        undiscounted_unit_price=unit_price,\n+        undiscounted_total_price=unit_price,\n+        tax_rate=Decimal(\"0.23\"),\n+    )\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": variant_name}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == 1\n+    assert content[\"data\"][\"orders\"][\"edges\"][0][\"node\"][\n+        \"id\"\n+    ] == graphene.Node.to_global_id(\"Order\", order.pk)\n+\n+\n+def test_orders_query_with_search_by_product_sku(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    product,\n+    variant,\n+):\n+    # given\n+    order = order_list[2]\n+    channel = order.channel\n+    channel_listing = variant.channel_listings.get(channel=channel)\n+    net = variant.get_price(channel_listing)\n+    currency = net.currency\n+    gross = Money(amount=net.amount * Decimal(1.23), currency=currency)\n+    unit_price = TaxedMoney(net=net, gross=gross)\n+    sku = variant.sku\n+    order.lines.create(\n+        product_name=str(product),\n+        variant_name=str(variant),\n+        product_sku=sku,\n+        product_variant_id=variant.get_global_id(),\n+        is_shipping_required=variant.is_shipping_required(),\n+        is_gift_card=variant.is_gift_card(),\n+        quantity=4,\n+        variant=variant,\n+        unit_price=unit_price,\n+        total_price=unit_price * 4,\n+        undiscounted_unit_price=unit_price,\n+        undiscounted_total_price=unit_price * 4,\n+        tax_rate=Decimal(\"0.23\"),\n+    )\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": sku}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == 1\n+    assert content[\"data\"][\"orders\"][\"edges\"][0][\"node\"][\n+        \"id\"\n+    ] == graphene.Node.to_global_id(\"Order\", order.pk)\n+\n+\n+@pytest.mark.parametrize(\n+    (\"search_value\", \"expected_count\"),\n+    [\n+        (\"First\", 1),\n+        (\"Last\", 1),\n+        (\"First Last\", 1),\n+        (\"Billing Street\", 1),\n+        (\"PL\", 1),\n+        (\"US\", 2),\n+        (\"Nonexistent\", 0),\n+    ],\n+)\n+def test_orders_query_with_search_by_billing_address_fields(\n+    search_value,\n+    expected_count,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    address,\n+    address_usa,\n+):\n+    # given\n+    order = order_list[0]\n+    address.first_name = \"First\"\n+    address.last_name = \"Last\"\n+    address.street_address_1 = \"Billing Street\"\n+    address.country = \"PL\"\n+    address.save()\n+\n+    order.billing_address = address\n+    for order in order_list[1:]:\n+        order.billing_address = address_usa\n+    Order.objects.bulk_update(order_list, [\"billing_address\"])\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"search_value\", \"expected_count\"),\n+    [\n+        (\"First\", 1),\n+        (\"Last\", 1),\n+        (\"First Last\", 1),\n+        (\"Shipping Street\", 1),\n+        (\"JP\", 1),\n+        (\"US\", 2),\n+        (\"Nonexistent\", 0),\n+    ],\n+)\n+def test_orders_query_with_search_by_shipping_address_fields(\n+    search_value,\n+    expected_count,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    address,\n+    address_usa,\n+):\n+    # given\n+    order = order_list[0]\n+    address.first_name = \"First\"\n+    address.last_name = \"Last\"\n+    address.street_address_1 = \"Shipping Street\"\n+    address.country = \"JP\"\n+    address.save()\n+\n+    order.shipping_address = address\n+    for order in order_list[1:]:\n+        order.shipping_address = address_usa\n+    Order.objects.bulk_update(order_list, [\"shipping_address\"])\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"search_value\", \"expected_order_idxes\"),\n+    [\n+        (\"EXT-REF-12345\", [0]),\n+        (\"REF\", [0, 1]),\n+        (\"ANOTHER-REF-67890\", [1]),\n+        (\"nonexistent-ref\", []),\n+    ],\n+)\n+def test_orders_query_with_search_by_external_reference(\n+    search_value,\n+    expected_order_idxes,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+):\n+    # given\n+    external_references = [\"EXT-REF-12345\", \"ANOTHER-REF-67890\", \"\"]\n+    for order, ext_ref in zip(order_list, external_references, strict=True):\n+        order.external_reference = ext_ref\n+    Order.objects.bulk_update(order_list, [\"external_reference\"])\n+\n+    update_orders_search_vector(order_list)\n+\n+    variables = {\"search\": search_value}\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDERS_QUERY_WITH_SEARCH, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"orders\"][\"totalCount\"] == len(expected_order_idxes)\n+    returned_numbers = [\n+        edge[\"node\"][\"number\"] for edge in content[\"data\"][\"orders\"][\"edges\"]\n+    ]\n+    expected_numbers = [str(order_list[idx].number) for idx in expected_order_idxes]\n+    assert set(returned_numbers) == set(expected_numbers)\n"
        },
        {
          "path": "saleor/order/migrations/0213_auto_20250618_1246.py",
          "status": "added",
          "diff": "Index: saleor/order/migrations/0213_auto_20250618_1246.py\n===================================================================\n--- saleor/order/migrations/0213_auto_20250618_1246.py\td7bef8c (parent)\n+++ saleor/order/migrations/0213_auto_20250618_1246.py\t4815c54 (commit)\n@@ -0,0 +1,28 @@\n+# Generated by Django 5.2.1 on 2025-06-18 12:46\n+\n+from django.apps import apps as registry\n+from django.db import migrations\n+from django.db.models.signals import post_migrate\n+\n+from ...core.search_tasks import set_order_search_document_values\n+\n+\n+def update_order_search_vector(apps, _schema_editor):\n+    def on_migrations_complete(sender=None, **kwargs):\n+        set_order_search_document_values.delay()\n+\n+    sender = registry.get_app_config(\"order\")\n+    post_migrate.connect(on_migrations_complete, weak=False, sender=sender)\n+\n+\n+class Migration(migrations.Migration):\n+    dependencies = [\n+        (\"order\", \"0212_orderline_product_type_id_btree_idx\"),\n+    ]\n+\n+    operations = [\n+        migrations.RunPython(\n+            update_order_search_vector,\n+            reverse_code=migrations.RunPython.noop,\n+        )\n+    ]\n"
        },
        {
          "path": "saleor/order/search.py",
          "status": "modified",
          "diff": "Index: saleor/order/search.py\n===================================================================\n--- saleor/order/search.py\td7bef8c (parent)\n+++ saleor/order/search.py\t4815c54 (commit)\n@@ -6,8 +6,9 @@\n from django.db.models import F, Q, Value, prefetch_related_objects\n \n from ..account.search import generate_address_search_vector_value\n from ..core.postgres import FlatConcatSearchVector, NoValidationSearchVector\n+from . import OrderEvents\n \n if TYPE_CHECKING:\n     from django.db.models import QuerySet\n \n@@ -34,11 +35,18 @@\n             \"payments\",\n             \"discounts\",\n             \"lines\",\n             \"payment_transactions__events\",\n+            \"invoices\",\n+            \"events\",\n         )\n     search_vectors = [\n-        NoValidationSearchVector(Value(str(order.number)), config=\"simple\", weight=\"A\")\n+        NoValidationSearchVector(Value(str(order.number)), config=\"simple\", weight=\"A\"),\n+        NoValidationSearchVector(\n+            Value(graphene.Node.to_global_id(\"Order\", order.id)),\n+            config=\"simple\",\n+            weight=\"A\",\n+        ),\n     ]\n     if order.user_email:\n         search_vectors.append(\n             NoValidationSearchVector(\n@@ -63,21 +71,36 @@\n                     Value(order.user.last_name), config=\"simple\", weight=\"A\"\n                 )\n             )\n \n+    if order.customer_note:\n+        search_vectors.append(\n+            NoValidationSearchVector(\n+                Value(order.customer_note), config=\"simple\", weight=\"B\"\n+            )\n+        )\n+\n     if order.billing_address:\n         search_vectors += generate_address_search_vector_value(\n             order.billing_address, weight=\"B\"\n         )\n     if order.shipping_address:\n         search_vectors += generate_address_search_vector_value(\n             order.shipping_address, weight=\"B\"\n         )\n+    if order.external_reference:\n+        search_vectors.append(\n+            NoValidationSearchVector(\n+                Value(order.external_reference), config=\"simple\", weight=\"B\"\n+            )\n+        )\n \n     search_vectors += generate_order_payments_search_vector_value(order)\n     search_vectors += generate_order_discounts_search_vector_value(order)\n     search_vectors += generate_order_lines_search_vector_value(order)\n     search_vectors += generate_order_transactions_search_vector_value(order)\n+    search_vectors += generate_order_invoices_search_vector_value(order)\n+    search_vectors += generate_order_events_search_vector_value(order)\n     return search_vectors\n \n \n def generate_order_transactions_search_vector_value(\n@@ -212,8 +235,44 @@\n             )\n     return line_vectors\n \n \n+def generate_order_invoices_search_vector_value(\n+    order: \"Order\",\n+) -> list[NoValidationSearchVector]:\n+    invoice_vectors = []\n+    for invoice in order.invoices.all().order_by(\"-created_at\")[\n+        : settings.SEARCH_ORDERS_MAX_INDEXED_INVOICES\n+    ]:\n+        invoice_vectors.append(\n+            NoValidationSearchVector(\n+                Value(graphene.Node.to_global_id(\"Invoice\", invoice.id)),\n+                config=\"simple\",\n+                weight=\"D\",\n+            )\n+        )\n+    return invoice_vectors\n+\n+\n+def generate_order_events_search_vector_value(\n+    order: \"Order\",\n+) -> list[NoValidationSearchVector]:\n+    event_vectors = []\n+    events = order.events.filter(\n+        type__in=[OrderEvents.NOTE_ADDED, OrderEvents.NOTE_UPDATED]\n+    ).order_by(\"-date\")\n+    for event in events[: settings.SEARCH_ORDERS_MAX_INDEXED_EVENTS]:\n+        if message := event.parameters.get(\"message\"):\n+            event_vectors.append(\n+                NoValidationSearchVector(\n+                    Value(message),\n+                    config=\"simple\",\n+                    weight=\"D\",\n+                )\n+            )\n+    return event_vectors\n+\n+\n def search_orders(qs: \"QuerySet[Order]\", value) -> \"QuerySet[Order]\":\n     if value:\n         query = SearchQuery(value, search_type=\"websearch\", config=\"simple\")\n         lookup = Q(search_vector=query)\n"
        },
        {
          "path": "saleor/settings.py",
          "status": "modified",
          "diff": "Index: saleor/settings.py\n===================================================================\n--- saleor/settings.py\td7bef8c (parent)\n+++ saleor/settings.py\t4815c54 (commit)\n@@ -927,8 +927,10 @@\n SEARCH_ORDERS_MAX_INDEXED_TRANSACTIONS = 20\n SEARCH_ORDERS_MAX_INDEXED_PAYMENTS = 20\n SEARCH_ORDERS_MAX_INDEXED_DISCOUNTS = 20\n SEARCH_ORDERS_MAX_INDEXED_LINES = 100\n+SEARCH_ORDERS_MAX_INDEXED_INVOICES = 20\n+SEARCH_ORDERS_MAX_INDEXED_EVENTS = 50\n \n # Maximum related objects that can be indexed in a product\n PRODUCT_MAX_INDEXED_ATTRIBUTES = 1000\n PRODUCT_MAX_INDEXED_ATTRIBUTE_VALUES = 100\n"
        }
      ]
    },
    {
      "id": "extend-page-where",
      "sha": "836d01d8429ff250a78abbc5439743c28bc1f772",
      "parentSha": "f3c1a9678d36c934c9295ce557c409cb1279c79f",
      "spec": "Implement reference-based filtering in Page where inputs and supporting utilities.\n\nMake the following changes:\n\n1) GraphQL core filter inputs\n- File: saleor/graphql/core/filters/where_input.py\n  - Add two new descriptions to FilterInputDescriptions:\n    - CONTAINS_ALL: \"The field contains all of the specified values.\"\n    - CONTAINS_ANY: \"The field contains at least one of the specified values.\"\n  - Define a new input type ContainsFilterInput with two optional fields:\n    - contains_any: [String!] (NonNullList of String), description=CONTAINS_ANY\n    - contains_all: [String!] (NonNullList of String), description=CONTAINS_ALL\n  - Ensure Meta.description explains it targets fields that can contain multiple values.\n\n2) Attribute filters utilities (shared reference filtering builders)\n- File: saleor/graphql/attribute/filters.py\n  - Update imports:\n    - Add: from typing import Literal, TypedDict\n    - Replace: from django.db.models import Q -> from django.db.models import Exists, OuterRef, Q, QuerySet\n    - Replace product import alias: from ...product import models as product_models\n    - Add: from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue (AssignedPageAttributeValue needed for page assignments)\n    - Add: from ...page import models as page_models\n    - Adjust BaseInputObjectType/NonNullList imports to: from ..core.types.base import BaseInputObjectType and from ..core.types.common import NonNullList\n  - Switch any use of models.Product/Category to product_models.Product and product_models.Category accordingly in filter_attributes_by_product_types.\n  - Introduce type aliases and builders:\n    - Define CONTAINS_TYPING = dict[Literal[\"contains_any\", \"contains_all\"], list[str]]\n    - Define SharedContainsFilterParams TypedDict with: attr_id, db_connection_name, assigned_attr_model, assigned_id_field_name (\"page_id\" literal), identifier_field_name (one of \"slug\", \"id\", \"sku\").\n    - Implement filter_by_contains_referenced_object_ids(attr_id, attr_value, db_connection_name, assigned_attr_model, assigned_id_field_name):\n      - Parse GraphQL global IDs to per-type ID sets for Page, Product, ProductVariant using graphene.Node.from_global_id.\n      - If contains_all present: AND together conditions per type; if contains_any present: OR together conditions across types.\n      - For each type, delegate to _filter_contains_all_condition/_filter_contains_any_condition with identifier_field_name=\"id\" and attr_value_reference_field_name matching the AttributeValue FK field: reference_page_id, reference_product_id, reference_variant_id.\n      - Return a Q expression.\n    - Implement _filter_contains_single_expression(attr_id, db_connection_name, reference_objs QuerySet, attr_value_reference_field_name, assigned_attr_model, assigned_id_field_name):\n      - Build a subquery on AttributeValue filtering Exists(reference_objs.filter(id=OuterRef(attr_value_reference_field_name))). If attr_id provided, restrict by Attribute id via Exists.\n      - Build Assigned...AttributeValue queryset (for the caller’s assigned_attr_model) filtering Exists(single_reference_qs.filter(id=OuterRef(\"value_id\"))) and match the parent object via assigned_id_field_name=OuterRef(\"id\").\n      - Return Q(Exists(...)).\n    - Implement _filter_contains_all_condition(...) to AND per-identifier single-expression Qs where reference object is resolved by identifier_field_name value equals identifier.\n    - Implement _filter_contains_any_condition(...) to OR matches by passing a single queryset resolved by identifier_field_name__in to _filter_contains_single_expression.\n    - Implement wrappers for specific reference types that use slugs/SKUs:\n      - filter_by_contains_referenced_pages(...): identifier_field_name=\"slug\", referenced_model=page_models.Page, attr_value_reference_field_name=\"reference_page_id\".\n      - filter_by_contains_referenced_products(...): identifier_field_name=\"slug\", referenced_model=product_models.Product, attr_value_reference_field_name=\"reference_product_id\".\n      - filter_by_contains_referenced_variants(...): identifier_field_name=\"sku\", referenced_model=product_models.ProductVariant, attr_value_reference_field_name=\"reference_variant_id\".\n\n3) Page where filtering for reference attributes\n- File: saleor/graphql/page/filters.py\n  - Add import: from typing import Literal\n  - Import the shared utilities from attribute filters:\n    - CONTAINS_TYPING\n    - filter_by_contains_referenced_object_ids\n    - filter_by_contains_referenced_pages\n    - filter_by_contains_referenced_products\n    - filter_by_contains_referenced_variants\n  - Extend filter_pages_by_attributes(qs, value):\n    - When attr.input_type == AttributeInputType.REFERENCE, add a branch to AND the expression with filter_pages_by_reference_attributes(attr.id, attr_value[\"reference\"], qs.db).\n  - Implement filter_pages_by_reference_attributes(attr_id, attr_value, db_connection_name):\n    - attr_value is a dict whose keys may include any of: \"referenced_ids\", \"page_slugs\", \"product_slugs\", \"product_variant_skus\", each mapping to a ContainsFilterInput.\n    - For each present key, build a Q condition using the appropriate shared utility, with assigned_attr_model=AssignedPageAttributeValue and assigned_id_field_name=\"page_id\". AND these conditions together and return.\n  - Add validation for reference inputs:\n    - Implement validate_attribute_value_reference_input(values: list[dict|None]):\n      - For each entry:\n        - Reject null/empty entries (raise GraphQLError: \"Invalid input for reference attributes. Provided 'value' cannot be null or empty.\").\n        - For each subfield (pageSlugs/productSlugs/productVariantSkus/referencedIds):\n          - Do not allow both containsAll and containsAny together for the same key; collect and raise: \"Invalid input for reference attributes. For fields: <fields>. Cannot provide both 'containsAll' and 'containsAny' for the same reference filter.\".\n          - If containsAll present but is null/empty, collect and raise: \"Invalid input for reference attributes. For fields: <fields>. Provided values cannot be null or empty.\". Same for containsAny.\n    - Integrate into validate_attribute_value_input():\n      - Collect all provided value_key == \"reference\" values into reference_value_list.\n      - In type-specific validation, ensure that when value_key == \"reference\", the attribute input type is AttributeInputType.REFERENCE; otherwise include slug in invalid_input_type_list.\n      - After other validations, call validate_attribute_value_reference_input(reference_value_list).\n  - Extend inputs for where filters:\n    - Define class ReferenceAttributeWhereInput with fields:\n      - referenced_ids: ContainsFilterInput (IDs)\n      - page_slugs: ContainsFilterInput (slugs)\n      - product_slugs: ContainsFilterInput\n      - product_variant_skus: ContainsFilterInput\n    - Add a new optional field to AttributeValuePageInput:\n      - reference: ReferenceAttributeWhereInput, description \"Filter by reference attribute value.\"\n\n4) Schema updates\n- File: saleor/graphql/schema.graphql\n  - In input AttributeValuePageInput, add field reference: ReferenceAttributeWhereInput with the matching description.\n  - Add input ReferenceAttributeWhereInput with fields and descriptions:\n    - referencedIds: ContainsFilterInput – Returns objects with a reference pointing to an object identified by the given ID.\n    - pageSlugs: ContainsFilterInput – Returns objects with a reference pointing to a page identified by the given slug.\n    - productSlugs: ContainsFilterInput – Returns objects with a reference pointing to a product identified by the given slug.\n    - productVariantSkus: ContainsFilterInput – Returns objects with a reference pointing to a product variant identified by the given sku.\n  - Add input ContainsFilterInput with containsAny and containsAll, including descriptions matching FilterInputDescriptions.\n\n5) Tests and fixtures\n- File: saleor/graphql/page/tests/queries/test_pages.py\n  - Update parameterized test_pages_with_filtering to expect 4 results when filter_by = {\"slugs\": []} (reflecting expanded fixture list).\n- File: saleor/page/tests/fixtures/page.py\n  - Update page_list fixture to create four published pages instead of two (add test3 and test4 entries) so empty slugs filtering counts 4.\n- File: saleor/graphql/page/tests/queries/test_pages_with_where.py\n  - Add new tests covering reference attribute filtering and validation:\n    - Filtering pages by reference to pages using pageSlugs with containsAny and containsAll.\n    - Filtering by reference to products with productSlugs (containsAny/containsAll).\n    - Filtering by reference to variants with productVariantSkus (containsAny/containsAll).\n    - Filtering by referenced global IDs via referencedIds (containsAny/containsAll) for pages, variants, and products.\n    - Negative test cases verifying validation errors for empty/null lists and when both containsAny and containsAll are supplied, and when reference filter appears for non-reference attributes.\n  - Ensure imports include AttributeValue and to_global_id_or_none and adjust any attribute slugs used in the tests per fixtures.\n\nAcceptance criteria\n- The pages(where: ...) filtering supports reference attribute values with containsAny/containsAll semantics via any of referencedIds, pageSlugs, productSlugs, productVariantSkus.\n- Validation prevents null/empty ContainsFilterInput payloads and forbids mixing containsAny with containsAll for the same key.\n- New ContainsFilterInput and ReferenceAttributeWhereInput are present in the schema; docs/descriptions reflect the above.\n- Existing non-reference attribute filters continue to behave unchanged.\n- Tests pass with updated fixtures and new reference filtering coverage.\n",
      "prompt": "Extend the Pages where filter to support filtering by reference attributes.\n\nAt a high level:\n- Add an input for list-based membership checks with containsAny and containsAll.\n- Support reference filters in pages where attributes so that clients can query by:\n  - Global IDs of referenced objects\n  - Page slugs\n  - Product slugs\n  - Variant SKUs\n- For containsAll, only return pages that reference all specified items (AND semantics). For containsAny, return pages that reference at least one of them (OR semantics). Multiple keys can be combined and should all apply (AND between keys).\n- Implement database-side filters using efficient Exists/OuterRef subqueries that resolve IDs, slugs, and SKUs for Page, Product, and ProductVariant references.\n- Validate the where input: reject empty or null lists, and disallow providing both containsAny and containsAll for the same reference key. Also ensure the reference filter is only used for reference-type attributes.\n- Update the GraphQL schema to include the new inputs and fields, and add tests for both happy-path and invalid inputs.\n",
      "supplementalFiles": [
        "saleor/page/models.py",
        "saleor/product/models.py",
        "saleor/graphql/core/filters/where_filters.py",
        "saleor/graphql/core/types/base.py",
        "saleor/graphql/core/types/common.py",
        "saleor/graphql/utils/filters.py",
        "saleor/attribute/utils.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/attribute/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/filters.py\n===================================================================\n--- saleor/graphql/attribute/filters.py\tf3c1a96 (parent)\n+++ saleor/graphql/attribute/filters.py\t836d01d (commit)\n@@ -1,13 +1,16 @@\n+from typing import Literal, TypedDict\n+\n import django_filters\n import graphene\n-from django.db.models import Q\n+from django.db.models import Exists, OuterRef, Q, QuerySet\n \n from ...attribute import AttributeInputType\n-from ...attribute.models import Attribute, AttributeValue\n+from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue\n from ...channel.models import Channel\n+from ...page import models as page_models\n from ...permission.utils import has_one_of_permissions\n-from ...product import models\n+from ...product import models as product_models\n from ...product.models import ALL_PRODUCTS_PERMISSIONS\n from ..channel.filters import get_channel_slug_from_filter_data\n from ..core.doc_category import DOC_CATEGORY_ATTRIBUTES\n from ..core.enums import MeasurementUnitsEnum\n@@ -30,12 +33,10 @@\n     FilterInputDescriptions,\n     StringFilterInput,\n     WhereInputObjectType,\n )\n-from ..core.types import (\n-    BaseInputObjectType,\n-    NonNullList,\n-)\n+from ..core.types.base import BaseInputObjectType\n+from ..core.types.common import NonNullList\n from ..core.utils import from_global_id_or_error\n from ..utils import get_user_or_app_from_context\n from ..utils.filters import filter_by_ids, filter_slug_list, filter_where_by_value_field\n from .enums import AttributeEntityTypeEnum, AttributeInputTypeEnum, AttributeTypeEnum\n@@ -48,15 +49,17 @@\n     channel = None\n     if channel_slug is not None:\n         channel = Channel.objects.using(qs.db).filter(slug=str(channel_slug)).first()\n     limited_channel_access = False if channel_slug is None else True\n-    product_qs = models.Product.objects.using(qs.db).visible_to_user(\n+    product_qs = product_models.Product.objects.using(qs.db).visible_to_user(\n         requestor, channel, limited_channel_access\n     )\n \n     if field == \"in_category\":\n         _type, category_id = from_global_id_or_error(value, \"Category\")\n-        category = models.Category.objects.using(qs.db).filter(pk=category_id).first()\n+        category = (\n+            product_models.Category.objects.using(qs.db).filter(pk=category_id).first()\n+        )\n \n         if category is None:\n             return qs.none()\n \n@@ -329,4 +332,353 @@\n     class Meta:\n         filterset_class = AttributeValueWhere\n         description = \"Where filtering options for attribute values.\"\n         doc_category = DOC_CATEGORY_ATTRIBUTES\n+\n+\n+CONTAINS_TYPING = dict[Literal[\"contains_any\", \"contains_all\"], list[str]]\n+\n+\n+class SharedContainsFilterParams(TypedDict):\n+    attr_id: int | None\n+    db_connection_name: str\n+    assigned_attr_model: type[AssignedPageAttributeValue]\n+    assigned_id_field_name: Literal[\"page_id\"]\n+    identifier_field_name: Literal[\"slug\", \"id\", \"sku\"]\n+\n+\n+def filter_by_contains_referenced_object_ids(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for objects referencing other entities by global IDs.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to other entities (like: variants, products, pages), identified by\n+    global IDs.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified global IDs will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified global IDs will match.\n+    \"\"\"\n+\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    variant_ids = set()\n+    product_ids = set()\n+    page_ids = set()\n+\n+    for obj_id in contains_any or contains_all or []:\n+        type_, id_ = graphene.Node.from_global_id(obj_id)\n+        if type_ == \"Page\":\n+            page_ids.add(id_)\n+        elif type_ == \"Product\":\n+            product_ids.add(id_)\n+        elif type_ == \"ProductVariant\":\n+            variant_ids.add(id_)\n+\n+    expression = Q()\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"id\",\n+    }\n+    if contains_all:\n+        if page_ids:\n+            expression &= _filter_contains_all_condition(\n+                contains_all=list(page_ids),\n+                referenced_model=page_models.Page,\n+                attr_value_reference_field_name=\"reference_page_id\",\n+                **shared_filter_params,\n+            )\n+        if product_ids:\n+            expression &= _filter_contains_all_condition(\n+                contains_all=list(product_ids),\n+                referenced_model=product_models.Product,\n+                attr_value_reference_field_name=\"reference_product_id\",\n+                **shared_filter_params,\n+            )\n+        if variant_ids:\n+            expression &= _filter_contains_all_condition(\n+                contains_all=list(variant_ids),\n+                referenced_model=product_models.ProductVariant,\n+                attr_value_reference_field_name=\"reference_variant_id\",\n+                **shared_filter_params,\n+            )\n+        return expression\n+\n+    if contains_any:\n+        if page_ids:\n+            expression |= _filter_contains_any_condition(\n+                contains_any=list(page_ids),\n+                referenced_model=page_models.Page,\n+                attr_value_reference_field_name=\"reference_page_id\",\n+                **shared_filter_params,\n+            )\n+\n+        if product_ids:\n+            expression |= _filter_contains_any_condition(\n+                contains_any=list(product_ids),\n+                referenced_model=product_models.Product,\n+                attr_value_reference_field_name=\"reference_product_id\",\n+                **shared_filter_params,\n+            )\n+\n+        if variant_ids:\n+            expression |= _filter_contains_any_condition(\n+                contains_any=list(variant_ids),\n+                referenced_model=product_models.ProductVariant,\n+                attr_value_reference_field_name=\"reference_variant_id\",\n+                **shared_filter_params,\n+            )\n+    return expression\n+\n+\n+def _filter_contains_single_expression(\n+    attr_id: int | None,\n+    db_connection_name: str,\n+    reference_objs: QuerySet[\n+        page_models.Page | product_models.Product | product_models.ProductVariant\n+    ],\n+    attr_value_reference_field_name: Literal[\n+        \"reference_page_id\", \"reference_product_id\", \"reference_variant_id\"\n+    ],\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    single_reference_qs = AttributeValue.objects.using(db_connection_name).filter(\n+        Exists(reference_objs.filter(id=OuterRef(attr_value_reference_field_name))),\n+    )\n+    if attr_id:\n+        attr_query = Attribute.objects.using(db_connection_name).filter(id=attr_id)\n+        single_reference_qs = single_reference_qs.filter(\n+            Exists(attr_query.filter(id=OuterRef(\"attribute_id\"))),\n+        )\n+    assigned_attr_value = assigned_attr_model.objects.using(db_connection_name).filter(\n+        Exists(single_reference_qs.filter(id=OuterRef(\"value_id\"))),\n+        **{str(assigned_id_field_name): OuterRef(\"id\")},\n+    )\n+    return Q(Exists(assigned_attr_value))\n+\n+\n+def _filter_contains_all_condition(\n+    attr_id: int | None,\n+    db_connection_name: str,\n+    contains_all: list[str],\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+    identifier_field_name: Literal[\"slug\", \"id\", \"sku\"],\n+    referenced_model: type[\n+        page_models.Page | product_models.Product | product_models.ProductVariant\n+    ],\n+    attr_value_reference_field_name: Literal[\n+        \"reference_page_id\", \"reference_product_id\", \"reference_variant_id\"\n+    ],\n+):\n+    \"\"\"Build a filter expression that ensures all specified references are present.\n+\n+    Constructs a Q expression that checks for references to all entities from\n+    `referenced_model`, matched using the provided identifiers in `contains_all`.\n+\n+    For each identifier, it resolves the corresponding object using\n+    `identifier_field_name` and adds a subquery to verify the presence\n+    of that reference. The subqueries are combined using logical AND.\n+    \"\"\"\n+\n+    identifiers = contains_all\n+    expression = Q()\n+\n+    for identifier in identifiers:\n+        reference_obj = referenced_model.objects.using(db_connection_name).filter(\n+            **{str(identifier_field_name): identifier}\n+        )\n+        expression &= _filter_contains_single_expression(\n+            attr_id,\n+            db_connection_name,\n+            reference_obj,\n+            attr_value_reference_field_name,\n+            assigned_attr_model,\n+            assigned_id_field_name,\n+        )\n+    return expression\n+\n+\n+def _filter_contains_any_condition(\n+    attr_id: int | None,\n+    db_connection_name: str,\n+    contains_any: list[str],\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+    identifier_field_name: Literal[\"slug\", \"id\", \"sku\"],\n+    referenced_model: type[\n+        page_models.Page | product_models.Product | product_models.ProductVariant\n+    ],\n+    attr_value_reference_field_name: Literal[\n+        \"reference_page_id\", \"reference_product_id\", \"reference_variant_id\"\n+    ],\n+):\n+    \"\"\"Build a filter expression that ensures at least one specified reference is present.\n+\n+    Constructs a Q expression that checks for a reference to any entity from\n+    `referenced_model`, matched using the provided identifiers in `contains_any`.\n+\n+    All matching references are resolved using `identifier_field_name`,\n+    and passed as a single queryset to be checked in a single subquery.\n+\n+    \"\"\"\n+    identifiers = contains_any\n+    reference_objs = referenced_model.objects.using(db_connection_name).filter(\n+        **{f\"{identifier_field_name}__in\": identifiers}\n+    )\n+    return _filter_contains_single_expression(\n+        attr_id,\n+        db_connection_name,\n+        reference_objs,\n+        attr_value_reference_field_name,\n+        assigned_attr_model,\n+        assigned_id_field_name,\n+    )\n+\n+\n+def filter_by_contains_referenced_pages(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for referenced pages.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to pages.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified pages will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified pages will match.\n+    \"\"\"\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"slug\",\n+    }\n+    if contains_all:\n+        return _filter_contains_all_condition(\n+            contains_all=contains_all,\n+            referenced_model=page_models.Page,\n+            attr_value_reference_field_name=\"reference_page_id\",\n+            **shared_filter_params,\n+        )\n+\n+    if contains_any:\n+        return _filter_contains_any_condition(\n+            contains_any=contains_any,\n+            referenced_model=page_models.Page,\n+            attr_value_reference_field_name=\"reference_page_id\",\n+            **shared_filter_params,\n+        )\n+    return Q()\n+\n+\n+def filter_by_contains_referenced_products(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for referenced products.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to products.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified products will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified products will match.\n+    \"\"\"\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"slug\",\n+    }\n+\n+    if contains_all:\n+        return _filter_contains_all_condition(\n+            contains_all=contains_all,\n+            referenced_model=product_models.Product,\n+            attr_value_reference_field_name=\"reference_product_id\",\n+            **shared_filter_params,\n+        )\n+\n+    if contains_any:\n+        return _filter_contains_any_condition(\n+            contains_any=contains_any,\n+            referenced_model=product_models.Product,\n+            attr_value_reference_field_name=\"reference_product_id\",\n+            **shared_filter_params,\n+        )\n+    return Q()\n+\n+\n+def filter_by_contains_referenced_variants(\n+    attr_id: int | None,\n+    attr_value: CONTAINS_TYPING,\n+    db_connection_name: str,\n+    assigned_attr_model: type[AssignedPageAttributeValue],\n+    assigned_id_field_name: Literal[\"page_id\"],\n+):\n+    \"\"\"Build a filter expression for referenced product variants.\n+\n+    Returns a Q expression to filter objects based on their references\n+    to product variants.\n+\n+    - If `contains_all` is provided, only objects that reference all of the\n+    specified variants will match.\n+    - If `contains_any` is provided, objects that reference at least one of\n+    the specified variants will match.\n+    \"\"\"\n+\n+    contains_all = attr_value.get(\"contains_all\")\n+    contains_any = attr_value.get(\"contains_any\")\n+\n+    shared_filter_params: SharedContainsFilterParams = {\n+        \"attr_id\": attr_id,\n+        \"db_connection_name\": db_connection_name,\n+        \"assigned_attr_model\": assigned_attr_model,\n+        \"assigned_id_field_name\": assigned_id_field_name,\n+        \"identifier_field_name\": \"sku\",\n+    }\n+\n+    if contains_all:\n+        return _filter_contains_all_condition(\n+            contains_all=contains_all,\n+            referenced_model=product_models.ProductVariant,\n+            attr_value_reference_field_name=\"reference_variant_id\",\n+            **shared_filter_params,\n+        )\n+\n+    if contains_any:\n+        return _filter_contains_any_condition(\n+            contains_any=contains_any,\n+            referenced_model=product_models.ProductVariant,\n+            attr_value_reference_field_name=\"reference_variant_id\",\n+            **shared_filter_params,\n+        )\n+    return Q()\n"
        },
        {
          "path": "saleor/graphql/core/filters/where_input.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/filters/where_input.py\n===================================================================\n--- saleor/graphql/core/filters/where_input.py\tf3c1a96 (parent)\n+++ saleor/graphql/core/filters/where_input.py\t836d01d (commit)\n@@ -55,8 +55,10 @@\n     EQ = \"The value equal to.\"\n     ONE_OF = \"The value included in.\"\n     NOT_ONE_OF = \"The value not included in.\"\n     RANGE = \"The value in range.\"\n+    CONTAINS_ALL = \"The field contains all of the specified values.\"\n+    CONTAINS_ANY = \"The field contains at least one of the specified values.\"\n \n \n class StringFilterInput(graphene.InputObjectType):\n     eq = graphene.String(description=FilterInputDescriptions.EQ, required=False)\n@@ -181,4 +183,22 @@\n           Matches objects where the metadata key \"color\" is set to either \"blue\" or \"green\".\n         - `{key: \"status\", value: {eq: \"active\"}}`\n           Matches objects where the metadata key \"status\" is set to \"active\".\n         \"\"\"\n+\n+\n+class ContainsFilterInput(graphene.InputObjectType):\n+    contains_any = NonNullList(\n+        graphene.String,\n+        description=FilterInputDescriptions.CONTAINS_ANY,\n+        required=False,\n+    )\n+    contains_all = NonNullList(\n+        graphene.String,\n+        description=FilterInputDescriptions.CONTAINS_ALL,\n+        required=False,\n+    )\n+\n+    class Meta:\n+        description = (\n+            \"Define the filtering options for fields that can contain multiple values.\"\n+        )\n"
        },
        {
          "path": "saleor/graphql/page/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/filters.py\n===================================================================\n--- saleor/graphql/page/filters.py\tf3c1a96 (parent)\n+++ saleor/graphql/page/filters.py\t836d01d (commit)\n@@ -1,4 +1,6 @@\n+from typing import Literal\n+\n import django_filters\n import graphene\n from django.db.models import Exists, FloatField, OuterRef, Q\n from django.db.models.functions import Cast\n@@ -6,8 +8,15 @@\n \n from ...attribute import AttributeInputType\n from ...attribute.models import AssignedPageAttributeValue, Attribute, AttributeValue\n from ...page import models\n+from ..attribute.filters import (\n+    CONTAINS_TYPING,\n+    filter_by_contains_referenced_object_ids,\n+    filter_by_contains_referenced_pages,\n+    filter_by_contains_referenced_products,\n+    filter_by_contains_referenced_variants,\n+)\n from ..core.context import ChannelQsContext\n from ..core.doc_category import DOC_CATEGORY_PAGES\n from ..core.filters import (\n     FilterInputObjectType,\n@@ -21,8 +30,9 @@\n     MetadataWhereBase,\n     OperationObjectTypeWhereFilter,\n )\n from ..core.filters.where_input import (\n+    ContainsFilterInput,\n     DecimalFilterInput,\n     GlobalIDFilterInput,\n     StringFilterInput,\n     WhereInputObjectType,\n@@ -211,18 +221,130 @@\n         elif attr.input_type == AttributeInputType.DATE_TIME:\n             attr_filter_expression &= filter_by_date_time_attribute(\n                 attr.id, attr_value[\"date_time\"], qs.db\n             )\n+        elif attr.input_type == AttributeInputType.REFERENCE:\n+            attr_filter_expression &= filter_pages_by_reference_attributes(\n+                attr.id, attr_value[\"reference\"], qs.db\n+            )\n     if attr_filter_expression != Q():\n         return qs.filter(attr_filter_expression)\n     return qs.none()\n \n \n+def filter_pages_by_reference_attributes(\n+    attr_id: int | None,\n+    attr_value: dict[\n+        Literal[\n+            \"referenced_ids\", \"page_slugs\", \"product_slugs\", \"product_variant_skus\"\n+        ],\n+        CONTAINS_TYPING,\n+    ],\n+    db_connection_name: str,\n+):\n+    filter_expression = Q()\n+\n+    if \"referenced_ids\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_object_ids(\n+            attr_id,\n+            attr_value[\"referenced_ids\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    if \"page_slugs\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_pages(\n+            attr_id,\n+            attr_value[\"page_slugs\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    if \"product_slugs\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_products(\n+            attr_id,\n+            attr_value[\"product_slugs\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    if \"product_variant_skus\" in attr_value:\n+        filter_expression &= filter_by_contains_referenced_variants(\n+            attr_id,\n+            attr_value[\"product_variant_skus\"],\n+            db_connection_name,\n+            assigned_attr_model=AssignedPageAttributeValue,\n+            assigned_id_field_name=\"page_id\",\n+        )\n+    return filter_expression\n+\n+\n+def validate_attribute_value_reference_input(\n+    values: list[\n+        dict[\n+            Literal[\n+                \"referenced_ids\", \"page_slugs\", \"product_slugs\", \"product_variant_skus\"\n+            ],\n+            CONTAINS_TYPING,\n+        ]\n+        | None\n+    ],\n+):\n+    \"\"\"Validate the input for reference attributes.\n+\n+    This function checks if the input for reference attributes is valid.\n+    It raises a GraphQLError if the input is invalid.\n+    \"\"\"\n+    duplicated_error = []\n+    empty_input_value_error = set()\n+    for value in values:\n+        if not value:\n+            raise GraphQLError(\n+                message=\"Invalid input for reference attributes. \"\n+                \"Provided 'value' cannot be null or empty.\"\n+            )\n+        for key in value:\n+            single_key_value = value[key]\n+            if (\n+                \"contains_all\" in single_key_value\n+                and \"contains_any\" in single_key_value\n+            ):\n+                duplicated_error.append(key)\n+                continue\n+            if (\n+                \"contains_all\" in single_key_value\n+                and not single_key_value[\"contains_all\"]\n+            ):\n+                empty_input_value_error.add(key)\n+                continue\n+            if (\n+                \"contains_any\" in single_key_value\n+                and not single_key_value[\"contains_any\"]\n+            ):\n+                empty_input_value_error.add(key)\n+\n+    if empty_input_value_error:\n+        raise GraphQLError(\n+            message=(\n+                f\"Invalid input for reference attributes. For fields: {', '.join(empty_input_value_error)}. \"\n+                f\"Provided values cannot be null or empty.\"\n+            )\n+        )\n+    if duplicated_error:\n+        raise GraphQLError(\n+            message=(\n+                f\"Invalid input for reference attributes. For fields: {', '.join(duplicated_error)}. \"\n+                \"Cannot provide both 'containsAll' and 'containsAny' for the same reference filter.\"\n+            )\n+        )\n+\n+\n def validate_attribute_value_input(attributes: list[dict], db_connection_name: str):\n     slug_list = [attr[\"slug\"] for attr in attributes]\n     value_as_empty_list = []\n     value_more_than_one_list = []\n     invalid_input_type_list = []\n+    reference_value_list = []\n     if len(slug_list) != len(set(slug_list)):\n         raise GraphQLError(\n             message=\"Duplicated attribute slugs in attribute 'where' input are not allowed.\"\n         )\n@@ -244,8 +366,10 @@\n             type_specific_value_list[attr[\"slug\"]] = value_key\n         if value[value_key] is None:\n             value_as_empty_list.append(attr[\"slug\"])\n             continue\n+        if value_key == \"reference\":\n+            reference_value_list.append(value[\"reference\"])\n \n     if type_specific_value_list:\n         attribute_input_type_map = Attribute.objects.using(db_connection_name).in_bulk(\n             type_specific_value_list.keys(),\n@@ -264,9 +388,13 @@\n             if \"date_time\" == value_key and input_type != AttributeInputType.DATE_TIME:\n                 invalid_input_type_list.append(attr_slug)\n             if \"boolean\" == value_key and input_type != AttributeInputType.BOOLEAN:\n                 invalid_input_type_list.append(attr_slug)\n+            if \"reference\" == value_key and input_type != AttributeInputType.REFERENCE:\n+                invalid_input_type_list.append(attr_slug)\n \n+    validate_attribute_value_reference_input(reference_value_list)\n+\n     if value_as_empty_list:\n         raise GraphQLError(\n             message=(\n                 f\"Incorrect input for attributes with slugs: {','.join(value_as_empty_list)}. \"\n@@ -288,8 +416,28 @@\n             )\n         )\n \n \n+class ReferenceAttributeWhereInput(BaseInputObjectType):\n+    referenced_ids = ContainsFilterInput(\n+        description=\"Returns objects with a reference pointing to an object identified by the given ID.\",\n+    )\n+    page_slugs = ContainsFilterInput(\n+        description=\"Returns objects with a reference pointing to a page identified by the given slug.\",\n+    )\n+    product_slugs = ContainsFilterInput(\n+        description=(\n+            \"Returns objects with a reference pointing to a product identified by the given slug.\"\n+        )\n+    )\n+    product_variant_skus = ContainsFilterInput(\n+        description=(\n+            \"Returns objects with a reference pointing \"\n+            \"to a product variant identified by the given sku.\"\n+        )\n+    )\n+\n+\n class AttributeValuePageInput(BaseInputObjectType):\n     slug = StringFilterInput(\n         description=\"Filter by slug assigned to AttributeValue.\",\n     )\n@@ -311,8 +459,12 @@\n     boolean = graphene.Boolean(\n         required=False,\n         description=\"Filter by boolean value for attributes of boolean type.\",\n     )\n+    reference = ReferenceAttributeWhereInput(\n+        required=False,\n+        description=(\"Filter by reference attribute value.\"),\n+    )\n \n \n class AttributePageWhereInput(BaseInputObjectType):\n     slug = graphene.String(description=\"Filter by attribute slug.\", required=True)\n"
        },
        {
          "path": "saleor/graphql/page/tests/queries/test_pages.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/queries/test_pages.py\n===================================================================\n--- saleor/graphql/page/tests/queries/test_pages.py\tf3c1a96 (parent)\n+++ saleor/graphql/page/tests/queries/test_pages.py\t836d01d (commit)\n@@ -140,9 +140,9 @@\n     (\"filter_by\", \"pages_count\"),\n     [\n         ({\"slugs\": [\"test-url-1\"]}, 1),\n         ({\"slugs\": [\"test-url-1\", \"test-url-2\"]}, 2),\n-        ({\"slugs\": []}, 2),\n+        ({\"slugs\": []}, 4),\n     ],\n )\n def test_pages_with_filtering(filter_by, pages_count, staff_api_client, page_list):\n     # given\n"
        },
        {
          "path": "saleor/graphql/page/tests/queries/test_pages_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/tests/queries/test_pages_with_where.py\n===================================================================\n--- saleor/graphql/page/tests/queries/test_pages_with_where.py\tf3c1a96 (parent)\n+++ saleor/graphql/page/tests/queries/test_pages_with_where.py\t836d01d (commit)\n@@ -3,10 +3,12 @@\n import graphene\n import pytest\n \n from .....attribute import AttributeInputType\n+from .....attribute.models import AttributeValue\n from .....attribute.utils import associate_attribute_values_to_instance\n from .....page.models import Page, PageType\n+from ....core.utils import to_global_id_or_none\n from ....tests.utils import get_graphql_content\n \n QUERY_PAGES_WITH_WHERE = \"\"\"\n     query ($where: PageWhereInput) {\n@@ -600,8 +602,640 @@\n     )\n \n \n @pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 2), (\"containsAll\", 1)]\n+)\n+def test_pages_query_with_attribute_value_reference_to_pages(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_page_reference_attribute,\n+):\n+    # given\n+    page_type.page_attributes.add(page_type_page_reference_attribute)\n+\n+    reference_page_1_slug = \"referenced-page-1\"\n+    reference_page_2_slug = \"referenced-page-2\"\n+    referenced_page_1, referenced_page_2 = Page.objects.bulk_create(\n+        [\n+            Page(\n+                title=\"Referenced Page 1\",\n+                slug=reference_page_1_slug,\n+                page_type=page_type,\n+                is_published=True,\n+            ),\n+            Page(\n+                title=\"Referenced Page 2\",\n+                slug=reference_page_2_slug,\n+                page_type=page_type,\n+                is_published=True,\n+            ),\n+        ]\n+    )\n+\n+    attribute_value_1, attribute_value_2 = AttributeValue.objects.bulk_create(\n+        [\n+            AttributeValue(\n+                attribute=page_type_page_reference_attribute,\n+                name=f\"Page {referenced_page_1.pk}\",\n+                slug=f\"page-{referenced_page_1.pk}\",\n+                reference_page=referenced_page_1,\n+            ),\n+            AttributeValue(\n+                attribute=page_type_page_reference_attribute,\n+                name=f\"Page {referenced_page_2.pk}\",\n+                slug=f\"page-{referenced_page_2.pk}\",\n+                reference_page=referenced_page_2,\n+            ),\n+        ]\n+    )\n+    page_with_both_references = page_list[0]\n+    associate_attribute_values_to_instance(\n+        page_with_both_references,\n+        {page_type_page_reference_attribute.pk: [attribute_value_1, attribute_value_2]},\n+    )\n+\n+    page_with_single_reference = page_list[1]\n+    associate_attribute_values_to_instance(\n+        page_with_single_reference,\n+        {page_type_page_reference_attribute.pk: [attribute_value_2]},\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": \"page-reference\",\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"pageSlugs\": {\n+                                filter_type: [\n+                                    reference_page_1_slug,\n+                                    reference_page_2_slug,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 2), (\"containsAll\", 1)]\n+)\n+def test_pages_query_with_attribute_value_reference_to_products(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_product_reference_attribute,\n+    product_list,\n+):\n+    # given\n+    page_type.page_attributes.add(page_type_product_reference_attribute)\n+\n+    first_product = product_list[0]\n+    second_product = product_list[1]\n+\n+    attribute_value_1, attribute_value_2 = AttributeValue.objects.bulk_create(\n+        [\n+            AttributeValue(\n+                attribute=page_type_product_reference_attribute,\n+                name=f\"Product {first_product.pk}\",\n+                slug=f\"product-{first_product.pk}\",\n+                reference_product=first_product,\n+            ),\n+            AttributeValue(\n+                attribute=page_type_product_reference_attribute,\n+                name=f\"Product {second_product.pk}\",\n+                slug=f\"product-{second_product.pk}\",\n+                reference_product=second_product,\n+            ),\n+        ]\n+    )\n+\n+    page_with_both_references = page_list[0]\n+    associate_attribute_values_to_instance(\n+        page_with_both_references,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                attribute_value_1,\n+                attribute_value_2,\n+            ]\n+        },\n+    )\n+\n+    page_with_single_reference = page_list[1]\n+    associate_attribute_values_to_instance(\n+        page_with_single_reference,\n+        {page_type_product_reference_attribute.pk: [attribute_value_2]},\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": \"product-reference\",\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"productSlugs\": {\n+                                filter_type: [first_product.slug, second_product.slug]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+    assert pages_nodes[0][\"node\"][\"id\"] == graphene.Node.to_global_id(\n+        \"Page\", page_list[0].pk\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 2), (\"containsAll\", 1)]\n+)\n+def test_pages_query_with_attribute_value_reference_to_product_variants(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_variant_reference_attribute,\n+    product_variant_list,\n+):\n+    # given\n+    page_type.page_attributes.add(page_type_variant_reference_attribute)\n+\n+    first_variant_sku = \"test-variant-1\"\n+    second_variant_sku = \"test-variant-2\"\n+\n+    first_variant = product_variant_list[0]\n+    first_variant.sku = first_variant_sku\n+    first_variant.save()\n+\n+    second_variant = product_variant_list[1]\n+    second_variant.sku = second_variant_sku\n+    second_variant.save()\n+\n+    attribute_value_1, attribute_value_2 = AttributeValue.objects.bulk_create(\n+        [\n+            AttributeValue(\n+                attribute=page_type_variant_reference_attribute,\n+                name=f\"Variant {first_variant.pk}\",\n+                slug=f\"variant-{first_variant.pk}\",\n+                reference_variant=first_variant,\n+            ),\n+            AttributeValue(\n+                attribute=page_type_variant_reference_attribute,\n+                name=f\"Variant {second_variant.pk}\",\n+                slug=f\"variant-{second_variant.pk}\",\n+                reference_variant=second_variant,\n+            ),\n+        ]\n+    )\n+\n+    page_with_both_references = page_list[0]\n+    associate_attribute_values_to_instance(\n+        page_with_both_references,\n+        {\n+            page_type_variant_reference_attribute.pk: [\n+                attribute_value_1,\n+                attribute_value_2,\n+            ]\n+        },\n+    )\n+\n+    page_with_single_reference = page_list[1]\n+    associate_attribute_values_to_instance(\n+        page_with_single_reference,\n+        {page_type_variant_reference_attribute.pk: [attribute_value_2]},\n+    )\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": \"variant-reference\",\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"productVariantSkus\": {\n+                                filter_type: [\n+                                    first_variant_sku,\n+                                    second_variant_sku,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(pages_nodes) == expected_count\n+    assert pages_nodes[0][\"node\"][\"id\"] == graphene.Node.to_global_id(\n+        \"Page\", page_list[0].pk\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 3), (\"containsAll\", 2)]\n+)\n+def test_pages_query_with_attribute_value_referenced_page_ids(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_page_reference_attribute,\n+):\n+    # given\n+    page_type.page_attributes.add(\n+        page_type_page_reference_attribute,\n+    )\n+\n+    referenced_first_page, referenced_second_page, referenced_third_page = (\n+        Page.objects.bulk_create(\n+            [\n+                Page(\n+                    title=\"Referenced Page\",\n+                    slug=\"referenced-page\",\n+                    page_type=page_type,\n+                    is_published=True,\n+                ),\n+                Page(\n+                    title=\"Referenced Page\",\n+                    slug=\"referenced-page2\",\n+                    page_type=page_type,\n+                    is_published=True,\n+                ),\n+                Page(\n+                    title=\"Referenced Page\",\n+                    slug=\"referenced-page3\",\n+                    page_type=page_type,\n+                    is_published=True,\n+                ),\n+            ]\n+        )\n+    )\n+\n+    first_attr_value, second_attr_value, third_attr_value = (\n+        AttributeValue.objects.bulk_create(\n+            [\n+                AttributeValue(\n+                    attribute=page_type_page_reference_attribute,\n+                    name=f\"Page {referenced_first_page.pk}\",\n+                    slug=f\"page-{referenced_first_page.pk}\",\n+                    reference_page=referenced_first_page,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_page_reference_attribute,\n+                    name=f\"Page {referenced_second_page.pk}\",\n+                    slug=f\"page-{referenced_second_page.pk}\",\n+                    reference_page=referenced_second_page,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_page_reference_attribute,\n+                    name=f\"Page {referenced_third_page.pk}\",\n+                    slug=f\"page-{referenced_third_page.pk}\",\n+                    reference_page=referenced_third_page,\n+                ),\n+            ]\n+        )\n+    )\n+    fist_page_with_all_ids = page_list[0]\n+    second_page_with_all_ids = page_list[1]\n+    page_with_single_id = page_list[2]\n+    associate_attribute_values_to_instance(\n+        fist_page_with_all_ids,\n+        {\n+            page_type_page_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        second_page_with_all_ids,\n+        {\n+            page_type_page_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_with_single_id,\n+        {page_type_page_reference_attribute.pk: [first_attr_value]},\n+    )\n+\n+    referenced_first_global_id = to_global_id_or_none(referenced_first_page)\n+    referenced_second_global_id = to_global_id_or_none(referenced_second_page)\n+    referenced_third_global_id = to_global_id_or_none(referenced_third_page)\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": page_type_page_reference_attribute.slug,\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"referencedIds\": {\n+                                filter_type: [\n+                                    referenced_first_global_id,\n+                                    referenced_second_global_id,\n+                                    referenced_third_global_id,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(page_list) > len(pages_nodes)\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 3), (\"containsAll\", 2)]\n+)\n+def test_pages_query_with_attribute_value_referenced_variant_ids(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_variant_reference_attribute,\n+    product_variant_list,\n+):\n+    # given\n+    page_type.page_attributes.add(\n+        page_type_variant_reference_attribute,\n+    )\n+\n+    first_variant = product_variant_list[0]\n+    second_variant = product_variant_list[1]\n+    third_variant = product_variant_list[2]\n+\n+    first_attr_value, second_attr_value, third_attr_value = (\n+        AttributeValue.objects.bulk_create(\n+            [\n+                AttributeValue(\n+                    attribute=page_type_variant_reference_attribute,\n+                    name=f\"Variant {first_variant.pk}\",\n+                    slug=f\"variant-{first_variant.pk}\",\n+                    reference_variant=first_variant,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_variant_reference_attribute,\n+                    name=f\"Variant {second_variant.pk}\",\n+                    slug=f\"variant-{second_variant.pk}\",\n+                    reference_variant=second_variant,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_variant_reference_attribute,\n+                    name=f\"Variant {third_variant.pk}\",\n+                    slug=f\"variant-{third_variant.pk}\",\n+                    reference_variant=third_variant,\n+                ),\n+            ]\n+        )\n+    )\n+    fist_page_with_all_ids = page_list[0]\n+    second_page_with_all_ids = page_list[1]\n+    page_with_single_id = page_list[2]\n+    associate_attribute_values_to_instance(\n+        fist_page_with_all_ids,\n+        {\n+            page_type_variant_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        second_page_with_all_ids,\n+        {\n+            page_type_variant_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_with_single_id,\n+        {page_type_variant_reference_attribute.pk: [first_attr_value]},\n+    )\n+    referenced_first_global_id = to_global_id_or_none(first_variant)\n+    referenced_second_global_id = to_global_id_or_none(second_variant)\n+    referenced_third_global_id = to_global_id_or_none(third_variant)\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": page_type_variant_reference_attribute.slug,\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"referencedIds\": {\n+                                filter_type: [\n+                                    referenced_first_global_id,\n+                                    referenced_second_global_id,\n+                                    referenced_third_global_id,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                }\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(page_list) > len(pages_nodes)\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"filter_type\", \"expected_count\"), [(\"containsAny\", 3), (\"containsAll\", 2)]\n+)\n+def test_pages_query_with_attribute_value_referenced_product_ids(\n+    filter_type,\n+    expected_count,\n+    staff_api_client,\n+    page_list,\n+    page_type,\n+    page_type_product_reference_attribute,\n+    product_list,\n+):\n+    # given\n+    page_type.page_attributes.add(\n+        page_type_product_reference_attribute,\n+    )\n+    first_product = product_list[0]\n+    second_product = product_list[1]\n+    third_product = product_list[2]\n+\n+    first_attr_value, second_attr_value, third_attr_value = (\n+        AttributeValue.objects.bulk_create(\n+            [\n+                AttributeValue(\n+                    attribute=page_type_product_reference_attribute,\n+                    name=f\"Product {first_product.pk}\",\n+                    slug=f\"Product-{first_product.pk}\",\n+                    reference_product=first_product,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_product_reference_attribute,\n+                    name=f\"Product {second_product.pk}\",\n+                    slug=f\"product-{second_product.pk}\",\n+                    reference_product=second_product,\n+                ),\n+                AttributeValue(\n+                    attribute=page_type_product_reference_attribute,\n+                    name=f\"Product {third_product.pk}\",\n+                    slug=f\"Product-{third_product.pk}\",\n+                    reference_product=third_product,\n+                ),\n+            ]\n+        )\n+    )\n+    fist_page_with_all_ids = page_list[0]\n+    second_page_with_all_ids = page_list[1]\n+    page_with_single_id = page_list[2]\n+    associate_attribute_values_to_instance(\n+        fist_page_with_all_ids,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        second_page_with_all_ids,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                first_attr_value,\n+                second_attr_value,\n+                third_attr_value,\n+            ],\n+        },\n+    )\n+\n+    associate_attribute_values_to_instance(\n+        page_with_single_id,\n+        {\n+            page_type_product_reference_attribute.pk: [\n+                first_attr_value,\n+            ],\n+        },\n+    )\n+    referenced_first_global_id = to_global_id_or_none(first_product)\n+    referenced_second_global_id = to_global_id_or_none(second_product)\n+    referenced_third_global_id = to_global_id_or_none(third_product)\n+\n+    variables = {\n+        \"where\": {\n+            \"attributes\": [\n+                {\n+                    \"slug\": page_type_product_reference_attribute.slug,\n+                    \"value\": {\n+                        \"reference\": {\n+                            \"referencedIds\": {\n+                                filter_type: [\n+                                    referenced_first_global_id,\n+                                    referenced_second_global_id,\n+                                    referenced_third_global_id,\n+                                ]\n+                            }\n+                        }\n+                    },\n+                },\n+            ]\n+        }\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        QUERY_PAGES_WITH_WHERE,\n+        variables,\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    pages_nodes = content[\"data\"][\"pages\"][\"edges\"]\n+    assert len(page_list) > len(pages_nodes)\n+    assert len(pages_nodes) == expected_count\n+\n+\n+@pytest.mark.parametrize(\n     \"attribute_filter\",\n     [\n         # When input receives None\n         [{\"slug\": \"page-size\"}, {\"slug\": \"page-size\"}],\n@@ -658,8 +1292,160 @@\n         [{\"slug\": \"date_time\", \"value\": {\"name\": None}}],\n         [{\"slug\": \"date_time\", \"value\": {\"slug\": None}}],\n         # Date time can't be used with non date time fields\n         [{\"slug\": \"date_time\", \"value\": {\"numeric\": {\"eq\": 1.2}}}],\n+        # Reference attribute\n+        [\n+            {\n+                \"slug\": \"date_time\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"pageSlugs\": {\n+                            \"containsAll\": [\n+                                \"about\",\n+                            ]\n+                        }\n+                    }\n+                },\n+            }\n+        ],\n+        [{\"slug\": \"reference-product\", \"value\": {}}],\n+        [{\"slug\": \"reference-product\", \"value\": {\"reference\": {}}}],\n+        [{\"slug\": \"reference-product\", \"value\": {\"reference\": None}}],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAll\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAny\": []}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\"pageSlugs\": {\"containsAny\": [], \"containsAll\": []}}\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"productSlugs\": {\"containsAny\": [], \"containsAll\": []}\n+                    }\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"productVariantSkus\": {\"containsAny\": [], \"containsAll\": []}\n+                    }\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\n+                    \"reference\": {\n+                        \"referencedIds\": {\"containsAny\": [], \"containsAll\": []}\n+                    }\n+                },\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAll\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"pageSlugs\": {\"containsAny\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productSlugs\": {\"containsAny\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"productVariantSkus\": {\"containsAny\": None}}},\n+            }\n+        ],\n+        [\n+            {\n+                \"slug\": \"reference-product\",\n+                \"value\": {\"reference\": {\"referencedIds\": {\"containsAny\": None}}},\n+            }\n+        ],\n     ],\n )\n def test_pages_query_failed_filter_validation(\n     attribute_filter,\n@@ -671,15 +1457,22 @@\n     boolean_attribute,\n     numeric_attribute_without_unit,\n     date_attribute,\n     date_time_attribute,\n+    page_type_product_reference_attribute,\n ):\n     # given\n     boolean_attribute.type = \"PAGE_TYPE\"\n     boolean_attribute.save()\n     numeric_attribute_without_unit.type = \"PAGE_TYPE\"\n     numeric_attribute_without_unit.save()\n \n+    page_type_product_reference_attribute.slug = \"reference-product\"\n+    page_type_product_reference_attribute.save()\n+\n+    page_type.page_attributes.add(\n+        page_type_product_reference_attribute,\n+    )\n     page_type.page_attributes.add(size_page_attribute)\n     page_type.page_attributes.add(tag_page_attribute)\n     page_type.page_attributes.add(boolean_attribute)\n     page_type.page_attributes.add(numeric_attribute_without_unit)\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\tf3c1a96 (parent)\n+++ saleor/graphql/schema.graphql\t836d01d (commit)\n@@ -13033,10 +13033,46 @@\n   dateTime: DateTimeRangeInput\n \n   \"\"\"Filter by boolean value for attributes of boolean type.\"\"\"\n   boolean: Boolean\n+\n+  \"\"\"Filter by reference attribute value.\"\"\"\n+  reference: ReferenceAttributeWhereInput\n }\n \n+input ReferenceAttributeWhereInput {\n+  \"\"\"\n+  Returns objects with a reference pointing to an object identified by the given ID.\n+  \"\"\"\n+  referencedIds: ContainsFilterInput\n+\n+  \"\"\"\n+  Returns objects with a reference pointing to a page identified by the given slug.\n+  \"\"\"\n+  pageSlugs: ContainsFilterInput\n+\n+  \"\"\"\n+  Returns objects with a reference pointing to a product identified by the given slug.\n+  \"\"\"\n+  productSlugs: ContainsFilterInput\n+\n+  \"\"\"\n+  Returns objects with a reference pointing to a product variant identified by the given sku.\n+  \"\"\"\n+  productVariantSkus: ContainsFilterInput\n+}\n+\n+\"\"\"\n+Define the filtering options for fields that can contain multiple values.\n+\"\"\"\n+input ContainsFilterInput {\n+  \"\"\"The field contains at least one of the specified values.\"\"\"\n+  containsAny: [String!]\n+\n+  \"\"\"The field contains all of the specified values.\"\"\"\n+  containsAll: [String!]\n+}\n+\n type PageTypeCountableConnection @doc(category: \"Pages\") {\n   \"\"\"Pagination data for this connection.\"\"\"\n   pageInfo: PageInfo!\n   edges: [PageTypeCountableEdge!]!\n"
        },
        {
          "path": "saleor/page/tests/fixtures/page.py",
          "status": "modified",
          "diff": "Index: saleor/page/tests/fixtures/page.py\n===================================================================\n--- saleor/page/tests/fixtures/page.py\tf3c1a96 (parent)\n+++ saleor/page/tests/fixtures/page.py\t836d01d (commit)\n@@ -62,9 +62,25 @@\n         \"content\": dummy_editorjs(\"Test content.\"),\n         \"is_published\": True,\n         \"page_type\": page_type,\n     }\n-    pages = Page.objects.bulk_create([Page(**data_1), Page(**data_2)])\n+    data_3 = {\n+        \"slug\": \"test3\",\n+        \"title\": \"Test page3\",\n+        \"content\": dummy_editorjs(\"Test content.\"),\n+        \"is_published\": True,\n+        \"page_type\": page_type,\n+    }\n+    data_4 = {\n+        \"slug\": \"test4\",\n+        \"title\": \"Test page4\",\n+        \"content\": dummy_editorjs(\"Test content.\"),\n+        \"is_published\": True,\n+        \"page_type\": page_type,\n+    }\n+    pages = Page.objects.bulk_create(\n+        [Page(**data_1), Page(**data_2), Page(**data_3), Page(**data_4)]\n+    )\n     return pages\n \n \n @pytest.fixture\n"
        }
      ]
    },
    {
      "id": "filter-checkout-webhooks",
      "sha": "b79cf8f91f04a919b16912bdb6ec1aae0ec85cad",
      "parentSha": "5646e7c4fbaaebb2260d2183cdbc65499bbefc59",
      "spec": "Implement channel-filterable async subscriptions for checkout events and update webhook filtering and payload handling accordingly.\n\nMake these changes:\n\n1) GraphQL subscription types and schema\n- Edit saleor/graphql/webhook/subscription_types.py:\n  - Import ADDED_IN_321 from saleor/graphql/core/descriptions.py.\n  - Rename default_order_resolver to default_channel_filterable_resolver and use it for all existing order subscription fields that support channel filtering.\n  - Update channels_argument description to use “object” instead of “order”.\n  - Add BaseField definitions for the following fields on Subscription, each with channels: [String!] argument, using resolver=default_channel_filterable_resolver and doc_category=DOC_CATEGORY_CHECKOUT.\n    - checkout_created: description includes “Event sent when new checkout is created.” + ADDED_IN_321 + PREVIEW_FEATURE.\n    - checkout_updated: description includes “Event sent when checkout is updated.” + ADDED_IN_321 + PREVIEW_FEATURE.\n    - checkout_fully_paid: description includes “Event sent when checkout is fully-paid.” + ADDED_IN_321 + PREVIEW_FEATURE.\n    - checkout_metadata_updated: description includes “Event sent when checkout metadata is updated.” + ADDED_IN_321 + PREVIEW_FEATURE.\n- Edit saleor/graphql/schema.graphql to reflect the above:\n  - Update channels argument descriptions across the existing order fields to say “object” in place of “order”.\n  - Add new checkoutCreated, checkoutUpdated, checkoutFullyPaid, checkoutMetadataUpdated in the Subscription type with channels argument and the specified descriptions (with Added in Saleor 3.21 and Feature Preview note).\n  - Ensure the event types CheckoutCreated, CheckoutUpdated, CheckoutFullyPaid, CheckoutMetadataUpdated include issuedAt, version, issuingPrincipal, recipient, and checkout.\n  - Remove any duplicated old definitions of these checkout event types from the lower sections of the schema.\n\n2) Schema printer improvements\n- Edit saleor/graphql/schema_printer.py:\n  - In print_field_directives_for_category, ensure doc_category for Mutation and Subscription fields is read from field.type.graphene_type first; if not found, fall back to resolver’s doc_category (for Query). Keep returning @doc(category: \"...\") when available.\n  - Maintain the adjusted typing for print_description signature (grouped union types) without changing behavior.\n\n3) Subscription payload processing refactor\n- Edit saleor/graphql/webhook/subscription_payload.py:\n  - Add a private helper _process_payload_instance(payload_instance) that:\n    - Iterates keys in payload_instance.data, runs get_event_payload on each value, and replaces them in-place.\n    - Returns event payload dict: if key \"event\" exists or data is empty, return payload_instance.data.get(\"event\") or {}; else wrap payload as {\"data\": payload_instance.data}.\n  - Use _process_payload_instance in both generate_payload_promise_from_subscription and generate_payload_from_subscription to build event_payload consistently.\n\n4) Webhook plugin channel-based filtering\n- Edit saleor/plugins/webhook/plugin.py:\n  - Replace _get_webhooks_for_order_events with a generalized _get_webhooks_for_channel_events(event_type, channel_slug, webhooks=None) that:\n    - Fetches appropriate webhooks for the event (when webhooks arg is None),\n    - If a webhook has no subscription_query or filterable_channel_slugs is empty, include it,\n    - Otherwise, include the webhook only if channel_slug is in webhook.filterable_channel_slugs.\n  - Update all order event handlers (order_created, order_confirmed, order_fully_paid, order_paid, order_refunded, order_fully_refunded, order_updated, order_expired, order_cancelled, order_fulfilled, order_metadata_updated) to call _get_webhooks_for_channel_events(event_type, order.channel.slug, webhooks) instead of the old helper.\n  - Update checkout event handlers (checkout_created, checkout_updated, checkout_fully_paid) to call _get_webhooks_for_channel_events with checkout.channel.slug and proceed as before (enqueue with settings.CHECKOUT_WEBHOOK_EVENTS_CELERY_QUEUE_NAME and use generate_checkout_payload).\n  - Update checkout_metadata_updated to first get filtered webhooks via _get_webhooks_for_channel_events and then call _trigger_metadata_updated_event with those.\n\n5) Fixtures\n- Edit saleor/app/tests/fixtures/app.py:\n  - Ensure webhook_app fixture adds permission_manage_checkouts to the app.permissions.\n- Edit saleor/checkout/tests/fixtures/checkout.py:\n  - Ensure the checkout_JPY fixture creates CheckoutMetadata for the new checkout to back metadata_storage use cases: CheckoutMetadata.objects.create(checkout=checkout).\n\n6) Tests for filterable checkout subscriptions\n- Add test modules under saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/:\n  - test_checkout_created.py\n  - test_checkout_updated.py\n  - test_checkout_fully_paid.py\n  - test_checkout_metadata_updated.py\nEach should:\n  - Register a subscription_webhook whose query includes the channels argument (and a variant without channels argument).\n  - Assign filterable_channel_slugs from SubscriptionQuery(query).get_filterable_channel_slugs().\n  - Exercise the plugin manager’s checkout_* method for a checkout in default channel and in a different channel.\n  - Assert that EventDelivery is created or not based on channel matching, and that send_webhook_request_async.apply_async is called only when expected.\n  - Validate payload content includes expected checkout fields (id, token, lines, and metadata for metadata_updated).\n\n7) CHANGELOG\n- Edit CHANGELOG.md: Under the unreleased section, add an entry: “Add filterable subscriptions for checkout events (checkoutCreated, checkoutUpdated, checkoutFullyPaid, checkoutMetadataUpdated)” with the PR/issue reference.\n\nBehavioral expectations:\n- For subscription webhooks with channels argument provided, only deliver events when the checkout’s channel slug matches any of the specified filters.\n- For subscriptions without channels input or with an empty filter list, deliver events regardless of channel.\n- Generated GraphQL schema includes the new filterable checkout subscription fields and has consistent doc_category directives and channels argument descriptions.\n- Payloads generated through subscription-based delivery consistently wrap data under {\"data\": ...} when appropriate and include extracted event payloads under the correct keys.",
      "prompt": "Add channel-filterable GraphQL subscriptions for checkout events and make webhook delivery honor those filters. Introduce subscription fields for checkout created, updated, fully paid, and metadata updated that accept a list of channel slugs to filter deliveries. Ensure the webhook plugin filters async deliveries for both orders and checkouts by channel slug when a webhook’s subscription defines channel filters. Unify how subscription payloads are processed so the event payload structure is consistent. Update schema docs so channels argument refers to the generic object, not just orders. Adjust fixtures so apps have checkout permissions and checkouts used in tests have metadata storage. Provide tests validating that webhooks only fire for matching channels and that payloads are correct.",
      "supplementalFiles": [
        "saleor/graphql/webhook/subscription_query.py",
        "saleor/webhook/models.py",
        "saleor/webhook/utils.py",
        "saleor/webhook/payloads.py",
        "saleor/graphql/core/descriptions.py",
        "saleor/graphql/core/types/event.py",
        "saleor/graphql/core/fields.py",
        "saleor/checkout/models.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t5646e7c (parent)\n+++ CHANGELOG.md\tb79cf8f (commit)\n@@ -69,8 +69,9 @@\n - `DraftOrderInput`, `OrderUpdateInput` and `DraftOrderCreateInput` now allow to provide `languageCode` - #17553 by @lkostrowski\n - Expose line-level discounts through the `OrderLineDiscount` type, retrievable via the `OrderLine.discounts` API field - #17510 by @korycins\n - Introduce total field in OrderDiscount to replace the amount field, with OrderDiscount.amount now deprecated - #17510 by @korycins\n - Introduce `useLegacyLineVoucherPropagation` flag to control legacy propagation behavior for specific voucher types - #17587 - by @korycins\n+- Add filterable subscriptions for checkout events (`checkoutCreated`, `checkoutUpdated`, `checkoutFullyPaid`, `checkoutMetadataUpdated`) - #17647 by @korycins\n \n ### Webhooks\n \n - Fixed webhookTrigger payload type for events related to ProductVariant - #16956 by @delemeator\n"
        },
        {
          "path": "saleor/app/tests/fixtures/app.py",
          "status": "modified",
          "diff": "Index: saleor/app/tests/fixtures/app.py\n===================================================================\n--- saleor/app/tests/fixtures/app.py\t5646e7c (parent)\n+++ saleor/app/tests/fixtures/app.py\tb79cf8f (commit)\n@@ -38,8 +38,9 @@\n     permission_manage_products,\n     permission_manage_staff,\n     permission_manage_orders,\n     permission_manage_users,\n+    permission_manage_checkouts,\n ):\n     app = App.objects.create(name=\"Webhook app\", is_active=True)\n     app.permissions.add(permission_manage_shipping)\n     app.permissions.add(permission_manage_gift_card)\n@@ -48,8 +49,9 @@\n     app.permissions.add(permission_manage_products)\n     app.permissions.add(permission_manage_staff)\n     app.permissions.add(permission_manage_orders)\n     app.permissions.add(permission_manage_users)\n+    app.permissions.add(permission_manage_checkouts)\n     return app\n \n \n @pytest.fixture\n"
        },
        {
          "path": "saleor/checkout/tests/fixtures/checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/fixtures/checkout.py\n===================================================================\n--- saleor/checkout/tests/fixtures/checkout.py\t5646e7c (parent)\n+++ saleor/checkout/tests/fixtures/checkout.py\tb79cf8f (commit)\n@@ -29,8 +29,9 @@\n     checkout = Checkout.objects.create(\n         currency=channel_JPY.currency_code, channel=channel_JPY\n     )\n     checkout.set_country(\"JP\", commit=True)\n+    CheckoutMetadata.objects.create(checkout=checkout)\n     return checkout\n \n \n @pytest.fixture\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\t5646e7c (parent)\n+++ saleor/graphql/schema.graphql\tb79cf8f (commit)\n@@ -29751,9 +29751,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   draftOrderCreated(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): DraftOrderCreated @doc(category: \"Orders\")\n \n@@ -29765,9 +29765,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   draftOrderUpdated(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): DraftOrderUpdated @doc(category: \"Orders\")\n \n@@ -29779,9 +29779,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   draftOrderDeleted(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): DraftOrderDeleted @doc(category: \"Orders\")\n \n@@ -29793,9 +29793,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderCreated(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderCreated @doc(category: \"Orders\")\n \n@@ -29807,9 +29807,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderUpdated(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderUpdated @doc(category: \"Orders\")\n \n@@ -29821,9 +29821,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderConfirmed(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderConfirmed @doc(category: \"Orders\")\n \n@@ -29835,9 +29835,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderPaid(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderPaid @doc(category: \"Orders\")\n \n@@ -29849,9 +29849,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderFullyPaid(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderFullyPaid @doc(category: \"Orders\")\n \n@@ -29863,9 +29863,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderRefunded(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderRefunded @doc(category: \"Orders\")\n \n@@ -29877,9 +29877,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderFullyRefunded(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderFullyRefunded @doc(category: \"Orders\")\n \n@@ -29891,9 +29891,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderFulfilled(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderFulfilled @doc(category: \"Orders\")\n \n@@ -29905,9 +29905,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderCancelled(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderCancelled @doc(category: \"Orders\")\n \n@@ -29919,9 +29919,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderExpired(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderExpired @doc(category: \"Orders\")\n \n@@ -29933,9 +29933,9 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderMetadataUpdated(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderMetadataUpdated @doc(category: \"Orders\")\n \n@@ -29947,12 +29947,68 @@\n   Note: this API is currently in Feature Preview and can be subject to changes at later point.\n   \"\"\"\n   orderBulkCreated(\n     \"\"\"\n-    List of channel slugs. The event will be sent only if the order belongs to one of the provided channels. If the channel slug list is empty, orders that belong to any channel will be sent. Maximally 500 items.\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n     \"\"\"\n     channels: [String!]\n   ): OrderBulkCreated @doc(category: \"Orders\")\n+\n+  \"\"\"\n+  Event sent when new checkout is created.\n+  \n+  Added in Saleor 3.21.\n+  \n+  Note: this API is currently in Feature Preview and can be subject to changes at later point.\n+  \"\"\"\n+  checkoutCreated(\n+    \"\"\"\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n+    \"\"\"\n+    channels: [String!]\n+  ): CheckoutCreated @doc(category: \"Checkout\")\n+\n+  \"\"\"\n+  Event sent when checkout is updated.\n+  \n+  Added in Saleor 3.21.\n+  \n+  Note: this API is currently in Feature Preview and can be subject to changes at later point.\n+  \"\"\"\n+  checkoutUpdated(\n+    \"\"\"\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n+    \"\"\"\n+    channels: [String!]\n+  ): CheckoutUpdated @doc(category: \"Checkout\")\n+\n+  \"\"\"\n+  Event sent when checkout is fully-paid.\n+  \n+  Added in Saleor 3.21.\n+  \n+  Note: this API is currently in Feature Preview and can be subject to changes at later point.\n+  \"\"\"\n+  checkoutFullyPaid(\n+    \"\"\"\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n+    \"\"\"\n+    channels: [String!]\n+  ): CheckoutFullyPaid @doc(category: \"Checkout\")\n+\n+  \"\"\"\n+  Event sent when checkout metadata is updated.\n+  \n+  Added in Saleor 3.21.\n+  \n+  Note: this API is currently in Feature Preview and can be subject to changes at later point.\n+  \"\"\"\n+  checkoutMetadataUpdated(\n+    \"\"\"\n+    List of channel slugs. The event will be sent only if the object belongs to one of the provided channels. If the channel slug list is empty, objects that belong to any channel will be sent. Maximally 500 items.\n+    \"\"\"\n+    channels: [String!]\n+  ): CheckoutMetadataUpdated @doc(category: \"Checkout\")\n }\n \n interface Event {\n   \"\"\"Time of the event.\"\"\"\n@@ -30241,8 +30297,82 @@\n   \"\"\"The orders the event relates to.\"\"\"\n   orders: [Order!]\n }\n \n+\"\"\"Event sent when new checkout is created.\"\"\"\n+type CheckoutCreated implements Event @doc(category: \"Checkout\") {\n+  \"\"\"Time of the event.\"\"\"\n+  issuedAt: DateTime\n+\n+  \"\"\"Saleor version that triggered the event.\"\"\"\n+  version: String\n+\n+  \"\"\"The user or application that triggered the event.\"\"\"\n+  issuingPrincipal: IssuingPrincipal\n+\n+  \"\"\"The application receiving the webhook.\"\"\"\n+  recipient: App\n+\n+  \"\"\"The checkout the event relates to.\"\"\"\n+  checkout: Checkout\n+}\n+\n+\"\"\"Event sent when checkout is updated.\"\"\"\n+type CheckoutUpdated implements Event @doc(category: \"Checkout\") {\n+  \"\"\"Time of the event.\"\"\"\n+  issuedAt: DateTime\n+\n+  \"\"\"Saleor version that triggered the event.\"\"\"\n+  version: String\n+\n+  \"\"\"The user or application that triggered the event.\"\"\"\n+  issuingPrincipal: IssuingPrincipal\n+\n+  \"\"\"The application receiving the webhook.\"\"\"\n+  recipient: App\n+\n+  \"\"\"The checkout the event relates to.\"\"\"\n+  checkout: Checkout\n+}\n+\n+\"\"\"\n+Event sent when checkout is fully paid with transactions. The checkout is considered as fully paid when the checkout `charge_status` is `FULL` or `OVERCHARGED`. The event is not sent when the checkout authorization flow strategy is used.\n+\"\"\"\n+type CheckoutFullyPaid implements Event @doc(category: \"Checkout\") {\n+  \"\"\"Time of the event.\"\"\"\n+  issuedAt: DateTime\n+\n+  \"\"\"Saleor version that triggered the event.\"\"\"\n+  version: String\n+\n+  \"\"\"The user or application that triggered the event.\"\"\"\n+  issuingPrincipal: IssuingPrincipal\n+\n+  \"\"\"The application receiving the webhook.\"\"\"\n+  recipient: App\n+\n+  \"\"\"The checkout the event relates to.\"\"\"\n+  checkout: Checkout\n+}\n+\n+\"\"\"Event sent when checkout metadata is updated.\"\"\"\n+type CheckoutMetadataUpdated implements Event @doc(category: \"Checkout\") {\n+  \"\"\"Time of the event.\"\"\"\n+  issuedAt: DateTime\n+\n+  \"\"\"Saleor version that triggered the event.\"\"\"\n+  version: String\n+\n+  \"\"\"The user or application that triggered the event.\"\"\"\n+  issuingPrincipal: IssuingPrincipal\n+\n+  \"\"\"The application receiving the webhook.\"\"\"\n+  recipient: App\n+\n+  \"\"\"The checkout the event relates to.\"\"\"\n+  checkout: Checkout\n+}\n+\n enum DistanceUnitsEnum {\n   MM\n   CM\n   DM\n@@ -32013,82 +32143,8 @@\n     channel: String\n   ): Collection\n }\n \n-\"\"\"Event sent when new checkout is created.\"\"\"\n-type CheckoutCreated implements Event @doc(category: \"Checkout\") {\n-  \"\"\"Time of the event.\"\"\"\n-  issuedAt: DateTime\n-\n-  \"\"\"Saleor version that triggered the event.\"\"\"\n-  version: String\n-\n-  \"\"\"The user or application that triggered the event.\"\"\"\n-  issuingPrincipal: IssuingPrincipal\n-\n-  \"\"\"The application receiving the webhook.\"\"\"\n-  recipient: App\n-\n-  \"\"\"The checkout the event relates to.\"\"\"\n-  checkout: Checkout\n-}\n-\n-\"\"\"Event sent when checkout is updated.\"\"\"\n-type CheckoutUpdated implements Event @doc(category: \"Checkout\") {\n-  \"\"\"Time of the event.\"\"\"\n-  issuedAt: DateTime\n-\n-  \"\"\"Saleor version that triggered the event.\"\"\"\n-  version: String\n-\n-  \"\"\"The user or application that triggered the event.\"\"\"\n-  issuingPrincipal: IssuingPrincipal\n-\n-  \"\"\"The application receiving the webhook.\"\"\"\n-  recipient: App\n-\n-  \"\"\"The checkout the event relates to.\"\"\"\n-  checkout: Checkout\n-}\n-\n-\"\"\"\n-Event sent when checkout is fully paid with transactions. The checkout is considered as fully paid when the checkout `charge_status` is `FULL` or `OVERCHARGED`. The event is not sent when the checkout authorization flow strategy is used.\n-\"\"\"\n-type CheckoutFullyPaid implements Event @doc(category: \"Checkout\") {\n-  \"\"\"Time of the event.\"\"\"\n-  issuedAt: DateTime\n-\n-  \"\"\"Saleor version that triggered the event.\"\"\"\n-  version: String\n-\n-  \"\"\"The user or application that triggered the event.\"\"\"\n-  issuingPrincipal: IssuingPrincipal\n-\n-  \"\"\"The application receiving the webhook.\"\"\"\n-  recipient: App\n-\n-  \"\"\"The checkout the event relates to.\"\"\"\n-  checkout: Checkout\n-}\n-\n-\"\"\"Event sent when checkout metadata is updated.\"\"\"\n-type CheckoutMetadataUpdated implements Event @doc(category: \"Checkout\") {\n-  \"\"\"Time of the event.\"\"\"\n-  issuedAt: DateTime\n-\n-  \"\"\"Saleor version that triggered the event.\"\"\"\n-  version: String\n-\n-  \"\"\"The user or application that triggered the event.\"\"\"\n-  issuingPrincipal: IssuingPrincipal\n-\n-  \"\"\"The application receiving the webhook.\"\"\"\n-  recipient: App\n-\n-  \"\"\"The checkout the event relates to.\"\"\"\n-  checkout: Checkout\n-}\n-\n \"\"\"Event sent when new page is created.\"\"\"\n type PageCreated implements Event @doc(category: \"Pages\") {\n   \"\"\"Time of the event.\"\"\"\n   issuedAt: DateTime\n"
        },
        {
          "path": "saleor/graphql/schema_printer.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema_printer.py\n===================================================================\n--- saleor/graphql/schema_printer.py\t5646e7c (parent)\n+++ saleor/graphql/schema_printer.py\tb79cf8f (commit)\n@@ -155,15 +155,17 @@\n     return directive\n \n \n def print_field_directives_for_category(field, name) -> str:\n-    # Get doc_category for `type Query` fields.\n-    doc_category = getattr(field.resolver, \"doc_category\", None)\n-\n-    # Get doc_category for `type Mutation` fields.\n-    if not doc_category and hasattr(field.type, \"graphene_type\"):\n+    doc_category = None\n+    # Get doc_category for `type Mutation` & `type Subscription` fields.\n+    if hasattr(field.type, \"graphene_type\"):\n         doc_category = getattr(field.type.graphene_type, \"doc_category\", None)\n \n+    if not doc_category:\n+        # Get doc_category for `type Query` fields.\n+        doc_category = getattr(field.resolver, \"doc_category\", None)\n+\n     return f' @doc(category: \"{doc_category}\")' if doc_category else \"\"\n \n \n def print_field_directives_for_webhook_events_info(field, name) -> str:\n@@ -456,17 +458,19 @@\n     return f'\"\"\"{before}{escaped_value}{after}\"\"\"'\n \n \n def print_description(\n-    def_: GraphQLArgument\n-    | GraphQLDirective\n-    | GraphQLEnumType\n-    | GraphQLEnumValue\n-    | GraphQLInputObjectType\n-    | GraphQLInterfaceType\n-    | GraphQLObjectType\n-    | GraphQLScalarType\n-    | GraphQLUnionType,\n+    def_: (\n+        GraphQLArgument\n+        | GraphQLDirective\n+        | GraphQLEnumType\n+        | GraphQLEnumValue\n+        | GraphQLInputObjectType\n+        | GraphQLInterfaceType\n+        | GraphQLObjectType\n+        | GraphQLScalarType\n+        | GraphQLUnionType\n+    ),\n     indentation: str = \"\",\n     first_in_block: bool = True,\n ) -> str:\n     description: str | None = def_.description\n"
        },
        {
          "path": "saleor/graphql/webhook/subscription_payload.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/subscription_payload.py\n===================================================================\n--- saleor/graphql/webhook/subscription_payload.py\t5646e7c (parent)\n+++ saleor/graphql/webhook/subscription_payload.py\tb79cf8f (commit)\n@@ -64,8 +64,21 @@\n         return event.get()\n     return event\n \n \n+def _process_payload_instance(payload_instance):\n+    \"\"\"Process a payload instance to extract data.\"\"\"\n+    for payload_key in payload_instance.data:\n+        extracted_payload = get_event_payload(payload_instance.data.get(payload_key))\n+        payload_instance.data[payload_key] = extracted_payload\n+    if \"event\" in payload_instance.data or not payload_instance.data:\n+        event_payload = payload_instance.data.get(\"event\") or {}\n+    else:\n+        event_payload = {\"data\": payload_instance.data}\n+\n+    return event_payload\n+\n+\n def generate_payload_promise_from_subscription(\n     event_type: str,\n     subscribable_object,\n     subscription_query: str,\n@@ -128,9 +141,9 @@\n             )\n             return None\n \n         payload_instance = payload[0]\n-        event_payload = payload_instance.data.get(\"event\") or {}\n+        event_payload = _process_payload_instance(payload_instance)\n \n         def check_errors(event_payload, payload_instance=payload_instance):\n             if payload_instance.errors:\n                 event_payload[\"errors\"] = [\n@@ -206,17 +219,9 @@\n         )\n         return None\n \n     payload_instance = payload[0]\n-    payload_data_keys = payload_instance.data.keys()\n-    for key in payload_data_keys:\n-        extracted_payload = get_event_payload(payload_instance.data.get(key))\n-        payload_instance.data[key] = extracted_payload\n-    if \"event\" in payload_instance.data or not payload_instance.data:\n-        event_payload = payload_instance.data.get(\"event\") or {}\n-    else:\n-        event_payload = {\"data\": payload_instance.data}\n-\n+    event_payload = _process_payload_instance(payload_instance)\n     if payload_instance.errors:\n         event_payload[\"errors\"] = [\n             format_error(error, (GraphQLError, PermissionDenied))\n             for error in payload_instance.errors\n"
        },
        {
          "path": "saleor/graphql/webhook/subscription_types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/subscription_types.py\n===================================================================\n--- saleor/graphql/webhook/subscription_types.py\t5646e7c (parent)\n+++ saleor/graphql/webhook/subscription_types.py\tb79cf8f (commit)\n@@ -46,8 +46,9 @@\n from ..core.descriptions import (\n     ADDED_IN_318,\n     ADDED_IN_319,\n     ADDED_IN_320,\n+    ADDED_IN_321,\n     DEPRECATED_IN_3X_EVENT,\n     PREVIEW_FEATURE,\n )\n from ..core.doc_category import (\n@@ -2592,18 +2593,18 @@\n         interfaces = (Event,)\n         description = \"Event sent when warehouse metadata is updated.\"\n \n \n-def default_order_resolver(root, info, channels=None):\n+def default_channel_filterable_resolver(root, info, channels=None):\n     return Observable.from_([root])\n \n \n channels_argument = graphene.Argument(\n     NonNullList(graphene.String),\n     description=(\n-        \"List of channel slugs. The event will be sent only if the order \"\n+        \"List of channel slugs. The event will be sent only if the object \"\n         \"belongs to one of the provided channels. If the channel slug list is \"\n-        \"empty, orders that belong to any channel will be sent. Maximally \"\n+        \"empty, objects that belong to any channel will be sent. Maximally \"\n         f\"{MAX_FILTERABLE_CHANNEL_SLUGS_LIMIT} items.\"\n     ),\n )\n \n@@ -2619,54 +2620,54 @@\n             \"Event sent when new draft order is created.\"\n             + ADDED_IN_320\n             + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     draft_order_updated = BaseField(\n         DraftOrderUpdated,\n         description=(\n             \"Event sent when draft order is updated.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     draft_order_deleted = BaseField(\n         DraftOrderDeleted,\n         description=(\n             \"Event sent when draft order is deleted.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_created = BaseField(\n         OrderCreated,\n         description=(\n             \"Event sent when new order is created.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_updated = BaseField(\n         OrderUpdated,\n         description=(\n             \"Event sent when order is updated.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_confirmed = BaseField(\n         OrderConfirmed,\n         description=(\n             \"Event sent when order is confirmed.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_paid = BaseField(\n@@ -2675,18 +2676,18 @@\n             \"Payment has been made. The order may be partially or fully paid.\"\n             + ADDED_IN_320\n             + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_fully_paid = BaseField(\n         OrderFullyPaid,\n         description=(\n             \"Event sent when order is fully paid.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_refunded = BaseField(\n@@ -2694,43 +2695,43 @@\n         description=(\n             \"The order received a refund. The order may be partially or fully \"\n             \"refunded.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_fully_refunded = BaseField(\n         OrderFullyRefunded,\n         description=(\"The order is fully refunded.\" + ADDED_IN_320 + PREVIEW_FEATURE),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_fulfilled = BaseField(\n         OrderFulfilled,\n         description=(\n             \"Event sent when order is fulfilled.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_cancelled = BaseField(\n         OrderCancelled,\n         description=(\n             \"Event sent when order is cancelled.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_expired = BaseField(\n         OrderExpired,\n         description=(\n             \"Event sent when order becomes expired.\" + ADDED_IN_320 + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_metadata_updated = BaseField(\n@@ -2739,9 +2740,9 @@\n             \"Event sent when order metadata is updated.\"\n             + ADDED_IN_320\n             + PREVIEW_FEATURE\n         ),\n-        resolver=default_order_resolver,\n+        resolver=default_channel_filterable_resolver,\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n     order_bulk_created = BaseField(\n@@ -2752,8 +2753,47 @@\n         channels=channels_argument,\n         doc_category=DOC_CATEGORY_ORDERS,\n     )\n \n+    checkout_created = BaseField(\n+        CheckoutCreated,\n+        description=(\n+            \"Event sent when new checkout is created.\" + ADDED_IN_321 + PREVIEW_FEATURE\n+        ),\n+        resolver=default_channel_filterable_resolver,\n+        channels=channels_argument,\n+        doc_category=DOC_CATEGORY_CHECKOUT,\n+    )\n+    checkout_updated = BaseField(\n+        CheckoutUpdated,\n+        description=(\n+            \"Event sent when checkout is updated.\" + ADDED_IN_321 + PREVIEW_FEATURE\n+        ),\n+        resolver=default_channel_filterable_resolver,\n+        channels=channels_argument,\n+        doc_category=DOC_CATEGORY_CHECKOUT,\n+    )\n+    checkout_fully_paid = BaseField(\n+        CheckoutFullyPaid,\n+        description=(\n+            \"Event sent when checkout is fully-paid.\" + ADDED_IN_321 + PREVIEW_FEATURE\n+        ),\n+        resolver=default_channel_filterable_resolver,\n+        channels=channels_argument,\n+        doc_category=DOC_CATEGORY_CHECKOUT,\n+    )\n+    checkout_metadata_updated = BaseField(\n+        CheckoutMetadataUpdated,\n+        description=(\n+            \"Event sent when checkout metadata is updated.\"\n+            + ADDED_IN_321\n+            + PREVIEW_FEATURE\n+        ),\n+        resolver=default_channel_filterable_resolver,\n+        channels=channels_argument,\n+        doc_category=DOC_CATEGORY_CHECKOUT,\n+    )\n+\n     class Meta:\n         doc_category = DOC_CATEGORY_MISC\n \n     @staticmethod\n"
        },
        {
          "path": "saleor/plugins/webhook/plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/plugin.py\n===================================================================\n--- saleor/plugins/webhook/plugin.py\t5646e7c (parent)\n+++ saleor/plugins/webhook/plugin.py\tb79cf8f (commit)\n@@ -775,20 +775,19 @@\n             export,\n         )\n         return previous_value\n \n-    def _get_webhooks_for_order_events(\n+    def _get_webhooks_for_channel_events(\n         self,\n         event_type: str,\n-        order: \"Order\",\n+        channel_slug: str,\n         webhooks: Iterable[\"Webhook\"] | None = None,\n     ) -> Iterable[\"Webhook\"]:\n-        \"\"\"Get webhooks for order events.\n+        \"\"\"Get webhooks for channel-based events.\n \n         Fetch all valid webhooks and filter out the ones that have a subscription query\n-        with filter that doesn't match to the order.\n+        with filter that doesn't match to the channel.\n         \"\"\"\n-        order_channel_slug = order.channel.slug\n         if webhooks is None:\n             webhooks = get_webhooks_for_event(event_type)\n         filtered_webhooks = []\n         for webhook in webhooks:\n@@ -798,9 +797,9 @@\n             filterable_channel_slugs = list(webhook.filterable_channel_slugs)\n             if not filterable_channel_slugs:\n                 filtered_webhooks.append(webhook)\n                 continue\n-            if order_channel_slug in filterable_channel_slugs:\n+            if channel_slug in filterable_channel_slugs:\n                 filtered_webhooks.append(webhook)\n         return filtered_webhooks\n \n     def order_created(\n@@ -808,9 +807,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_CREATED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -908,9 +909,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_CONFIRMED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -929,9 +932,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_FULLY_PAID\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -948,9 +953,11 @@\n     def order_paid(self, order: \"Order\", previous_value: None, webhooks=None) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_PAID\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -969,9 +976,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_REFUNDED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -990,9 +999,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_FULLY_REFUNDED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1011,9 +1022,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_UPDATED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1032,9 +1045,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_EXPIRED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1352,9 +1367,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_CANCELLED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1373,9 +1390,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_FULFILLED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1394,9 +1413,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.ORDER_METADATA_UPDATED\n-        webhooks = self._get_webhooks_for_order_events(event_type, order, webhooks)\n+        webhooks = self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        )\n         self._trigger_metadata_updated_event(\n             event_type,\n             order,\n             webhooks=webhooks,\n@@ -1459,9 +1480,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.DRAFT_ORDER_CREATED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1480,9 +1503,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.DRAFT_ORDER_UPDATED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -1501,9 +1526,11 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.DRAFT_ORDER_DELETED\n-        if webhooks := self._get_webhooks_for_order_events(event_type, order, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, order.channel.slug, webhooks\n+        ):\n             order_data_generator = partial(\n                 generate_order_payload, order, self.requestor\n             )\n             self.trigger_webhooks_async(\n@@ -2041,11 +2068,15 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.CHECKOUT_CREATED\n-        if webhooks := self._get_webhooks_for_event(event_type, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, checkout.channel.slug, webhooks\n+        ):\n             checkout_data_generator = partial(\n-                generate_checkout_payload, checkout, self.requestor\n+                generate_checkout_payload,\n+                checkout,\n+                self.requestor,\n             )\n             self.trigger_webhooks_async(\n                 None,\n                 event_type,\n@@ -2062,11 +2093,15 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n-        if webhooks := self._get_webhooks_for_event(event_type, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, checkout.channel.slug, webhooks\n+        ):\n             checkout_data_generator = partial(\n-                generate_checkout_payload, checkout, self.requestor\n+                generate_checkout_payload,\n+                checkout,\n+                self.requestor,\n             )\n             self.trigger_webhooks_async(\n                 None,\n                 event_type,\n@@ -2083,11 +2118,15 @@\n     ) -> None:\n         if not self.active:\n             return previous_value\n         event_type = WebhookEventAsyncType.CHECKOUT_FULLY_PAID\n-        if webhooks := self._get_webhooks_for_event(event_type, webhooks):\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, checkout.channel.slug, webhooks\n+        ):\n             checkout_data_generator = partial(\n-                generate_checkout_payload, checkout, self.requestor\n+                generate_checkout_payload,\n+                checkout,\n+                self.requestor,\n             )\n             self.trigger_webhooks_async(\n                 None,\n                 event_type,\n@@ -2103,11 +2142,15 @@\n         self, checkout: \"Checkout\", previous_value: None, webhooks=None\n     ) -> None:\n         if not self.active:\n             return previous_value\n-        self._trigger_metadata_updated_event(\n-            WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED, checkout, webhooks=webhooks\n-        )\n+        event_type = WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED\n+        if webhooks := self._get_webhooks_for_channel_events(\n+            event_type, checkout.channel.slug, webhooks\n+        ):\n+            self._trigger_metadata_updated_event(\n+                event_type, checkout, webhooks=webhooks\n+            )\n         return previous_value\n \n     def notify(\n         self,\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_created.py",
          "status": "added",
          "diff": "Index: saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_created.py\n===================================================================\n--- saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_created.py\t5646e7c (parent)\n+++ saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_created.py\tb79cf8f (commit)\n@@ -0,0 +1,243 @@\n+import json\n+from unittest.mock import patch\n+\n+import graphene\n+from django.test import override_settings\n+\n+from ......core.models import EventDelivery\n+from ......graphql.webhook.subscription_query import SubscriptionQuery\n+from ......webhook.event_types import WebhookEventAsyncType\n+from .....manager import get_plugins_manager\n+\n+CHECKOUT_CREATED_SUBSCRIPTION = \"\"\"\n+subscription {\n+  checkoutCreated(channels: [\"%s\"]) {\n+    checkout {\n+      id\n+      token\n+      lines {\n+        id\n+        variant {\n+          id\n+        }\n+      }\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_created(\n+    mocked_async, checkout_with_item, subscription_webhook, settings\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_CREATED\n+\n+    query = CHECKOUT_CREATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_created(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutCreated\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_created_without_channels_input(\n+    mocked_async, checkout_with_item, subscription_webhook\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_CREATED\n+\n+    query = \"\"\"subscription {\n+      checkoutCreated {\n+        checkout {\n+          id\n+          token\n+          lines {\n+            id\n+            variant {\n+              id\n+            }\n+          }\n+        }\n+      }\n+    }\"\"\"\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_created(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutCreated\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_created_with_different_channel(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_JPY_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_JPY_with_item\n+    channel = checkout.channel\n+    assert channel.slug != settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_CREATED\n+\n+    query = CHECKOUT_CREATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_created(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n+def test_different_event_doesnt_trigger_webhook(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = CHECKOUT_CREATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_created(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_paid.py",
          "status": "added",
          "diff": "Index: saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_paid.py\n===================================================================\n--- saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_paid.py\t5646e7c (parent)\n+++ saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_fully_paid.py\tb79cf8f (commit)\n@@ -0,0 +1,247 @@\n+import json\n+from unittest.mock import patch\n+\n+import graphene\n+from django.test import override_settings\n+\n+from ......core.models import EventDelivery\n+from ......graphql.webhook.subscription_query import SubscriptionQuery\n+from ......webhook.event_types import WebhookEventAsyncType\n+from .....manager import get_plugins_manager\n+\n+CHECKOUT_FULLY_PAID_SUBSCRIPTION = \"\"\"\n+subscription {\n+  checkoutFullyPaid(channels: [\"%s\"]) {\n+    checkout {\n+      id\n+      token\n+      lines {\n+        id\n+        variant {\n+          id\n+        }\n+      }\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_fully_paid(\n+    mocked_async, checkout_with_item, subscription_webhook, settings\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_PAID\n+\n+    query = CHECKOUT_FULLY_PAID_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_fully_paid(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutFullyPaid\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_fully_paid_without_channels_input(\n+    mocked_async, checkout_with_item, subscription_webhook\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_PAID\n+\n+    query = \"\"\"subscription {\n+      checkoutFullyPaid {\n+        checkout {\n+          id\n+          token\n+          lines {\n+            id\n+            variant {\n+              id\n+            }\n+          }\n+        }\n+      }\n+    }\"\"\"\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_fully_paid(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutFullyPaid\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_fully_paid_with_different_channel(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_JPY_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_JPY_with_item\n+    channel = checkout.channel\n+    assert channel.slug != settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_FULLY_PAID\n+\n+    query = CHECKOUT_FULLY_PAID_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_fully_paid(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_different_event_doesnt_trigger_webhook(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+\n+    checkout = checkout_with_item\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = CHECKOUT_FULLY_PAID_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_fully_paid(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_metadata_updated.py",
          "status": "added",
          "diff": "Index: saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_metadata_updated.py\n===================================================================\n--- saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_metadata_updated.py\t5646e7c (parent)\n+++ saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_metadata_updated.py\tb79cf8f (commit)\n@@ -0,0 +1,273 @@\n+import json\n+from unittest.mock import patch\n+\n+import graphene\n+from django.test import override_settings\n+\n+from ......core.models import EventDelivery\n+from ......graphql.webhook.subscription_query import SubscriptionQuery\n+from ......webhook.event_types import WebhookEventAsyncType\n+from .....manager import get_plugins_manager\n+\n+CHECKOUT_METADATA_UPDATED_SUBSCRIPTION = \"\"\"\n+subscription {\n+  checkoutMetadataUpdated(channels: [\"%s\"]) {\n+    checkout {\n+      id\n+      token\n+      metadata {\n+        key\n+        value\n+      }\n+      lines {\n+        id\n+        variant {\n+          id\n+        }\n+      }\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_metadata_updated(\n+    mocked_async, checkout_with_item, subscription_webhook, settings\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    # Add metadata to checkout\n+    metadata_items = [{\"key\": \"test_key\", \"value\": \"test_value\"}]\n+    checkout.metadata_storage.metadata = {\"test_key\": \"test_value\"}\n+    checkout.metadata_storage.save(update_fields=[\"metadata\"])\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED\n+\n+    query = CHECKOUT_METADATA_UPDATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_metadata_updated(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutMetadataUpdated\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"metadata\": metadata_items,\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_metadata_updated_without_channels_input(\n+    mocked_async, checkout_with_item, subscription_webhook\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    # Add metadata to checkout\n+    metadata_items = [{\"key\": \"test_key\", \"value\": \"test_value\"}]\n+    checkout.metadata_storage.metadata = {\"test_key\": \"test_value\"}\n+    checkout.metadata_storage.save(update_fields=[\"metadata\"])\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED\n+\n+    query = \"\"\"subscription {\n+      checkoutMetadataUpdated {\n+        checkout {\n+          id\n+          token\n+          metadata {\n+            key\n+            value\n+          }\n+          lines {\n+            id\n+            variant {\n+              id\n+            }\n+          }\n+        }\n+      }\n+    }\"\"\"\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_metadata_updated(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutMetadataUpdated\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"metadata\": metadata_items,\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_metadata_updated_with_different_channel(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_JPY_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_JPY_with_item\n+    channel = checkout.channel\n+    assert channel.slug != settings.DEFAULT_CHANNEL_SLUG\n+\n+    # Add metadata to checkout\n+    checkout.metadata_storage.metadata = {\"test_key\": \"test_value\"}\n+    checkout.metadata_storage.save(update_fields=[\"metadata\"])\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_METADATA_UPDATED\n+\n+    query = CHECKOUT_METADATA_UPDATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_metadata_updated(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_different_event_doesnt_trigger_webhook(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    # Add metadata to checkout\n+    checkout.metadata_storage.metadata = {\"test_key\": \"test_value\"}\n+    checkout.metadata_storage.save(update_fields=[\"metadata\"])\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = CHECKOUT_METADATA_UPDATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_metadata_updated(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_updated.py",
          "status": "added",
          "diff": "Index: saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_updated.py\n===================================================================\n--- saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_updated.py\t5646e7c (parent)\n+++ saleor/plugins/webhook/tests/subscription_webhooks/filterable_webhooks/test_checkout_updated.py\tb79cf8f (commit)\n@@ -0,0 +1,242 @@\n+import json\n+from unittest.mock import patch\n+\n+import graphene\n+from django.test import override_settings\n+\n+from ......core.models import EventDelivery\n+from ......graphql.webhook.subscription_query import SubscriptionQuery\n+from ......webhook.event_types import WebhookEventAsyncType\n+from .....manager import get_plugins_manager\n+\n+CHECKOUT_UPDATED_SUBSCRIPTION = \"\"\"\n+subscription {\n+  checkoutUpdated(channels: [\"%s\"]) {\n+    checkout {\n+      id\n+      token\n+      lines {\n+        id\n+        variant {\n+          id\n+        }\n+      }\n+    }\n+  }\n+}\n+\"\"\"\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_updated(\n+    mocked_async,\n+    checkout_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = CHECKOUT_UPDATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_updated(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutUpdated\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n+def test_checkout_updated_without_channels_input(\n+    mocked_async, checkout_with_item, subscription_webhook\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = \"\"\"subscription {\n+      checkoutUpdated {\n+        checkout {\n+          id\n+          token\n+          lines {\n+            id\n+            variant {\n+              id\n+            }\n+          }\n+        }\n+      }\n+    }\"\"\"\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    checkout_id = graphene.Node.to_global_id(\"Checkout\", checkout.pk)\n+\n+    # when\n+    manager.checkout_updated(checkout)\n+\n+    # then\n+    expected_payload = json.dumps(\n+        {\n+            \"data\": {\n+                \"checkoutUpdated\": {\n+                    \"checkout\": {\n+                        \"id\": checkout_id,\n+                        \"token\": str(checkout.token),\n+                        \"lines\": [\n+                            {\n+                                \"id\": graphene.Node.to_global_id(\n+                                    \"CheckoutLine\", checkout_line.id\n+                                ),\n+                                \"variant\": {\n+                                    \"id\": graphene.Node.to_global_id(\n+                                        \"ProductVariant\", checkout_line.variant_id\n+                                    )\n+                                },\n+                            }\n+                        ],\n+                    }\n+                }\n+            }\n+        }\n+    )\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 1\n+    assert deliveries[0].payload.get_payload() == expected_payload\n+    assert deliveries[0].webhook == webhook\n+    assert mocked_async.called\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(\n+    PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"],\n+    CELERY_TASK_ALWAYS_EAGER=True,\n+)\n+def test_checkout_updated_with_different_channel(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_JPY_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_JPY_with_item\n+    channel = checkout.channel\n+    assert channel.slug != settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_UPDATED\n+\n+    query = CHECKOUT_UPDATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_updated(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n+\n+\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.create_event_delivery_list_for_webhooks\"\n+)\n+@patch(\n+    \"saleor.webhook.transport.asynchronous.transport.send_webhook_request_async.apply_async\"\n+)\n+@override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n+def test_different_event_doesnt_trigger_webhook(\n+    mocked_async,\n+    mocked_create_event_delivery_list_for_webhooks,\n+    checkout_with_item,\n+    subscription_webhook,\n+    settings,\n+):\n+    # given\n+    manager = get_plugins_manager(False)\n+    checkout = checkout_with_item\n+    channel = checkout.channel\n+    assert channel.slug == settings.DEFAULT_CHANNEL_SLUG\n+\n+    event_type = WebhookEventAsyncType.CHECKOUT_CREATED\n+\n+    query = CHECKOUT_UPDATED_SUBSCRIPTION % settings.DEFAULT_CHANNEL_SLUG\n+    webhook = subscription_webhook(query, event_type)\n+    subscription_query = SubscriptionQuery(query)\n+    webhook.filterable_channel_slugs = subscription_query.get_filterable_channel_slugs()\n+    webhook.save()\n+\n+    # when\n+    manager.checkout_updated(checkout)\n+\n+    # then\n+    assert not mocked_async.called\n+    assert not mocked_create_event_delivery_list_for_webhooks.called\n+    deliveries = EventDelivery.objects.all()\n+    assert len(deliveries) == 0\n"
        }
      ]
    },
    {
      "id": "fix-allocation-bug",
      "sha": "0696ec30d60663cce98725c3f8c7ae4709c62a42",
      "parentSha": "411da1495ade413130c3965a224c9a420559b563",
      "spec": "Implement a robust and consistent stock allocation/deallocation flow across order editing and fulfillment, and ensure Stock.quantity_allocated always matches the sum of allocations.\n\nScope and required changes:\n\n1) GraphQL order line update: allocate on unconfirmed orders only\n- File: saleor/graphql/order/mutations/order_line_update.py\n  - In save(), compute order_is_unconfirmed = instance.order.is_unconfirmed() once.\n  - Compute warehouse_pk from the first allocation only when a line allocation exists AND the order is unconfirmed (use order_is_unconfirmed).\n  - Pass allocate_stock=order_is_unconfirmed to change_order_line_quantity().\n\n2) Order actions: replace legacy deallocation and call unified stock decrease\n- File: saleor/order/actions.py\n  - cancel_order(): replace deallocate_stock_for_order(order, manager) with deallocate_stock_for_orders([order.id], manager).\n  - Remove the private helper _decrease_stocks and call the stock management API directly:\n    - approve_fulfillment(): call decrease_stock(lines_to_fulfill, manager, allow_stock_to_be_exceeded=allow_stock_to_be_exceeded) and then proceed; do not pre-filter lines here; decrease_stock will handle filtering/deallocation.\n    - fulfill_order_lines(): call decrease_stock(order_lines_info, manager, allow_stock_to_be_exceeded=allow_stock_to_be_exceeded) then increase line quantities.\n  - _create_fulfillment_lines(): rename parameter decrease_stock to should_decrease_stock and, if True, call decrease_stock(lines_info, manager, allow_stock_to_be_exceeded=allow_stock_to_be_exceeded). Update the create_fulfillments() caller accordingly to pass should_decrease_stock=auto_approved.\n\n3) Order utils: allocation updates tied to allocate_stock flag, including disabled tracking cases\n- File: saleor/order/utils.py\n  - In add_variant_to_order() (editing an existing line): construct OrderLineInfo with line and the variant (variant must be present on the line_info); pass allocate_stock through to change_order_line_quantity(). Remove the separate increase_allocations(...) block for the allocate_stock case (allocations will be handled inside change_order_line_quantity based on the flag).\n  - Modify _update_allocations_for_line():\n    - Only require track-inventory for the increase path. When increasing (old < new), if the variant doesn’t track inventory or is preorder, return without increasing allocations.\n    - When decreasing (old > new), always call decrease_allocations, even for variants with tracking disabled, to drop any stale allocations.\n  - change_order_line_quantity(): add parameter allocate_stock: bool = False and use it instead of line.order.is_unconfirmed() to decide whether to adjust allocations via _update_allocations_for_line().\n\n4) Warehouse management: aggregate allocation deltas per stock and unify flows\n- File: saleor/warehouse/management.py\n  - allocate_stocks(): after bulk_create of Allocation objects, aggregate quantity per stock and bulk_update Stock.quantity_allocated once per stock. Stop incrementing per allocation row during a loop over returned objects; instead compute aggregated deltas and apply in one bulk update. Ensure out-of-stock webhook triggers are evaluated after updates.\n  - Add helper _reduce_quantity_allocated_for_stocks(allocations: Iterable[Allocation]) -> list[Stock]: aggregate allocated quantities per stock and return a list of Stock instances with quantity_allocated decreased by the aggregated amounts; use this when cleaning up old allocations before reallocation.\n  - increase_allocations(): after selecting existing allocations, compute per-line existing allocated amounts and adjust line_info.quantity to reflect the new total to be allocated. Before allocating afresh, call _reduce_quantity_allocated_for_stocks on those existing allocations, delete the existing Allocation rows, bulk_update the affected stocks to reduce quantity_allocated, and then call allocate_stocks().\n  - decrease_allocations(): replace the previous implementation with deallocation of existing allocations for all relevant lines, including lines with tracking disabled. Use new helper get_order_lines_to_deallocate() (see below). Handle AllocationError by zeroing allocations for affected order lines via update().\n  - decrease_stock(): change signature to remove update_stocks parameter and always decrease stocks. First call decrease_allocations(order_lines_info, manager) to drop allocations for the lines involved. Then filter order_lines_info via get_order_lines_with_track_inventory(); if none, return. Then proceed to lock stocks, compute per-stock current totals, and decrease stock quantities; annotate available_quantity and trigger out-of-stock webhook when appropriate.\n  - Add helper _get_variant_for_order_line_info(order_line_info) to ensure variant is present (load from line if necessary and cache to line_info.variant).\n  - Update get_order_lines_with_track_inventory(order_lines_info): use the helper above; include only lines whose variant exists, is not in preorder, and has track_inventory=True.\n  - Add get_order_lines_to_deallocate(order_lines_info): return all lines that have existing allocations regardless of the track_inventory flag, ensuring we always deallocate when allocations exist.\n  - Unify deallocate_stock_for_order into deallocate_stock_for_orders(orders_ids: list[UUID], manager): accept a list of order IDs; lock allocations, reduce stock.quantity_allocated using _reduce_quantity_allocated_for_stocks(), trigger back-in-stock events where applicable, set allocations to zero using update(), and bulk_update affected stocks. Update all call sites accordingly (see item 2).\n\n5) Fulfillment approval test fixtures used by GraphQL tests\n- File: saleor/order/tests/fixtures/fulfillment.py\n  - Introduce full_fulfillment_awaiting_approval fixture: mark the first fulfillment on a fulfilled_order as WAITING_FOR_APPROVAL; set fulfillment line quantities to match their corresponding order line quantities; set Stock.quantity for each FulfillmentLine.stock to match its order line quantity; set each OrderLine.quantity_fulfilled to match; bulk_update Stocks, FulfillmentLines, and OrderLines.\n  - Introduce partial_fulfillment_awaiting_approval fixture: based on full_fulfillment_awaiting_approval, set each FulfillmentLine.quantity to 1 and Stock.quantity to 1, and set each OrderLine.quantity_fulfilled to 1; bulk_update affected entities.\n\n6) GraphQL fulfillment approval test updates\n- File: saleor/graphql/order/tests/mutations/test_fulfillment_approve.py\n  - Replace references to fulfillment and fulfillment_awaiting_approval with full_fulfillment_awaiting_approval and partial_fulfillment_awaiting_approval as appropriate.\n  - Remove in-test status mutation patterns; rely on fixtures to set WAITING_FOR_APPROVAL and appropriate quantities and stocks.\n\n7) Order utils tests\n- File: saleor/order/tests/test_order_utils.py\n  - When calling change_order_line_quantity(...), pass allocate_stock=order_with_lines.is_unconfirmed() so allocations are only updated for unconfirmed orders.\n\n8) Warehouse tests\n- File: saleor/warehouse/tests/test_stock_management.py\n  - Update imports to replace deallocate_stock_for_order with deallocate_stock_for_orders and add import decrease_allocations.\n  - Rename the test for updating allocations only: test_decrease_stock_without_stock_update -> test_decrease_allocations; call decrease_allocations(...) and assert only allocations change.\n  - Add test covering increase_allocations with multiple allocations for the same stock in one operation; assert that Stock.quantity_allocated reflects the sum of both allocations plus both requested increases.\n  - Update deallocation tests to use deallocate_stock_for_orders([order.id], manager) and add a case with two allocations for the same stock, asserting Stock.quantity_allocated and both Allocation.quantity_allocated drop to 0 after deallocation.\n\nConstraints & behavior expectations:\n- Stock.quantity_allocated must always equal the sum of Allocation.quantity_allocated for that stock, even when multiple allocations affecting the same stock occur in a single operation.\n- When increasing an unconfirmed order line quantity, add allocations only if the variant tracks inventory and is not a preorder; when decreasing quantities, always deallocate any existing allocations, even if the variant currently has track inventory disabled.\n- decrease_stock must first deallocate allocations and then decrease stock quantities for tracked (non-preorder) variants; allow allow_stock_to_be_exceeded to bypass InsufficientStock errors when true.\n- cancel_order() must deallocate allocations for the order using the batch deallocation function.\n- Approval and fulfillment flows must rely on the unified decrease_stock behavior rather than private helpers.\n- GraphQL order line mutation must drive allocation updates via the new allocate_stock flag derived from order.is_unconfirmed().\n",
      "prompt": "We need to fix stock allocation and deallocation so Stock.quantity_allocated always matches the sum of allocations, and make allocation updates occur only when editing unconfirmed orders. Implement bulk, per-stock aggregation of allocation increments and decrements to avoid mismatch when multiple allocations for the same stock are processed at once. Unify the decrease flow so that decreasing stock always first removes allocations, then reduces stock for variants that actively track inventory (non-preorder). When decreasing quantities, also remove allocations even if track inventory is turned off but allocations exist.\n\nUpdate the order line update mutation to compute whether the order is unconfirmed once and pass that through to the change quantity operation to decide whether to allocate. Replace the single-order deallocation function with a batch function that takes a list of order IDs and update its call sites (e.g., order cancel). Update fulfillment approval to use the unified decrease_stock function and rename the parameter in the fulfillment creation path to reflect whether stock should be decreased.\n\nAdd or update fixtures to set up fully or partially awaiting-approval fulfillments that set both fulfillment line quantities and stock quantities appropriately. Adjust tests to rely on these fixtures, add coverage for multiple allocations on the same stock in a single operation, and rename the allocation-only decrease test accordingly.",
      "supplementalFiles": [
        "saleor/warehouse/models.py",
        "saleor/order/models.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t411da14 (parent)\n+++ CHANGELOG.md\t0696ec3 (commit)\n@@ -117,4 +117,6 @@\n - Allow to change Admin email plugin custom templates back to default - #17563 by @wcislo-saleor\n - Fixes incorrect gift card balances after covering the full order total - #17566 by @korycins\n - Fixes tax class not clearing when selecting a shipping method without a tax class - #17560 by @korycins\n - The prices for draft orders created in `OrderBulkCreate` now are properly calculated - #17583 by @IKarbowiak\n+- Fixes incorrect stock deallocation when multiple order lines share the same ProductVariant - #17657 by @korycins\n+- Decrease allocations for lines with inventory tracking disabled, if allocations exist - #17657 by @korycins\n"
        },
        {
          "path": "saleor/graphql/order/mutations/order_line_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/order_line_update.py\n===================================================================\n--- saleor/graphql/order/mutations/order_line_update.py\t411da14 (parent)\n+++ saleor/graphql/order/mutations/order_line_update.py\t0696ec3 (commit)\n@@ -73,12 +73,13 @@\n     @classmethod\n     def save(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n \n+        order_is_unconfirmed = instance.order.is_unconfirmed()\n         line_allocation = instance.allocations.first()\n         warehouse_pk = (\n             line_allocation.stock.warehouse.pk\n-            if line_allocation and instance.order.is_unconfirmed()\n+            if line_allocation and order_is_unconfirmed\n             else None\n         )\n         app = get_app_promise(info.context).get()\n         with traced_atomic_transaction():\n@@ -97,8 +98,9 @@\n                     instance.old_quantity,\n                     instance.quantity,\n                     order,\n                     manager,\n+                    allocate_stock=order_is_unconfirmed,\n                 )\n             except InsufficientStock as e:\n                 raise ValidationError(\n                     \"Cannot set new quantity because of insufficient stock.\",\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_fulfillment_approve.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_fulfillment_approve.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_fulfillment_approve.py\t411da14 (parent)\n+++ saleor/graphql/order/tests/mutations/test_fulfillment_approve.py\t0696ec3 (commit)\n@@ -43,15 +43,15 @@\n def test_fulfillment_approve(\n     mock_email_fulfillment,\n     mock_fulfillment_approved,\n     staff_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n ):\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n+\n     query = APPROVE_FULFILLMENT_MUTATION\n     fulfillment_id = graphene.Node.to_global_id(\"Fulfillment\", fulfillment.id)\n     variables = {\"id\": fulfillment_id, \"notifyCustomer\": True}\n \n@@ -77,21 +77,19 @@\n \n \n def test_fulfillment_approve_by_user_no_channel_access(\n     staff_api_client,\n-    fulfillment,\n+    partial_fulfillment_awaiting_approval,\n     permission_group_all_perms_channel_USD_only,\n     channel_PLN,\n ):\n     # given\n     permission_group_all_perms_channel_USD_only.user_set.add(staff_api_client.user)\n+    fulfillment = partial_fulfillment_awaiting_approval\n     order = fulfillment.order\n     order.channel = channel_PLN\n     order.save(update_fields=[\"channel\"])\n \n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n-\n     query = APPROVE_FULFILLMENT_MUTATION\n     fulfillment_id = graphene.Node.to_global_id(\"Fulfillment\", fulfillment.id)\n     variables = {\"id\": fulfillment_id, \"notifyCustomer\": True}\n \n@@ -107,14 +105,13 @@\n def test_fulfillment_approve_by_app(\n     mock_email_fulfillment,\n     mock_fulfillment_approved,\n     app_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_manage_orders,\n ):\n     # given\n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n     query = APPROVE_FULFILLMENT_MUTATION\n     fulfillment_id = graphene.Node.to_global_id(\"Fulfillment\", fulfillment.id)\n     variables = {\"id\": fulfillment_id, \"notifyCustomer\": True}\n \n@@ -145,14 +142,13 @@\n @patch(\"saleor.order.actions.send_fulfillment_confirmation_to_customer\", autospec=True)\n def test_fulfillment_approve_delete_products_before_approval_allow_stock_exceeded_true(\n     mock_email_fulfillment,\n     staff_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n ):\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n \n     Product.objects.all().delete()\n \n     query = APPROVE_FULFILLMENT_MUTATION\n@@ -184,16 +180,15 @@\n def test_fulfillment_approve_delete_products_before_approval_allow_stock_exceeded_false(\n     mock_email_fulfillment,\n     mock_fulfillment_approved,\n     staff_api_client,\n-    fulfillment,\n+    partial_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n     django_capture_on_commit_callbacks,\n ):\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = partial_fulfillment_awaiting_approval\n \n     Product.objects.all().delete()\n \n     query = APPROVE_FULFILLMENT_MUTATION\n@@ -242,16 +237,15 @@\n @patch(\"saleor.order.actions.send_fulfillment_confirmation_to_customer\", autospec=True)\n def test_fulfillment_approve_gift_cards_created(\n     mock_email_fulfillment,\n     staff_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n     gift_card_shippable_order_line,\n     gift_card_non_shippable_order_line,\n ):\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n \n     gift_card_line_1 = gift_card_shippable_order_line\n     gift_card_line_2 = gift_card_non_shippable_order_line\n     stock_1 = gift_card_line_1.variant.stocks.first()\n@@ -311,19 +305,20 @@\n @patch(\"saleor.order.actions.send_fulfillment_confirmation_to_customer\", autospec=True)\n def test_fulfillment_approve_when_stock_is_exceeded_and_flag_enabled(\n     mock_email_fulfillment,\n     staff_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n ):\n     # make stocks exceeded\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    for stock in [line.stock for line in fulfillment.lines.all()]:\n+    for stock in [\n+        line.stock for line in full_fulfillment_awaiting_approval.lines.all()\n+    ]:\n         stock.quantity = -99\n         stock.save()\n \n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n     query = APPROVE_FULFILLMENT_MUTATION\n     fulfillment_id = graphene.Node.to_global_id(\"Fulfillment\", fulfillment.id)\n \n     # make response with flag disabled, raised error is expected\n@@ -352,19 +347,20 @@\n @patch(\"saleor.order.actions.send_fulfillment_confirmation_to_customer\", autospec=True)\n def test_fulfillment_approve_when_stock_is_exceeded_and_flag_disabled(\n     mock_email_fulfillment,\n     staff_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n ):\n     # make stocks exceeded\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    for stock in [line.stock for line in fulfillment.lines.all()]:\n+    for stock in [\n+        line.stock for line in full_fulfillment_awaiting_approval.lines.all()\n+    ]:\n         stock.quantity = -99\n         stock.save()\n \n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n     query = APPROVE_FULFILLMENT_MUTATION\n     fulfillment_id = graphene.Node.to_global_id(\"Fulfillment\", fulfillment.id)\n \n     variables = {\n@@ -401,15 +397,15 @@\n def test_fulfillment_approve_partial_order_fulfill(\n     mock_email_fulfillment,\n     mock_fulfillment_approved,\n     staff_api_client,\n-    fulfillment_awaiting_approval,\n+    partial_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n ):\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     query = APPROVE_FULFILLMENT_MUTATION\n-    order = fulfillment_awaiting_approval.order\n+    order = partial_fulfillment_awaiting_approval.order\n \n     second_fulfillment = order.fulfillments.create()\n     line_1 = order.lines.first()\n     line_2 = order.lines.last()\n@@ -427,9 +423,9 @@\n \n     OrderLine.objects.bulk_update([line_1, line_2], [\"quantity_fulfilled\"])\n \n     fulfillment_id = graphene.Node.to_global_id(\n-        \"Fulfillment\", fulfillment_awaiting_approval.id\n+        \"Fulfillment\", partial_fulfillment_awaiting_approval.id\n     )\n     variables = {\"id\": fulfillment_id, \"notifyCustomer\": False}\n \n     # when\n@@ -440,14 +436,14 @@\n     data = content[\"data\"][\"orderFulfillmentApprove\"]\n     assert not data[\"errors\"]\n     assert data[\"fulfillment\"][\"status\"] == FulfillmentStatus.FULFILLED.upper()\n     assert data[\"order\"][\"status\"] == \"PARTIALLY_FULFILLED\"\n-    fulfillment_awaiting_approval.refresh_from_db()\n-    assert fulfillment_awaiting_approval.status == FulfillmentStatus.FULFILLED\n+    partial_fulfillment_awaiting_approval.refresh_from_db()\n+    assert partial_fulfillment_awaiting_approval.status == FulfillmentStatus.FULFILLED\n \n     assert mock_email_fulfillment.call_count == 0\n     mock_fulfillment_approved.assert_called_once_with(\n-        fulfillment_awaiting_approval, False\n+        partial_fulfillment_awaiting_approval, False\n     )\n \n \n def test_fulfillment_approve_invalid_status(\n@@ -515,18 +511,18 @@\n @patch(\"saleor.plugins.webhook.plugin.trigger_webhooks_async\")\n def test_fulfillment_approve_trigger_webhook_event(\n     mocked_trigger_async,\n     staff_api_client,\n-    fulfillment,\n+    full_fulfillment_awaiting_approval,\n     permission_group_manage_orders,\n     settings,\n     subscription_fulfillment_approved_webhook,\n ):\n     # given\n     settings.PLUGINS = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n-    fulfillment.save(update_fields=[\"status\"])\n+    fulfillment = full_fulfillment_awaiting_approval\n+\n     query = APPROVE_FULFILLMENT_MUTATION\n     fulfillment_id = graphene.Node.to_global_id(\"Fulfillment\", fulfillment.id)\n     variables = {\"id\": fulfillment_id, \"notifyCustomer\": True}\n \n"
        },
        {
          "path": "saleor/order/actions.py",
          "status": "modified",
          "diff": "Index: saleor/order/actions.py\n===================================================================\n--- saleor/order/actions.py\t411da14 (parent)\n+++ saleor/order/actions.py\t0696ec3 (commit)\n@@ -36,11 +36,10 @@\n from ..plugins.manager import PluginsManager\n from ..shipping.models import ShippingMethodChannelListing\n from ..warehouse.management import (\n     deallocate_stock,\n-    deallocate_stock_for_order,\n+    deallocate_stock_for_orders,\n     decrease_stock,\n-    get_order_lines_with_track_inventory,\n )\n from ..warehouse.models import Stock\n from ..webhook.event_types import WebhookEventAsyncType, WebhookEventSyncType\n from ..webhook.utils import get_webhooks_for_multiple_events\n@@ -418,9 +417,9 @@\n     \"\"\"\n     # transaction ensures proper allocation and event triggering\n     with traced_atomic_transaction():\n         events.order_canceled_event(order=order, user=user, app=app)\n-        deallocate_stock_for_order(order, manager)\n+        deallocate_stock_for_orders([order.id], manager)\n         order.status = OrderStatus.CANCELED\n         order.save(update_fields=[\"status\", \"updated_at\"])\n         if not webhook_event_map:\n             webhook_event_map = get_webhooks_for_multiple_events(\n@@ -899,9 +898,13 @@\n \n         if insufficient_stocks:\n             raise InsufficientStock(insufficient_stocks)\n \n-        _decrease_stocks(lines_to_fulfill, manager, allow_stock_to_be_exceeded)\n+        decrease_stock(\n+            lines_to_fulfill,\n+            manager,\n+            allow_stock_to_be_exceeded=allow_stock_to_be_exceeded,\n+        )\n         order.refresh_from_db()\n         order_fulfilled(\n             [fulfillment],\n             user,\n@@ -1031,18 +1034,8 @@\n             \"Orders with transactions can not be manually marked as paid.\",\n         )\n \n \n-def _decrease_stocks(order_lines_info, manager, allow_stock_to_be_exceeded=False):\n-    lines_to_decrease_stock = get_order_lines_with_track_inventory(order_lines_info)\n-    if lines_to_decrease_stock:\n-        decrease_stock(\n-            lines_to_decrease_stock,\n-            manager,\n-            allow_stock_to_be_exceeded=allow_stock_to_be_exceeded,\n-        )\n-\n-\n def _increase_order_line_quantity(order_lines_info):\n     order_lines = []\n     for line_info in order_lines_info:\n         line = line_info.line\n@@ -1060,9 +1053,13 @@\n     \"\"\"Fulfill order line with given quantity.\"\"\"\n     # transaction ensures that there is a consistency between quantities in order line\n     # and stocks\n     with traced_atomic_transaction():\n-        _decrease_stocks(order_lines_info, manager, allow_stock_to_be_exceeded)\n+        decrease_stock(\n+            order_lines_info,\n+            manager,\n+            allow_stock_to_be_exceeded=allow_stock_to_be_exceeded,\n+        )\n         _increase_order_line_quantity(order_lines_info)\n \n \n def automatically_fulfill_digital_lines(\n@@ -1135,9 +1132,9 @@\n     lines_data: list[OrderFulfillmentLineInfo],\n     channel_slug: str,\n     gift_card_lines_info: list[GiftCardLineData],\n     manager: \"PluginsManager\",\n-    decrease_stock: bool = True,\n+    should_decrease_stock: bool = True,\n     allow_stock_to_be_exceeded: bool = False,\n ) -> list[FulfillmentLine]:\n     \"\"\"Modify stocks and allocations. Return list of unsaved FulfillmentLines.\n \n@@ -1156,9 +1153,9 @@\n         channel_slug (str): Channel for which fulfillment lines should be created.\n         gift_card_lines_info (List): List with information required\n             to create gift cards.\n         manager (PluginsManager): Plugin manager from given context\n-        decrease_stock (Bool): Stocks will get decreased if this is True.\n+        should_decrease_stock (Bool): Stocks will get decreased if this is True.\n         allow_stock_to_be_exceeded (bool): If `True` then stock quantity could exceed.\n             Default value is set to `False`.\n \n     Return:\n@@ -1238,10 +1235,15 @@\n     if insufficient_stocks:\n         raise InsufficientStock(insufficient_stocks)\n \n     if lines_info:\n-        if decrease_stock:\n-            _decrease_stocks(lines_info, manager, allow_stock_to_be_exceeded)\n+        if should_decrease_stock:\n+            decrease_stock(\n+                lines_info,\n+                manager,\n+                allow_stock_to_be_exceeded=allow_stock_to_be_exceeded,\n+            )\n+\n         _increase_order_line_quantity(lines_info)\n \n     return fulfillment_lines\n \n@@ -1337,9 +1339,9 @@\n                     fulfillment_lines_for_warehouses[warehouse_pk],\n                     order.channel.slug,\n                     gift_card_lines_info,\n                     manager,\n-                    decrease_stock=auto_approved,\n+                    should_decrease_stock=auto_approved,\n                     allow_stock_to_be_exceeded=allow_stock_to_be_exceeded,\n                 )\n             )\n             if tracking_number:\n"
        },
        {
          "path": "saleor/order/tests/fixtures/fulfillment.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/fixtures/fulfillment.py\n===================================================================\n--- saleor/order/tests/fixtures/fulfillment.py\t411da14 (parent)\n+++ saleor/order/tests/fixtures/fulfillment.py\t0696ec3 (commit)\n@@ -2,9 +2,9 @@\n \n import graphene\n import pytest\n \n-from ....warehouse.models import Warehouse\n+from ....warehouse.models import Stock, Warehouse\n from ...models import FulfillmentLine, FulfillmentStatus, Order, OrderLine\n \n \n @pytest.fixture\n@@ -12,24 +12,51 @@\n     return fulfilled_order.fulfillments.first()\n \n \n @pytest.fixture\n-def fulfillment_awaiting_approval(fulfilled_order):\n+def full_fulfillment_awaiting_approval(fulfilled_order):\n     fulfillment = fulfilled_order.fulfillments.first()\n     fulfillment.status = FulfillmentStatus.WAITING_FOR_APPROVAL\n     fulfillment.save(update_fields=[\"status\"])\n \n+    fulfillment_lines_to_update = []\n+    order_lines_to_update = []\n+    for f_line in fulfillment.lines.all():\n+        order_line = f_line.order_line\n+        f_line.stock.quantity = order_line.quantity\n+        f_line.quantity = order_line.quantity\n+        fulfillment_lines_to_update.append(f_line)\n+\n+        order_line.quantity_fulfilled = order_line.quantity\n+        order_lines_to_update.append(order_line)\n+\n+    Stock.objects.bulk_update(\n+        [line.stock for line in fulfillment_lines_to_update], [\"quantity\"]\n+    )\n+    FulfillmentLine.objects.bulk_update(fulfillment_lines_to_update, [\"quantity\"])\n+    OrderLine.objects.bulk_update(order_lines_to_update, [\"quantity_fulfilled\"])\n+\n+    return fulfillment\n+\n+\n+@pytest.fixture\n+def partial_fulfillment_awaiting_approval(full_fulfillment_awaiting_approval):\n+    fulfillment = full_fulfillment_awaiting_approval\n     quantity = 1\n     fulfillment_lines_to_update = []\n     order_lines_to_update = []\n     for f_line in fulfillment.lines.all():\n+        f_line.stock.quantity = quantity\n         f_line.quantity = quantity\n         fulfillment_lines_to_update.append(f_line)\n \n         order_line = f_line.order_line\n         order_line.quantity_fulfilled = quantity\n         order_lines_to_update.append(order_line)\n \n+    Stock.objects.bulk_update(\n+        [line.stock for line in fulfillment_lines_to_update], [\"quantity\"]\n+    )\n     FulfillmentLine.objects.bulk_update(fulfillment_lines_to_update, [\"quantity\"])\n     OrderLine.objects.bulk_update(order_lines_to_update, [\"quantity_fulfilled\"])\n \n     return fulfillment\n"
        },
        {
          "path": "saleor/order/tests/test_order_utils.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_order_utils.py\n===================================================================\n--- saleor/order/tests/test_order_utils.py\t411da14 (parent)\n+++ saleor/order/tests/test_order_utils.py\t0696ec3 (commit)\n@@ -73,8 +73,9 @@\n         previous_quantity,\n         new_quantity,\n         order_with_lines,\n         get_plugins_manager(allow_replica=False),\n+        allocate_stock=order_with_lines.is_unconfirmed(),\n     )\n \n     if removed_count:\n         expected_type = OrderEvents.REMOVED_PRODUCTS\n"
        },
        {
          "path": "saleor/order/utils.py",
          "status": "modified",
          "diff": "Index: saleor/order/utils.py\n===================================================================\n--- saleor/order/utils.py\t411da14 (parent)\n+++ saleor/order/utils.py\t0696ec3 (commit)\n@@ -374,16 +374,16 @@\n     \"\"\"Add total_quantity of variant to order.\n \n     Returns an order line the variant was added to.\n     \"\"\"\n-    channel = order.channel\n-\n     is_new_line = not line_data.line_id\n     if not is_new_line:\n         line = order.lines.get(pk=line_data.line_id)\n         old_quantity = line.quantity\n         new_quantity = old_quantity + line_data.quantity\n-        line_info = OrderLineInfo(line=line, quantity=old_quantity)\n+        line_info = OrderLineInfo(\n+            line=line, variant=line_data.variant, quantity=old_quantity\n+        )\n         update_fields: list[str] = []\n         if new_quantity and line_data.price_override is not None:\n             update_line_base_unit_prices_with_custom_price(\n                 order, line_data, line, update_fields\n@@ -398,27 +398,14 @@\n             order,\n             manager=manager,\n             send_event=False,\n             update_fields=update_fields,\n+            allocate_stock=allocate_stock,\n         )\n \n         if update_fields:\n             line.save(update_fields=update_fields)\n \n-        if allocate_stock:\n-            increase_allocations(\n-                [\n-                    OrderLineInfo(\n-                        line=line,\n-                        quantity=line_data.quantity,\n-                        variant=line_data.variant,\n-                        warehouse_pk=None,\n-                    )\n-                ],\n-                channel,\n-                manager=manager,\n-            )\n-\n         return line\n \n     return create_order_line(\n         order,\n@@ -549,12 +536,11 @@\n ):\n     if old_quantity == new_quantity:\n         return\n \n-    if not get_order_lines_with_track_inventory([line_info]):\n-        return\n-\n     if old_quantity < new_quantity:\n+        if not get_order_lines_with_track_inventory([line_info]):\n+            return\n         line_info.quantity = new_quantity - old_quantity\n         increase_allocations([line_info], channel, manager)\n     else:\n         line_info.quantity = old_quantity - new_quantity\n@@ -570,15 +556,16 @@\n     order: \"Order\",\n     manager: \"PluginsManager\",\n     send_event: bool = True,\n     update_fields: list[str] | None = None,\n+    allocate_stock: bool = False,\n ):\n     \"\"\"Change the quantity of ordered items in a order line.\"\"\"\n     line = line_info.line\n     channel = order.channel\n     currency = channel.currency_code\n     if new_quantity:\n-        if line.order.is_unconfirmed():\n+        if allocate_stock:\n             _update_allocations_for_line(\n                 line_info, old_quantity, new_quantity, channel, manager\n             )\n         line.quantity = new_quantity\n"
        },
        {
          "path": "saleor/warehouse/management.py",
          "status": "modified",
          "diff": "Index: saleor/warehouse/management.py\n===================================================================\n--- saleor/warehouse/management.py\t411da14 (parent)\n+++ saleor/warehouse/management.py\t0696ec3 (commit)\n@@ -34,9 +34,8 @@\n )\n \n if TYPE_CHECKING:\n     from ..channel.models import Channel\n-    from ..order.models import Order\n \n \n class StockData(NamedTuple):\n     pk: int\n@@ -191,17 +190,22 @@\n     if insufficient_stock:\n         raise InsufficientStock(insufficient_stock)\n \n     if allocations:\n-        stocks_to_update = []\n-        for alloc in Allocation.objects.bulk_create(allocations):\n-            stock = alloc.stock\n-            stock.quantity_allocated = (\n-                F(\"quantity_allocated\") + alloc.quantity_allocated\n-            )\n-            stocks_to_update.append(stock)\n-        Stock.objects.bulk_update(stocks_to_update, [\"quantity_allocated\"])\n+        Allocation.objects.bulk_create(allocations)\n \n+        stocks_to_update_map = {alloc.stock_id: alloc.stock for alloc in allocations}\n+        quantity_from_allocations: dict[int, int] = defaultdict(int)\n+\n+        for alloc in allocations:\n+            quantity_from_allocations[alloc.stock_id] += alloc.quantity_allocated\n+\n+        for stock_id, quantity in quantity_from_allocations.items():\n+            stock = stocks_to_update_map[stock_id]\n+            stock.quantity_allocated = F(\"quantity_allocated\") + quantity\n+\n+        Stock.objects.bulk_update(stocks_to_update_map.values(), [\"quantity_allocated\"])\n+\n         for allocation in allocations:\n             allocated_stock = (\n                 Allocation.objects.filter(stock_id=allocation.stock_id).aggregate(\n                     Sum(\"quantity_allocated\")\n@@ -445,8 +449,30 @@\n         stock.quantity_allocated = F(\"quantity_allocated\") + quantity\n         stock.save(update_fields=[\"quantity_allocated\"])\n \n \n+def _reduce_quantity_allocated_for_stocks(\n+    allocations: Iterable[Allocation],\n+) -> list[Stock]:\n+    \"\"\"Reduce quantity allocated for stocks from allocations.\n+\n+    This function reduces the quantity allocated for stocks based on the allocations\n+    associated with them. It takes a list of Allocation objects and returns a list of\n+    Stock objects with their quantity_allocated field updated.\n+    \"\"\"\n+    stocks_to_update_map: dict[int, Stock] = {\n+        alloc.stock_id: alloc.stock for alloc in allocations\n+    }\n+    quantity_allocated_to_reduce: dict[int, int] = defaultdict(int)\n+    for alloc in allocations:\n+        quantity_allocated_to_reduce[alloc.stock_id] += alloc.quantity_allocated\n+\n+    for stock_pk, quantity_allocated in quantity_allocated_to_reduce.items():\n+        stock = stocks_to_update_map[stock_pk]\n+        stock.quantity_allocated = F(\"quantity_allocated\") - quantity_allocated\n+    return list(stocks_to_update_map.values())\n+\n+\n @traced_atomic_transaction()\n def increase_allocations(\n     lines_info: list[\"OrderLineInfo\"], channel: \"Channel\", manager: PluginsManager\n ):\n@@ -469,13 +495,12 @@\n         allocated = sum(allocation_quantity_map[line_info.line.pk])\n         # line_info.quantity resembles amount to add, sum it with already allocated.\n         line_info.quantity += allocated\n \n-    stocks_to_update = []\n-    for alloc in allocations:\n-        stock = alloc.stock\n-        stock.quantity_allocated = F(\"quantity_allocated\") - alloc.quantity_allocated\n-        stocks_to_update.append(stock)\n+    # Reduces quantity allocated for stocks from allocations, as `allocate_stocks`\n+    # will create new allocations.\n+    stocks_to_update = _reduce_quantity_allocated_for_stocks(allocations=allocations)\n+\n     Allocation.objects.filter(pk__in=allocation_pks_to_delete).delete()\n     Stock.objects.bulk_update(stocks_to_update, [\"quantity_allocated\"])\n \n     order = lines_info[0].line.order\n@@ -490,20 +515,24 @@\n     )\n \n \n def decrease_allocations(lines_info: list[\"OrderLineInfo\"], manager):\n-    \"\"\"Decreate allocations for provided order lines.\"\"\"\n-    tracked_lines = get_order_lines_with_track_inventory(lines_info)\n-    if not tracked_lines:\n+    \"\"\"Decrease allocations for provided order lines.\"\"\"\n+    lines_to_deallocate = get_order_lines_to_deallocate(lines_info)\n+    if not lines_to_deallocate:\n         return\n-    decrease_stock(tracked_lines, update_stocks=False, manager=manager)\n+    try:\n+        deallocate_stock(lines_info, manager)\n+    except AllocationError as exc:\n+        Allocation.objects.order_by(\"stock_id\").filter(\n+            order_line__in=exc.order_lines\n+        ).update(quantity_allocated=0)\n \n \n @traced_atomic_transaction()\n def decrease_stock(\n     order_lines_info: list[\"OrderLineInfo\"],\n     manager,\n-    update_stocks=True,\n     allow_stock_to_be_exceeded: bool = False,\n ):\n     \"\"\"Decrease stocks quantities for given `order_lines` in given warehouses.\n \n@@ -511,20 +540,17 @@\n     from requested function deallocate whole quantity. Next function try to find the\n     stock in a given warehouse, if stock not exists or have not enough stock,\n     the function raise InsufficientStock exception. When the stock has enough quantity\n     function decrease it by given value.\n-    If update_stocks is False, allocations will decrease but stocks quantities\n-    will stay unmodified (case of unconfirmed order editing).\n     If allow_stock_to_be_exceeded flag is True then quantity could be < 0.\n     \"\"\"\n+    decrease_allocations(order_lines_info, manager)\n+\n+    order_lines_info = get_order_lines_with_track_inventory(order_lines_info)\n+    if not order_lines_info:\n+        return\n     variants = [line_info.variant for line_info in order_lines_info]\n     warehouse_pks = [line_info.warehouse_pk for line_info in order_lines_info]\n-    try:\n-        deallocate_stock(order_lines_info, manager)\n-    except AllocationError as exc:\n-        Allocation.objects.order_by(\"stock_id\").filter(\n-            order_line__in=exc.order_lines\n-        ).update(quantity_allocated=0)\n \n     stocks = (\n         stock_qs_select_for_update()\n         .filter(product_variant__in=variants)\n@@ -546,29 +572,24 @@\n         .values(\"stock\")\n         .annotate(Sum(\"quantity_allocated\"))\n     )\n \n-    if update_stocks:\n-        quantity_allocation_for_stocks: dict[int, int] = defaultdict(int)\n-        for allocation in quantity_allocation_list:\n-            quantity_allocation_for_stocks[allocation[\"stock\"]] += allocation[\n-                \"quantity_allocated__sum\"\n-            ]\n-        _decrease_stocks_quantity(\n-            order_lines_info,\n-            variant_and_warehouse_to_stock,\n-            quantity_allocation_for_stocks,\n-            allow_stock_to_be_exceeded,\n-        )\n+    quantity_allocation_for_stocks: dict[int, int] = defaultdict(int)\n+    for allocation in quantity_allocation_list:\n+        quantity_allocation_for_stocks[allocation[\"stock\"]] += allocation[\n+            \"quantity_allocated__sum\"\n+        ]\n+    _decrease_stocks_quantity(\n+        order_lines_info,\n+        variant_and_warehouse_to_stock,\n+        quantity_allocation_for_stocks,\n+        allow_stock_to_be_exceeded,\n+    )\n \n-        stock_ids = (s.id for s in stocks)\n-        for stock in Stock.objects.filter(\n-            id__in=stock_ids\n-        ).annotate_available_quantity():\n-            if stock.available_quantity <= 0:\n-                transaction.on_commit(\n-                    lambda: manager.product_variant_out_of_stock(stock)\n-                )\n+    stock_ids = (s.id for s in stocks)\n+    for stock in Stock.objects.filter(id__in=stock_ids).annotate_available_quantity():\n+        if stock.available_quantity <= 0:\n+            transaction.on_commit(lambda: manager.product_variant_out_of_stock(stock))\n \n \n def _decrease_stocks_quantity(\n     order_lines_info: list[\"OrderLineInfo\"],\n@@ -623,61 +644,74 @@\n \n     Stock.objects.bulk_update(stocks_to_update, [\"quantity\"])\n \n \n+def _get_variant_for_order_line_info(\n+    order_line_info: OrderLineInfo,\n+) -> ProductVariant | None:\n+    variant = order_line_info.variant\n+    if not variant and order_line_info.line.variant_id:\n+        variant = order_line_info.line.variant\n+        order_line_info.variant = variant\n+    return variant\n+\n+\n def get_order_lines_with_track_inventory(\n     order_lines_info: list[\"OrderLineInfo\"],\n ) -> list[\"OrderLineInfo\"]:\n     \"\"\"Return order lines with variants with track inventory set to True.\"\"\"\n-    return [\n-        line_info\n-        for line_info in order_lines_info\n-        if line_info.variant\n-        and line_info.variant.track_inventory\n-        and not line_info.variant.is_preorder_active()\n-    ]\n \n+    lines_to_return = []\n+    for line_info in order_lines_info:\n+        variant = _get_variant_for_order_line_info(line_info)\n \n-@traced_atomic_transaction()\n-def deallocate_stock_for_order(order: \"Order\", manager: PluginsManager):\n-    \"\"\"Remove all allocations for given order.\"\"\"\n-    lines = OrderLine.objects.filter(order_id=order.id)\n-    allocations = allocation_with_stock_qs_select_for_update().filter(\n-        Exists(lines.filter(id=OuterRef(\"order_line_id\"))), quantity_allocated__gt=0\n-    )\n+        if not variant:\n+            continue\n+        if variant.is_preorder_active():\n+            continue\n+        if not variant.track_inventory:\n+            continue\n+        lines_to_return.append(line_info)\n+    return lines_to_return\n \n-    stocks_to_update = []\n-    for alloc in allocations:\n-        stock = alloc.stock\n-        stock.quantity_allocated = F(\"quantity_allocated\") - alloc.quantity_allocated\n-        stocks_to_update.append(stock)\n \n-    allocations_for_back_in_stock = Allocation.objects.filter(\n-        id__in=[allocation.id for allocation in allocations]\n+def get_order_lines_to_deallocate(\n+    order_lines_info: list[\"OrderLineInfo\"],\n+) -> list[\"OrderLineInfo\"]:\n+    \"\"\"Get order lines to deallocate.\n+\n+    The function returns the lines with active track inventory and the lines where track\n+    inventory was turned off but for some reason the allocations are present.\n+    Case like turning on & off the track-inventory.\n+    \"\"\"\n+\n+    order_lines_info_map = {\n+        line_info.line.id: line_info for line_info in order_lines_info\n+    }\n+\n+    lines_to_deallocate = []\n+    existing_allocations = Allocation.objects.filter(\n+        order_line_id__in=order_lines_info_map.keys(),\n     )\n-    for allocation in allocations_for_back_in_stock.annotate_stock_available_quantity():\n-        if allocation.stock_available_quantity <= 0:\n-            transaction.on_commit(\n-                lambda: manager.product_variant_back_in_stock(allocation.stock)\n-            )\n+    for allocation in existing_allocations:\n+        line_to_deallocate = order_lines_info_map.get(allocation.order_line_id)\n+        if line_to_deallocate is None:\n+            continue\n+        _get_variant_for_order_line_info(line_to_deallocate)\n+        lines_to_deallocate.append(line_to_deallocate)\n \n-    allocations.update(quantity_allocated=0)\n-    Stock.objects.bulk_update(stocks_to_update, [\"quantity_allocated\"])\n+    return lines_to_deallocate\n \n \n @traced_atomic_transaction()\n-def deallocate_stock_for_orders(orders_id, manager: PluginsManager):\n-    \"\"\"Remove all allocations for given order.\"\"\"\n-    lines = OrderLine.objects.filter(order_id__in=orders_id)\n+def deallocate_stock_for_orders(orders_ids: list[UUID], manager: PluginsManager):\n+    \"\"\"Remove all allocations for given orders.\"\"\"\n+    lines = OrderLine.objects.filter(order_id__in=orders_ids)\n     allocations = allocation_with_stock_qs_select_for_update().filter(\n         Exists(lines.filter(id=OuterRef(\"order_line_id\"))), quantity_allocated__gt=0\n     )\n \n-    stocks_to_update = []\n-    for alloc in allocations:\n-        stock = alloc.stock\n-        stock.quantity_allocated = F(\"quantity_allocated\") - alloc.quantity_allocated\n-        stocks_to_update.append(stock)\n+    stocks_to_update = _reduce_quantity_allocated_for_stocks(allocations)\n \n     allocations_for_back_in_stock = Allocation.objects.filter(\n         id__in=[allocation.id for allocation in allocations]\n     )\n"
        },
        {
          "path": "saleor/warehouse/tests/test_stock_management.py",
          "status": "modified",
          "diff": "Index: saleor/warehouse/tests/test_stock_management.py\n===================================================================\n--- saleor/warehouse/tests/test_stock_management.py\t411da14 (parent)\n+++ saleor/warehouse/tests/test_stock_management.py\t0696ec3 (commit)\n@@ -13,9 +13,10 @@\n from ..management import (\n     allocate_preorders,\n     allocate_stocks,\n     deallocate_stock,\n-    deallocate_stock_for_order,\n+    deallocate_stock_for_orders,\n+    decrease_allocations,\n     decrease_stock,\n     increase_allocations,\n     increase_stock,\n )\n@@ -655,8 +656,79 @@\n         == initially_allocated + quantity\n     )\n \n \n+@pytest.mark.parametrize(\n+    (\"first_quantity\", \"second_quantity\"),\n+    [(9, 20), (2, 19)],\n+)\n+def test_increase_allocations_with_multiple_allocations_for_the_same_stock(\n+    first_quantity, second_quantity, allocations\n+):\n+    # given\n+    first_allocation = allocations[0]\n+    second_allocation = allocations[1]\n+\n+    # make sure that we have only two allocations for the same stock\n+    Allocation.objects.exclude(\n+        pk__in=[first_allocation.pk, second_allocation.pk]\n+    ).delete()\n+\n+    first_order_line = first_allocation.order_line\n+    first_order_line_info = OrderLineInfo(\n+        line=first_order_line,\n+        quantity=first_quantity,\n+        variant=first_order_line.variant,\n+        warehouse_pk=first_allocation.stock.warehouse.pk,\n+    )\n+\n+    second_order_line = second_allocation.order_line\n+    second_order_line_info = OrderLineInfo(\n+        line=second_order_line,\n+        quantity=second_quantity,\n+        variant=second_order_line.variant,\n+        warehouse_pk=second_allocation.stock.warehouse.pk,\n+    )\n+\n+    assert first_order_line.variant == second_order_line.variant\n+    assert first_allocation.stock_id == second_allocation.stock_id\n+\n+    stock = first_allocation.stock\n+    stock.quantity = 100\n+    stock.quantity_allocated = 80\n+    stock.save(update_fields=[\"quantity\", \"quantity_allocated\"])\n+\n+    initially_allocated_in_single_allocation = stock.quantity_allocated / 2\n+    first_allocation.quantity_allocated = initially_allocated_in_single_allocation\n+    first_allocation.save(update_fields=[\"quantity_allocated\"])\n+    second_allocation.quantity_allocated = initially_allocated_in_single_allocation\n+    second_allocation.save(update_fields=[\"quantity_allocated\"])\n+\n+    # when\n+    increase_allocations(\n+        [first_order_line_info, second_order_line_info],\n+        first_order_line.order.channel,\n+        manager=get_plugins_manager(allow_replica=False),\n+    )\n+\n+    stock.refresh_from_db()\n+    assert stock.quantity == 100\n+\n+    # Check that both allocations are properly accounted for\n+    first_allocated = first_order_line.allocations.all().aggregate(\n+        Sum(\"quantity_allocated\")\n+    )[\"quantity_allocated__sum\"]\n+    second_allocated = second_order_line.allocations.all().aggregate(\n+        Sum(\"quantity_allocated\")\n+    )[\"quantity_allocated__sum\"]\n+\n+    assert (\n+        first_allocated + second_allocated\n+        == stock.quantity_allocated\n+        == 80 + first_quantity + second_quantity\n+    )\n+\n+\n def test_increase_allocation_insufficient_stock(allocation):\n     order_line = allocation.order_line\n     order_line_info = OrderLineInfo(\n         line=order_line,\n@@ -736,18 +808,18 @@\n     assert allocation.quantity_allocated == 30\n \n \n @pytest.mark.parametrize((\"quantity\", \"expected_allocated\"), [(50, 30), (200, 0)])\n-def test_decrease_stock_without_stock_update(quantity, expected_allocated, allocation):\n+def test_decrease_allocations(quantity, expected_allocated, allocation):\n     stock = allocation.stock\n     stock.quantity = 100\n     stock.quantity_allocated = 80\n     stock.save(update_fields=[\"quantity\", \"quantity_allocated\"])\n     allocation.quantity_allocated = 80\n     allocation.save(update_fields=[\"quantity_allocated\"])\n     warehouse_pk = allocation.stock.warehouse.pk\n \n-    decrease_stock(\n+    decrease_allocations(\n         [\n             OrderLineInfo(\n                 line=allocation.order_line,\n                 quantity=quantity,\n@@ -755,9 +827,8 @@\n                 warehouse_pk=warehouse_pk,\n             )\n         ],\n         manager=get_plugins_manager(allow_replica=False),\n-        update_stocks=False,\n     )\n \n     stock.refresh_from_db()\n     assert stock.quantity == 100\n@@ -1013,13 +1084,15 @@\n     allocation.refresh_from_db()\n     assert allocation.quantity_allocated == 80\n \n \n-def test_deallocate_stock_for_order(order_line_with_allocation_in_many_stocks):\n+def test_deallocate_stock_for_orders(order_line_with_allocation_in_many_stocks):\n     order_line = order_line_with_allocation_in_many_stocks\n     order = order_line.order\n \n-    deallocate_stock_for_order(order, manager=get_plugins_manager(allow_replica=False))\n+    deallocate_stock_for_orders(\n+        [order.id], manager=get_plugins_manager(allow_replica=False)\n+    )\n \n     allocations = order_line.allocations.all()\n     assert (\n         allocations[0].quantity_allocated\n@@ -1032,8 +1105,53 @@\n         == 0\n     )\n \n \n+def test_deallocate_stock_for_orders_with_multiple_allocations_from_the_same_stock(\n+    allocations,\n+):\n+    # given\n+    first_allocation = allocations[0]\n+    second_allocation = allocations[1]\n+\n+    # make sure that we have only two allocations for the same stock\n+    Allocation.objects.exclude(\n+        pk__in=[first_allocation.pk, second_allocation.pk]\n+    ).delete()\n+\n+    stock = first_allocation.stock\n+    stock.quantity = 100\n+    stock.quantity_allocated = (\n+        first_allocation.quantity_allocated + second_allocation.quantity_allocated\n+    )\n+\n+    stock.save(update_fields=[\"quantity\", \"quantity_allocated\"])\n+\n+    first_order_line = first_allocation.order_line\n+    second_order_line = second_allocation.order_line\n+    order = first_order_line.order\n+\n+    second_order_line.order = order\n+    second_order_line.save(update_fields=[\"order\"])\n+\n+    assert first_order_line.variant == second_order_line.variant\n+    assert first_allocation.stock_id == second_allocation.stock_id\n+\n+    # when\n+    deallocate_stock_for_orders(\n+        [order.id], manager=get_plugins_manager(allow_replica=False)\n+    )\n+\n+    # then\n+    first_allocation.refresh_from_db()\n+    second_allocation.refresh_from_db()\n+    stock.refresh_from_db()\n+\n+    assert stock.quantity_allocated == 0\n+    assert first_allocation.quantity_allocated == 0\n+    assert second_allocation.quantity_allocated == 0\n+\n+\n @mock.patch(\"saleor.plugins.manager.PluginsManager.product_variant_back_in_stock\")\n def test_increase_stock_with_back_in_stock_webhook_not_triggered(\n     product_variant_back_in_stock_webhook,\n     allocation,\n"
        }
      ]
    },
    {
      "id": "fix-avatax-lines",
      "sha": "7a4e9b6bfc0e8f1d16ed559d24de8f2016229e25",
      "parentSha": "90a3d34a7db5cde02dffb99f8152003588cc76e8",
      "spec": "Implement disambiguated AvaTax line mapping and signature updates across the AvaTax plugin, plugin manager, and order calculations.\n\nScope and expected behavior:\n- Disambiguate duplicated itemCode lines in AvaTax requests by adding a sequential, 1-based \"number\" string to every line sent to AvaTax for both checkout and orders.\n- Convert AvaTax response lines from a list to a dict keyed by internal IDs:\n  - For checkout: key by CheckoutLine.id (string) for product lines; and by the SHIPPING_ITEM_CODE constant for shipping.\n  - For orders: key by OrderLine.id (string) for product lines; and by SHIPPING_ITEM_CODE for shipping.\n  - Use response lineNumber and itemCode to match each response line to the correct internal line and only assign when both number and itemCode match. Ensure shipping is included under SHIPPING_ITEM_CODE.\n- Update all consumers to use the new dict shape (not a list) when reading taxes_data[\"lines\"].\n- Ensure the AvaTax plugin can handle the case where get_cached_response_or_fetch returns None; in that case, return None upstream and preserve previous values.\n- Update plugin, manager, and core to pass OrderLine to get_order_line_tax_rate.\n\nRequired code changes by file:\n1) saleor/plugins/avatax/__init__.py\n- In append_line_to_data: support optional \"number\" and include it when present.\n- In generate_request_data_from_checkout_lines: enumerate lines starting at 1; pass number=str(index) to append_line_to_data for each line.\n- In get_order_lines_data: accept an explicit list[OrderLine] parameter (prefetched externally); enumerate with line_number starting at 1 and pass number=str(line_number) to append_line_to_data.\n- Add helpers:\n  - iter_checkout_lines(lines_info) -> yields (str(index), variant, str(line.id)).\n  - iter_order_lines(order_lines) -> yields (str(index), variant, str(line.id)) and skips lines without variant.\n  - convert_response_lines_list_to_dict(response, lines_iterable): convert response[\"lines\"] from list to dict keyed by internal IDs using lineNumber+itemCode to match; insert shipping under SHIPPING_ITEM_CODE; replace response[\"lines\"] with the new dict.\n- In get_checkout_tax_data: after fetching response, return early if None; otherwise convert response lines to dict via convert_response_lines_list_to_dict(iter_checkout_lines(...)).\n- In get_order_request_data: change signature to (order, config, order_lines) and build lines via get_order_lines_data(order, config, discounted, lines=order_lines).\n- In get_order_tax_data: prefetch order lines locally, pass to get_order_request_data; handle None responses; convert response lines to dict via convert_response_lines_list_to_dict(iter_order_lines(order_lines)).\n\n2) saleor/plugins/avatax/plugin.py\n- Where calculating checkout line totals (calculate_checkout_subtotal, _calculate_checkout_line_total_price, etc.), switch from scanning a list by itemCode to indexing taxes_data[\"lines\"][checkout_line_id].\n- Where calculating order line totals (_calculate_order_line_total_price and methods that call it), switch from itemCode lookups to taxes_data[\"lines\"][order_line_id].\n- For shipping calculations (_calculate_checkout_shipping, _calculate_order_shipping), access the line via taxes_data[\"lines\"].get(SHIPPING_ITEM_CODE) rather than iterating lists.\n- Update calculate_checkout_line_total_price/_calculate_checkout_line_total_price to take checkout_line_id (string) instead of item_code and use dict lookup; fall back to base_value when line not found.\n- Update calculate_order_line_total/_calculate_order_line_total_price to accept order_line_id (string) and handle taxes_data possibly being None.\n- Update _get_item_tax_rate signature: response may be None; accept object_line_id (string key, not itemCode); index response[\"lines\"][object_line_id] and compute tax rate by summing detail rates where tax > 0; if any taxableAmount mismatch is found, log warning and return base_rate; preserve existing logging but rename \"item_code\" field in log extras to \"object_line_id\".\n- Update call sites to pass string IDs: for checkout: str(checkout_line_info.line.id); for orders: str(order_line.id); for shipping: pass SHIPPING_ITEM_CODE.\n- In calculate methods where request_data is built for orders (preprocess_order_creation and related), fetch order_line list via prefetch_related and pass to get_order_request_data.\n\n3) saleor/plugins/base_plugin.py\n- Update the callable type signature for get_order_line_tax_rate to include OrderLine as a parameter: (order, order_line, product, variant, address|None, Decimal) -> Decimal.\n\n4) saleor/plugins/manager.py\n- Update PluginsManager.get_order_line_tax_rate signature to include order_line; propagate order_line into plugin method invocations.\n\n5) saleor/order/calculations.py\n- In _recalculate_with_plugins (or equivalent recalculation path), update call to manager.get_order_line_tax_rate to include the current line instance as the second argument.\n\n6) Tests (behavioral expectations only; ensure code conforms):\n- All sites where tax_data[\"lines\"] was treated as a list should now treat it as a dict keyed by line ID or SHIPPING_ITEM_CODE.\n- get_order_request_data call sites should supply an explicit, prefetched list of order lines.\n- Where responses are cached and reused, deep-copy mocked responses before code converts list to dict (to avoid mutating shared fixtures).\n- Add coverage to ensure duplicate itemCode lines are correctly disambiguated via lineNumber mapping and that added forced lines (force_new_line) are reflected in correct subtotal/total computations.\n\nNon-functional requirements:\n- Maintain backward compatibility for other plugins; only AvaTax changes its internal response handling to dict, but BasePlugin signature and manager changes apply globally.\n- Ensure None safety is preserved where the tax fetch returns None; return base values in those cases.\n- Keep shipping handling backward compatible but switch to dict-based lookups under SHIPPING_ITEM_CODE.\n",
      "prompt": "Update the AvaTax integration to correctly map and compute taxes when multiple lines share the same item code. Assign a sequential line number to each line sent to AvaTax, and use the response’s line number and item code to map back to Saleor line IDs. Convert the tax response’s lines from a list into a dictionary keyed by the checkout or order line ID, with shipping keyed under a shipping constant. Update all calculations to use this dict shape for lookups, including item and shipping totals. Also update the plugin and manager interfaces so the order line object is passed when requesting an order line’s tax rate, and ensure call sites are updated accordingly. Preserve behavior when tax data is missing. Adjust tests conceptually to the new lines structure and the new signature.",
      "supplementalFiles": [
        "saleor/checkout/fetch.py",
        "saleor/checkout/base_calculations.py",
        "saleor/order/models.py",
        "saleor/order/utils.py",
        "saleor/product/models.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_calculations.py\n===================================================================\n--- saleor/checkout/tests/test_calculations.py\t90a3d34 (parent)\n+++ saleor/checkout/tests/test_calculations.py\t7a4e9b6 (commit)\n@@ -45,12 +45,9 @@\n     logger,\n )\n from ..fetch import CheckoutLineInfo, fetch_checkout_info, fetch_checkout_lines\n from ..models import Checkout\n-from ..utils import (\n-    add_promo_code_to_checkout,\n-    assign_external_shipping_to_checkout,\n-)\n+from ..utils import add_promo_code_to_checkout, assign_external_shipping_to_checkout\n \n \n @pytest.fixture\n def tax_data(checkout_with_items, checkout_lines):\n@@ -1174,20 +1171,20 @@\n     channel.tax_configuration.tax_app_id = DeprecatedAvataxPlugin.PLUGIN_IDENTIFIER\n     channel.tax_configuration.save(update_fields=[\"tax_app_id\"])\n \n     tax_data = {\n-        \"lines\": [\n-            {\n+        \"lines\": {\n+            str(checkout.lines.first().id): {\n                 \"lineAmount\": 30.0000,\n                 \"quantity\": 3.0,\n                 \"itemCode\": \"SKU_A\",\n             },\n-            {\n+            \"Shipping\": {\n                 \"lineAmount\": -8.1300,\n                 \"quantity\": 1.0,\n                 \"itemCode\": \"Shipping\",\n             },\n-        ]\n+        }\n     }\n     mock_get_tax_data.return_value = tax_data\n \n     plugin_configuration()\n@@ -1219,20 +1216,20 @@\n     channel.tax_configuration.tax_app_id = DeprecatedAvataxPlugin.PLUGIN_IDENTIFIER\n     channel.tax_configuration.save(update_fields=[\"tax_app_id\"])\n \n     tax_data = {\n-        \"lines\": [\n-            {\n+        \"lines\": {\n+            str(checkout.lines.first().id): {\n                 \"lineAmount\": 3892370265647658029.0000,\n                 \"quantity\": 3.0,\n                 \"itemCode\": \"SKU_A\",\n             },\n-            {\n+            \"Shipping\": {\n                 \"lineAmount\": 8.1300,\n                 \"quantity\": 1.0,\n                 \"itemCode\": \"Shipping\",\n             },\n-        ]\n+        }\n     }\n     mock_get_tax_data.return_value = tax_data\n \n     plugin_configuration()\n"
        },
        {
          "path": "saleor/order/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/order/calculations.py\n===================================================================\n--- saleor/order/calculations.py\t90a3d34 (parent)\n+++ saleor/order/calculations.py\t7a4e9b6 (commit)\n@@ -356,8 +356,9 @@\n             line.total_price = line_total.price_with_discounts\n \n             line.tax_rate = manager.get_order_line_tax_rate(\n                 order,\n+                line,\n                 product,\n                 variant,\n                 None,\n                 line.total_price,\n"
        },
        {
          "path": "saleor/order/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_calculations.py\n===================================================================\n--- saleor/order/tests/test_calculations.py\t90a3d34 (parent)\n+++ saleor/order/tests/test_calculations.py\t7a4e9b6 (commit)\n@@ -1714,25 +1714,25 @@\n     channel.tax_configuration.tax_app_id = DeprecatedAvataxPlugin.PLUGIN_IDENTIFIER\n     channel.tax_configuration.save(update_fields=[\"tax_app_id\"])\n \n     tax_data = {\n-        \"lines\": [\n-            {\n+        \"lines\": {\n+            str(order_with_lines.lines.all()[0].id): {\n                 \"lineAmount\": -30.0000,\n                 \"quantity\": 3.0,\n                 \"itemCode\": \"SKU_A\",\n             },\n-            {\n+            str(order_with_lines.lines.all()[1].id): {\n                 \"lineAmount\": 40.0000,\n                 \"quantity\": 2.0,\n                 \"itemCode\": \"SKU_B\",\n             },\n-            {\n+            \"Shipping\": {\n                 \"lineAmount\": 8.1300,\n                 \"quantity\": 1.0,\n                 \"itemCode\": \"Shipping\",\n             },\n-        ]\n+        }\n     }\n     mock_get_tax_data.return_value = tax_data\n \n     plugin_configuration()\n@@ -1762,25 +1762,25 @@\n     channel.tax_configuration.tax_app_id = DeprecatedAvataxPlugin.PLUGIN_IDENTIFIER\n     channel.tax_configuration.save(update_fields=[\"tax_app_id\"])\n \n     tax_data = {\n-        \"lines\": [\n-            {\n+        \"lines\": {\n+            str(order_with_lines.lines.all()[0].id): {\n                 \"lineAmount\": 30.0000,\n                 \"quantity\": 3.0,\n                 \"itemCode\": \"SKU_A\",\n             },\n-            {\n+            str(order_with_lines.lines.all()[1].id): {\n                 \"lineAmount\": 40.0000,\n                 \"quantity\": 2.0,\n                 \"itemCode\": \"SKU_B\",\n             },\n-            {\n+            \"Shipping\": {\n                 \"lineAmount\": 83689989725697628976.1300,\n                 \"quantity\": 1.0,\n                 \"itemCode\": \"Shipping\",\n             },\n-        ]\n+        }\n     }\n     mock_get_tax_data.return_value = tax_data\n \n     plugin_configuration()\n"
        },
        {
          "path": "saleor/plugins/avatax/__init__.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/__init__.py\n===================================================================\n--- saleor/plugins/avatax/__init__.py\t90a3d34 (parent)\n+++ saleor/plugins/avatax/__init__.py\t7a4e9b6 (commit)\n@@ -1,7 +1,8 @@\n import datetime\n import json\n import logging\n+from collections.abc import Iterator\n from dataclasses import dataclass\n from decimal import Decimal\n from typing import TYPE_CHECKING, Any, cast\n from urllib.parse import urljoin\n@@ -29,10 +30,10 @@\n from ...warehouse.models import Warehouse\n \n if TYPE_CHECKING:\n     from ...checkout.fetch import CheckoutInfo, CheckoutLineInfo\n-    from ...order.models import Order\n-    from ...product.models import Product, ProductType\n+    from ...order.models import Order, OrderLine\n+    from ...product.models import Product, ProductType, ProductVariant\n     from ...tax.models import TaxClass\n \n \n logger = logging.getLogger(__name__)\n@@ -240,8 +241,9 @@\n     discounted: bool | None = False,\n     tax_override_data: dict | None = None,\n     ref1: str | None = None,\n     ref2: str | None = None,\n+    number: str | None = None,\n ):\n     line_data = {\n         \"quantity\": quantity,\n         \"amount\": str(amount),\n@@ -251,8 +253,10 @@\n         \"discounted\": discounted,\n         \"description\": name,\n     }\n \n+    if number:\n+        line_data[\"number\"] = number\n     if tax_override_data:\n         line_data[\"taxOverride\"] = tax_override_data\n     if ref1:\n         line_data[\"ref1\"] = ref1\n@@ -295,9 +299,9 @@\n     applicable_checkout_discount = (\n         bool(checkout_info.discounts) or is_entire_order_discount\n     )\n \n-    for line_info in lines_info:\n+    for index, line_info in enumerate(lines_info, start=1):\n         product = line_info.product\n         product_type = line_info.product_type\n         tax_code = _get_product_tax_code(product, product_type)\n \n@@ -340,8 +344,9 @@\n             \"name\": name,\n             \"prices_entered_with_tax\": prices_entered_with_tax,\n             \"discounted\": applicable_checkout_discount,\n             \"tax_override_data\": tax_override_data,\n+            \"number\": str(index),\n         }\n \n         append_line_to_data(\n             **append_line_to_data_kwargs,  # type: ignore[arg-type]\n@@ -367,21 +372,19 @@\n     return data\n \n \n def get_order_lines_data(\n-    order: \"Order\", config: AvataxConfiguration, discounted: bool\n+    order: \"Order\",\n+    config: AvataxConfiguration,\n+    discounted: bool,\n+    lines: list[\"OrderLine\"],\n ) -> list[dict[str, str | int | bool | None]]:\n     data: list[dict[str, str | int | bool | None]] = []\n-    lines = order.lines.prefetch_related(\n-        \"variant__product__category\",\n-        \"variant__product__collections\",\n-        \"variant__product__product_type\",\n-    )\n \n     tax_configuration = order.channel.tax_configuration\n     prices_entered_with_tax = tax_configuration.prices_entered_with_tax\n \n-    for line in lines:\n+    for line_number, line in enumerate(lines, start=1):\n         if not line.variant:\n             continue\n \n         tax_code = None\n@@ -415,8 +418,9 @@\n             \"item_code\": line.variant.sku or line.variant.get_global_id(),\n             \"name\": line.variant.product.name,\n             \"prices_entered_with_tax\": prices_entered_with_tax,\n             \"discounted\": discounted,\n+            \"number\": str(line_number),\n         }\n         append_line_to_data(\n             **append_line_to_data_kwargs,\n             amount=price_with_discounts_amount,\n@@ -596,27 +600,82 @@\n         _, response = cached_data\n     return response\n \n \n+def iter_checkout_lines(\n+    lines_info: list[\"CheckoutLineInfo\"],\n+) -> Iterator[tuple[str, \"ProductVariant\", str]]:\n+    for index, line_info in enumerate(lines_info, start=1):\n+        yield str(index), line_info.variant, str(line_info.line.id)\n+\n+\n+def iter_order_lines(\n+    order_lines: list[\"OrderLine\"],\n+) -> Iterator[tuple[str, \"ProductVariant\", str]]:\n+    for index, line in enumerate(order_lines, start=1):\n+        if not line.variant:\n+            continue\n+        yield str(index), line.variant, str(line.id)\n+\n+\n+def convert_response_lines_list_to_dict(\n+    response: dict[str, Any],\n+    lines_iterable: Iterator[tuple[str, \"ProductVariant\", str]],\n+):\n+    # Convert `lines` to dict as we can send multiple lines with the same itemCode\n+    # and we need to be able to find proper line by line id.\n+    lines_from_response = {\n+        line[\"lineNumber\"]: line for line in response.get(\"lines\", [])\n+    }\n+    line_data_dict = {}\n+    for line_index, variant, line_id in lines_iterable:\n+        response_line = lines_from_response.get(line_index)\n+        if not response_line:\n+            continue\n+\n+        variant_item_code = variant.sku or variant.get_global_id()\n+        if response_line.get(\"itemCode\") != variant_item_code:\n+            continue\n+\n+        line_data_dict[line_id] = response_line\n+\n+    for item in response.get(\"lines\", []):\n+        if item.get(\"itemCode\") == SHIPPING_ITEM_CODE:\n+            line_data_dict[SHIPPING_ITEM_CODE] = item\n+    response[\"lines\"] = line_data_dict\n+\n+\n def get_checkout_tax_data(\n     checkout_info: \"CheckoutInfo\",\n     lines_info: list[\"CheckoutLineInfo\"],\n     config: AvataxConfiguration,\n-) -> dict[str, Any]:\n+) -> dict[str, Any] | None:\n     data = generate_request_data_from_checkout(checkout_info, lines_info, config)\n-    return get_cached_response_or_fetch(data, str(checkout_info.checkout.token), config)\n+    response = get_cached_response_or_fetch(\n+        data, str(checkout_info.checkout.token), config\n+    )\n \n+    if response is None:\n+        return response\n \n-def get_order_request_data(order: \"Order\", config: AvataxConfiguration):\n+    convert_response_lines_list_to_dict(response, iter_checkout_lines(lines_info))\n+    return response\n+\n+\n+def get_order_request_data(\n+    order: \"Order\", config: AvataxConfiguration, order_lines: list[\"OrderLine\"]\n+):\n     address = get_address_for_order_taxes(order)\n     transaction = (\n         TransactionType.INVOICE\n         if not (order.is_draft() or order.is_unconfirmed())\n         else TransactionType.ORDER\n     )\n     discount_amount = get_total_order_discount_excluding_shipping(order).amount\n     discounted_lines = discount_amount != Decimal(0)\n-    lines = get_order_lines_data(order, config, discounted=discounted_lines)\n+    lines = get_order_lines_data(\n+        order, config, discounted=discounted_lines, lines=order_lines\n+    )\n     # if there is no lines to sent we do not want to send the request to avalara\n     if not lines:\n         return {}\n     data = generate_request_data(\n@@ -633,10 +692,17 @@\n \n \n def get_order_tax_data(\n     order: \"Order\", config: AvataxConfiguration, force_refresh=False\n-) -> dict[str, Any]:\n-    data = get_order_request_data(order, config)\n+) -> dict[str, Any] | None:\n+    order_lines = list(\n+        order.lines.prefetch_related(\n+            \"variant__product__category\",\n+            \"variant__product__collections\",\n+            \"variant__product__product_type\",\n+        ).all()\n+    )\n+    data = get_order_request_data(order, config, order_lines)\n     response = get_cached_response_or_fetch(\n         data, f\"order_{order.id}\", config, force_refresh\n     )\n     if response and \"error\" in response:\n@@ -649,8 +715,12 @@\n             msg,\n         )\n         log_address_if_validation_skipped_for_order(order, logger)\n         raise TaxError(response.get(\"error\"))\n+    if response is None:\n+        return response\n+\n+    convert_response_lines_list_to_dict(response, iter_order_lines(order_lines))\n     return response\n \n \n def generate_tax_codes_dict(response: dict[str, Any]) -> dict[str, str]:\n"
        },
        {
          "path": "saleor/plugins/avatax/plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/plugin.py\n===================================================================\n--- saleor/plugins/avatax/plugin.py\t90a3d34 (parent)\n+++ saleor/plugins/avatax/plugin.py\t7a4e9b6 (commit)\n@@ -228,9 +228,9 @@\n \n         for line in lines:\n             taxed_line_total_data = self._calculate_checkout_line_total_price(\n                 taxes_data=response,\n-                item_code=line.variant.sku or line.variant.get_global_id(),\n+                checkout_line_id=str(line.line.id),\n                 prices_entered_with_tax=prices_entered_with_tax,\n                 # for some cases we will need a base_value but no need to call it for\n                 # each line\n                 base_value=SimpleLazyObject(\n@@ -242,9 +242,9 @@\n         base_shipping_price = base_calculations.base_checkout_delivery_price(\n             checkout_info, lines\n         )\n         shipping_price = self._calculate_checkout_shipping(\n-            checkout_info, currency, response.get(\"lines\", []), base_shipping_price\n+            checkout_info, currency, response.get(\"lines\", {}), base_shipping_price\n         )\n \n         taxed_total += shipping_price\n \n@@ -256,23 +256,22 @@\n     def _calculate_checkout_shipping(\n         self,\n         checkout_info: \"CheckoutInfo\",\n         currency: str,\n-        lines: list[dict],\n+        lines: dict[str, dict],\n         shipping_price: Money,\n     ) -> TaxedMoney:\n         discount_amount = Decimal(0.0)\n         shipping_tax = Decimal(0.0)\n         shipping_net = shipping_price.amount\n-        for line in lines:\n-            if line[\"itemCode\"] == SHIPPING_ITEM_CODE:\n-                # The lineAmount does not include the discountAmount,\n-                # but tax is calculated for discounted net price, that\n-                # take into account provided discount.\n-                shipping_net = Decimal(line[\"lineAmount\"])\n-                discount_amount = Decimal(line.get(\"discountAmount\", 0.0))\n-                shipping_tax = Decimal(line[\"tax\"])\n-                break\n+        line = lines.get(SHIPPING_ITEM_CODE)\n+        if line:\n+            # The lineAmount does not include the discountAmount,\n+            # but tax is calculated for discounted net price, that\n+            # take into account provided discount.\n+            shipping_net = Decimal(line[\"lineAmount\"])\n+            discount_amount = Decimal(line.get(\"discountAmount\", 0.0))\n+            shipping_tax = Decimal(line[\"tax\"])\n \n         prices_entered_with_tax = partial(\n             _get_prices_entered_with_tax_for_checkout, checkout_info\n         )\n@@ -303,9 +302,9 @@\n             return previous_value\n \n         currency = str(response.get(\"currencyCode\"))\n         return self._calculate_checkout_shipping(\n-            checkout_info, currency, response.get(\"lines\", []), base_shipping_price.net\n+            checkout_info, currency, response.get(\"lines\", {}), base_shipping_price.net\n         )\n \n     def preprocess_order_creation(\n         self,\n@@ -380,9 +379,16 @@\n             and tax_app_identifier != self.PLUGIN_IDENTIFIER\n         ):\n             return previous_value\n \n-        request_data = get_order_request_data(order, self.config)\n+        order_lines = list(\n+            order.lines.prefetch_related(\n+                \"variant__product__category\",\n+                \"variant__product__collections\",\n+                \"variant__product__product_type\",\n+            ).all()\n+        )\n+        request_data = get_order_request_data(order, self.config, order_lines)\n         if not request_data:\n             return previous_value\n \n         transaction_url = urljoin(\n@@ -409,16 +415,15 @@\n             _get_prices_entered_with_tax_for_checkout, checkout_info\n         )\n \n         taxes_data = self._get_checkout_tax_data(checkout_info, lines, previous_value)\n-        variant = checkout_line_info.variant\n \n         if not taxes_data or \"error\" in taxes_data:\n             return previous_value\n \n         return self._calculate_checkout_line_total_price(\n             taxes_data,\n-            variant.sku or variant.get_global_id(),\n+            str(checkout_line_info.line.id),\n             prices_entered_with_tax,\n             base_value=SimpleLazyObject(\n                 lambda: base_calculations.calculate_base_line_total_price(\n                     checkout_line_info\n@@ -428,19 +433,17 @@\n \n     @staticmethod\n     def _calculate_checkout_line_total_price(\n         taxes_data: dict[str, Any],\n-        item_code: str,\n+        checkout_line_id: str,\n         prices_entered_with_tax: Callable[[], bool],\n         # base_value should be provided as SimpleLazyObject\n         base_value: Money,\n     ) -> TaxedMoney:\n-        currency = taxes_data.get(\"currencyCode\")\n+        currency: str = taxes_data.get(\"currencyCode\") or base_value.currency\n \n-        for line in taxes_data.get(\"lines\", []):\n-            if line.get(\"itemCode\") != item_code:\n-                continue\n-\n+        line = taxes_data.get(\"lines\", {}).get(checkout_line_id)\n+        if line:\n             # The lineAmount does not include the discountAmount, but tax is calculated\n             # for discounted net price, that take into account provided discount.\n             tax = Decimal(line.get(\"tax\", 0.0))\n             discount_amount = Decimal(line.get(\"discountAmount\", 0.0))\n@@ -457,9 +460,8 @@\n             else:\n                 net -= discount_amount\n                 line_gross = Money(amount=net + tax, currency=currency)\n                 line_net = Money(amount=net, currency=currency)\n-\n             return TaxedMoney(net=line_net, gross=line_gross)\n         if isinstance(base_value, SimpleLazyObject):\n             base_value = base_value._setupfunc()  # type: ignore[attr-defined]\n         return TaxedMoney(net=base_value, gross=base_value)\n@@ -484,17 +486,17 @@\n         prices_entered_with_tax = partial(_get_prices_entered_with_tax_for_order, order)\n         taxes_data = self._get_order_tax_data(order, previous_value)\n         return self._calculate_order_line_total_price(\n             taxes_data,\n-            variant.sku or variant.get_global_id(),\n+            str(order_line.id),\n             prices_entered_with_tax,\n             base_value,\n         )\n \n     @staticmethod\n     def _calculate_order_line_total_price(\n-        taxes_data: dict[str, Any],\n-        item_code: str,\n+        taxes_data: dict[str, Any] | None,\n+        order_line_id: str,\n         prices_entered_with_tax: Callable[[], bool],\n         base_value: OrderTaxedPricesData,\n     ) -> OrderTaxedPricesData:\n         if not taxes_data or \"error\" in taxes_data:\n@@ -502,12 +504,10 @@\n \n         currency = taxes_data.get(\"currencyCode\")\n         line_price_with_discounts = None\n \n-        for line in taxes_data.get(\"lines\", []):\n-            if line.get(\"itemCode\") != item_code:\n-                continue\n-\n+        line = taxes_data.get(\"lines\", {}).get(order_line_id)\n+        if line:\n             # The lineAmount does not include the discountAmount, but tax is calculated\n             # for discounted net price, that take into account provided discount.\n             tax = Decimal(line.get(\"tax\", 0.0))\n             discount_amount = Decimal(line.get(\"discountAmount\", 0.0))\n@@ -549,18 +549,17 @@\n \n         prices_entered_with_tax = partial(\n             _get_prices_entered_with_tax_for_checkout, checkout_info\n         )\n-        variant = checkout_line_info.variant\n \n         quantity = checkout_line_info.line.quantity\n         taxes_data = self._get_checkout_tax_data(checkout_info, lines, previous_value)\n         if not taxes_data or \"error\" in taxes_data:\n             return previous_value\n \n         taxed_total_price = self._calculate_checkout_line_total_price(\n             taxes_data,\n-            variant.sku or variant.get_global_id(),\n+            str(checkout_line_info.line.id),\n             prices_entered_with_tax,\n             base_value=SimpleLazyObject(\n                 lambda: base_calculations.calculate_base_line_total_price(\n                     checkout_line_info\n@@ -589,9 +588,9 @@\n         base_total = order_base_calculation.base_order_line_total(order_line)\n \n         taxed_total_prices_data = self._calculate_order_line_total_price(\n             taxes_data,\n-            variant.sku or variant.get_global_id(),\n+            str(order_line.id),\n             prices_entered_with_tax,\n             base_total,\n         )\n         return OrderTaxedPricesData(\n@@ -602,20 +601,20 @@\n \n     def _calculate_order_shipping(self, order, taxes_data) -> TaxedMoney:\n         prices_entered_with_tax = partial(_get_prices_entered_with_tax_for_order, order)\n         currency = taxes_data.get(\"currencyCode\")\n-        for line in taxes_data.get(\"lines\", []):\n-            if line[\"itemCode\"] == SHIPPING_ITEM_CODE:\n-                tax = Decimal(line.get(\"tax\", 0.0))\n-                discount_amount = Decimal(line.get(\"discountAmount\", 0.0))\n-                net = Decimal(line.get(\"lineAmount\", 0.0)) - discount_amount\n-                if currency == \"JPY\" and prices_entered_with_tax():\n-                    gross = order.base_shipping_price\n-                    net = Money(amount=gross.amount - tax, currency=currency)\n-                else:\n-                    gross = Money(amount=net + tax, currency=currency)\n-                    net = Money(amount=net, currency=currency)\n-                return TaxedMoney(net=net, gross=gross)\n+        line = taxes_data.get(\"lines\", {}).get(SHIPPING_ITEM_CODE)\n+        if line:\n+            tax = Decimal(line.get(\"tax\", 0.0))\n+            discount_amount = Decimal(line.get(\"discountAmount\", 0.0))\n+            net = Decimal(line.get(\"lineAmount\", 0.0)) - discount_amount\n+            if currency == \"JPY\" and prices_entered_with_tax():\n+                gross = order.base_shipping_price\n+                net = Money(amount=gross.amount - tax, currency=currency)\n+            else:\n+                gross = Money(amount=net + tax, currency=currency)\n+                net = Money(amount=net, currency=currency)\n+            return TaxedMoney(net=net, gross=gross)\n \n         price = order.base_shipping_price\n         return TaxedMoney(\n             net=price,\n@@ -651,9 +650,9 @@\n                 * line.quantity,\n             )\n             taxed_line_total_data = self._calculate_order_line_total_price(\n                 taxes_data,\n-                line.product_sku or line.variant_name,\n+                str(line.id),\n                 prices_entered_with_tax,\n                 base_line_price,\n             ).price_with_discounts\n             taxed_subtotal += taxed_line_total_data\n@@ -689,20 +688,20 @@\n         if not charge_taxes:\n             return previous_value\n \n         response = self._get_checkout_tax_data(checkout_info, lines, previous_value)\n-        variant = checkout_line_info.variant\n         return self._get_item_tax_rate(\n             response,\n-            variant.sku or variant.get_global_id(),\n+            str(checkout_line_info.line.id),\n             previous_value,\n             str(checkout_info.checkout.pk),\n             \"Checkout\",\n         )\n \n     def get_order_line_tax_rate(\n         self,\n         order: \"Order\",\n+        order_line: \"OrderLine\",\n         product: \"Product\",\n         variant: \"ProductVariant\",\n         address: Optional[\"Address\"],\n         previous_value: Decimal,\n@@ -713,9 +712,9 @@\n \n         response = self._get_order_tax_data(order, previous_value)\n         return self._get_item_tax_rate(\n             response,\n-            variant.sku or variant.get_global_id(),\n+            str(order_line.id),\n             previous_value,\n             str(order.pk),\n             \"Order\",\n         )\n@@ -729,18 +728,22 @@\n     ):\n         response = self._get_checkout_tax_data(checkout_info, lines, previous_value)\n         return self._get_item_tax_rate(\n             response,\n-            SHIPPING_ITEM_CODE,\n-            previous_value,\n-            str(checkout_info.checkout.pk),\n-            \"Checkout\",\n+            object_line_id=SHIPPING_ITEM_CODE,\n+            base_rate=previous_value,\n+            related_object_id=str(checkout_info.checkout.pk),\n+            related_object_type=\"Checkout\",\n         )\n \n     def get_order_shipping_tax_rate(self, order: \"Order\", previous_value: Decimal):\n         response = self._get_order_tax_data(order, previous_value)\n         return self._get_item_tax_rate(\n-            response, SHIPPING_ITEM_CODE, previous_value, str(order.pk), \"Order\"\n+            response,\n+            object_line_id=SHIPPING_ITEM_CODE,\n+            base_rate=previous_value,\n+            related_object_id=str(order.pk),\n+            related_object_type=\"Order\",\n         )\n \n     def _get_checkout_tax_data(\n         self,\n@@ -786,9 +789,9 @@\n             checkout_info.checkout.tax_error = tax_error_message\n \n     def _get_order_tax_data(\n         self, order: \"Order\", base_value: Decimal | OrderTaxedPricesData\n-    ):\n+    ) -> dict[str, Any] | None:\n         if self._skip_plugin(base_value):\n             self._set_order_tax_error(order, TaxDataErrorMessage.EMPTY)\n             return None\n \n@@ -815,68 +818,64 @@\n             order.tax_error = tax_error\n \n     @staticmethod\n     def _get_item_tax_rate(\n-        response: dict[str, Any],\n-        item_code: str,\n+        response: dict[str, Any] | None,\n+        object_line_id: str,\n         base_rate: Decimal,\n         related_object_id: str,\n         related_object_type: str,\n     ):\n         if response is None:\n             return base_rate\n-        lines_data = response.get(\"lines\", [])\n-        for line in lines_data:\n-            if line[\"itemCode\"] == item_code:\n-                taxable_amount = Decimal(line[\"taxableAmount\"]).quantize(\n-                    Decimal(\".0001\")\n-                )\n-                details = line.get(\"details\")\n-                if not details:\n-                    return base_rate\n+        lines_data = response.get(\"lines\", {})\n+        line = lines_data.get(object_line_id)\n+        if line:\n+            taxable_amount = Decimal(line[\"taxableAmount\"]).quantize(Decimal(\".0001\"))\n+            details = line.get(\"details\")\n+            if not details:\n+                return base_rate\n \n-                # when tax is equal to 0 tax rate for product is still provided\n-                # in the response\n-                rate = Decimal(0)\n-                for detail in details:\n-                    if not Decimal(detail.get(\"tax\", 0)):\n-                        # When tax is zero, any rate provided in response should not be\n-                        # included in returned tax-rate\n-                        continue\n-                    taxable_amount_from_detail = Decimal(\n-                        detail.get(\"taxableAmount\", 0)\n-                    ).quantize(Decimal(\".0001\"))\n-                    if (\n-                        taxable_amount_from_detail\n-                        and taxable_amount_from_detail != taxable_amount\n-                    ):\n-                        logger.warning(\n-                            \"taxableAmounts from line.details[] are different than \"\n-                            \"line.taxableAmount. Returning the rate calculated by \"\n-                            \"Saleor. For %s:%s\",\n-                            related_object_type,\n-                            related_object_id,\n-                            extra={\n-                                \"line_taxable_amount\": line[\"taxableAmount\"],\n-                                \"line_details\": [\n-                                    {\n-                                        \"tax\": log_detail.get(\"tax\"),\n-                                        \"taxable_amount\": log_detail.get(\n-                                            \"taxableAmount\"\n-                                        ),\n-                                        \"rate\": log_detail.get(\"rate\"),\n-                                    }\n-                                    for log_detail in line[\"details\"]\n-                                ],\n-                                \"id\": related_object_id,\n-                                \"type\": related_object_type,\n-                                \"item_code\": item_code,\n-                                \"base_rate\": base_rate,\n-                            },\n-                        )\n-                        return base_rate\n-                    rate += Decimal(detail.get(\"rate\", 0.0))\n-                return rate\n+            # when tax is equal to 0 tax rate for product is still provided\n+            # in the response\n+            rate = Decimal(0)\n+            for detail in details:\n+                if not Decimal(detail.get(\"tax\", 0)):\n+                    # When tax is zero, any rate provided in response should not be\n+                    # included in returned tax-rate\n+                    continue\n+                taxable_amount_from_detail = Decimal(\n+                    detail.get(\"taxableAmount\", 0)\n+                ).quantize(Decimal(\".0001\"))\n+                if (\n+                    taxable_amount_from_detail\n+                    and taxable_amount_from_detail != taxable_amount\n+                ):\n+                    logger.warning(\n+                        \"taxableAmounts from line.details[] are different than \"\n+                        \"line.taxableAmount. Returning the rate calculated by \"\n+                        \"Saleor. For %s:%s\",\n+                        related_object_type,\n+                        related_object_id,\n+                        extra={\n+                            \"line_taxable_amount\": line[\"taxableAmount\"],\n+                            \"line_details\": [\n+                                {\n+                                    \"tax\": log_detail.get(\"tax\"),\n+                                    \"taxable_amount\": log_detail.get(\"taxableAmount\"),\n+                                    \"rate\": log_detail.get(\"rate\"),\n+                                }\n+                                for log_detail in line[\"details\"]\n+                            ],\n+                            \"id\": related_object_id,\n+                            \"type\": related_object_type,\n+                            \"object_line_id\": object_line_id,\n+                            \"base_rate\": base_rate,\n+                        },\n+                    )\n+                    return base_rate\n+                rate += Decimal(detail.get(\"rate\", 0.0))\n+            return rate\n         return base_rate\n \n     def get_tax_code_from_object_meta(\n         self,\n@@ -979,9 +978,9 @@\n         \"\"\"Check if tax data contains negative values.\"\"\"\n         if not tax_data:\n             return False\n \n-        for line in tax_data.get(\"lines\", []):\n+        for line in tax_data.get(\"lines\", {}).values():\n             if line.get(\"lineAmount\", 0) < 0:\n                 return True\n \n         return False\n@@ -991,9 +990,9 @@\n         \"\"\"Check if line prices are lower than a billion.\"\"\"\n         if not tax_data:\n             return False\n \n-        for line in tax_data.get(\"lines\", []):\n+        for line in tax_data.get(\"lines\", {}).values():\n             if line.get(\"lineAmount\", 0) > MAXIMUM_PRICE:\n                 return True\n \n         return False\n"
        },
        {
          "path": "saleor/plugins/avatax/tests/conftest.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/tests/conftest.py\n===================================================================\n--- saleor/plugins/avatax/tests/conftest.py\t90a3d34 (parent)\n+++ saleor/plugins/avatax/tests/conftest.py\t7a4e9b6 (commit)\n@@ -642,4 +642,338 @@\n                 \"exemption\": 0.0,\n             }\n         ],\n     }\n+\n+\n+@pytest.fixture\n+def test_response_multiple_lines_with_same_item_code():\n+    return {\n+        \"id\": 0,\n+        \"code\": \"139256ab-1bd9-4573-951c-e612314e2014\",\n+        \"companyId\": 7799660,\n+        \"date\": \"2025-11-06\",\n+        \"paymentDate\": \"2025-11-06\",\n+        \"status\": \"Temporary\",\n+        \"type\": \"SalesOrder\",\n+        \"batchCode\": \"\",\n+        \"currencyCode\": \"USD\",\n+        \"exchangeRateCurrencyCode\": \"USD\",\n+        \"customerUsageType\": \"\",\n+        \"entityUseCode\": \"\",\n+        \"customerVendorCode\": \"0\",\n+        \"customerCode\": \"0\",\n+        \"exemptNo\": \"\",\n+        \"reconciled\": False,\n+        \"locationCode\": \"\",\n+        \"reportingLocationCode\": \"\",\n+        \"purchaseOrderNo\": \"\",\n+        \"referenceCode\": \"\",\n+        \"salespersonCode\": \"\",\n+        \"totalAmount\": 62.33,\n+        \"totalExempt\": 0.0,\n+        \"totalDiscount\": 0.0,\n+        \"totalTax\": 14.34,\n+        \"totalTaxable\": 62.33,\n+        \"totalTaxCalculated\": 14.34,\n+        \"adjustmentReason\": \"NotAdjusted\",\n+        \"locked\": False,\n+        \"version\": 1,\n+        \"originAddressId\": 2,\n+        \"destinationAddressId\": 1,\n+        \"exchangeRateEffectiveDate\": \"2025-11-06\",\n+        \"exchangeRate\": 1.0,\n+        \"email\": \"user@email.com\",\n+        \"modifiedDate\": \"2025-11-06T11:57:33.6683291Z\",\n+        \"modifiedUserId\": 6479978,\n+        \"taxDate\": \"2025-11-06\",\n+        \"lines\": [\n+            {\n+                \"id\": 0,\n+                \"transactionId\": 0,\n+                \"lineNumber\": \"1\",\n+                \"customerUsageType\": \"\",\n+                \"entityUseCode\": \"\",\n+                \"description\": \"Test product\",\n+                \"destinationAddressId\": 1,\n+                \"originAddressId\": 2,\n+                \"discountAmount\": 0.0,\n+                \"exemptAmount\": 0.0,\n+                \"exemptCertId\": 0,\n+                \"exemptNo\": \"\",\n+                \"isItemTaxable\": True,\n+                \"itemCode\": \"123\",\n+                \"lineAmount\": 30.0,\n+                \"quantity\": 3.0,\n+                \"ref1\": \"123\",\n+                \"ref2\": \"\",\n+                \"reportingDate\": \"2025-11-06\",\n+                \"revAccount\": \"\",\n+                \"sourcing\": \"Destination\",\n+                \"tax\": 6.9,\n+                \"taxableAmount\": 30.0,\n+                \"taxCalculated\": 6.9,\n+                \"taxCode\": \"O9999999\",\n+                \"taxCodeId\": 9111,\n+                \"taxDate\": \"2025-11-06\",\n+                \"taxIncluded\": False,\n+                \"details\": [\n+                    {\n+                        \"id\": 0,\n+                        \"transactionLineId\": 0,\n+                        \"transactionId\": 0,\n+                        \"country\": \"PL\",\n+                        \"region\": \"PL\",\n+                        \"stateFIPS\": \"PL\",\n+                        \"exemptAmount\": 0.0,\n+                        \"jurisCode\": \"PL\",\n+                        \"jurisName\": \"POLAND\",\n+                        \"jurisdictionId\": 200102,\n+                        \"stateAssignedNo\": \"\",\n+                        \"jurisType\": \"CNT\",\n+                        \"jurisdictionType\": \"Country\",\n+                        \"nonTaxableAmount\": 0.0,\n+                        \"rate\": 0.230000,\n+                        \"sourcing\": \"Destination\",\n+                        \"tax\": 6.9,\n+                        \"taxableAmount\": 30.0,\n+                        \"taxType\": \"Output\",\n+                        \"taxSubTypeId\": \"O\",\n+                        \"taxName\": \"Standard Rate\",\n+                        \"taxAuthorityTypeId\": 45,\n+                        \"taxCalculated\": 6.9,\n+                        \"rateType\": \"Standard\",\n+                        \"rateTypeCode\": \"S\",\n+                        \"taxableUnits\": 30.0000,\n+                        \"nonTaxableUnits\": 0.0000,\n+                        \"exemptUnits\": 0.0000,\n+                        \"unitOfBasis\": \"PerCurrencyUnit\",\n+                        \"isNonPassThru\": False,\n+                        \"isFee\": False,\n+                        \"reportingTaxableUnits\": 30.0,\n+                        \"reportingNonTaxableUnits\": 0.0,\n+                        \"reportingExemptUnits\": 0.0,\n+                        \"reportingTax\": 6.9,\n+                        \"reportingTaxCalculated\": 6.9,\n+                        \"liabilityType\": \"Seller\",\n+                        \"chargedTo\": \"Buyer\",\n+                        \"vatCode\": \"PL_S_-_230_C\",\n+                    }\n+                ],\n+                \"nonPassthroughDetails\": [],\n+                \"hsCode\": \"\",\n+                \"costInsuranceFreight\": 0.0,\n+                \"vatCode\": \"PLS-230C\",\n+                \"vatNumberTypeId\": 0,\n+            },\n+            {\n+                \"id\": 0,\n+                \"transactionId\": 0,\n+                \"lineNumber\": \"2\",\n+                \"customerUsageType\": \"\",\n+                \"entityUseCode\": \"\",\n+                \"description\": \"Test product\",\n+                \"destinationAddressId\": 1,\n+                \"originAddressId\": 2,\n+                \"discountAmount\": 0.0,\n+                \"exemptAmount\": 0.0,\n+                \"exemptCertId\": 0,\n+                \"exemptNo\": \"\",\n+                \"isItemTaxable\": True,\n+                \"itemCode\": \"123\",\n+                \"lineAmount\": 22.33,\n+                \"quantity\": 1.0,\n+                \"ref1\": \"123\",\n+                \"ref2\": \"\",\n+                \"reportingDate\": \"2025-11-06\",\n+                \"revAccount\": \"\",\n+                \"sourcing\": \"Destination\",\n+                \"tax\": 5.14,\n+                \"taxableAmount\": 22.33,\n+                \"taxCalculated\": 5.14,\n+                \"taxCode\": \"O9999999\",\n+                \"taxCodeId\": 9111,\n+                \"taxDate\": \"2025-11-06\",\n+                \"taxIncluded\": False,\n+                \"details\": [\n+                    {\n+                        \"id\": 0,\n+                        \"transactionLineId\": 0,\n+                        \"transactionId\": 0,\n+                        \"country\": \"PL\",\n+                        \"region\": \"PL\",\n+                        \"stateFIPS\": \"PL\",\n+                        \"exemptAmount\": 0.0,\n+                        \"jurisCode\": \"PL\",\n+                        \"jurisName\": \"POLAND\",\n+                        \"jurisdictionId\": 200102,\n+                        \"stateAssignedNo\": \"\",\n+                        \"jurisType\": \"CNT\",\n+                        \"jurisdictionType\": \"Country\",\n+                        \"nonTaxableAmount\": 0.0,\n+                        \"rate\": 0.230000,\n+                        \"sourcing\": \"Destination\",\n+                        \"tax\": 5.14,\n+                        \"taxableAmount\": 22.33,\n+                        \"taxType\": \"Output\",\n+                        \"taxSubTypeId\": \"O\",\n+                        \"taxName\": \"Standard Rate\",\n+                        \"taxAuthorityTypeId\": 45,\n+                        \"taxCalculated\": 5.14,\n+                        \"rateType\": \"Standard\",\n+                        \"rateTypeCode\": \"S\",\n+                        \"taxableUnits\": 22.3300,\n+                        \"nonTaxableUnits\": 0.0000,\n+                        \"exemptUnits\": 0.0000,\n+                        \"unitOfBasis\": \"PerCurrencyUnit\",\n+                        \"isNonPassThru\": False,\n+                        \"isFee\": False,\n+                        \"reportingTaxableUnits\": 22.33,\n+                        \"reportingNonTaxableUnits\": 0.0,\n+                        \"reportingExemptUnits\": 0.0,\n+                        \"reportingTax\": 5.14,\n+                        \"reportingTaxCalculated\": 5.14,\n+                        \"liabilityType\": \"Seller\",\n+                        \"chargedTo\": \"Buyer\",\n+                        \"vatCode\": \"PL_S_-_230_C\",\n+                    }\n+                ],\n+                \"nonPassthroughDetails\": [],\n+                \"hsCode\": \"\",\n+                \"costInsuranceFreight\": 0.0,\n+                \"vatCode\": \"PLS-230C\",\n+                \"vatNumberTypeId\": 0,\n+            },\n+            {\n+                \"id\": 0,\n+                \"transactionId\": 0,\n+                \"lineNumber\": \"3\",\n+                \"customerUsageType\": \"\",\n+                \"entityUseCode\": \"\",\n+                \"destinationAddressId\": 1,\n+                \"originAddressId\": 2,\n+                \"discountAmount\": 0.0,\n+                \"exemptAmount\": 0.0,\n+                \"exemptCertId\": 0,\n+                \"exemptNo\": \"\",\n+                \"isItemTaxable\": True,\n+                \"itemCode\": \"Shipping\",\n+                \"lineAmount\": 10.0,\n+                \"quantity\": 1.0,\n+                \"ref1\": \"\",\n+                \"ref2\": \"\",\n+                \"reportingDate\": \"2025-11-06\",\n+                \"revAccount\": \"\",\n+                \"sourcing\": \"Destination\",\n+                \"tax\": 2.3,\n+                \"taxableAmount\": 10.0,\n+                \"taxCalculated\": 2.3,\n+                \"taxCode\": \"FR000000\",\n+                \"taxCodeId\": 8550,\n+                \"taxDate\": \"2025-11-06\",\n+                \"taxIncluded\": False,\n+                \"details\": [\n+                    {\n+                        \"id\": 0,\n+                        \"transactionLineId\": 0,\n+                        \"transactionId\": 0,\n+                        \"country\": \"PL\",\n+                        \"region\": \"PL\",\n+                        \"stateFIPS\": \"PL\",\n+                        \"exemptAmount\": 0.0,\n+                        \"jurisCode\": \"PL\",\n+                        \"jurisName\": \"POLAND\",\n+                        \"jurisdictionId\": 200102,\n+                        \"stateAssignedNo\": \"\",\n+                        \"jurisType\": \"CNT\",\n+                        \"jurisdictionType\": \"Country\",\n+                        \"nonTaxableAmount\": 0.0,\n+                        \"rate\": 0.230000,\n+                        \"sourcing\": \"Destination\",\n+                        \"tax\": 2.3,\n+                        \"taxableAmount\": 10.0,\n+                        \"taxType\": \"Output\",\n+                        \"taxSubTypeId\": \"O\",\n+                        \"taxName\": \"Standard Rate\",\n+                        \"taxAuthorityTypeId\": 45,\n+                        \"taxCalculated\": 2.3,\n+                        \"rateType\": \"Standard\",\n+                        \"rateTypeCode\": \"S\",\n+                        \"taxableUnits\": 10.0000,\n+                        \"nonTaxableUnits\": 0.0000,\n+                        \"exemptUnits\": 0.0000,\n+                        \"unitOfBasis\": \"PerCurrencyUnit\",\n+                        \"isNonPassThru\": False,\n+                        \"isFee\": False,\n+                        \"reportingTaxableUnits\": 10.0,\n+                        \"reportingNonTaxableUnits\": 0.0,\n+                        \"reportingExemptUnits\": 0.0,\n+                        \"reportingTax\": 2.3,\n+                        \"reportingTaxCalculated\": 2.3,\n+                        \"liabilityType\": \"Seller\",\n+                        \"chargedTo\": \"Buyer\",\n+                        \"vatCode\": \"PL_S_-_230_D\",\n+                    }\n+                ],\n+                \"nonPassthroughDetails\": [],\n+                \"hsCode\": \"\",\n+                \"costInsuranceFreight\": 0.0,\n+                \"vatCode\": \"PLS-230D\",\n+                \"vatNumberTypeId\": 0,\n+            },\n+        ],\n+        \"addresses\": [\n+            {\n+                \"id\": 1,\n+                \"transactionId\": 0,\n+                \"boundaryLevel\": \"Zip5\",\n+                \"line1\": \"Olawska 10\",\n+                \"line2\": \"\",\n+                \"line3\": \"\",\n+                \"city\": \"WROCLAW\",\n+                \"region\": \"\",\n+                \"postalCode\": \"53-105\",\n+                \"country\": \"PL\",\n+                \"taxRegionId\": 205102,\n+                \"taxRegionIdAv\": 0,\n+                \"latitude\": \"\",\n+                \"longitude\": \"\",\n+            },\n+            {\n+                \"id\": 2,\n+                \"transactionId\": 0,\n+                \"boundaryLevel\": \"Zip5\",\n+                \"line1\": \"Teczowa 7\",\n+                \"line2\": \"\",\n+                \"line3\": \"\",\n+                \"city\": \"Wroclaw\",\n+                \"region\": \"\",\n+                \"postalCode\": \"53-601\",\n+                \"country\": \"PL\",\n+                \"taxRegionId\": 205102,\n+                \"taxRegionIdAv\": 0,\n+                \"latitude\": \"\",\n+                \"longitude\": \"\",\n+            },\n+        ],\n+        \"summary\": [\n+            {\n+                \"country\": \"PL\",\n+                \"region\": \"PL\",\n+                \"jurisType\": \"Country\",\n+                \"jurisCode\": \"PL\",\n+                \"jurisName\": \"POLAND\",\n+                \"taxAuthorityType\": 45,\n+                \"stateAssignedNo\": \"\",\n+                \"taxType\": \"Output\",\n+                \"taxSubType\": \"O\",\n+                \"taxName\": \"Standard Rate\",\n+                \"rateType\": \"Standard\",\n+                \"taxable\": 62.33,\n+                \"rate\": 0.230000,\n+                \"tax\": 14.34,\n+                \"taxCalculated\": 14.34,\n+                \"nonTaxable\": 0.0,\n+                \"exemption\": 0.0,\n+            }\n+        ],\n+    }\n"
        },
        {
          "path": "saleor/plugins/avatax/tests/test_avatax.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/tests/test_avatax.py\n===================================================================\n--- saleor/plugins/avatax/tests/test_avatax.py\t90a3d34 (parent)\n+++ saleor/plugins/avatax/tests/test_avatax.py\t7a4e9b6 (commit)\n@@ -1,5 +1,6 @@\n import datetime\n+from copy import deepcopy\n from decimal import Decimal\n from json import JSONDecodeError\n from unittest.mock import Mock, patch\n \n@@ -28,9 +29,9 @@\n     create_or_update_discount_objects_from_promotion_for_checkout,\n )\n from ....order import OrderStatus\n from ....product import ProductTypeKind\n-from ....product.models import Product, ProductType\n+from ....product.models import Product, ProductType, ProductVariant\n from ....product.utils.variant_prices import update_discounted_prices_for_promotion\n from ....product.utils.variants import fetch_variants_for_promotion_rules\n from ....tax import TaxCalculationStrategy\n from ....tax.models import TaxClass\n@@ -39,8 +40,9 @@\n from .. import (\n     DEFAULT_TAX_CODE,\n     META_CODE_KEY,\n     META_DESCRIPTION_KEY,\n+    SHIPPING_ITEM_CODE,\n     TAX_CODE_NON_TAXABLE_PRODUCT,\n     AvataxConfiguration,\n     TransactionType,\n     _validate_address_details,\n@@ -4085,8 +4087,9 @@\n \n     # when\n     tax_rate = manager.get_order_line_tax_rate(\n         order,\n+        order_line,\n         product,\n         order_line.variant,\n         None,\n         unit_price,\n@@ -4111,8 +4114,9 @@\n \n     # when\n     tax_rate = manager.get_order_line_tax_rate(\n         order,\n+        order_line,\n         product,\n         order_line.variant,\n         None,\n         unit_price,\n@@ -4146,8 +4150,9 @@\n \n     # when\n     tax_rate = manager.get_order_line_tax_rate(\n         order,\n+        order_line,\n         product,\n         order_line.variant,\n         None,\n         unit_price,\n@@ -4194,13 +4199,18 @@\n     avalara_response_for_checkout_with_items_and_shipping, channel_USD, checkout\n ):\n     manager = get_plugins_manager(allow_replica=False)\n     plugin = manager.get_plugin(DeprecatedAvataxPlugin.PLUGIN_ID, channel_USD.slug)\n+    shipping_line = next(\n+        line\n+        for line in avalara_response_for_checkout_with_items_and_shipping[\"lines\"]\n+        if line[\"itemCode\"] == SHIPPING_ITEM_CODE\n+    )\n \n     # 0.46 == sum of two tax districts\n     assert Decimal(\"0.46\") == plugin._get_item_tax_rate(\n-        avalara_response_for_checkout_with_items_and_shipping,\n-        \"Shipping\",\n+        {\"lines\": {SHIPPING_ITEM_CODE: shipping_line}},\n+        SHIPPING_ITEM_CODE,\n         Decimal(0.0),\n         str(checkout.pk),\n         \"Checkout\",\n     ).quantize(Decimal(\".01\"))\n@@ -4211,13 +4221,19 @@\n     avalara_response_for_checkout_with_items_and_shipping, channel_USD, checkout\n ):\n     manager = get_plugins_manager(allow_replica=False)\n     plugin = manager.get_plugin(DeprecatedAvataxPlugin.PLUGIN_ID, channel_USD.slug)\n+    line_id = \"123\"\n+    line = next(\n+        line\n+        for line in avalara_response_for_checkout_with_items_and_shipping[\"lines\"]\n+        if line[\"itemCode\"] == line_id\n+    )\n \n     # 0.36 == sum of two tax districts\n     assert Decimal(\"0.36\") == plugin._get_item_tax_rate(\n-        avalara_response_for_checkout_with_items_and_shipping,\n-        \"123\",\n+        {\"lines\": {line_id: line}},\n+        line_id,\n         Decimal(0.0),\n         str(checkout.pk),\n         \"Checkout\",\n     ).quantize(Decimal(\".01\"))\n@@ -4230,13 +4246,21 @@\n     checkout,\n ):\n     manager = get_plugins_manager(allow_replica=False)\n     plugin = manager.get_plugin(DeprecatedAvataxPlugin.PLUGIN_ID, channel_USD.slug)\n+    line_id = \"123\"\n+    line = next(\n+        line\n+        for line in avalara_response_with_line_details_and_zero_tax_with_returned_rate[\n+            \"lines\"\n+        ]\n+        if line[\"itemCode\"] == line_id\n+    )\n \n     # 0.36 == sum of two tax districts\n     assert Decimal(0) == plugin._get_item_tax_rate(\n-        avalara_response_with_line_details_and_zero_tax_with_returned_rate,\n-        \"123\",\n+        {\"lines\": {line_id: line}},\n+        line_id,\n         Decimal(0.0),\n         str(checkout.pk),\n         \"Checkout\",\n     ).quantize(Decimal(\".01\"))\n@@ -4266,9 +4290,13 @@\n     item_code = \"123\"\n \n     # when\n     returned_tax_rate = plugin._get_item_tax_rate(\n-        response, item_code, default_rate_value, str(checkout.pk), object_type\n+        {\"lines\": {item_code: line_data}},\n+        item_code,\n+        default_rate_value,\n+        str(checkout.pk),\n+        object_type,\n     ).quantize(Decimal(\".01\"))\n \n     # then\n     assert default_rate_value == returned_tax_rate\n@@ -4300,9 +4328,9 @@\n                 },\n             ],\n             \"id\": str(checkout.pk),\n             \"type\": object_type,\n-            \"item_code\": item_code,\n+            \"object_line_id\": item_code,\n             \"base_rate\": default_rate_value,\n         },\n     )\n \n@@ -4652,8 +4680,9 @@\n                     \"itemCode\": order_line.variant.sku,\n                     \"quantity\": order_line.quantity,\n                     \"taxCode\": DEFAULT_TAX_CODE,\n                     \"taxIncluded\": True,\n+                    \"number\": \"1\",\n                 }\n             ],\n             \"code\": str(order.id),\n             \"date\": datetime.datetime.now(tz=datetime.UTC).date().strftime(\"%Y-%m-%d\"),\n@@ -5027,9 +5056,11 @@\n     order_with_lines.shipping_method = method\n     order_with_lines.save()\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n     # then\n     assert all(line for line in lines_data if line[\"taxIncluded\"] is True)\n@@ -5058,9 +5089,11 @@\n     order_with_lines.shipping_method = None\n     order_with_lines.save()\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n \n     # then\n     expected_address_data = address_other_country.as_data()\n     addresses = request_data[\"createTransactionModel\"][\"addresses\"]\n@@ -5106,9 +5139,11 @@\n     avatax_config.from_postal_code = address_data.get(\"postal_code\")\n     avatax_config.from_country = address_data.get(\"country\")\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n \n     # then\n     addresses = request_data[\"createTransactionModel\"][\"addresses\"]\n     assert \"shipFrom\" not in addresses\n@@ -5147,9 +5182,11 @@\n     order_with_lines.shipping_method = method\n     order_with_lines.save()\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n \n     # then\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n     lines_1_data = lines_data[0]\n@@ -5204,9 +5241,11 @@\n             \"shipping_tax_class_private_metadata\",\n         ]\n     )\n \n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n     # extra one from shipping data\n     assert len(lines_data) == order_with_lines.lines.count() + 1\n@@ -5247,9 +5286,9 @@\n         ]\n     )\n \n     # when\n-    request_data = get_order_request_data(order, avatax_config)\n+    request_data = get_order_request_data(order, avatax_config, list(order.lines.all()))\n \n     # then\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n@@ -5297,9 +5336,11 @@\n         ]\n     )\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n \n     # then\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n@@ -5357,9 +5398,11 @@\n         ]\n     )\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n \n     # then\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n@@ -5415,9 +5458,11 @@\n         ]\n     )\n \n     # when\n-    request_data = get_order_request_data(order_with_lines, avatax_config)\n+    request_data = get_order_request_data(\n+        order_with_lines, avatax_config, list(order_with_lines.lines.all())\n+    )\n \n     # then\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n@@ -5468,9 +5513,9 @@\n         ]\n     )\n \n     # when\n-    request_data = get_order_request_data(order, avatax_config)\n+    request_data = get_order_request_data(order, avatax_config, list(order.lines.all()))\n \n     # then\n     lines_data = request_data[\"createTransactionModel\"][\"lines\"]\n \n@@ -5482,9 +5527,9 @@\n @patch(\"saleor.plugins.avatax.get_cached_response_or_fetch\")\n def test_get_order_tax_data(\n     get_cached_response_or_fetch_mock,\n     get_order_request_data_mock,\n-    order,\n+    order_with_lines,\n     plugin_configuration,\n ):\n     # given\n     conf = plugin_configuration()\n@@ -5492,12 +5537,13 @@\n     return_value = {\"id\": 0, \"code\": \"3d4893da\", \"companyId\": 123}\n     get_cached_response_or_fetch_mock.return_value = return_value\n \n     # when\n-    response = get_order_tax_data(order, conf)\n+    response = get_order_tax_data(order_with_lines, conf)\n \n     # then\n-    get_order_request_data_mock.assert_called_once_with(order, conf)\n+    lines = list(order_with_lines.lines.all())\n+    get_order_request_data_mock.assert_called_once_with(order_with_lines, conf, lines)\n     assert response == return_value\n \n \n @pytest.mark.vcr\n@@ -5982,9 +6028,14 @@\n     )\n     tax_class.save()\n \n     # when\n-    lines_data = get_order_lines_data(order_with_lines, avatax_config, discounted=False)\n+    lines_data = get_order_lines_data(\n+        order_with_lines,\n+        avatax_config,\n+        discounted=False,\n+        lines=list(order_with_lines.lines.all()),\n+    )\n \n     # then\n     assert lines_data[0][\"taxCode\"] == tax_code\n \n@@ -6008,9 +6059,14 @@\n     )\n     tax_class.save()\n \n     # when\n-    lines_data = get_order_lines_data(order_with_lines, avatax_config, discounted=False)\n+    lines_data = get_order_lines_data(\n+        order_with_lines,\n+        avatax_config,\n+        discounted=False,\n+        lines=list(order_with_lines.lines.all()),\n+    )\n \n     # then\n     assert lines_data[0][\"taxCode\"] == tax_code\n \n@@ -6037,22 +6093,28 @@\n     )\n     variant.product.tax_class.save()\n \n     # when\n-    lines_data = get_order_lines_data(order_with_lines, avatax_config, discounted=False)\n+    lines_data = get_order_lines_data(\n+        order_with_lines,\n+        avatax_config,\n+        discounted=False,\n+        lines=list(order_with_lines.lines.all()),\n+    )\n \n     # then\n     assert lines_data[0][\"amount\"] == \"0.000\"\n     assert lines_data[0][\"taxCode\"] == DEFAULT_TAX_CODE\n \n \n def test_get_order_lines_data_with_discounted(\n-    settings, channel_USD, plugin_configuration, order, order_line, avatax_config\n+    settings, channel_USD, plugin_configuration, order_line, avatax_config\n ):\n     # given\n     settings.PLUGINS = [\"saleor.plugins.avatax.plugin.DeprecatedAvataxPlugin\"]\n     plugin_configuration(channel=channel_USD)\n \n+    order = order_line.order\n     order_line.unit_price_gross_amount = Decimal(10)\n     order_line.undiscounted_unit_price_gross_amount = Decimal(20)\n     order_line.quantity = 1\n     order_line.save(\n@@ -6068,9 +6130,14 @@\n     )\n     variant.product.tax_class.save()\n \n     # when\n-    lines_data = get_order_lines_data(order, avatax_config, discounted=True)\n+    lines_data = get_order_lines_data(\n+        order,\n+        avatax_config,\n+        discounted=True,\n+        lines=list(order.lines.all()),\n+    )\n \n     # then\n     assert len(lines_data) == 1\n     line_data = lines_data[0]\n@@ -6104,9 +6171,14 @@\n \n     config = avatax_config\n \n     # when\n-    lines_data = get_order_lines_data(order_with_lines, config, discounted=False)\n+    lines_data = get_order_lines_data(\n+        order_with_lines,\n+        config,\n+        discounted=False,\n+        lines=list(order_with_lines.lines.all()),\n+    )\n \n     # then\n     assert lines_data[0][\"amount\"] == \"10.000\"\n     assert lines_data[0][\"taxCode\"] == \"taxcode\"\n@@ -6131,9 +6203,14 @@\n     line.variant.product.tax_class = tax_class_zero_rates\n     line.variant.product.save(update_fields=[\"tax_class\"])\n \n     # when\n-    lines_data = get_order_lines_data(order_with_lines, avatax_config, discounted=False)\n+    lines_data = get_order_lines_data(\n+        order_with_lines,\n+        avatax_config,\n+        discounted=False,\n+        lines=list(order_with_lines.lines.all()),\n+    )\n \n     # then\n     assert len(lines_data) == len(order_with_lines.lines.all())\n \n@@ -6484,25 +6561,25 @@\n \n def test_validate_plugin_tax_data_with_negative_values(lines_info, caplog):\n     # given\n     tax_data = {\n-        \"lines\": [\n-            {\n+        \"lines\": {\n+            \"123\": {\n                 \"lineAmount\": -30.0000,\n                 \"quantity\": 3.0,\n                 \"itemCode\": \"SKU_A\",\n             },\n-            {\n+            \"124\": {\n                 \"lineAmount\": 40.0000,\n                 \"quantity\": 2.0,\n                 \"itemCode\": \"SKU_B\",\n             },\n-            {\n+            \"125\": {\n                 \"lineAmount\": 8.1300,\n                 \"quantity\": 1.0,\n                 \"itemCode\": \"Shipping\",\n             },\n-        ]\n+        }\n     }\n \n     # when\n     error_message = DeprecatedAvataxPlugin.validate_tax_data(tax_data, lines_info)\n@@ -6513,28 +6590,208 @@\n \n def test_validate_plugin_tax_data_price_overflow(lines_info, caplog):\n     # given\n     tax_data = {\n-        \"lines\": [\n-            {\n+        \"lines\": {\n+            \"123\": {\n                 \"lineAmount\": 30.0000,\n                 \"quantity\": 3.0,\n                 \"itemCode\": \"SKU_A\",\n             },\n-            {\n+            \"124\": {\n                 \"lineAmount\": 99999999999999999.0000,\n                 \"quantity\": 2.0,\n                 \"itemCode\": \"SKU_B\",\n             },\n-            {\n+            \"125\": {\n                 \"lineAmount\": 8.1300,\n                 \"quantity\": 1.0,\n                 \"itemCode\": \"Shipping\",\n             },\n-        ]\n+        }\n     }\n \n     # when\n     error_message = DeprecatedAvataxPlugin.validate_tax_data(tax_data, lines_info)\n \n     # then\n     assert error_message == TaxDataErrorMessage.OVERFLOW\n+\n+\n+@patch(\"saleor.plugins.avatax.get_cached_response_or_fetch\")\n+@override_settings(PLUGINS=[\"saleor.plugins.avatax.plugin.DeprecatedAvataxPlugin\"])\n+def test_calculate_checkout_subtotal_with_additional_force_line(\n+    mock_get_cached_response_or_fetch,\n+    checkout_with_item,\n+    monkeypatch,\n+    ship_to_pl_address,\n+    shipping_zone,\n+    address,\n+    plugin_configuration,\n+    test_response_multiple_lines_with_same_item_code,\n+):\n+    # given\n+    plugin_configuration()\n+    monkeypatch.setattr(\n+        \"saleor.plugins.avatax.plugin.get_cached_tax_codes_or_fetch\",\n+        lambda _: {\"PC040156\": \"desc\"},\n+    )\n+\n+    def mocked_response(*args, **kwargs):\n+        # Making a copy, as we are repalcing the list of lines with the dict of\n+        # lines in the code\n+        return deepcopy(test_response_multiple_lines_with_same_item_code)\n+\n+    mock_get_cached_response_or_fetch.side_effect = mocked_response\n+    manager = get_plugins_manager(allow_replica=False)\n+\n+    tax_configuration = checkout_with_item.channel.tax_configuration\n+    tax_configuration.prices_entered_with_tax = False\n+    tax_configuration.charge_taxes = True\n+    tax_configuration.save(update_fields=[\"charge_taxes\", \"prices_entered_with_tax\"])\n+    tax_configuration.country_exceptions.all().delete()\n+\n+    checkout_with_item.shipping_address = ship_to_pl_address\n+    checkout_with_item.shipping_method = shipping_zone.shipping_methods.get()\n+    checkout_with_item.save()\n+    checkout_info = fetch_checkout_info(checkout_with_item, [], manager)\n+\n+    first_checkout_line = checkout_with_item.lines.first()\n+    variant = first_checkout_line.variant\n+    first_variant_base_price = variant.get_base_price(\n+        variant.channel_listings.get(channel=checkout_with_item.channel)\n+    ).amount\n+    price_override = Decimal(\"22.33\")\n+    override_quantity = 1\n+    add_variant_to_checkout(\n+        checkout_info,\n+        variant,\n+        override_quantity,\n+        force_new_line=True,\n+        price_override=price_override,\n+    )\n+\n+    # Make sure that price override is different than the original price\n+    assert first_variant_base_price != price_override\n+    # Make sure that quantity override is different than the original quantity\n+    assert first_checkout_line.quantity != override_quantity\n+\n+    lines, _ = fetch_checkout_lines(checkout_with_item)\n+\n+    # when\n+    subtotal = manager.calculate_checkout_subtotal(checkout_info, lines, address)\n+\n+    # then\n+    expected_subtotal_net = quantize_price(\n+        (first_variant_base_price * first_checkout_line.quantity + price_override),\n+        checkout_with_item.currency,\n+    )\n+    expected_subtotal_gross = quantize_price(\n+        expected_subtotal_net * Decimal(\"1.23\"), checkout_with_item.currency\n+    )\n+    assert subtotal == TaxedMoney(\n+        net=Money(expected_subtotal_net, checkout_with_item.currency),\n+        gross=Money(expected_subtotal_gross, checkout_with_item.currency),\n+    )\n+\n+\n+@patch(\"saleor.plugins.avatax.get_cached_response_or_fetch\")\n+@override_settings(PLUGINS=[\"saleor.plugins.avatax.plugin.DeprecatedAvataxPlugin\"])\n+def test_calculate_order_total_with_additional_force_line(\n+    mock_get_cached_response_or_fetch,\n+    order_line,\n+    shipping_zone,\n+    site_settings,\n+    address,\n+    plugin_configuration,\n+    test_response_multiple_lines_with_same_item_code,\n+):\n+    # given\n+    def mocked_response(*args, **kwargs):\n+        # Making a copy, as we are repalcing the list of lines with the dict of\n+        # lines in the code\n+        return deepcopy(test_response_multiple_lines_with_same_item_code)\n+\n+    mock_get_cached_response_or_fetch.side_effect = mocked_response\n+\n+    plugin_configuration()\n+    manager = get_plugins_manager(allow_replica=False)\n+    order = order_line.order\n+\n+    assert order.lines.count() == 1\n+\n+    variant = order_line.variant\n+    # Set SKU to the same as the lines from the:\n+    # test_response_multiple_lines_with_same_item_code\n+    ProductVariant.objects.filter(sku=\"123\").delete()\n+    variant.sku = \"123\"\n+    variant.save()\n+\n+    product = variant.product\n+    quantity = 1\n+\n+    channel = order.channel\n+\n+    tax_configuration = channel.tax_configuration\n+    tax_configuration.prices_entered_with_tax = False\n+    tax_configuration.charge_taxes = True\n+    tax_configuration.save(update_fields=[\"charge_taxes\", \"prices_entered_with_tax\"])\n+    tax_configuration.country_exceptions.all().delete()\n+\n+    price_overridden = Money(Decimal(\"22.33\"), channel.currency_code)\n+    overriden_unit_price = TaxedMoney(net=price_overridden, gross=price_overridden)\n+    order_line.base_unit_price_amount = Decimal(\"10.00\")\n+    order_line.save()\n+\n+    assert order_line.unit_price.net.amount != price_overridden\n+\n+    order.lines.create(\n+        product_name=str(product),\n+        variant_name=str(variant),\n+        product_sku=variant.sku,\n+        product_variant_id=variant.get_global_id(),\n+        is_shipping_required=True,\n+        is_gift_card=variant.is_gift_card(),\n+        quantity=quantity,\n+        variant=variant,\n+        unit_price=overriden_unit_price,\n+        total_price=overriden_unit_price * quantity,\n+        undiscounted_unit_price=overriden_unit_price,\n+        undiscounted_total_price=overriden_unit_price * quantity,\n+        base_unit_price=overriden_unit_price.gross,\n+        undiscounted_base_unit_price=overriden_unit_price.gross,\n+        tax_rate=Decimal(0),\n+        tax_class=variant.product.tax_class,\n+        is_price_overridden=True,\n+    )\n+\n+    order.status = OrderStatus.DRAFT\n+    order.shipping_address = order.billing_address.get_copy()\n+    order.should_refresh_prices = True\n+    method = shipping_zone.shipping_methods.get()\n+\n+    order.shipping_address = order.billing_address.get_copy()\n+    order_set_shipping_method(order, method)\n+    order.base_shipping_price_amount = Decimal(\"10.00\")\n+    order.save()\n+\n+    # when\n+    total = manager.calculate_order_total(order, order.lines.all())\n+\n+    # then\n+    expected_tax_rate = Decimal(\"1.23\")\n+\n+    expected_shipping_net = Money(order.base_shipping_price_amount, order.currency)\n+\n+    expected_total_net = quantize_price(\n+        (\n+            order_line.unit_price.net * order_line.quantity\n+            + price_overridden\n+            + expected_shipping_net\n+        ),\n+        order.currency,\n+    )\n+    expected_total_gross = quantize_price(\n+        expected_total_net * expected_tax_rate,\n+        order.currency,\n+    )\n+    assert total == TaxedMoney(net=expected_total_net, gross=expected_total_gross)\n"
        },
        {
          "path": "saleor/plugins/avatax/tests/test_avatax_caching.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/tests/test_avatax_caching.py\n===================================================================\n--- saleor/plugins/avatax/tests/test_avatax_caching.py\t90a3d34 (parent)\n+++ saleor/plugins/avatax/tests/test_avatax_caching.py\t7a4e9b6 (commit)\n@@ -1,4 +1,5 @@\n+from copy import deepcopy\n from decimal import Decimal\n from unittest.mock import ANY, Mock, patch\n \n from django.test import override_settings\n@@ -131,14 +132,19 @@\n     lines, _ = fetch_checkout_lines(checkout)\n     avalara_request_data = generate_request_data_from_checkout(\n         checkout_info, lines, plugin.config, transaction_token=[]\n     )\n-    mocked_cache = Mock(\n-        return_value=(\n+\n+    def mock_side_effect(*args, **kwargs):\n+        return (\n             avalara_request_data,\n-            avalara_response_for_checkout_with_items_and_shipping,\n+            # Deep copy, as after caching the response, we replace list lines\n+            # with dict lines\n+            deepcopy(avalara_response_for_checkout_with_items_and_shipping),\n         )\n-    )\n+\n+    mocked_cache = Mock(side_effect=mock_side_effect)\n+\n     monkeypatch.setattr(\"saleor.plugins.avatax.cache.get\", mocked_cache)\n     mock_validate_tax_data.return_value = \"\"\n \n     # then\n"
        },
        {
          "path": "saleor/plugins/avatax/tests/test_tasks.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/avatax/tests/test_tasks.py\n===================================================================\n--- saleor/plugins/avatax/tests/test_tasks.py\t90a3d34 (parent)\n+++ saleor/plugins/avatax/tests/test_tasks.py\t7a4e9b6 (commit)\n@@ -30,9 +30,11 @@\n         from_city=\"WROCŁAW\",\n         from_postal_code=\"53-601\",\n         from_country=\"PL\",\n     )\n-    request_data = get_order_request_data(order_with_lines, config)\n+    request_data = get_order_request_data(\n+        order_with_lines, config, list(order_with_lines.lines.all())\n+    )\n \n     transaction_url = urljoin(\n         get_api_url(config.use_sandbox), \"transactions/createoradjust\"\n     )\n@@ -62,9 +64,11 @@\n         from_city=\"WROCŁAW\",\n         from_postal_code=\"53-601\",\n         from_country=\"PL\",\n     )\n-    request_data = get_order_request_data(order_with_lines, config)\n+    request_data = get_order_request_data(\n+        order_with_lines, config, list(order_with_lines.lines.all())\n+    )\n \n     transaction_url = urljoin(\n         get_api_url(config.use_sandbox), \"transactions/createoradjust\"\n     )\n@@ -95,9 +99,11 @@\n         from_city=\"WROCŁAW\",\n         from_postal_code=\"53-601\",\n         from_country=\"PL\",\n     )\n-    request_data = get_order_request_data(order_with_lines, config)\n+    request_data = get_order_request_data(\n+        order_with_lines, config, list(order_with_lines.lines.all())\n+    )\n \n     transaction_url = urljoin(\n         get_api_url(config.use_sandbox), \"transactions/createoradjust\"\n     )\n"
        },
        {
          "path": "saleor/plugins/base_plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/base_plugin.py\n===================================================================\n--- saleor/plugins/base_plugin.py\t90a3d34 (parent)\n+++ saleor/plugins/base_plugin.py\t7a4e9b6 (commit)\n@@ -740,9 +740,16 @@\n \n     get_client_token: Callable[[Any, Any], Any]\n \n     get_order_line_tax_rate: Callable[\n-        [\"Order\", \"Product\", \"ProductVariant\", Union[\"Address\", None], Decimal],\n+        [\n+            \"Order\",\n+            \"OrderLine\",\n+            \"Product\",\n+            \"ProductVariant\",\n+            Union[\"Address\", None],\n+            Decimal,\n+        ],\n         Decimal,\n     ]\n \n     get_order_shipping_tax_rate: Callable[[\"Order\", Any], Any]\n"
        },
        {
          "path": "saleor/plugins/manager.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/manager.py\n===================================================================\n--- saleor/plugins/manager.py\t90a3d34 (parent)\n+++ saleor/plugins/manager.py\t7a4e9b6 (commit)\n@@ -597,8 +597,9 @@\n \n     def get_order_line_tax_rate(\n         self,\n         order: \"Order\",\n+        order_line: \"OrderLine\",\n         product: \"Product\",\n         variant: \"ProductVariant\",\n         address: Optional[\"Address\"],\n         price: TaxedMoney,\n@@ -608,8 +609,9 @@\n         return self.__run_method_on_plugins(\n             \"get_order_line_tax_rate\",\n             default_value,\n             order,\n+            order_line,\n             product,\n             variant,\n             address,\n             channel_slug=order.channel.slug,\n"
        },
        {
          "path": "saleor/plugins/tests/sample_plugins.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/tests/sample_plugins.py\n===================================================================\n--- saleor/plugins/tests/sample_plugins.py\t90a3d34 (parent)\n+++ saleor/plugins/tests/sample_plugins.py\t7a4e9b6 (commit)\n@@ -268,8 +268,9 @@\n \n     def get_order_line_tax_rate(\n         self,\n         order: \"Order\",\n+        order_line: \"OrderLine\",\n         product: \"Product\",\n         variant: \"ProductVariant\",\n         address: Optional[\"Address\"],\n         previous_value: Decimal,\n"
        },
        {
          "path": "saleor/plugins/tests/test_manager.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/tests/test_manager.py\n===================================================================\n--- saleor/plugins/tests/test_manager.py\t90a3d34 (parent)\n+++ saleor/plugins/tests/test_manager.py\t7a4e9b6 (commit)\n@@ -357,8 +357,9 @@\n     plugins = [\"saleor.plugins.tests.sample_plugins.PluginSample\"]\n     unit_price = TaxedMoney(Money(12, \"USD\"), Money(15, \"USD\"))\n     tax_rate = PluginsManager(plugins=plugins).get_order_line_tax_rate(\n         order,\n+        line,\n         product,\n         line.variant,\n         None,\n         unit_price,\n@@ -380,8 +381,9 @@\n     line = order.lines.first()\n     product = Product.objects.get(name=line.product_name)\n     tax_rate = PluginsManager(plugins=[]).get_order_line_tax_rate(\n         order,\n+        line,\n         product,\n         line.variant,\n         None,\n         unit_price,\n"
        }
      ]
    },
    {
      "id": "fix-bulk-pricing",
      "sha": "e5ff65b54ecd6a7152675ab953ae5315a7304fa7",
      "parentSha": "1a8b592913a0cadca6d0b171e9afb2f8e4b823f6",
      "spec": "Implement correct draft order price calculations and line-discount persistence for orders created through the OrderBulkCreate mutation.\n\nMake the following changes in saleor/graphql/order/bulk_mutations/order_bulk_create.py:\n- Imports:\n  - Add DiscountType, OrderLineDiscount to discounts imports.\n  - Add TaxConfiguration to tax models imports.\n- Dataclasses:\n  - Extend OrderBulkOrderLine to include a new attribute: line_discount: OrderLineDiscount | None.\n  - Extend OrderBulkCreateData to include: tax_configuration: TaxConfiguration | None.\n  - Add a property all_order_line_discounts returning a flat list of all non-null OrderLineDiscount objects from self.lines.\n  - Extend LineAmounts to add fields base_unit_price: Decimal and undiscounted_base_unit_price: Decimal.\n- Instance prefetching (get_all_instances):\n  - Fetch TaxConfiguration objects for all channels referenced in input (channel IDs derived from slugs), and store them in object_storage using key pattern: \"TaxConfiguration.channel_id.{channel_id}\".\n- Order-related instances (get_instances_related_to_order/create_single_order):\n  - If a channel is resolved, fetch its TaxConfiguration from object_storage and set order_data.tax_configuration accordingly.\n- Line calculations (make_order_line_calculations):\n  - Determine prices_entered_with_tax based on order_data.tax_configuration.prices_entered_with_tax; default to True if no configuration.\n  - Compute undiscounted_base_unit_price_amount as undiscounted_unit_price_gross_amount when prices_entered_with_tax is True, otherwise undiscounted_unit_price_net_amount.\n  - Compute base_unit_price as undiscounted_base_unit_price_amount minus unit_discount_amount (if any).\n  - Return these in LineAmounts.base_unit_price and LineAmounts.undiscounted_base_unit_price alongside existing amounts and fields.\n- Line creation (create_single_order_line):\n  - When instantiating OrderLine, set:\n    - base_unit_price_amount from line_amounts.base_unit_price\n    - undiscounted_base_unit_price_amount from line_amounts.undiscounted_base_unit_price\n  - If a per-unit discount is present (line_amounts.unit_discount_amount > 0), create an OrderLineDiscount instance (do not save yet) with:\n    - line set to the created OrderLine\n    - unique_type=DiscountType.MANUAL, type=DiscountType.MANUAL\n    - value_type set to the provided unit discount type (converted to the expected enum value), falling back to FIXED when absent\n    - value set to the provided unit discount value\n    - amount_value computed as unit_discount_amount * quantity\n    - currency set to the order line currency\n    - reason set from unit_discount_reason\n  - Return OrderBulkOrderLine including the new line_discount.\n- Persisting data (save_data):\n  - After bulk-creating OrderLine objects, bulk-create all applicable OrderLineDiscount objects collected from orders_data via the new all_order_line_discounts property.\n\nTests and GraphQL helpers:\n- saleor/graphql/order/tests/mutations/test_order_bulk_create.py:\n  - Update ORDER_BULK_CREATE selection set for lines to include undiscountedTotalPrice { gross { amount } net { amount } } so assertions can cover undiscounted totals.\n- saleor/graphql/order/tests/integration/test_bulk_order.py:\n  - Add an integration test that:\n    - Imports a draft order via orderBulkCreate with a line-level discount\n    - Asserts that the created order line exposes unitDiscount fields and that totals match the provided line totals\n    - Refetches prices using fetch_order_prices_if_expired with get_plugins_manager and force_update=True and verifies that discount and totals remain consistent with line data\n- E2E test and utilities:\n  - Add saleor/tests/e2e/orders/test_able_to_update_draft_order_after_bulk_order_creation_with_line_discount.py to cover:\n    - Creating a draft order via orderBulkCreate with a line-level discount\n    - Updating the draft order (e.g., changing delivery method) and forcing price recalculation\n    - Verifying that the line discount is still applied and order totals align with the discounted line totals\n  - Add saleor/tests/e2e/orders/utils/fragments.py with ORDER_LINE_FRAGMENT containing line fields including unit pricing, discounts, and undiscounted prices.\n  - Add saleor/tests/e2e/orders/utils/order_bulk_create.py exposing ORDER_BULK_CREATE_MUTATION plus order_bulk_create(api_client, orders) helper. Use ORDER_LINE_FRAGMENT in the selection set and include order fields for totals and undiscounted totals.\n  - Update saleor/tests/e2e/orders/utils/__init__.py to export order_bulk_create.\n  - Update saleor/tests/e2e/orders/utils/order_query.py to import and use ORDER_LINE_FRAGMENT and to include subtotal, total, and undiscountedTotal in the selection set.\n  - Update saleor/tests/e2e/shop/utils/preparing_shop.py to include created channel currency code in the returned channel data map, under the key \"currency\": created_channel[\"currencyCode\"].\n\nDocumentation/metadata:\n- CHANGELOG.md: Append an entry indicating that draft orders created via OrderBulkCreate now have properly calculated prices.\n\nBehavioral expectations:\n- Order lines created via OrderBulkCreate have base_unit_price_amount and undiscounted_base_unit_price_amount correctly set based on channel tax configuration.\n- Manual line discounts provided in input are persisted as OrderLineDiscount records and reflected in OrderLine.unit_discount_* fields and totals.\n- Subsequent price refreshes (e.g., fetch_order_prices_if_expired) respect stored base prices and discounts, maintaining consistent totals.\n- E2E flows retain line-level discounts when draft order properties are updated and totals recompute accordingly.",
      "prompt": "Implement correct draft-order pricing and line-discount persistence for orders created via the bulk order import mutation.\n\nRequirements:\n- Use the channel’s tax configuration to decide whether prices are entered with tax and compute per-unit base prices accordingly.\n- Store both undiscounted and discounted base unit prices on each line and ensure they’re used when prices are recalculated.\n- Persist manual line-level discounts as dedicated line discount objects and reflect them in line unit discount fields and totals.\n- Ensure bulk-created discount objects are saved alongside lines.\n- Update integration and end-to-end tests and utilities to validate that imported draft orders with per-line discounts are priced correctly at creation, remain correct after price refresh, and retain discounts when the draft order is updated.\n- Update the order query and bulk-create selection sets to include undiscounted totals where needed.\n- Add currency to prepared channel data in test setup to support assertions.",
      "supplementalFiles": [
        "saleor/order/models.py",
        "saleor/order/calculations.py",
        "saleor/order/base_calculations.py",
        "saleor/discount/models.py",
        "saleor/tax/models.py",
        "saleor/graphql/schema.graphql"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t1a8b592 (parent)\n+++ CHANGELOG.md\te5ff65b (commit)\n@@ -107,4 +107,5 @@\n - Improve status calculation for orders with waiting-for-approval fulfillments - #17471 by @delemeator\n - Allow to change Admin email plugin custom templates back to default - #17563 by @wcislo-saleor\n - Fixes incorrect gift card balances after covering the full order total - #17566 by @korycins\n - Fixes tax class not clearing when selecting a shipping method without a tax class - #17560 by @korycins\n+- The prices for draft orders created in `OrderBulkCreate` now are properly calculated - #17583 by @IKarbowiak\n"
        },
        {
          "path": "saleor/graphql/order/bulk_mutations/order_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/bulk_mutations/order_bulk_create.py\n===================================================================\n--- saleor/graphql/order/bulk_mutations/order_bulk_create.py\t1a8b592 (parent)\n+++ saleor/graphql/order/bulk_mutations/order_bulk_create.py\te5ff65b (commit)\n@@ -23,9 +23,14 @@\n from ....core.prices import quantize_price\n from ....core.tracing import traced_atomic_transaction\n from ....core.utils.url import validate_storefront_url\n from ....core.weight import zero_weight\n-from ....discount.models import OrderDiscount, VoucherCode\n+from ....discount.models import (\n+    DiscountType,\n+    OrderDiscount,\n+    OrderLineDiscount,\n+    VoucherCode,\n+)\n from ....discount.utils.manual_discount import apply_discount_to_value\n from ....giftcard.models import GiftCard\n from ....invoice.models import Invoice\n from ....order import (\n@@ -43,9 +48,9 @@\n from ....payment.models import TransactionEvent, TransactionItem\n from ....permission.enums import OrderPermissions\n from ....product.models import ProductVariant\n from ....shipping.models import ShippingMethod, ShippingMethodChannelListing\n-from ....tax.models import TaxClass\n+from ....tax.models import TaxClass, TaxConfiguration\n from ....warehouse.management import stock_bulk_update\n from ....warehouse.models import Stock, Warehouse\n from ...account.i18n import I18nMixin\n from ...account.types import AddressInput\n@@ -101,8 +106,9 @@\n \n @dataclass\n class OrderBulkOrderLine:\n     line: OrderLine\n+    line_discount: OrderLineDiscount | None\n     warehouse: Warehouse\n \n \n @dataclass\n@@ -124,8 +130,9 @@\n     gift_cards: list[GiftCard] = dataclass_field(default_factory=list)\n     user: User | None = None\n     billing_address: Address | None = None\n     channel: Channel | None = None\n+    tax_configuration: TaxConfiguration | None = None\n     shipping_address: Address | None = None\n     voucher_code: VoucherCode | None = None\n     # error which ignores error policy and disqualify order\n     is_critical_error: bool = False\n@@ -164,8 +171,16 @@\n     def all_order_lines(self) -> list[OrderLine]:\n         return [order_line.line for order_line in self.lines]\n \n     @property\n+    def all_order_line_discounts(self) -> list[OrderLineDiscount]:\n+        return [\n+            order_line.line_discount\n+            for order_line in self.lines\n+            if order_line.line_discount\n+        ]\n+\n+    @property\n     def all_fulfillment_lines(self) -> list[FulfillmentLine]:\n         return [\n             fulfillment_line.line\n             for fulfillment in self.fulfillments\n@@ -275,8 +290,10 @@\n     total_gross: Decimal\n     total_net: Decimal\n     unit_gross: Decimal\n     unit_net: Decimal\n+    base_unit_price: Decimal\n+    undiscounted_base_unit_price: Decimal\n     unit_discount_value: Decimal\n     unit_discount_type: str | None\n     unit_discount_reason: str | None\n     undiscounted_total_gross: Decimal\n@@ -764,8 +781,11 @@\n             | Q(sku__in=identifiers.variant_skus.keys)\n             | Q(external_reference__in=identifiers.variant_external_references.keys)\n         )\n         channels = Channel.objects.filter(slug__in=identifiers.channel_slugs.keys)\n+        tax_configurations = TaxConfiguration.objects.filter(\n+            channel_id__in=channels.values(\"id\")\n+        )\n         voucher_codes = VoucherCode.objects.filter(\n             code__in=identifiers.voucher_codes.keys\n         ).select_related(\"voucher\")\n         warehouses = Warehouse.objects.filter(pk__in=identifiers.warehouse_ids.keys)\n@@ -802,8 +822,13 @@\n \n         for channel in channels:\n             object_storage[f\"Channel.slug.{channel.slug}\"] = channel\n \n+        for tax_configuration in tax_configurations:\n+            object_storage[\n+                f\"TaxConfiguration.channel_id.{tax_configuration.channel_id}\"\n+            ] = tax_configuration\n+\n         for voucher_code in voucher_codes:\n             object_storage[f\"VoucherCode.code.{voucher_code.code}\"] = voucher_code\n \n         for gift_card in gift_cards:\n@@ -1038,8 +1063,14 @@\n             key_map={\"channel\": \"slug\"},\n             object_storage=object_storage,\n         )\n \n+        tax_configuration = None\n+        if channel:\n+            tax_configuration = object_storage.get(\n+                f\"TaxConfiguration.channel_id.{channel.id}\"\n+            )\n+\n         billing_address: Address | None = None\n         billing_address_input = order_input[\"billing_address\"]\n         metadata_list: list[MetadataInput] = billing_address_input.pop(\"metadata\", None)\n         private_metadata_list: list[MetadataInput] = billing_address_input.pop(\n@@ -1124,8 +1155,9 @@\n                 )\n \n         order_data.user = user\n         order_data.channel = channel\n+        order_data.tax_configuration = tax_configuration\n         order_data.billing_address = billing_address\n         order_data.shipping_address = shipping_address\n         order_data.voucher_code = voucher_code\n \n@@ -1237,13 +1269,28 @@\n                     code=OrderBulkCreateErrorCode.PRICE_ERROR,\n                 )\n             )\n \n+        prices_entered_with_tax = True\n+        if tax_configuration := order_data.tax_configuration:\n+            prices_entered_with_tax = tax_configuration.prices_entered_with_tax\n+\n+        undiscounted_base_unit_price_amount = (\n+            undiscounted_unit_price_gross_amount\n+            if prices_entered_with_tax\n+            else undiscounted_unit_price_net_amount\n+        )\n+        base_unit_price = undiscounted_base_unit_price_amount\n+        if unit_discount_amount:\n+            base_unit_price -= unit_discount_amount\n+\n         return LineAmounts(\n             total_gross=gross_amount,\n             total_net=net_amount,\n             unit_gross=unit_price_gross_amount,\n             unit_net=unit_price_net_amount,\n+            base_unit_price=base_unit_price,\n+            undiscounted_base_unit_price=undiscounted_base_unit_price_amount,\n             unit_discount_reason=unit_discount_reason,\n             unit_discount_type=unit_discount_type,\n             unit_discount_value=unit_discount_value,\n             undiscounted_total_gross=undiscounted_gross_amount,\n@@ -1737,13 +1784,29 @@\n             undiscounted_unit_price_net_amount=line_amounts.undiscounted_unit_net,\n             undiscounted_unit_price_gross_amount=line_amounts.undiscounted_unit_gross,\n             undiscounted_total_price_net_amount=line_amounts.undiscounted_total_net,\n             undiscounted_total_price_gross_amount=line_amounts.undiscounted_total_gross,\n+            base_unit_price_amount=line_amounts.base_unit_price,\n+            undiscounted_base_unit_price_amount=line_amounts.undiscounted_base_unit_price,\n             unit_discount_amount=line_amounts.unit_discount_amount,\n             tax_rate=line_amounts.tax_rate,\n             tax_class=line_tax_class,\n             tax_class_name=order_line_input.get(\"tax_class_name\"),\n         )\n+        line_discount = None\n+        if line_amounts.unit_discount_amount > 0:\n+            discount_amount = line_amounts.unit_discount_amount * line_amounts.quantity\n+            line_discount = OrderLineDiscount(\n+                line=order_line,\n+                unique_type=DiscountType.MANUAL,\n+                type=DiscountType.MANUAL,\n+                value_type=line_amounts.unit_discount_type\n+                or DiscountValueTypeEnum.FIXED.name,  # type: ignore[attr-defined]\n+                value=line_amounts.unit_discount_value,\n+                amount_value=discount_amount,\n+                currency=order_line.currency,\n+                reason=line_amounts.unit_discount_reason,\n+            )\n \n         if metadata := order_line_input.get(\"metadata\"):\n             cls.process_metadata(\n                 metadata=metadata,\n@@ -1774,9 +1837,11 @@\n                 path=f\"lines.{index}.tax_class_private_metadata\",\n                 field=order_line.tax_class_private_metadata,\n             )\n \n-        return OrderBulkOrderLine(line=order_line, warehouse=warehouse)\n+        return OrderBulkOrderLine(\n+            line=order_line, line_discount=line_discount, warehouse=warehouse\n+        )\n \n     @classmethod\n     def create_single_fulfillment(\n         cls,\n@@ -2285,8 +2350,18 @@\n             [],\n         )\n         OrderLine.objects.bulk_create(order_lines)\n \n+        order_line_discounts: list[OrderLineDiscount] = sum(\n+            [\n+                order_data.all_order_line_discounts\n+                for order_data in orders_data\n+                if order_data.order\n+            ],\n+            [],\n+        )\n+        OrderLineDiscount.objects.bulk_create(order_line_discounts)\n+\n         notes = [\n             note\n             for order_data in orders_data\n             for note in order_data.notes\n"
        },
        {
          "path": "saleor/graphql/order/tests/integration/test_bulk_order.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/integration/test_bulk_order.py\n===================================================================\n--- saleor/graphql/order/tests/integration/test_bulk_order.py\t1a8b592 (parent)\n+++ saleor/graphql/order/tests/integration/test_bulk_order.py\te5ff65b (commit)\n@@ -5,11 +5,14 @@\n import graphene\n import pytest\n \n from saleor.order import OrderEvents\n-from saleor.order.models import Order\n+from saleor.order.models import Order, OrderLine\n from saleor.payment.models import TransactionItem\n \n+from .....order.calculations import fetch_order_prices_if_expired\n+from .....plugins.manager import get_plugins_manager\n+from ....discount.enums import DiscountValueTypeEnum\n from ....order.enums import OrderStatusEnum\n from ....payment.enums import TransactionActionEnum\n from ....payment.tests.mutations.test_transaction_request_action import (\n     MUTATION_TRANSACTION_REQUEST_ACTION,\n@@ -300,4 +303,105 @@\n     assert data_1[\"totalCount\"] == 1\n     assert data_1[\"edges\"][0][\"node\"][\"id\"] == order_2_id\n     assert data_2[\"totalCount\"] == 1\n     assert data_2[\"edges\"][0][\"node\"][\"id\"] == order_3_id\n+\n+\n+@pytest.mark.integration\n+def test_refresh_order_prices_from_imported_draft_order_with_unit_discount(\n+    staff_api_client,\n+    permission_manage_orders_import,\n+    permission_group_manage_orders,\n+    order_bulk_input,  # noqa: F811\n+    product,\n+    channel_USD,\n+):\n+    # given\n+    staff_api_client.user.user_permissions.add(permission_manage_orders_import)\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+\n+    # when\n+    # import draft order from external system\n+    order = order_bulk_input\n+    order[\"status\"] = OrderStatusEnum.DRAFT.name\n+    order[\"deliveryMethod\"] = None\n+    order[\"channel\"] = channel_USD.slug\n+    order[\"currency\"] = \"USD\"\n+    order[\"fulfillments\"] = []\n+    order[\"transactions\"] = []\n+    order[\"invoices\"] = []\n+    order[\"discounts\"] = []\n+\n+    discount_type = DiscountValueTypeEnum.FIXED.name\n+    discount_value = 10\n+    discount_reason = \"Test discount\"\n+    variant = product.variants.first()\n+    order[\"lines\"][0][\"variantId\"] = graphene.Node.to_global_id(\n+        \"ProductVariant\", variant.id\n+    )\n+    order[\"lines\"][0][\"isShippingRequired\"] = False\n+    order[\"lines\"][0][\"unitDiscountValue\"] = discount_value\n+    order[\"lines\"][0][\"unitDiscountType\"] = discount_type\n+    order[\"lines\"][0][\"unitDiscountReason\"] = discount_reason\n+\n+    line_total_price_net = 50\n+    line_total_price_gross = 60\n+    order[\"lines\"][0][\"totalPrice\"][\"net\"] = line_total_price_net\n+    order[\"lines\"][0][\"totalPrice\"][\"gross\"] = line_total_price_gross\n+\n+    variables = {\n+        \"orders\": [order],\n+        \"stockUpdatePolicy\": StockUpdatePolicyEnum.UPDATE.name,\n+    }\n+\n+    response = staff_api_client.post_graphql(ORDER_BULK_CREATE, variables)\n+    content = get_graphql_content(response)\n+\n+    data = content[\"data\"][\"orderBulkCreate\"][\"results\"]\n+    assert not data[0][\"errors\"]\n+\n+    order_response_data = data[0][\"order\"]\n+\n+    order_line = order_response_data[\"lines\"][0]\n+    assert order_line[\"variant\"][\"id\"] == graphene.Node.to_global_id(\n+        \"ProductVariant\", variant.id\n+    )\n+    assert order_line[\"unitDiscountType\"] == discount_type\n+    assert order_line[\"unitDiscountValue\"] == discount_value\n+    assert order_line[\"unitDiscountReason\"] == discount_reason\n+    assert order_response_data[\"total\"][\"net\"][\"amount\"] == line_total_price_net\n+    assert order_response_data[\"total\"][\"gross\"][\"amount\"] == line_total_price_gross\n+    assert (\n+        order_response_data[\"undiscountedTotal\"][\"net\"][\"amount\"]\n+        == order[\"lines\"][0][\"undiscountedTotalPrice\"][\"net\"]\n+    )\n+    assert (\n+        order_response_data[\"undiscountedTotal\"][\"gross\"][\"amount\"]\n+        == order[\"lines\"][0][\"undiscountedTotalPrice\"][\"gross\"]\n+    )\n+    assert order_response_data[\"shippingPrice\"][\"gross\"][\"amount\"] == 0\n+    assert order_response_data[\"shippingPrice\"][\"net\"][\"amount\"] == 0\n+\n+    db_order_line = OrderLine.objects.get()\n+    assert db_order_line.variant == variant\n+    assert db_order_line.unit_discount_type == discount_type.lower()\n+    assert db_order_line.unit_discount_value == discount_value\n+    assert db_order_line.unit_discount_reason == discount_reason\n+\n+    assert order_response_data\n+\n+    # refetch order prices\n+    order = Order.objects.get()\n+    order, lines = fetch_order_prices_if_expired(\n+        order, get_plugins_manager(allow_replica=True), force_update=True\n+    )\n+\n+    # then - ensure the order prices are updated, the discount is applied\n+    line = lines[0]\n+    assert line.unit_discount_type == discount_type.lower()\n+    assert line.unit_discount_value == discount_value\n+    assert line.unit_discount_reason == discount_reason\n+    assert (\n+        line.undiscounted_total_price_net_amount - line.total_price_net_amount\n+    ) / line.quantity == line.unit_discount_amount\n+    assert order.total_net_amount == line.total_price_net_amount\n+    assert order.total_gross_amount == line.total_price_gross_amount\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_bulk_create.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_bulk_create.py\t1a8b592 (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_bulk_create.py\te5ff65b (commit)\n@@ -109,8 +109,16 @@\n                             net {\n                                 amount\n                             }\n                         }\n+                        undiscountedTotalPrice{\n+                            gross {\n+                                amount\n+                            }\n+                            net {\n+                                amount\n+                            }\n+                        }\n                         metadata {\n                             key\n                             value\n                         }\n"
        },
        {
          "path": "saleor/tests/e2e/orders/test_able_to_update_draft_order_after_bulk_order_creation_with_line_discount.py",
          "status": "added",
          "diff": "Index: saleor/tests/e2e/orders/test_able_to_update_draft_order_after_bulk_order_creation_with_line_discount.py\n===================================================================\n--- saleor/tests/e2e/orders/test_able_to_update_draft_order_after_bulk_order_creation_with_line_discount.py\t1a8b592 (parent)\n+++ saleor/tests/e2e/orders/test_able_to_update_draft_order_after_bulk_order_creation_with_line_discount.py\te5ff65b (commit)\n@@ -0,0 +1,231 @@\n+import graphene\n+from django.utils import timezone\n+\n+from .. import DEFAULT_ADDRESS\n+from ..product.utils.preparing_product import prepare_product\n+from ..shop.utils.preparing_shop import prepare_shop\n+from ..taxes.utils import update_country_tax_rates\n+from ..utils import assert_address_data, assign_permissions\n+from .utils import draft_order_update, order_bulk_create, order_query\n+\n+\n+def prepare_order_bulk_create_input(\n+    customer_user,\n+    product_variant_id,\n+    warehouse_id,\n+    shipping_method_id,\n+    channel_slug,\n+    currency,\n+    tax_class_id,\n+    line_discount_data,\n+):\n+    user = {\n+        \"id\": graphene.Node.to_global_id(\"User\", customer_user.id),\n+        \"email\": None,\n+    }\n+    delivery_method = {\n+        \"shippingMethodId\": shipping_method_id,\n+        \"shippingMethodName\": \"Denormalized name\",\n+        \"shippingPrice\": {\n+            \"gross\": 60,\n+            \"net\": 50,\n+        },\n+        \"shippingTaxRate\": 0.2,\n+        \"shippingTaxClassId\": tax_class_id,\n+        \"shippingTaxClassName\": \"Denormalized name\",\n+    }\n+    line = {\n+        \"variantId\": product_variant_id,\n+        \"createdAt\": timezone.now(),\n+        \"productName\": \"Product Name\",\n+        \"variantName\": \"Variant Name\",\n+        \"translatedProductName\": \"Nazwa Produktu\",\n+        \"translatedVariantName\": \"Nazwa Wariantu\",\n+        \"isShippingRequired\": True,\n+        \"isGiftCard\": False,\n+        \"quantity\": 5,\n+        \"totalPrice\": {\n+            \"gross\": 120,\n+            \"net\": 100,\n+        },\n+        \"undiscountedTotalPrice\": {\n+            \"gross\": 120,\n+            \"net\": 100,\n+        },\n+        \"taxRate\": 0.2,\n+        \"taxClassId\": tax_class_id,\n+        \"warehouse\": warehouse_id,\n+        \"metadata\": [{\"key\": \"md key\", \"value\": \"md value\"}],\n+        \"privateMetadata\": [{\"key\": \"pmd key\", \"value\": \"pmd value\"}],\n+        **line_discount_data,\n+    }\n+    return {\n+        \"channel\": channel_slug,\n+        \"createdAt\": timezone.now(),\n+        \"status\": \"DRAFT\",\n+        \"user\": user,\n+        \"billingAddress\": DEFAULT_ADDRESS,\n+        \"shippingAddress\": DEFAULT_ADDRESS,\n+        \"currency\": currency,\n+        \"languageCode\": \"PL\",\n+        \"deliveryMethod\": delivery_method,\n+        \"lines\": [line],\n+        \"weight\": \"10.15\",\n+        \"redirectUrl\": \"https://www.example.com\",\n+        \"metadata\": [{\"key\": \"md key\", \"value\": \"md value\"}],\n+        \"privateMetadata\": [{\"key\": \"pmd key\", \"value\": \"pmd value\"}],\n+    }\n+\n+\n+def test_able_to_update_draft_order_after_bulk_order_creation_with_line_discount_CORE_0258(\n+    e2e_staff_api_client,\n+    e2e_logged_api_client,\n+    shop_permissions,\n+    permission_manage_product_types_and_attributes,\n+    permission_manage_orders,\n+    permission_manage_orders_import,\n+):\n+    # Before\n+    permissions = [\n+        *shop_permissions,\n+        permission_manage_product_types_and_attributes,\n+        permission_manage_orders,\n+        permission_manage_orders_import,\n+    ]\n+    assign_permissions(e2e_staff_api_client, permissions)\n+\n+    shipping_country = \"US\"\n+    shipping_class_tax_rate = 8\n+    tax_settings = {\n+        \"charge_taxes\": True,\n+        \"tax_calculation_strategy\": \"FLAT_RATES\",\n+        \"display_gross_prices\": False,\n+        \"prices_entered_with_tax\": True,\n+        \"tax_rates\": [\n+            {\n+                \"type\": \"shipping_country\",\n+                \"name\": \"Shipping Country Tax Rate\",\n+                \"country_code\": shipping_country,\n+                \"rate\": shipping_class_tax_rate,\n+            },\n+        ],\n+    }\n+    price = 10\n+\n+    shop_data, tax_config = prepare_shop(\n+        e2e_staff_api_client,\n+        channels=[\n+            {\n+                \"shipping_zones\": [\n+                    {\n+                        \"shipping_methods\": [\n+                            {\n+                                \"add_channels\": {},\n+                            },\n+                            {\n+                                \"name\": \"Another shipping method\",\n+                                \"add_channels\": {},\n+                            },\n+                        ],\n+                    },\n+                ],\n+                \"order_settings\": {},\n+            },\n+        ],\n+        tax_settings=tax_settings,\n+    )\n+    channel_data = shop_data[0]\n+    channel_id = channel_data[\"id\"]\n+    channel_slug = channel_data[\"slug\"]\n+    currency = channel_data[\"currency\"]\n+    warehouse_id = channel_data[\"warehouse_id\"]\n+    shipping_method_id = channel_data[\"shipping_zones\"][0][\"shipping_methods\"][0][\"id\"]\n+    shipping_method_id_2 = channel_data[\"shipping_zones\"][0][\"shipping_methods\"][1][\n+        \"id\"\n+    ]\n+    tax_class_id = tax_config[0][\"shipping_country_tax_class_id\"]\n+\n+    update_country_tax_rates(\n+        e2e_staff_api_client,\n+        shipping_country,\n+        [{\"rate\": shipping_class_tax_rate}],\n+    )\n+\n+    _product_id, product_variant_id, _product_variant_price = prepare_product(\n+        e2e_staff_api_client,\n+        warehouse_id,\n+        channel_id,\n+        price,\n+    )\n+\n+    line_discount_data = {\n+        \"unitDiscountValue\": 10,\n+        \"unitDiscountType\": \"FIXED\",\n+        \"unitDiscountReason\": \"Test discount\",\n+        \"totalPrice\": {\n+            \"net\": 50,\n+            \"gross\": 60,\n+        },\n+    }\n+    order_input = prepare_order_bulk_create_input(\n+        e2e_logged_api_client.user,\n+        product_variant_id,\n+        warehouse_id,\n+        shipping_method_id,\n+        channel_slug,\n+        currency,\n+        tax_class_id,\n+        line_discount_data,\n+    )\n+\n+    # Step 1 - Create order with order bulk create\n+    create_order_response = order_bulk_create(e2e_staff_api_client, [order_input])\n+\n+    assert create_order_response[\"count\"] == 1\n+\n+    draft_order = create_order_response[\"results\"][0][\"order\"]\n+    assert draft_order\n+    order_id = draft_order[\"id\"]\n+    assert len(draft_order[\"lines\"]) == 1\n+    line = draft_order[\"lines\"][0]\n+    assert line[\"unitDiscountValue\"] == line_discount_data[\"unitDiscountValue\"]\n+    assert line[\"unitDiscountType\"] == line_discount_data[\"unitDiscountType\"]\n+    assert line[\"unitDiscountReason\"] == line_discount_data[\"unitDiscountReason\"]\n+    assert line[\"unitDiscount\"][\"amount\"] == line_discount_data[\"unitDiscountValue\"]\n+\n+    # Step 2 - Update delivery method\n+    address = DEFAULT_ADDRESS\n+    address[\"firstName\"] = \"New name\"\n+    input = {\n+        \"shippingMethod\": shipping_method_id_2,\n+        \"billingAddress\": DEFAULT_ADDRESS,  # force the price recalculation\n+    }\n+    draft_order = draft_order_update(\n+        e2e_staff_api_client,\n+        order_id,\n+        input,\n+    )\n+\n+    order_shipping_id = draft_order[\"order\"][\"deliveryMethod\"][\"id\"]\n+    assert order_shipping_id == shipping_method_id_2\n+    order_billing_address = draft_order[\"order\"][\"billingAddress\"]\n+    assert_address_data(order_billing_address, address)\n+\n+    # Step 3 - Ensure that the line discount is still applied\n+    draft_order = order_query(e2e_staff_api_client, order_id)\n+\n+    assert draft_order\n+    assert len(draft_order[\"lines\"]) == 1\n+    line = draft_order[\"lines\"][0]\n+    assert line[\"unitDiscountValue\"] == line_discount_data[\"unitDiscountValue\"]\n+    assert line[\"unitDiscountType\"] == line_discount_data[\"unitDiscountType\"]\n+    assert line[\"unitDiscountReason\"] == line_discount_data[\"unitDiscountReason\"]\n+    assert line[\"unitDiscount\"][\"amount\"] == line_discount_data[\"unitDiscountValue\"]\n+    assert (\n+        line[\"undiscountedUnitPrice\"][\"gross\"][\"amount\"] * line[\"quantity\"]\n+        - line[\"totalPrice\"][\"gross\"][\"amount\"]\n+    ) / 5 == line[\"unitDiscount\"][\"amount\"]\n+    assert (\n+        draft_order[\"subtotal\"][\"gross\"][\"amount\"]\n+        == line[\"totalPrice\"][\"gross\"][\"amount\"]\n+    )\n"
        },
        {
          "path": "saleor/tests/e2e/orders/utils/__init__.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/orders/utils/__init__.py\n===================================================================\n--- saleor/tests/e2e/orders/utils/__init__.py\t1a8b592 (parent)\n+++ saleor/tests/e2e/orders/utils/__init__.py\te5ff65b (commit)\n@@ -2,8 +2,9 @@\n from .draft_order_complete import draft_order_complete, raw_draft_order_complete\n from .draft_order_create import draft_order_create\n from .draft_order_delete import draft_order_delete\n from .draft_order_update import draft_order_update, raw_draft_order_update\n+from .order_bulk_create import order_bulk_create\n from .order_by_checkout_id_query import order_by_checkout_id_query\n from .order_cancel import order_cancel\n from .order_create_from_checkout import (\n     order_create_from_checkout,\n@@ -24,8 +25,9 @@\n from .order_update_shipping import order_update_shipping\n from .order_void import order_void, raw_order_void\n \n __all__ = [\n+    \"order_bulk_create\",\n     \"raw_draft_order_complete\",\n     \"draft_order_create\",\n     \"order_lines_create\",\n     \"draft_order_complete\",\n"
        },
        {
          "path": "saleor/tests/e2e/orders/utils/fragments.py",
          "status": "added",
          "diff": "Index: saleor/tests/e2e/orders/utils/fragments.py\n===================================================================\n--- saleor/tests/e2e/orders/utils/fragments.py\t1a8b592 (parent)\n+++ saleor/tests/e2e/orders/utils/fragments.py\te5ff65b (commit)\n@@ -0,0 +1,75 @@\n+ORDER_LINE_FRAGMENT = \"\"\"\n+fragment OrderLine on OrderLine {\n+    id\n+    variant {\n+        id\n+    }\n+    productName\n+    productSku\n+    variantName\n+    translatedVariantName\n+    translatedProductName\n+    productVariantId\n+    isShippingRequired\n+    quantity\n+    quantityFulfilled\n+    unitPrice {\n+        gross {\n+            amount\n+        }\n+        net {\n+            amount\n+        }\n+    }\n+    unitDiscount {\n+        amount\n+    }\n+    unitDiscountValue\n+    unitDiscountReason\n+    unitDiscountType\n+    totalPrice {\n+        gross {\n+            amount\n+        }\n+        net {\n+            amount\n+        }\n+    }\n+    undiscountedUnitPrice{\n+        gross {\n+            amount\n+        }\n+        net {\n+            amount\n+        }\n+    }\n+    undiscountedTotalPrice{\n+        gross {\n+            amount\n+        }\n+        net {\n+            amount\n+        }\n+    }\n+    metadata {\n+        key\n+        value\n+    }\n+    privateMetadata {\n+        key\n+        value\n+    }\n+    taxClass {\n+        id\n+    }\n+    taxClassName\n+    taxRate\n+    taxClassMetadata {\n+        key\n+        value\n+    }\n+    taxClassPrivateMetadata {\n+        key\n+        value\n+    }\n+}\"\"\"\n"
        },
        {
          "path": "saleor/tests/e2e/orders/utils/order_bulk_create.py",
          "status": "added",
          "diff": "Index: saleor/tests/e2e/orders/utils/order_bulk_create.py\n===================================================================\n--- saleor/tests/e2e/orders/utils/order_bulk_create.py\t1a8b592 (parent)\n+++ saleor/tests/e2e/orders/utils/order_bulk_create.py\te5ff65b (commit)\n@@ -0,0 +1,203 @@\n+from saleor.graphql.tests.utils import get_graphql_content\n+\n+from .fragments import ORDER_LINE_FRAGMENT\n+\n+ORDER_BULK_CREATE_MUTATION = (\n+    \"\"\"\n+ mutation OrderBulkCreate(\n+    $orders: [OrderBulkCreateInput!]!,\n+    $errorPolicy: ErrorPolicyEnum,\n+    $stockUpdatePolicy: StockUpdatePolicyEnum\n+) {\n+    orderBulkCreate(\n+        orders: $orders,\n+        errorPolicy: $errorPolicy,\n+        stockUpdatePolicy: $stockUpdatePolicy\n+    ) {\n+        count\n+        results {\n+            order {\n+                id\n+                user {\n+                    id\n+                    email\n+                }\n+                metadata {\n+                    key\n+                    value\n+                }\n+                privateMetadata {\n+                    key\n+                    value\n+                }\n+                lines {\n+                    ...OrderLine\n+                }\n+                billingAddress{\n+                    postalCode\n+                    metadata{\n+                        key\n+                        value\n+                    }\n+                }\n+                shippingAddress{\n+                    postalCode\n+                    metadata{\n+                        key\n+                        value\n+                    }\n+                }\n+                shippingMethodName\n+                shippingTaxClass{\n+                    name\n+                }\n+                shippingTaxClassName\n+                shippingTaxClassMetadata {\n+                    key\n+                    value\n+                }\n+                shippingTaxClassPrivateMetadata {\n+                    key\n+                    value\n+                }\n+                shippingPrice {\n+                    gross {\n+                        amount\n+                    }\n+                    net {\n+                        amount\n+                    }\n+                }\n+                subtotal{\n+                    gross {\n+                        amount\n+                    }\n+                    net {\n+                        amount\n+                    }\n+                }\n+                total{\n+                    gross {\n+                        amount\n+                    }\n+                    net {\n+                        amount\n+                    }\n+                }\n+                undiscountedTotal{\n+                    gross {\n+                        amount\n+                    }\n+                    net {\n+                        amount\n+                    }\n+                }\n+                events {\n+                    message\n+                    user {\n+                        id\n+                    }\n+                    app {\n+                        id\n+                    }\n+                }\n+                weight {\n+                    value\n+                }\n+                externalReference\n+                trackingClientId\n+                displayGrossPrices\n+                channel {\n+                    slug\n+                }\n+                status\n+                created\n+                languageCode\n+                collectionPointName\n+                redirectUrl\n+                origin\n+                fulfillments {\n+                    lines {\n+                        id\n+                        quantity\n+                        orderLine {\n+                            id\n+                        }\n+                    }\n+                    trackingNumber\n+                    fulfillmentOrder\n+                    status\n+                }\n+                transactions {\n+                    id\n+                    pspReference\n+                    message\n+                    name\n+                    authorizedAmount {\n+                        amount\n+                        currency\n+                    }\n+                    canceledAmount{\n+                        currency\n+                        amount\n+                    }\n+                    chargedAmount{\n+                        currency\n+                        amount\n+                    }\n+                    refundedAmount{\n+                        currency\n+                        amount\n+                    }\n+                    events {\n+                        amount {\n+                            amount\n+                        }\n+                        type\n+                    }\n+                }\n+                invoices {\n+                    number\n+                    url\n+                }\n+                discounts {\n+                    type\n+                    valueType\n+                    value\n+                    reason\n+                }\n+                voucher {\n+                    id\n+                    code\n+                }\n+                voucherCode\n+            }\n+            errors {\n+                path\n+                message\n+                code\n+            }\n+        }\n+        errors {\n+            message\n+            code\n+        }\n+    }\n+}\n+\"\"\"\n+    + ORDER_LINE_FRAGMENT\n+)\n+\n+\n+def order_bulk_create(api_client, orders):\n+    variables = {\"orders\": orders}\n+\n+    response = api_client.post_graphql(\n+        ORDER_BULK_CREATE_MUTATION,\n+        variables=variables,\n+    )\n+    content = get_graphql_content(response)\n+\n+    data = content[\"data\"][\"orderBulkCreate\"]\n+\n+    return data\n"
        },
        {
          "path": "saleor/tests/e2e/orders/utils/order_query.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/orders/utils/order_query.py\n===================================================================\n--- saleor/tests/e2e/orders/utils/order_query.py\t1a8b592 (parent)\n+++ saleor/tests/e2e/orders/utils/order_query.py\te5ff65b (commit)\n@@ -1,6 +1,7 @@\n from ...account.utils.fragments import ADDRESS_FRAGMENT\n from ...utils import get_graphql_content\n+from .fragments import ORDER_LINE_FRAGMENT\n \n ORDER_QUERY = (\n     \"\"\"\n query OrderDetails($id: ID!) {\n@@ -58,12 +59,40 @@\n     privateMetadata {\n       key\n       value\n     }\n+    lines {\n+      ...OrderLine\n+    }\n+    subtotal{\n+      gross {\n+          amount\n+      }\n+      net {\n+          amount\n+      }\n+    }\n+    total{\n+      gross {\n+          amount\n+      }\n+      net {\n+          amount\n+      }\n+    }\n+    undiscountedTotal{\n+      gross {\n+          amount\n+      }\n+      net {\n+          amount\n+      }\n+    }\n   }\n }\n \"\"\"\n     + ADDRESS_FRAGMENT\n+    + ORDER_LINE_FRAGMENT\n )\n \n \n def order_query(\n"
        },
        {
          "path": "saleor/tests/e2e/shop/utils/preparing_shop.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/shop/utils/preparing_shop.py\n===================================================================\n--- saleor/tests/e2e/shop/utils/preparing_shop.py\t1a8b592 (parent)\n+++ saleor/tests/e2e/shop/utils/preparing_shop.py\te5ff65b (commit)\n@@ -74,8 +74,9 @@\n             {\n                 \"id\": channel_id,\n                 \"warehouse_id\": warehouse_id,\n                 \"slug\": created_channel[\"slug\"],\n+                \"currency\": created_channel[\"currencyCode\"],\n                 \"shipping_zones\": [],\n                 \"order_settings\": created_channel[\"orderSettings\"],\n                 \"checkout_settings\": created_channel[\"checkoutSettings\"],\n             }\n"
        }
      ]
    },
    {
      "id": "fix-cc-switch",
      "sha": "659af1b19239efec168ffd752bb908f9e93ea65e",
      "parentSha": "6b23d81b4516289fd34fa420eadcafe735c7bb3e",
      "spec": "Implement deferred saving for checkout delivery-method cleanup and price invalidation, and ensure shipping address can be set after switching from click-and-collect (CC) to a standard shipping method.\n\nScope and required changes:\n\n1) Checkout utilities\n- In saleor/checkout/utils.py:\n  - Update clear_delivery_method to accept a save: bool flag and to return a list[str] of updated checkout fields. It must:\n    - Remove any currently set delivery method (shipping method, external shipping method, or collection point) and update related checkout fields accordingly.\n    - When a collection point is cleared, refresh checkout_info.shipping_address from checkout.shipping_address.\n    - Refresh delivery method lists in checkout_info based on the current state.\n    - Build and return the list of updated_fields and always include \"last_change\" in that list. Only perform checkout.save(update_fields=updated_fields) when save is True.\n  - Ensure invalidate_checkout returns a list[str] of fields to update and supports save control (existing behavior) so callers can perform a single combined save.\n\n2) Shipping method validation helper\n- In saleor/graphql/checkout/mutations/utils.py:\n  - Modify update_checkout_shipping_method_if_invalid to return list[str] of updated checkout fields and not save the checkout itself.\n  - Logic: calculate total quantity; if quantity is zero or shipping is not required, clear the delivery method; then validate the current delivery method; if invalid, clear it. Accumulate and return all fields changed by these operations without saving.\n\n3) GraphQL mutations\n- Update the following GraphQL checkout mutations to defer saving and perform one combined checkout.save per operation:\n  - saleor/graphql/checkout/mutations/checkout_add_promo_code.py\n  - saleor/graphql/checkout/mutations/checkout_line_delete.py\n  - saleor/graphql/checkout/mutations/checkout_lines_add.py\n  - saleor/graphql/checkout/mutations/checkout_lines_delete.py\n  - saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\n- For each, capture two sets of update fields:\n  - shipping_update_fields from update_checkout_shipping_method_if_invalid(checkout_info, lines)\n  - invalidate_update_fields from invalidate_checkout(checkout_info, lines, manager, recalculate_discount flag appropriate to the mutation, save=False)\n- Then call checkout.save(update_fields=shipping_update_fields + invalidate_update_fields) exactly once.\n- For checkout_shipping_address_update specifically:\n  - Do not validate/clear shipping method before persisting the new shipping address. First, save the shipping address and refresh checkout_info delivery method lists based on it. Then call update_checkout_shipping_method_if_invalid to collect any shipping-related updates, and include them in the single combined save along with shipping address update fields and price invalidation fields.\n\n4) GraphQL tests (unit/integration)\n- Update tests to reflect the new non-saving behavior in update_checkout_shipping_method_if_invalid and consolidated save:\n  - In saleor/graphql/checkout/tests/test_checkout_price_expiration.py:\n    - Patch invalidate_checkout in each relevant test and assert it is called with save=False.\n    - Adjust variable naming (mocked_invalidate_checkout) and return values accordingly.\n  - In saleor/graphql/checkout/tests/mutations/test_checkout_shipping_address_update.py:\n    - Add a test that sets a CC delivery method, then switches to a standard shipping method (clearing shipping_address), then performs a shipping address update mutation and asserts that the shipping address is now set.\n\n5) E2E layer\n- Add a new E2E test at saleor/tests/e2e/checkout/test_checkout_switch_from_cc_to_standard_delivery_method.py that:\n  - Prepares default shop/channel/warehouse with click-and-collect enabled (LOCAL) and a simple product variant.\n  - Creates a checkout, assigns a collection point as the delivery method, then switches to a standard shipping method and verifies shippingAddress becomes null.\n  - Updates the shipping address, creates a dummy payment for the checkout’s total, and completes the checkout, asserting order status and delivery method correctness.\n- Update saleor/tests/e2e/checkout/utils/checkout_delivery_method_update.py GraphQL selection set to include shippingAddress in the checkout payload so the E2E test can assert on it.\n- Standardize default warehouse address data for E2E to a valid US address:\n  - Change DEFAULT_WAREHOUSE_ADDRESS in saleor/tests/e2e/__init__.py to a US address.\n  - Update saleor/tests/e2e/warehouse/utils/create_warehouse.py to use DEFAULT_WAREHOUSE_ADDRESS when creating a warehouse.\n\nAcceptance criteria:\n- update_checkout_shipping_method_if_invalid never performs a database save; it returns the fields to be saved by the caller.\n- All affected GraphQL mutations perform a single checkout.save with the union of fields from shipping method cleanup and price invalidation.\n- After switching from CC to a standard shipping method, a subsequent shipping address update successfully sets checkout.shipping_address.\n- Unit tests assert invalidate_checkout is called with save=False and pass.\n- New E2E test passes, including assertions around shippingAddress being cleared on switching to standard shipping and then set after address update.\n- No direct changes outside the files listed above are required except where specified.\n",
      "prompt": "Implement deferred saving for checkout delivery method cleanup and price invalidation. Ensure that when a user switches from click-and-collect to a standard shipping method, they can then set a shipping address successfully. Update GraphQL mutations to collect updated fields from shipping-method validation and from price invalidation, and perform a single save per mutation. Adjust tests to assert the new behavior and add an end-to-end test that switches from click-and-collect to standard shipping, updates the shipping address, pays, and completes the checkout. Also update the e2e default warehouse address and include shippingAddress in the delivery method update selection set so the test can assert on it.",
      "supplementalFiles": [
        "saleor/checkout/models.py",
        "saleor/checkout/fetch.py",
        "saleor/checkout/calculations.py",
        "saleor/checkout/complete_checkout.py",
        "saleor/graphql/schema.graphql",
        "saleor/tests/e2e/utils.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/utils.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/utils.py\n===================================================================\n--- saleor/checkout/utils.py\t6b23d81 (parent)\n+++ saleor/checkout/utils.py\t659af1b (commit)\n@@ -1014,9 +1014,11 @@\n         ).applicable_for_click_and_collect_no_quantity_check(lines, channel_id)\n     )\n \n \n-def clear_delivery_method(checkout_info: \"CheckoutInfo\"):\n+def clear_delivery_method(\n+    checkout_info: \"CheckoutInfo\", save: bool = True\n+) -> list[str]:\n     checkout = checkout_info.checkout\n     updated_fields = remove_delivery_method_from_checkout(checkout_info.checkout)\n \n     if \"collection_point_id\" in updated_fields:\n@@ -1030,16 +1032,15 @@\n         lines=checkout_info.lines,\n         shipping_channel_listings=checkout_info.shipping_channel_listings,\n     )\n     if updated_fields:\n-        checkout.save(\n-            update_fields=updated_fields\n-            + [\n-                \"last_change\",\n-            ]\n-        )\n+        updated_fields.append(\"last_change\")\n+        if save:\n+            checkout.save(update_fields=updated_fields)\n \n+    return updated_fields\n \n+\n def is_fully_paid(\n     manager: PluginsManager,\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_add_promo_code.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_add_promo_code.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_add_promo_code.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_add_promo_code.py\t659af1b (commit)\n@@ -113,16 +113,19 @@\n             lines=lines,\n             shipping_channel_listings=shipping_channel_listings,\n         )\n \n-        update_checkout_shipping_method_if_invalid(checkout_info, lines)\n-        invalidate_checkout(\n+        shipping_update_fields = update_checkout_shipping_method_if_invalid(\n+            checkout_info, lines\n+        )\n+        invalidate_update_fields = invalidate_checkout(\n             checkout_info,\n             lines,\n             manager,\n             recalculate_discount=False,\n-            save=True,\n+            save=False,\n         )\n+        checkout.save(update_fields=shipping_update_fields + invalidate_update_fields)\n         call_checkout_info_event(\n             manager=manager,\n             event_name=WebhookEventAsyncType.CHECKOUT_UPDATED,\n             checkout_info=checkout_info,\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_line_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_line_delete.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_line_delete.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_line_delete.py\t659af1b (commit)\n@@ -80,10 +80,15 @@\n \n         manager = get_plugin_manager_promise(info.context).get()\n         lines, _ = fetch_checkout_lines(checkout)\n         checkout_info = fetch_checkout_info(checkout, lines, manager)\n-        update_checkout_shipping_method_if_invalid(checkout_info, lines)\n-        invalidate_checkout(checkout_info, lines, manager, save=True)\n+        shipping_update_fields = update_checkout_shipping_method_if_invalid(\n+            checkout_info, lines\n+        )\n+        invalidate_update_fields = invalidate_checkout(\n+            checkout_info, lines, manager, save=False\n+        )\n+        checkout.save(update_fields=shipping_update_fields + invalidate_update_fields)\n         call_checkout_info_event(\n             manager,\n             event_name=WebhookEventAsyncType.CHECKOUT_UPDATED,\n             checkout_info=checkout_info,\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_lines_add.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_lines_add.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_lines_add.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_lines_add.py\t659af1b (commit)\n@@ -227,10 +227,15 @@\n             checkout_info,\n         )\n \n         update_checkout_external_shipping_method_if_invalid(checkout_info, lines)\n-        update_checkout_shipping_method_if_invalid(checkout_info, lines)\n-        invalidate_checkout(checkout_info, lines, manager, save=True)\n+        shipping_update_fields = update_checkout_shipping_method_if_invalid(\n+            checkout_info, lines\n+        )\n+        invalidate_update_fields = invalidate_checkout(\n+            checkout_info, lines, manager, save=False\n+        )\n+        checkout.save(update_fields=shipping_update_fields + invalidate_update_fields)\n         call_checkout_info_event(\n             manager,\n             event_name=WebhookEventAsyncType.CHECKOUT_UPDATED,\n             checkout_info=checkout_info,\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_lines_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_lines_delete.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_lines_delete.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_lines_delete.py\t659af1b (commit)\n@@ -99,10 +99,15 @@\n         lines, _ = fetch_checkout_lines(checkout)\n \n         manager = get_plugin_manager_promise(info.context).get()\n         checkout_info = fetch_checkout_info(checkout, lines, manager)\n-        update_checkout_shipping_method_if_invalid(checkout_info, lines)\n-        invalidate_checkout(checkout_info, lines, manager, save=True)\n+        shipping_update_fields = update_checkout_shipping_method_if_invalid(\n+            checkout_info, lines\n+        )\n+        invalidate_update_fields = invalidate_checkout(\n+            checkout_info, lines, manager, save=False\n+        )\n+        checkout.save(update_fields=shipping_update_fields + invalidate_update_fields)\n         call_checkout_info_event(\n             manager,\n             event_name=WebhookEventAsyncType.CHECKOUT_UPDATED,\n             checkout_info=checkout_info,\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_shipping_address_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/mutations/checkout_shipping_address_update.py\t659af1b (commit)\n@@ -194,10 +194,8 @@\n                 checkout_info.channel.slug,\n                 checkout_info.get_delivery_method_info(),\n             )\n \n-        update_checkout_shipping_method_if_invalid(checkout_info, lines)\n-\n         shipping_address_updated_fields = []\n         with traced_atomic_transaction():\n             shipping_address_instance.save()\n             shipping_address_updated_fields = change_shipping_address_in_checkout(\n@@ -206,14 +204,20 @@\n                 save_address,\n                 lines,\n                 shipping_channel_listings,\n             )\n+\n+        shipping_update_fields = update_checkout_shipping_method_if_invalid(\n+            checkout_info, lines\n+        )\n+\n         invalidate_prices_updated_fields = invalidate_checkout(\n             checkout_info, lines, manager, save=False\n         )\n         checkout.save(\n             update_fields=shipping_address_updated_fields\n             + invalidate_prices_updated_fields\n+            + shipping_update_fields\n         )\n \n         call_checkout_info_event(\n             manager,\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/utils.py\n===================================================================\n--- saleor/graphql/checkout/mutations/utils.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/mutations/utils.py\t659af1b (commit)\n@@ -111,24 +111,31 @@\n \n \n def update_checkout_shipping_method_if_invalid(\n     checkout_info: \"CheckoutInfo\", lines: list[CheckoutLineInfo]\n-):\n+) -> list[str]:\n+    \"\"\"Check if current shipping method is valid and clean it if not.\n+\n+    The method is not saving the applied changes on checkout.\n+    \"\"\"\n     quantity = calculate_checkout_quantity(lines)\n+    update_fields = []\n \n     # remove shipping method when empty checkout\n     if quantity == 0 or not is_shipping_required(lines):\n-        clear_delivery_method(checkout_info)\n+        update_fields = clear_delivery_method(checkout_info)\n \n     is_valid = clean_delivery_method(\n         checkout_info=checkout_info,\n         method=checkout_info.get_delivery_method_info().delivery_method,\n     )\n \n     if not is_valid:\n-        clear_delivery_method(checkout_info)\n+        update_fields = clear_delivery_method(checkout_info)\n \n+    return update_fields\n \n+\n def get_variants_and_total_quantities(\n     variants: list[ProductVariant],\n     lines_data: Iterable[CheckoutLineData],\n     quantity_to_update_check=False,\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_shipping_address_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_shipping_address_update.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_shipping_address_update.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_shipping_address_update.py\t659af1b (commit)\n@@ -1322,4 +1322,44 @@\n     checkout.refresh_from_db()\n     assert_address_data(checkout.shipping_address, graphql_address_data)\n     assert checkout.save_shipping_address is True\n     assert checkout.save_billing_address is False\n+\n+\n+def test_checkout_shipping_address_update_when_switching_from_cc(\n+    checkout_with_items,\n+    app_api_client,\n+    graphql_address_data_skipped_validation,\n+    permission_handle_checkouts,\n+    shipping_method,\n+    address,\n+):\n+    # given\n+    checkout = checkout_with_items\n+    address_data = graphql_address_data_skipped_validation\n+    # after switching for cc to standard shipping method - the shipping method is set\n+    # and the shipping address is cleared\n+    checkout.shipping_method = shipping_method\n+    checkout.billing_address = address\n+    checkout.shipping_address = None\n+    checkout.save(\n+        update_fields=[\"shipping_method\", \"billing_address\", \"shipping_address\"]\n+    )\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(checkout_with_items),\n+        \"shippingAddress\": address_data,\n+    }\n+\n+    # when\n+    response = app_api_client.post_graphql(\n+        MUTATION_CHECKOUT_SHIPPING_ADDRESS_UPDATE,\n+        variables,\n+        permissions=[permission_handle_checkouts],\n+    )\n+    content = get_graphql_content(response)\n+\n+    # then\n+    data = content[\"data\"][\"checkoutShippingAddressUpdate\"]\n+    assert not data[\"errors\"]\n+    checkout.refresh_from_db()\n+    assert checkout.shipping_address\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkout_price_expiration.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkout_price_expiration.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkout_price_expiration.py\t6b23d81 (parent)\n+++ saleor/graphql/checkout/tests/test_checkout_price_expiration.py\t659af1b (commit)\n@@ -24,15 +24,16 @@\n \n \n @patch(\"saleor.graphql.checkout.mutations.checkout_lines_add.invalidate_checkout\")\n def test_checkout_lines_add_invalidate_prices(\n-    mocked_function,\n+    mocked_invalidate_checkout,\n     api_client,\n     checkout_with_items,\n     stock,\n ):\n     # given\n     manager = get_plugins_manager(allow_replica=False)\n+    mocked_invalidate_checkout.return_value = []\n     query = ADD_CHECKOUT_LINES\n     variables = {\n         \"checkoutId\": graphene.Node.to_global_id(\"Checkout\", checkout_with_items.pk),\n         \"line\": {\n@@ -50,9 +51,11 @@\n     assert not response[\"data\"][\"checkoutLinesAdd\"][\"errors\"]\n     checkout_with_items.refresh_from_db()\n     lines, _ = fetch_checkout_lines(checkout_with_items)\n     checkout_info = fetch_checkout_info(checkout_with_items, lines, manager)\n-    mocked_function.assert_called_once_with(checkout_info, lines, mock.ANY, save=True)\n+    mocked_invalidate_checkout.assert_called_once_with(\n+        checkout_info, lines, mock.ANY, save=False\n+    )\n \n \n UPDATE_CHECKOUT_LINES = \"\"\"\n mutation updateCheckoutLines($token: UUID!, $line: CheckoutLineUpdateInput!) {\n@@ -67,15 +70,17 @@\n \n \n @patch(\"saleor.graphql.checkout.mutations.checkout_lines_add.invalidate_checkout\")\n def test_checkout_lines_update_invalidate_prices(\n-    mocked_function,\n+    mocked_invalidate_checkout,\n     api_client,\n     checkout_with_items,\n     stock,\n ):\n     # given\n     manager = get_plugins_manager(allow_replica=False)\n+    mocked_invalidate_checkout.return_value = []\n+\n     query = UPDATE_CHECKOUT_LINES\n     variables = {\n         \"token\": checkout_with_items.token,\n         \"line\": {\n@@ -86,16 +91,19 @@\n         },\n     }\n \n     # when\n-    response = get_graphql_content(api_client.post_graphql(query, variables))\n+    content = api_client.post_graphql(query, variables)\n+    response = get_graphql_content(content)\n \n     # then\n     assert not response[\"data\"][\"checkoutLinesUpdate\"][\"errors\"]\n     checkout_with_items.refresh_from_db()\n     lines, _ = fetch_checkout_lines(checkout_with_items)\n     checkout_info = fetch_checkout_info(checkout_with_items, lines, manager)\n-    mocked_function.assert_called_once_with(checkout_info, lines, mock.ANY, save=True)\n+    mocked_invalidate_checkout.assert_called_once_with(\n+        checkout_info, lines, mock.ANY, save=False\n+    )\n \n \n DELETE_CHECKOUT_LINES = \"\"\"\n mutation deleteCheckoutLines($token: UUID!, $lineId: ID!){\n@@ -110,14 +118,15 @@\n \n \n @patch(\"saleor.graphql.checkout.mutations.checkout_lines_delete.invalidate_checkout\")\n def test_checkout_lines_delete_invalidate_prices(\n-    mocked_function,\n+    mocked_invalidate_checkout,\n     api_client,\n     checkout_with_items,\n ):\n     # given\n     manager = get_plugins_manager(allow_replica=False)\n+    mocked_invalidate_checkout.return_value = []\n     query = DELETE_CHECKOUT_LINES\n     variables = {\n         \"token\": checkout_with_items.token,\n         \"lineId\": graphene.Node.to_global_id(\n@@ -132,9 +141,11 @@\n     assert not response[\"data\"][\"checkoutLinesDelete\"][\"errors\"]\n     checkout_with_items.refresh_from_db()\n     lines, _ = fetch_checkout_lines(checkout_with_items)\n     checkout_info = fetch_checkout_info(checkout_with_items, lines, manager)\n-    mocked_function.assert_called_once_with(checkout_info, lines, mock.ANY, save=True)\n+    mocked_invalidate_checkout.assert_called_once_with(\n+        checkout_info, lines, mock.ANY, save=False\n+    )\n \n \n DELETE_CHECKOUT_LINE = \"\"\"\n mutation deleteCheckoutLine($token: UUID!, $lineId: ID!){\n@@ -149,14 +160,15 @@\n \n \n @patch(\"saleor.graphql.checkout.mutations.checkout_line_delete.invalidate_checkout\")\n def test_checkout_line_delete_invalidate_prices(\n-    mocked_function,\n+    mocked_invalidate_checkout,\n     api_client,\n     checkout_with_items,\n ):\n     # given\n     manager = get_plugins_manager(allow_replica=False)\n+    mocked_invalidate_checkout.return_value = []\n     query = DELETE_CHECKOUT_LINE\n     variables = {\n         \"token\": checkout_with_items.token,\n         \"lineId\": graphene.Node.to_global_id(\n@@ -171,9 +183,11 @@\n     assert not response[\"data\"][\"checkoutLineDelete\"][\"errors\"]\n     checkout_with_items.refresh_from_db()\n     lines, _ = fetch_checkout_lines(checkout_with_items)\n     checkout_info = fetch_checkout_info(checkout_with_items, lines, manager)\n-    mocked_function.assert_called_once_with(checkout_info, lines, mock.ANY, save=True)\n+    mocked_invalidate_checkout.assert_called_once_with(\n+        checkout_info, lines, mock.ANY, save=False\n+    )\n \n \n UPDATE_CHECKOUT_SHIPPING_ADDRESS = \"\"\"\n mutation UpdateCheckoutShippingAddress($token: UUID!, $address: AddressInput!) {\n@@ -191,22 +205,23 @@\n     \"saleor.graphql.checkout.mutations.checkout_shipping_address_update\"\n     \".invalidate_checkout\"\n )\n def test_checkout_shipping_address_update_invalidate_prices(\n-    mocked_function,\n+    mocked_invalidate_checkout,\n     api_client,\n     checkout_with_items,\n     graphql_address_data,\n     plugins_manager,\n ):\n     # given\n     manager = get_plugins_manager(allow_replica=False)\n+    mocked_invalidate_checkout.return_value = []\n     query = UPDATE_CHECKOUT_SHIPPING_ADDRESS\n     variables = {\n         \"token\": checkout_with_items.token,\n         \"address\": graphql_address_data,\n     }\n-    mocked_function.return_value = []\n+    mocked_invalidate_checkout.return_value = []\n \n     # when\n     response = get_graphql_content(api_client.post_graphql(query, variables))\n \n@@ -214,9 +229,11 @@\n     assert not response[\"data\"][\"checkoutShippingAddressUpdate\"][\"errors\"]\n     checkout_with_items.refresh_from_db()\n     lines, _ = fetch_checkout_lines(checkout_with_items)\n     checkout_info = fetch_checkout_info(checkout_with_items, lines, manager)\n-    mocked_function.assert_called_once_with(checkout_info, lines, mock.ANY, save=False)\n+    mocked_invalidate_checkout.assert_called_once_with(\n+        checkout_info, lines, mock.ANY, save=False\n+    )\n \n \n UPDATE_CHECKOUT_BILLING_ADDRESS = \"\"\"\n mutation UpdateCheckoutBillingAddress($token: UUID!, $address: AddressInput!) {\n@@ -329,8 +346,9 @@\n ):\n     checkout = checkout_with_shipping_address_for_cc\n     checkout.price_expiration = timezone.now()\n     checkout.save(update_fields=[\"price_expiration\"])\n+\n     query = UPDATE_CHECKOUT_DELIVERY_METHOD\n     variables = {\n         \"token\": checkout.token,\n         \"deliveryMethodId\": graphene.Node.to_global_id(\n"
        },
        {
          "path": "saleor/tests/e2e/__init__.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/__init__.py\n===================================================================\n--- saleor/tests/e2e/__init__.py\t6b23d81 (parent)\n+++ saleor/tests/e2e/__init__.py\t659af1b (commit)\n@@ -14,15 +14,15 @@\n DEFAULT_WAREHOUSE_ADDRESS = {\n     \"firstName\": \"Saleor\",\n     \"lastName\": \"Mirumee\",\n     \"companyName\": \"Mirumee Software\",\n-    \"streetAddress1\": \"Tęczowa 7\",\n+    \"streetAddress1\": \"2137 Cantebury Drive\",\n     \"streetAddress2\": \"\",\n-    \"postalCode\": \"53-601\",\n-    \"country\": \"PL\",\n-    \"city\": \"Wrocław\",\n-    \"countryArea\": \"\",\n-    \"phone\": \"+48321321888\",\n+    \"postalCode\": \"10013\",\n+    \"country\": \"US\",\n+    \"city\": \"New York\",\n+    \"countryArea\": \"NY\",\n+    \"phone\": \"+19179920814\",\n }\n \n ADDRESS_DE = {\n     \"firstName\": \"John\",\n"
        },
        {
          "path": "saleor/tests/e2e/checkout/test_checkout_switch_from_cc_to_standard_delivery_method.py",
          "status": "added",
          "diff": "Index: saleor/tests/e2e/checkout/test_checkout_switch_from_cc_to_standard_delivery_method.py\n===================================================================\n--- saleor/tests/e2e/checkout/test_checkout_switch_from_cc_to_standard_delivery_method.py\t6b23d81 (parent)\n+++ saleor/tests/e2e/checkout/test_checkout_switch_from_cc_to_standard_delivery_method.py\t659af1b (commit)\n@@ -0,0 +1,119 @@\n+import pytest\n+\n+from ..product.utils.preparing_product import prepare_product\n+from ..shop.utils.preparing_shop import prepare_default_shop\n+from ..utils import assign_permissions\n+from ..warehouse.utils import update_warehouse\n+from .utils import (\n+    checkout_complete,\n+    checkout_create,\n+    checkout_delivery_method_update,\n+    checkout_dummy_payment_create,\n+    checkout_shipping_address_update,\n+)\n+\n+\n+@pytest.mark.e2e\n+def test_checkout_switch_from_cc_to_standard_delivery_method_CORE_0133(\n+    e2e_staff_api_client,\n+    e2e_logged_api_client,\n+    permission_manage_product_types_and_attributes,\n+    shop_permissions,\n+):\n+    # Before\n+    permissions = [\n+        permission_manage_product_types_and_attributes,\n+        *shop_permissions,\n+    ]\n+\n+    assign_permissions(e2e_staff_api_client, permissions)\n+\n+    shop_data = prepare_default_shop(e2e_staff_api_client)\n+    channel_id = shop_data[\"channel\"][\"id\"]\n+    channel_slug = shop_data[\"channel\"][\"slug\"]\n+    warehouse_id = shop_data[\"warehouse\"][\"id\"]\n+    shipping_method_id = shop_data[\"shipping_method\"][\"id\"]\n+    update_warehouse(\n+        e2e_staff_api_client,\n+        warehouse_id,\n+        is_private=False,\n+        click_and_collect_option=\"LOCAL\",\n+    )\n+    variant_price = 10\n+\n+    (\n+        _product_id,\n+        product_variant_id,\n+        _product_variant_price,\n+    ) = prepare_product(\n+        e2e_staff_api_client,\n+        warehouse_id,\n+        channel_id,\n+        variant_price,\n+    )\n+\n+    # Step 1 - Create checkout.\n+    lines = [\n+        {\"variantId\": product_variant_id, \"quantity\": 1},\n+    ]\n+    checkout_data = checkout_create(\n+        e2e_logged_api_client,\n+        lines,\n+        channel_slug,\n+        email=None,\n+    )\n+    checkout_id = checkout_data[\"id\"]\n+\n+    expected_email = e2e_logged_api_client.user.email\n+    assert checkout_data[\"email\"] == expected_email\n+    assert checkout_data[\"user\"][\"email\"] == expected_email\n+    assert checkout_data[\"isShippingRequired\"] is True\n+    checkout_shipping_address = checkout_data[\"shippingAddress\"]\n+\n+    collection_point = checkout_data[\"availableCollectionPoints\"][0]\n+    assert collection_point[\"id\"] == warehouse_id\n+    assert collection_point[\"isPrivate\"] is False\n+    assert collection_point[\"clickAndCollectOption\"] == \"LOCAL\"\n+\n+    # Step 2 - Assign CC as a delivery method\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_logged_api_client,\n+        checkout_id,\n+        collection_point[\"id\"],\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == warehouse_id\n+    # Ensure the address has been changed\n+    assert (\n+        checkout_data[\"shippingAddress\"][\"streetAddress1\"]\n+        != checkout_shipping_address[\"streetAddress1\"]\n+    )\n+\n+    # Step 3 - Change the delivery method to standard shipping method\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_logged_api_client,\n+        checkout_id,\n+        shipping_method_id,\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n+    assert checkout_data[\"shippingAddress\"] is None\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+\n+    # Step 4 - Update shipping address\n+    checkout_data = checkout_shipping_address_update(e2e_logged_api_client, checkout_id)\n+    assert checkout_data[\"shippingAddress\"]\n+\n+    # Step 5 - Create payment\n+    checkout_dummy_payment_create(\n+        e2e_logged_api_client,\n+        checkout_id,\n+        total_gross_amount,\n+    )\n+\n+    # Step 6 - Complete the checkout\n+    order_data = checkout_complete(\n+        e2e_logged_api_client,\n+        checkout_id,\n+    )\n+    assert order_data[\"status\"] == \"UNFULFILLED\"\n+    assert order_data[\"total\"][\"gross\"][\"amount\"] == total_gross_amount\n+    assert order_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n"
        },
        {
          "path": "saleor/tests/e2e/checkout/utils/checkout_delivery_method_update.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/checkout/utils/checkout_delivery_method_update.py\n===================================================================\n--- saleor/tests/e2e/checkout/utils/checkout_delivery_method_update.py\t6b23d81 (parent)\n+++ saleor/tests/e2e/checkout/utils/checkout_delivery_method_update.py\t659af1b (commit)\n@@ -49,8 +49,11 @@\n         tax {\n           amount\n         }\n       }\n+      shippingAddress {\n+        ...Address\n+      }\n       deliveryMethod {\n         ... on ShippingMethod {\n           id\n           price {\n"
        },
        {
          "path": "saleor/tests/e2e/warehouse/utils/create_warehouse.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/warehouse/utils/create_warehouse.py\n===================================================================\n--- saleor/tests/e2e/warehouse/utils/create_warehouse.py\t6b23d81 (parent)\n+++ saleor/tests/e2e/warehouse/utils/create_warehouse.py\t659af1b (commit)\n@@ -1,7 +1,7 @@\n import uuid\n \n-from ... import DEFAULT_ADDRESS\n+from ... import DEFAULT_WAREHOUSE_ADDRESS\n from ...utils import get_graphql_content\n \n WAREHOUSE_CREATE_MUTATION = \"\"\"\n mutation createWarehouse($input: WarehouseCreateInput!) {\n@@ -36,9 +36,9 @@\n def create_warehouse(\n     staff_api_client,\n     name=\"Test warehouse\",\n     slug=None,\n-    address=DEFAULT_ADDRESS,\n+    address=DEFAULT_WAREHOUSE_ADDRESS,\n ):\n     if slug is None:\n         slug = f\"warehouse_slug_{uuid.uuid4()}\"\n     variables = {\n"
        }
      ]
    },
    {
      "id": "fix-checkout-race",
      "sha": "909d452917cdd370b63a970aa6e596285cca71b3",
      "parentSha": "ec9c4bac76380ca77ee6d4751ea586c6ad7af847",
      "spec": "Implement race-safe checkout updates and error handling across checkout flows.\n\n1) Add a safe, locked update method on the Checkout model\n- File: saleor/checkout/models.py\n- Add method Checkout.safe_update(update_fields: list[str]) that:\n  - Uses allow_writer() (from saleor/core/db/connection.py) and transaction.atomic().\n  - Locks the checkout row via Checkout.objects.select_for_update().filter(pk=self.pk).only(\"pk\").first().\n  - If not found, raise Checkout.DoesNotExist(\"Checkout does not exist. Unable to update.\").\n  - Otherwise, call self.save(update_fields=update_fields).\n- Import transaction from django.db at top of file.\n\n2) Use safe_update instead of direct save in selected places\n- File: saleor/checkout/calculations.py\n  - In recalculate_discounts(...), replace checkout.save(update_fields=[\"discount_expiration\"], using=...) with checkout.safe_update(update_fields=[\"discount_expiration\"]). Remove the using kwarg.\n- File: saleor/checkout/complete_checkout.py\n  - In _prepare_checkout(...), change checkout.save(update_fields=to_update) to checkout.safe_update(update_fields=to_update).\n  - Remove the manager parameter from the _prepare_checkout function signature and calls. Update:\n    - def _prepare_checkout(checkout_info, lines, redirect_url)\n    - In _prepare_checkout_with_transactions and _prepare_checkout_with_payment, drop the manager=manager argument when invoking _prepare_checkout.\n- File: saleor/checkout/utils.py\n  - In clear_delivery_method(...), when save is True, replace checkout.save(update_fields=updated_fields) with checkout.safe_update(updated_fields).\n\n3) Avoid DatabaseError during recalculation if checkout disappears mid-flight\n- File: saleor/checkout/calculations.py\n  - In _fetch_checkout_prices_if_expired(...), wrap recalculate_discounts(...) in try/except Checkout.DoesNotExist. If caught, return (checkout_info, lines) immediately without saving.\n\n4) Improve locking and race handling in order creation and completion\n- File: saleor/checkout/complete_checkout.py\n  - create_order_from_checkout(...): Before increasing voucher usage (when voucher is present), capture checkout_pk = checkout_info.checkout.pk and, inside a transaction.atomic() block, select_for_update the Checkout by pk. If the row doesn't exist, return Order.objects.get_by_checkout_token(checkout_pk). Otherwise call _increase_voucher_code_usage_value(...). Keep the subsequent transaction that locks the checkout again for line fetching and order creation.\n  - complete_checkout_pre_payment_part(...): Around the call to _prepare_checkout_with_payment(...), add an except Checkout.DoesNotExist block that loads the order by checkout token (Order.objects.get_by_checkout_token(checkout_info.checkout.token)) and returns it early. The outer caller should tolerate receiving an Order when the checkout vanished.\n  - complete_checkout_with_transaction(...): Wrap the flow and add an except Checkout.DoesNotExist block that returns the order found by checkout token (as the function already returns an Order | None).\n\n5) GraphQL mutation should return the order if checkout no longer exists during address validation\n- File: saleor/graphql/checkout/mutations/checkout_complete.py\n  - Change import to also import models from ....checkout (from ....checkout import AddressType, models).\n  - Wrap cls.validate_checkout_addresses(checkout_info, lines) in try/except models.Checkout.DoesNotExist as e:\n    - Attempt to fetch order by checkout token (order_models.Order.objects.get_by_checkout_token(checkout_info.checkout.token)). If present, return a successful CheckoutComplete response containing that order (as SyncWebhookControlContext) with confirmation_needed=False and empty confirmation_data.\n    - If no order, raise a ValidationError with code CheckoutErrorCode.NOT_FOUND.\n\n6) Update benchmark test expectations and add coverage\n- File: saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\n  - Increment expected django_assert_num_queries by +3 in the listed tests:\n    - test_create_checkout_with_reservations: 87 -> 90 (both places)\n    - test_create_checkout_with_order_promotion: 93 -> 96\n    - test_update_checkout_lines_with_reservations: 109 -> 112 (both places)\n    - test_add_checkout_lines_with_reservations: 106 -> 109 (both places)\n    - test_add_checkout_lines_catalogue_discount_applies: 97 -> 100\n    - test_add_checkout_lines_multiple_catalogue_discount_applies: 97 -> 100\n    - test_add_checkout_lines_order_discount_applies: 103 -> 106\n    - test_add_checkout_lines_gift_discount_applies: 135 -> 138\n\n- File: saleor/checkout/tests/test_calculations.py\n  - Add test test_fetch_checkout_data_checkout_deleted_during_discount_recalculation which sets price_expiration to force recalculation, patches recalculate_discounts to delete the checkout, calls fetch_checkout_data, ensures checkout refresh raises DoesNotExist, and that returned checkout_info and lines_info are sensible (no crash and totals available).\n\n- File: saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\n  - Add tests covering:\n    - validate_checkout_addresses raising Checkout.DoesNotExist returns NOT_FOUND error when no order exists.\n    - Same error condition but returns the existing order if checkout_token is present on an order.\n\n- File: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\n  - Add test test_checkout_complete_race_condition_on_preparing_checkout to simulate checkout deletion during clean_checkout_shipping via race_condition.RunAfter and verify mutation returns the created order with no errors.\n\nBehavioral outcomes:\n- Concurrent deletion/conversion of a checkout during recalculation or completion should not raise DatabaseError; instead, the system skips persisting recalculated values and/or returns the existing order.\n- All mutations and paths that save Checkout via update_fields use a row-locked safe update that raises DoesNotExist if the checkout disappeared, preventing DatabaseError on stale instances.",
      "prompt": "Harden checkout completion and price recalculation against race conditions where a checkout can be deleted or converted to an order concurrently. Introduce a safe update mechanism for checkout updates to prevent database errors when the checkout no longer exists, and ensure that GraphQL checkoutComplete returns the already-created order if the checkout disappears mid-process. Also make recalculation flows tolerant to disappearing checkouts. Update relevant tests and query count assertions accordingly.",
      "supplementalFiles": [
        "saleor/core/db/connection.py",
        "saleor/checkout/lock_objects.py",
        "saleor/order/models.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/calculations.py\n===================================================================\n--- saleor/checkout/calculations.py\tec9c4ba (parent)\n+++ saleor/checkout/calculations.py\t909d452 (commit)\n@@ -389,14 +389,18 @@\n     tax_app_identifier = get_tax_app_identifier_for_checkout(\n         checkout_info, database_connection_name\n     )\n \n-    recalculate_discounts(\n-        checkout_info,\n-        lines,\n-        database_connection_name=database_connection_name,\n-        force_update=force_update,\n-    )\n+    try:\n+        recalculate_discounts(\n+            checkout_info,\n+            lines,\n+            database_connection_name=database_connection_name,\n+            force_update=force_update,\n+        )\n+    except Checkout.DoesNotExist:\n+        # Checkout was removed or converted to a order. Return data without saving.\n+        return checkout_info, lines\n \n     checkout.tax_error = None\n \n     no_need_to_calculate_taxes = not prices_entered_with_tax and not should_charge_tax\n@@ -528,11 +532,10 @@\n         )\n     else:\n         checkout.discount_expiration = timezone.now() + settings.CHECKOUT_PRICES_TTL\n \n-    checkout.save(\n+    checkout.safe_update(\n         update_fields=[\"discount_expiration\"],\n-        using=settings.DATABASE_CONNECTION_DEFAULT_NAME,\n     )\n \n     return checkout_info, lines\n \n"
        },
        {
          "path": "saleor/checkout/complete_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/complete_checkout.py\n===================================================================\n--- saleor/checkout/complete_checkout.py\tec9c4ba (parent)\n+++ saleor/checkout/complete_checkout.py\t909d452 (commit)\n@@ -916,9 +916,8 @@\n     return order\n \n \n def _prepare_checkout(\n-    manager: \"PluginsManager\",\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n     redirect_url,\n ):\n@@ -948,9 +947,9 @@\n         to_update.append(\"redirect_url\")\n \n     if to_update:\n         to_update.append(\"last_change\")\n-        checkout.save(update_fields=to_update)\n+        checkout.safe_update(update_fields=to_update)\n \n \n def _prepare_checkout_with_transactions(\n     manager: \"PluginsManager\",\n@@ -982,9 +981,8 @@\n             }\n         )\n     _validate_gift_cards(checkout_info.checkout)\n     _prepare_checkout(\n-        manager=manager,\n         checkout_info=checkout_info,\n         lines=lines,\n         redirect_url=redirect_url,\n     )\n@@ -1012,9 +1010,8 @@\n         CheckoutErrorCode,\n         last_payment=payment,\n     )\n     _prepare_checkout(\n-        manager=manager,\n         checkout_info=checkout_info,\n         lines=lines,\n         redirect_url=redirect_url,\n     )\n@@ -1122,8 +1119,11 @@\n             lines=lines,\n             redirect_url=redirect_url,\n             payment=payment,\n         )\n+    except Checkout.DoesNotExist:\n+        order = Order.objects.get_by_checkout_token(checkout_info.checkout.token)\n+        return order\n     except ValidationError as exc:\n         _complete_checkout_fail_handler(checkout_info, manager, payment=payment)\n         raise exc\n \n@@ -1596,15 +1596,21 @@\n     :raises: InsufficientStock, GiftCardNotApplicable\n     \"\"\"\n \n     code = None\n+    checkout_pk = checkout_info.checkout.pk\n \n     if voucher := checkout_info.voucher:\n         with transaction.atomic():\n+            checkout = (\n+                Checkout.objects.select_for_update().filter(pk=checkout_pk).first()\n+            )\n+            if not checkout:\n+                order = Order.objects.get_by_checkout_token(checkout_pk)\n+                return order\n             code = _increase_voucher_code_usage_value(checkout_info=checkout_info)\n \n     with transaction.atomic():\n-        checkout_pk = checkout_info.checkout.pk\n         checkout = Checkout.objects.select_for_update().filter(pk=checkout_pk).first()\n         if not checkout:\n             order = Order.objects.get_by_checkout_token(checkout_pk)\n             return order\n@@ -1787,8 +1793,11 @@\n             metadata_list=metadata_list,\n             private_metadata_list=private_metadata_list,\n             is_automatic_completion=is_automatic_completion,\n         )\n+    except Checkout.DoesNotExist:\n+        order = Order.objects.get_by_checkout_token(checkout_info.checkout.token)\n+        return order\n     except NotApplicable as e:\n         raise ValidationError(\n             {\n                 \"voucher_code\": ValidationError(\n"
        },
        {
          "path": "saleor/checkout/models.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/models.py\n===================================================================\n--- saleor/checkout/models.py\tec9c4ba (parent)\n+++ saleor/checkout/models.py\t909d452 (commit)\n@@ -8,9 +8,9 @@\n \n from django.conf import settings\n from django.contrib.postgres.indexes import BTreeIndex\n from django.core.validators import MinValueValidator\n-from django.db import models\n+from django.db import models, transaction\n from django.utils import timezone\n from django.utils.encoding import smart_str\n from django_countries.fields import Country, CountryField\n from prices import Money\n@@ -248,8 +248,33 @@\n \n     def __iter__(self):\n         return iter(self.lines.all())\n \n+    def safe_update(self, update_fields: list[str]) -> None:\n+        \"\"\"Safely update the checkout instance.\n+\n+        This method locks the checkout row in the database to prevent concurrent updates.\n+        In case the checkout does not exist, it raises a CheckoutDoesNotExist exception.\n+\n+        It prevents the DatabaseError that occurs in case save with update_fields is\n+        called on a deleted checkout instance.\n+        \"\"\"\n+        from ..core.db.connection import allow_writer\n+\n+        with allow_writer():\n+            with transaction.atomic():\n+                checkout = (\n+                    Checkout.objects.select_for_update()\n+                    .filter(pk=self.pk)\n+                    .only(\"pk\")\n+                    .first()\n+                )\n+                if not checkout:\n+                    raise Checkout.DoesNotExist(\n+                        \"Checkout does not exist. Unable to update.\"\n+                    )\n+                self.save(update_fields=update_fields)\n+\n     def get_customer_email(self) -> str | None:\n         if self.email:\n             return self.email\n         if self.user:\n"
        },
        {
          "path": "saleor/checkout/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_calculations.py\n===================================================================\n--- saleor/checkout/tests/test_calculations.py\tec9c4ba (parent)\n+++ saleor/checkout/tests/test_calculations.py\t909d452 (commit)\n@@ -1495,4 +1495,39 @@\n     assert checkout.last_change.isoformat() == freeze_time_str\n     assert checkout.email == expected_email\n     for old_line, new_line in zip(lines, checkout.lines.all(), strict=True):\n         assert old_line.quantity + 1 == new_line.quantity\n+\n+\n+def test_fetch_checkout_data_checkout_deleted_during_discount_recalculation(\n+    checkout_with_item_and_order_discount,\n+):\n+    # given\n+    checkout = checkout_with_item_and_order_discount\n+    checkout.price_expiration = timezone.now()\n+    checkout.save(update_fields=[\"price_expiration\"])\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines_info, _ = fetch_checkout_lines(checkout)\n+    fetch_kwargs = {\n+        \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n+        \"manager\": manager,\n+        \"lines\": lines_info,\n+    }\n+\n+    # when\n+    def delete_checkout(*args, **kwargs):\n+        Checkout.objects.filter(pk=checkout.pk).delete()\n+\n+    with patch(\n+        \"saleor.checkout.calculations.recalculate_discounts\",\n+        side_effect=delete_checkout,\n+    ):\n+        result_checkout_info, result_lines_info = fetch_checkout_data(**fetch_kwargs)\n+\n+    # then\n+    # Check if checkout was deleted.\n+    with pytest.raises(Checkout.DoesNotExist):\n+        checkout.refresh_from_db()\n+\n+    assert result_checkout_info.checkout.total is not None\n+    assert result_lines_info\n"
        },
        {
          "path": "saleor/checkout/utils.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/utils.py\n===================================================================\n--- saleor/checkout/utils.py\tec9c4ba (parent)\n+++ saleor/checkout/utils.py\t909d452 (commit)\n@@ -1061,9 +1061,9 @@\n     )\n     if updated_fields:\n         updated_fields.append(\"last_change\")\n         if save:\n-            checkout.save(update_fields=updated_fields)\n+            checkout.safe_update(updated_fields)\n \n     return updated_fields\n \n \n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_complete.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_complete.py\tec9c4ba (parent)\n+++ saleor/graphql/checkout/mutations/checkout_complete.py\t909d452 (commit)\n@@ -1,8 +1,8 @@\n import graphene\n from django.core.exceptions import ValidationError\n \n-from ....checkout import AddressType\n+from ....checkout import AddressType, models\n from ....checkout.checkout_cleaner import (\n     clean_checkout_shipping,\n     validate_checkout_email,\n )\n@@ -311,9 +311,28 @@\n                 }\n             )\n         checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n-        cls.validate_checkout_addresses(checkout_info, lines)\n+        try:\n+            cls.validate_checkout_addresses(checkout_info, lines)\n+        except models.Checkout.DoesNotExist as e:\n+            order = order_models.Order.objects.get_by_checkout_token(\n+                checkout_info.checkout.token\n+            )\n+            if order:\n+                return CheckoutComplete(\n+                    order=SyncWebhookControlContext(order),\n+                    confirmation_needed=False,\n+                    confirmation_data={},\n+                )\n+            raise ValidationError(\n+                {\n+                    \"checkout\": ValidationError(\n+                        \"Checkout does not exist anymore.\",\n+                        code=CheckoutErrorCode.NOT_FOUND.value,\n+                    )\n+                }\n+            ) from e\n \n         requestor = get_user_or_app_from_context(info.context)\n         if requestor and requestor.has_perm(AccountPermissions.IMPERSONATE_USER):\n             # Allow impersonating user and process a checkout by using user details\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\n===================================================================\n--- saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\tec9c4ba (parent)\n+++ saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\t909d452 (commit)\n@@ -421,9 +421,9 @@\n             \"shippingAddress\": shipping_address,\n         }\n     }\n \n-    with django_assert_num_queries(87):\n+    with django_assert_num_queries(90):\n         response = api_client.post_graphql(query, variables)\n         assert get_graphql_content(response)[\"data\"][\"checkoutCreate\"]\n         assert Checkout.objects.first().lines.count() == 1\n \n@@ -439,9 +439,9 @@\n             \"shippingAddress\": shipping_address,\n         }\n     }\n \n-    with django_assert_num_queries(87):\n+    with django_assert_num_queries(90):\n         response = api_client.post_graphql(query, variables)\n         assert get_graphql_content(response)[\"data\"][\"checkoutCreate\"]\n         assert Checkout.objects.first().lines.count() == 10\n \n@@ -571,9 +571,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(93):\n+    with django_assert_num_queries(96):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_CREATE, variables)\n \n     # then\n     assert Checkout.objects.get().discounts.exists()\n@@ -827,9 +827,9 @@\n         reservation_length=5,\n     )\n \n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(109):\n+    with django_assert_num_queries(112):\n         variant_id = graphene.Node.to_global_id(\"ProductVariant\", variants[0].pk)\n         variables = {\n             \"id\": to_global_id_or_none(checkout),\n             \"lines\": [{\"quantity\": 3, \"variantId\": variant_id}],\n@@ -841,9 +841,9 @@\n         data = content[\"data\"][\"checkoutLinesUpdate\"]\n         assert not data[\"errors\"]\n \n     # Updating multiple lines in checkout has same query count as updating one\n-    with django_assert_num_queries(109):\n+    with django_assert_num_queries(112):\n         variables = {\n             \"id\": to_global_id_or_none(checkout),\n             \"lines\": [],\n         }\n@@ -1102,9 +1102,9 @@\n         new_lines.append({\"quantity\": 2, \"variantId\": variant_id})\n \n     user_api_client.ensure_access_token()\n     # Adding multiple lines to checkout has same query count as adding one\n-    with django_assert_num_queries(106):\n+    with django_assert_num_queries(109):\n         variables = {\n             \"id\": Node.to_global_id(\"Checkout\", checkout.pk),\n             \"lines\": [new_lines[0]],\n             \"channelSlug\": checkout.channel.slug,\n@@ -1115,9 +1115,9 @@\n         assert not data[\"errors\"]\n \n     checkout.lines.exclude(id=line.id).delete()\n \n-    with django_assert_num_queries(106):\n+    with django_assert_num_queries(109):\n         variables = {\n             \"id\": Node.to_global_id(\"Checkout\", checkout.pk),\n             \"lines\": new_lines,\n             \"channelSlug\": checkout.channel.slug,\n@@ -1166,9 +1166,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(97):\n+    with django_assert_num_queries(100):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     content = get_graphql_content(response)\n@@ -1252,9 +1252,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(97):\n+    with django_assert_num_queries(100):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     content = get_graphql_content(response)\n@@ -1288,9 +1288,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(103):\n+    with django_assert_num_queries(106):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     assert checkout.discounts.exists()\n@@ -1323,9 +1323,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(135):\n+    with django_assert_num_queries(138):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     assert checkout.lines.count() == 2\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\tec9c4ba (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\t909d452 (commit)\n@@ -740,4 +740,94 @@\n \n     assert not Checkout.objects.filter(pk=checkout.pk).exists(), (\n         \"Checkout should have been deleted\"\n     )\n+\n+\n+@mock.patch(\n+    \"saleor.graphql.checkout.mutations.checkout_complete.CheckoutComplete.validate_checkout_addresses\"\n+)\n+def test_checkout_complete_validate_checkout_addresses_raises_does_not_exist_error(\n+    validate_addresses_mock,\n+    user_api_client,\n+    checkout_with_item,\n+    shipping_method,\n+    address,\n+):\n+    # given\n+    checkout = checkout_with_item\n+    checkout.billing_address = address\n+    checkout.shipping_address = address\n+    checkout.save_shipping_address = False\n+    checkout.save_billing_address = False\n+    checkout.shipping_method = shipping_method\n+    checkout.save(\n+        update_fields=[\n+            \"billing_address\",\n+            \"shipping_address\",\n+            \"save_shipping_address\",\n+            \"save_billing_address\",\n+            \"shipping_method\",\n+        ]\n+    )\n+    validate_addresses_mock.side_effect = Checkout.DoesNotExist()\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(checkout),\n+        \"redirectUrl\": \"https://www.example.com\",\n+    }\n+\n+    # when\n+    response = user_api_client.post_graphql(MUTATION_CHECKOUT_COMPLETE, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkoutComplete\"]\n+    assert len(data[\"errors\"]) == 1\n+    assert data[\"errors\"][0][\"code\"] == CheckoutErrorCode.NOT_FOUND.name\n+\n+\n+@mock.patch(\n+    \"saleor.graphql.checkout.mutations.checkout_complete.CheckoutComplete.validate_checkout_addresses\"\n+)\n+def test_checkout_complete_validate_checkout_addresses_raises_does_not_exist_error_order_returned(\n+    validate_addresses_mock,\n+    user_api_client,\n+    checkout_with_item,\n+    order,\n+    shipping_method,\n+    address,\n+):\n+    # given\n+    checkout = checkout_with_item\n+    checkout.billing_address = address\n+    checkout.shipping_address = address\n+    checkout.save_shipping_address = False\n+    checkout.save_billing_address = False\n+    checkout.shipping_method = shipping_method\n+    checkout.save(\n+        update_fields=[\n+            \"billing_address\",\n+            \"shipping_address\",\n+            \"save_shipping_address\",\n+            \"save_billing_address\",\n+            \"shipping_method\",\n+        ]\n+    )\n+    validate_addresses_mock.side_effect = Checkout.DoesNotExist()\n+    order.checkout_token = checkout.pk\n+    order.save(update_fields=[\"checkout_token\"])\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(checkout),\n+        \"redirectUrl\": \"https://www.example.com\",\n+    }\n+\n+    # when\n+\n+    response = user_api_client.post_graphql(MUTATION_CHECKOUT_COMPLETE, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkoutComplete\"]\n+    assert not data[\"errors\"]\n+    assert data[\"order\"]\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\tec9c4ba (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\t909d452 (commit)\n@@ -5670,4 +5670,45 @@\n     for line in order.lines.all():\n         assert (\n             line.product_type_id == variant_id_to_product_type_id_map[line.variant_id]\n         )\n+\n+\n+def test_checkout_complete_race_condition_on_preparing_checkout(\n+    user_api_client,\n+    checkout_with_item,\n+    address,\n+    shipping_method,\n+    transaction_events_generator,\n+    transaction_item_generator,\n+    order,\n+):\n+    # given\n+    checkout = prepare_checkout_for_test(\n+        checkout_with_item,\n+        address,\n+        address,\n+        shipping_method,\n+        transaction_item_generator,\n+        transaction_events_generator,\n+    )\n+    order.checkout_token = checkout.token\n+    order.save(update_fields=[\"checkout_token\"])\n+\n+    redirect_url = \"https://www.example.com/new\"\n+    variables = {\"id\": to_global_id_or_none(checkout), \"redirectUrl\": redirect_url}\n+\n+    def delete_checkout(*args, **kwargs):\n+        checkout.delete()\n+\n+    # when\n+    with race_condition.RunAfter(\n+        \"saleor.checkout.complete_checkout.clean_checkout_shipping\", delete_checkout\n+    ):\n+        response = user_api_client.post_graphql(MUTATION_CHECKOUT_COMPLETE, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkoutComplete\"]\n+\n+    assert not data[\"errors\"]\n+    assert data[\"order\"]\n"
        }
      ]
    },
    {
      "id": "fix-customer-race",
      "sha": "32194992c45f575e7c9f0c72bed6709cd1a7eeb1",
      "parentSha": "59455e1047c6f4717f15045bc1f11dde8fa8d2a3",
      "spec": "Implement concurrency-safe customer creation and refactor address saving across account mutations.\n\nScope and behavior requirements:\n\n1) Refactor save_default_addresses helper\n- File: saleor/graphql/account/mutations/base.py\n- Change the signature of BaseCustomerCreate.save_default_addresses to remove the save_user boolean argument. It should accept only cleaned_input and user_instance.\n- Behavior:\n  - If a default shipping address is present in cleaned_input, save the address object, add it to user_instance.addresses, and set user_instance.default_shipping_address to this address. Do not save the user here.\n  - If a default billing address is present, save the address object, add it to user_instance.addresses, and set user_instance.default_billing_address to this address. Do not save the user here.\n  - Do not persist the user within this helper. Callers are responsible for saving the user.\n- Also simplify the import of DEPRECATED_IN_3X_INPUT in this file to a single-line import.\n\n2) Update callers of save_default_addresses\n- File: saleor/graphql/account/mutations/account/account_update.py\n  - Update AccountUpdate.save to call save_default_addresses without the save_user argument.\n  - After updating addresses, recompute instance.search_document and persist the user.\n- File: saleor/graphql/account/mutations/staff/customer_update.py\n  - Update CustomerUpdate.save to call save_default_addresses without the save_user argument.\n  - Ensure instance.search_document is recomputed and the user is saved later in the method (as appropriate for this mutation’s flow).\n- Minor import formatting cleanup where multi-line imports of base symbols are flattened to a single line where shown in the diff.\n\n3) Make customer creation robust to race conditions and avoid orphan addresses\n- File: saleor/graphql/account/mutations/staff/customer_create.py\n- Add imports: django.core.exceptions.ValidationError; django.db.transaction and IntegrityError.\n- Add constants import for BILLING_ADDRESS_FIELD and SHIPPING_ADDRESS_FIELD from the base module.\n- Add a classmethod _save(instance) that:\n  - Wraps instance.save() in transaction.atomic.\n  - Catches IntegrityError during save. If caught, query for models.User.objects.get(email=instance.email). If found, raise a django.core.exceptions.ValidationError with the \"email\" key whose value is a ValidationError carrying message \"User with this Email already exists.\" and code AccountErrorCode.UNIQUE.\n  - If the user does not exist after IntegrityError, re-raise the original error.\n- Rewrite CustomerCreate.save to:\n  - Build a list of address objects to be linked to the user (shipping and billing from input if provided). Save these address objects to the DB before creating the user, but do not attach them to the user yet and do not set them as defaults here (defaults should already be on the instance from the input construction phase).\n  - Call cls._save(instance) to create the User. If it raises the UNIQUE ValidationError as above, abort without leaving any new Address rows attached to any user.\n  - If any addresses were present, link them to the user via instance.addresses.set(addresses_to_set_on_user). This should happen only after the user is successfully saved.\n  - Recompute instance.search_document using prepare_user_search_document_value(instance) and persist the user.\n  - Trigger the customer created plugin event and account event as before.\n\n4) Add a race condition test and adjust imports\n- File: saleor/graphql/account/tests/mutations/staff/test_customer_create.py\n  - Import Address and the race_condition test utility.\n  - Add a test test_customer_create_race_condition that:\n    - Disables account confirmation by email in site settings.\n    - Prepares shipping and billing address variables based on the address fixture.\n    - Uses race_condition.RunBefore to schedule creating a User with the same email just before CustomerCreate._save runs, to simulate a race.\n    - Executes the customerCreate mutation and asserts that one error is returned with code \"UNIQUE\".\n    - Asserts that no new Address objects (apart from the fixture address) exist in the DB (i.e., no orphan addresses were created).\n\n5) Fix the race_condition helper to handle classmethods\n- File: saleor/tests/race_condition.py\n  - In RaceConditionTrigger.__enter__, detect when the original function is a classmethod and, in that case, fetch the bound method from the target class (using self.patched_function.getter() and .attribute) so the wrapper calls a callable method instead of the raw classmethod descriptor. This avoids \"'classmethod' object is not callable\" errors when wrapping classmethods.\n\nAcceptance criteria:\n- Creating two customers concurrently with the same email reliably returns a GraphQL error with code UNIQUE on the email field, not an unhandled IntegrityError.\n- In the race scenario above, no new Address records are persisted.\n- CustomerCreate still sets default addresses on the user based on the input (via construct/clean flow in BaseCustomerCreate) and links the provided address records after user creation.\n- AccountUpdate and CustomerUpdate continue to update default addresses and save the user, with save_default_addresses no longer saving the user internally.\n- Unit tests, including the new race condition test, pass.",
      "prompt": "Implement concurrency-safe customer creation in the GraphQL API and refactor address handling.\n\nGoals:\n- Ensure that when two concurrent customer creations target the same email, the mutation responds with a UNIQUE email error (rather than raising a database exception) and does not leave any address records persisted.\n- Refactor default address handling so the helper does not save the user. Callers should set and save the user after updating defaults. Link address records to the user only after the user has been created.\n- Update account/customer update mutations to use the refactored helper.\n- Add a test that simulates the race using the existing race_condition utility, and adjust that utility to support wrapping classmethod targets.\n\nKeep the existing mutation behavior (events, search document update) intact while making the above safer and more consistent.",
      "supplementalFiles": [
        "saleor/account/models.py",
        "saleor/account/search.py",
        "saleor/tests/fixtures.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/account/mutations/account/account_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/account/account_update.py\n===================================================================\n--- saleor/graphql/account/mutations/account/account_update.py\t59455e1 (parent)\n+++ saleor/graphql/account/mutations/account/account_update.py\t3219499 (commit)\n@@ -99,11 +99,9 @@\n     @traced_atomic_transaction()\n     def save(cls, info: ResolveInfo, instance: models.User, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n \n-        cls.save_default_addresses(\n-            cleaned_input=cleaned_input, user_instance=instance, save_user=False\n-        )\n+        cls.save_default_addresses(cleaned_input=cleaned_input, user_instance=instance)\n \n         instance.search_document = prepare_user_search_document_value(instance)\n         instance.save()\n \n"
        },
        {
          "path": "saleor/graphql/account/mutations/base.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/base.py\n===================================================================\n--- saleor/graphql/account/mutations/base.py\t59455e1 (parent)\n+++ saleor/graphql/account/mutations/base.py\t3219499 (commit)\n@@ -19,11 +19,9 @@\n from ...account.i18n import I18nMixin\n from ...account.types import Address, AddressInput, User\n from ...app.dataloaders import get_app_promise\n from ...core import ResolveInfo, SaleorContext\n-from ...core.descriptions import (\n-    DEPRECATED_IN_3X_INPUT,\n-)\n+from ...core.descriptions import DEPRECATED_IN_3X_INPUT\n from ...core.doc_category import DOC_CATEGORY_USERS\n from ...core.enums import LanguageCodeEnum\n from ...core.mutations import DeprecatedModelMutation, ModelDeleteMutation\n from ...core.types import BaseInputObjectType, NonNullList\n@@ -354,36 +352,28 @@\n             if user_gift_cards := get_user_gift_cards(instance):\n                 mark_gift_cards_search_index_as_dirty(user_gift_cards)\n \n     @classmethod\n-    def save_default_addresses(\n-        cls, *, cleaned_input: dict, user_instance: models.User, save_user: bool\n-    ):\n+    def save_default_addresses(cls, *, cleaned_input: dict, user_instance: models.User):\n         default_shipping_address: models.Address | None = cleaned_input.get(\n             SHIPPING_ADDRESS_FIELD\n         )\n \n         if default_shipping_address:\n             default_shipping_address.save()\n+            user_instance.addresses.add(default_shipping_address)\n             user_instance.default_shipping_address = default_shipping_address\n \n         default_billing_address: models.Address | None = cleaned_input.get(\n             BILLING_ADDRESS_FIELD\n         )\n \n         if default_billing_address:\n             default_billing_address.save()\n+            user_instance.addresses.add(default_billing_address)\n             user_instance.default_billing_address = default_billing_address\n \n-        if save_user:\n-            user_instance.save()\n \n-        if default_billing_address:\n-            user_instance.addresses.add(default_billing_address)\n-        if default_shipping_address:\n-            user_instance.addresses.add(default_shipping_address)\n-\n-\n class UserDeleteMixin:\n     class Meta:\n         abstract = True\n \n"
        },
        {
          "path": "saleor/graphql/account/mutations/staff/customer_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/staff/customer_create.py\n===================================================================\n--- saleor/graphql/account/mutations/staff/customer_create.py\t59455e1 (parent)\n+++ saleor/graphql/account/mutations/staff/customer_create.py\t3219499 (commit)\n@@ -1,7 +1,9 @@\n from urllib.parse import urlencode\n \n from django.contrib.auth.tokens import default_token_generator\n+from django.core.exceptions import ValidationError\n+from django.db import IntegrityError, transaction\n \n from .....account import events as account_events\n from .....account import models\n from .....account.notifications import send_set_password_notification\n@@ -18,9 +20,9 @@\n from ....core.enums import AccountErrorCode\n from ....core.types import AccountError\n from ....core.utils import WebhookEventInfo\n from ....plugins.dataloaders import get_plugin_manager_promise\n-from ..base import BaseCustomerCreate\n+from ..base import BILLING_ADDRESS_FIELD, SHIPPING_ADDRESS_FIELD, BaseCustomerCreate\n \n \n class CustomerCreate(BaseCustomerCreate):\n     class Meta:\n@@ -53,18 +55,69 @@\n             ),\n         ]\n \n     @classmethod\n+    def _save(cls, instance):\n+        \"\"\"Prevent race condition when saving customer.\n+\n+        This is a hacky solution that catches DB error, to deduct that entity was\n+        created before.\n+\n+        Normally we would use get_or_create here, but it will lose reference -\n+        get_or_create returns new instance of model, but original \"instance\" is being\n+        returned in mutation.\n+\n+        This limitation comes from the Base/Model mutation. We can solve this e.g. by\n+        returning actual instance from save()\n+\n+        https://linear.app/saleor/issue/EXT-2162\n+        \"\"\"\n+        with transaction.atomic():\n+            try:\n+                with transaction.atomic():\n+                    instance.save()\n+            except IntegrityError:\n+                try:\n+                    # Verify if object already exists in DB.\n+                    # If yes, it means we have a race-condition\n+                    # This eventually leads to ValidationError because this user\n+                    # already exists\n+                    models.User.objects.get(email=instance.email)\n+\n+                    raise ValidationError(\n+                        {\n+                            # This validation error mimics built-in validation error\n+                            # So graphQL response is the same\n+                            \"email\": ValidationError(\n+                                \"User with this Email already exists.\",\n+                                code=AccountErrorCode.UNIQUE.value,\n+                            )\n+                        }\n+                    )\n+                except instance.DoesNotExist:\n+                    pass\n+                raise\n+\n+    @classmethod\n     @traced_atomic_transaction()\n     def save(cls, info: ResolveInfo, instance, cleaned_input):\n-        manager = get_plugin_manager_promise(info.context).get()\n+        addresses_to_set_on_user = []\n+        if default_shipping_address := cleaned_input.get(SHIPPING_ADDRESS_FIELD):\n+            addresses_to_set_on_user.append(default_shipping_address)\n+            default_shipping_address.save()\n+        if default_billing_address := cleaned_input.get(BILLING_ADDRESS_FIELD):\n+            addresses_to_set_on_user.append(default_billing_address)\n+            default_billing_address.save()\n \n-        cls.save_default_addresses(\n-            cleaned_input=cleaned_input, user_instance=instance, save_user=True\n-        )\n+        cls._save(instance)\n \n+        if addresses_to_set_on_user:\n+            instance.addresses.set(addresses_to_set_on_user)\n+\n+        manager = get_plugin_manager_promise(info.context).get()\n+\n         instance.search_document = prepare_user_search_document_value(instance)\n-        instance.save(update_fields=[\"search_document\"])\n+        instance.save()\n \n         cls.call_event(manager.customer_created, instance)\n         account_events.customer_account_created_event(user=instance)\n \n"
        },
        {
          "path": "saleor/graphql/account/mutations/staff/customer_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/staff/customer_update.py\n===================================================================\n--- saleor/graphql/account/mutations/staff/customer_update.py\t59455e1 (parent)\n+++ saleor/graphql/account/mutations/staff/customer_update.py\t3219499 (commit)\n@@ -20,12 +20,9 @@\n from ....core.types import AccountError\n from ....core.utils import WebhookEventInfo\n from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n-from ..base import (\n-    BaseCustomerCreate,\n-    CustomerInput,\n-)\n+from ..base import BaseCustomerCreate, CustomerInput\n \n \n class CustomerUpdate(BaseCustomerCreate, ModelWithExtRefMutation):\n     class Arguments:\n@@ -172,9 +169,10 @@\n     def save(cls, info: ResolveInfo, instance, cleaned_input):\n         manager = get_plugin_manager_promise(info.context).get()\n \n         cls.save_default_addresses(\n-            cleaned_input=cleaned_input, user_instance=instance, save_user=False\n+            cleaned_input=cleaned_input,\n+            user_instance=instance,\n         )\n \n         instance.search_document = prepare_user_search_document_value(instance)\n         instance.save()\n"
        },
        {
          "path": "saleor/graphql/account/tests/mutations/staff/test_customer_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/tests/mutations/staff/test_customer_create.py\n===================================================================\n--- saleor/graphql/account/tests/mutations/staff/test_customer_create.py\t59455e1 (parent)\n+++ saleor/graphql/account/tests/mutations/staff/test_customer_create.py\t3219499 (commit)\n@@ -2,17 +2,18 @@\n from urllib.parse import urlencode\n \n from ......account import events as account_events\n from ......account.error_codes import AccountErrorCode\n-from ......account.models import User\n+from ......account.models import Address, User\n from ......account.notifications import get_default_user_payload\n from ......account.search import (\n     generate_address_search_document_value,\n     generate_user_fields_search_document_value,\n )\n from ......core.notify import NotifyEventType\n from ......core.tests.utils import get_site_context_payload\n from ......core.utils.url import prepare_url\n+from ......tests import race_condition\n from .....tests.utils import get_graphql_content\n from ....tests.utils import convert_dict_keys_to_camel_case\n \n CUSTOMER_CREATE_MUTATION = \"\"\"\n@@ -553,4 +554,56 @@\n \n     # then\n     User.objects.get(email=email)\n     mocked_trigger_webhooks_async.assert_called()\n+\n+\n+def test_customer_create_race_condition(\n+    staff_api_client, site_settings, permission_manage_users, address\n+):\n+    \"\"\"Context.\n+\n+    This test checks case when two concurrent mutations fail,\n+    due to unique constraint on email field. In race-condition scenario it's possible\n+    that two calls will pass validation (user doesn't exist yet), but the second one\n+    will fail due to DB having a user created already.\n+    \"\"\"\n+\n+    # given\n+    site_settings.enable_account_confirmation_by_email = False\n+    site_settings.save(update_fields=[\"enable_account_confirmation_by_email\"])\n+\n+    email_to_create = \"test-user@example.com\"\n+\n+    address_data = convert_dict_keys_to_camel_case(address.as_data())\n+    address_data.pop(\"privateMetadata\")\n+    address_data.pop(\"validationSkipped\")\n+\n+    variables = {\n+        \"shipping\": address_data,\n+        \"billing\": address_data,\n+        \"email\": email_to_create,\n+        \"firstName\": \"api_first_name\",\n+        \"lastName\": \"api_last_name\",\n+    }\n+\n+    def create_existing_customer(*args, **kwargs):\n+        User.objects.create(email=email_to_create)\n+\n+    with race_condition.RunBefore(\n+        # CustomerCreate.save,\n+        \"saleor.graphql.account.mutations.staff.customer_create.CustomerCreate._save\",\n+        create_existing_customer,\n+    ):\n+        response = staff_api_client.post_graphql(\n+            CUSTOMER_CREATE_MUTATION, variables, permissions=[permission_manage_users]\n+        )\n+\n+        content = get_graphql_content(response)\n+\n+        errors_list = content[\"data\"][\"customerCreate\"][\"errors\"]\n+\n+        assert len(errors_list) == 1\n+        assert errors_list[0][\"code\"] == \"UNIQUE\"\n+\n+        # make sure that addresses were not saved.\n+        assert not Address.objects.exclude(id=address.id).exists()\n"
        },
        {
          "path": "saleor/tests/race_condition.py",
          "status": "modified",
          "diff": "Index: saleor/tests/race_condition.py\n===================================================================\n--- saleor/tests/race_condition.py\t59455e1 (parent)\n+++ saleor/tests/race_condition.py\t3219499 (commit)\n@@ -10,8 +10,16 @@\n \n     def __enter__(self):\n         self.patched_function = patch(self.target)\n         original_function, _ = self.patched_function.get_original()\n+        if type(original_function) is classmethod:\n+            # classmethod needs to have an initialized class. get_original\n+            # returns the direct handler to the classmethod. Calling it without class\n+            # produces \"'classmethod' object is not callable\" error\n+            target_class = self.patched_function.getter()\n+            target_method = self.patched_function.attribute\n+            original_function = getattr(target_class, target_method)\n+\n         self.patched_function.new = self.wrap(original_function)\n         return self.patched_function.__enter__()\n \n     def __exit__(self, exc_type, exc_value, traceback):\n"
        }
      ]
    },
    {
      "id": "fix-flat-rate-country",
      "sha": "2c770c685a57466c11d3cc9a0e9e12ed10243408",
      "parentSha": "c31fb4cfd08f5578c90b9109f98f662b119e208a",
      "spec": "Objective: Refactor checkout flat-rate tax country resolution to rely on CheckoutInfo, remove the address parameter from checkout calculation functions and their call sites, and update tests accordingly.\n\nBehavioral change:\n- Determine the active checkout country from CheckoutInfo using this priority: shipping address country, then billing address country, else the channel’s default country.\n- Use this derived country for flat-rate tax calculations, and derive any needed address context internally from CheckoutInfo rather than via function parameters.\n\nScope of changes:\n1) Add a country derivation helper for checkout:\n- In saleor/tax/utils.py, add a function that returns the active checkout country from CheckoutInfo using the priority above. Update existing tax configuration utilities to use this helper for country selection.\n\n2) Update flat-rate tax calculator to rely on CheckoutInfo:\n- In saleor/tax/calculations/checkout.py, update the flat-rate checkout price updater to no longer accept an address argument. Inside, use the new helper to get the active country and proceed with flat-rate calculations using that country code.\n\n3) Remove address parameter from checkout calculation flows and use CheckoutInfo:\n- In saleor/checkout/calculations.py, remove the address parameter from the following functions and their internal calls, and instead derive address/country from CheckoutInfo where needed:\n  - checkout_shipping_price, checkout_shipping_tax_rate, checkout_subtotal, calculate_checkout_total, checkout_line_total, checkout_line_unit_price, checkout_line_tax_rate, fetch_checkout_data, the internal price refresh routine, the internal tax calculation routine, the plugin/app call routine, and the plugin tax application routine.\n- Ensure plugin tax application uses an address derived from CheckoutInfo (shipping first, then billing) internally instead of accepting it as a parameter.\n- When invoking flat-rate calculations from the internal tax routine, no longer pass an address argument; rely on the updated flat-rate calculator that uses CheckoutInfo to get the country.\n\n4) Remove address argument from callers in actions and GraphQL layers:\n- In saleor/checkout/actions.py, drop the address argument where prices/taxes are refreshed in the sync webhook trigger.\n- In saleor/graphql/checkout/types.py, remove the address argument from fetch_checkout_data calls in Checkout resolvers and keep other arguments intact.\n\n5) Update tests and mocks to match new signatures and behavior:\n- In saleor/checkout/tests/test_calculations.py, remove address from common helper kwargs and call sites. Add a test that proves flat-rate calculations use the shipping address country when it differs from the channel default (set different default/tax rates per country via TaxClass and TaxClassCountryRate, set shipping/billing address on the checkout, and assert checkout and line tax reflect the shipping country rate).\n- In saleor/tax/tests/test_checkout_calculations.py, remove the address argument from all update_checkout_prices_with_flat_rates calls and adjust expectations accordingly.\n- In saleor/graphql/account/tests/queries/test_me.py and saleor/graphql/checkout/tests/*, update mocks/assert_called_once_with to remove address=None expectations for internal price refresh routines and flat-rate updater.\n- In saleor/graphql/checkout/tests/test_checkout_line_problems.py and saleor/webhook/transport/asynchronous/tests/test_deferred_payload.py, remove address from fetch_kwargs and calls to fetch_checkout_data.\n\n6) Cleanup:\n- Remove now-unused imports/types (e.g., Optional, Address, direct get_active_country imports where replaced by the new helper). Ensure all call sites compile with updated signatures.\n\nAcceptance criteria:\n- No checkout or tax calculation function accepts an address parameter; functions derive address/country from CheckoutInfo as described.\n- The helper for determining the active checkout country exists and is used in tax config selection and flat-rate calculation.\n- Flat-rate taxes are computed using the shipping address country when provided, falling back to billing address, then channel default.\n- All updated tests reflect the new signatures and pass, including the added test for differing shipping vs. channel default country impacting flat-rate taxes.",
      "prompt": "Refactor checkout tax calculations to determine the active country from the checkout itself and stop passing an address through pricing APIs. Use the shipping address country if available, otherwise the billing address country, and otherwise the channel’s default country. Update the flat-rate tax calculator to use this derived country, and adjust checkout calculation helpers and GraphQL layers to remove the address parameter throughout. Update tests and mocks to reflect the new signatures, and add a test that verifies flat-rate taxes follow the shipping address country rather than the channel default when they differ.",
      "supplementalFiles": [
        "saleor/core/utils/country.py",
        "saleor/checkout/base_calculations.py",
        "saleor/checkout/fetch.py",
        "saleor/checkout/models.py",
        "saleor/channel/models.py",
        "saleor/tax/models.py",
        "saleor/plugins/manager.py",
        "saleor/core/taxes.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/actions.py\n===================================================================\n--- saleor/checkout/actions.py\tc31fb4c (parent)\n+++ saleor/checkout/actions.py\t2c770c6 (commit)\n@@ -101,11 +101,8 @@\n         fetch_checkout_data(\n             checkout_info=checkout_info,\n             manager=manager,\n             lines=lines,\n-            address=address\n-            or checkout_info.shipping_address\n-            or checkout_info.billing_address,\n             force_update=True,\n         )\n \n \n"
        },
        {
          "path": "saleor/checkout/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/calculations.py\n===================================================================\n--- saleor/checkout/calculations.py\tc31fb4c (parent)\n+++ saleor/checkout/calculations.py\t2c770c6 (commit)\n@@ -64,9 +64,8 @@\n     checkout_info, _ = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n@@ -89,9 +88,8 @@\n     checkout_info, _ = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n     return checkout_info.checkout.shipping_tax_rate\n@@ -117,9 +115,8 @@\n     checkout_info, _ = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n@@ -198,9 +195,8 @@\n     checkout_info, _ = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         force_update=force_update,\n         allow_sync_webhooks=allow_sync_webhooks,\n@@ -224,14 +220,12 @@\n     \"\"\"\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n     currency = checkout_info.checkout.currency\n-    address = checkout_info.shipping_address or checkout_info.billing_address\n     _, lines = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n@@ -255,14 +249,12 @@\n     \"\"\"\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n     currency = checkout_info.checkout.currency\n-    address = checkout_info.shipping_address or checkout_info.billing_address\n     _, lines = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n@@ -283,14 +275,12 @@\n     \"\"\"Return the tax rate of provided line.\n \n     It takes in account all plugins.\n     \"\"\"\n-    address = checkout_info.shipping_address or checkout_info.billing_address\n     _, lines = fetch_checkout_data(\n         checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         database_connection_name=database_connection_name,\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n     checkout_line_info = find_checkout_line_info(lines, checkout_line_info.line.id)\n@@ -357,9 +347,8 @@\n     checkout_info: \"CheckoutInfo\",\n     manager: \"PluginsManager\",\n     lines: list[\"CheckoutLineInfo\"],\n     allow_sync_webhooks: bool,\n-    address: Optional[\"Address\"] = None,\n     force_update: bool = False,\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n     pregenerated_subscription_payloads: dict | None = None,\n ) -> tuple[\"CheckoutInfo\", list[\"CheckoutLineInfo\"]]:\n@@ -424,9 +413,8 @@\n                 manager,\n                 checkout_info,\n                 lines,\n                 prices_entered_with_tax,\n-                address,\n                 database_connection_name=database_connection_name,\n                 pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n             )\n         except TaxDataError as e:\n@@ -507,9 +495,8 @@\n     manager: \"PluginsManager\",\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n     prices_entered_with_tax: bool,\n-    address: Optional[\"Address\"] = None,\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n     pregenerated_subscription_payloads: dict | None = None,\n ):\n     if pregenerated_subscription_payloads is None:\n@@ -521,9 +508,8 @@\n             checkout,\n             checkout_info,\n             lines,\n             prices_entered_with_tax,\n-            address,\n             database_connection_name=database_connection_name,\n         )\n         return\n \n@@ -531,9 +517,9 @@\n     # If taxAppId is provided run tax plugin or Tax App. taxAppId can be\n     # configured with Avatax plugin identifier.\n     if not tax_app_identifier:\n         # Call the tax plugins.\n-        _apply_tax_data_from_plugins(checkout, manager, checkout_info, lines, address)\n+        _apply_tax_data_from_plugins(checkout, manager, checkout_info, lines)\n         # Get the taxes calculated with apps and apply to checkout.\n         # We should allow empty tax_data in case any tax webhook has not been\n         # configured - handled by `allowed_empty_tax_data`\n         tax_data = _get_taxes_for_checkout(\n@@ -551,9 +537,8 @@\n             checkout,\n             manager,\n             checkout_info,\n             lines,\n-            address,\n             pregenerated_subscription_payloads,\n         )\n \n \n@@ -562,9 +547,8 @@\n     checkout: \"Checkout\",\n     manager: \"PluginsManager\",\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n-    address: Optional[\"Address\"] = None,\n     pregenerated_subscription_payloads: dict | None = None,\n ):\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n@@ -582,9 +566,8 @@\n             checkout,\n             manager,\n             checkout_info,\n             lines,\n-            address,\n             plugin_ids=plugin_ids,\n         )\n         if checkout.tax_error:\n             raise TaxDataError(checkout.tax_error)\n@@ -701,11 +684,11 @@\n     checkout: \"Checkout\",\n     manager: \"PluginsManager\",\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n-    address: Optional[\"Address\"],\n     plugin_ids: list[str] | None = None,\n ) -> None:\n+    address = checkout_info.shipping_address or checkout_info.billing_address\n     for line_info in lines:\n         line = line_info.line\n \n         total_price = manager.calculate_checkout_line_total(\n@@ -786,9 +769,8 @@\n def fetch_checkout_data(\n     checkout_info: \"CheckoutInfo\",\n     manager: \"PluginsManager\",\n     lines: list[\"CheckoutLineInfo\"],\n-    address: Optional[\"Address\"] = None,\n     force_update: bool = False,\n     checkout_transactions: Iterable[\"TransactionItem\"] | None = None,\n     force_status_update: bool = False,\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n@@ -806,9 +788,8 @@\n     checkout_info, lines = _fetch_checkout_prices_if_expired(\n         checkout_info=checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n         force_update=force_update,\n         database_connection_name=database_connection_name,\n         pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         allow_sync_webhooks=allow_sync_webhooks,\n"
        },
        {
          "path": "saleor/checkout/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_calculations.py\n===================================================================\n--- saleor/checkout/tests/test_calculations.py\tc31fb4c (parent)\n+++ saleor/checkout/tests/test_calculations.py\t2c770c6 (commit)\n@@ -28,8 +28,9 @@\n from ...product.models import ProductVariantChannelListing\n from ...shipping.interface import ShippingMethodData\n from ...tax import TaxCalculationStrategy\n from ...tax.calculations.checkout import update_checkout_prices_with_flat_rates\n+from ...tax.models import TaxClass, TaxClassCountryRate\n from ...tests import race_condition\n from .. import CheckoutAuthorizeStatus, CheckoutChargeStatus\n from ..base_calculations import (\n     base_checkout_delivery_price,\n@@ -153,10 +154,8 @@\n             checkout_with_items, lines, plugins_manager\n         ),\n         \"manager\": plugins_manager,\n         \"lines\": lines,\n-        \"address\": checkout_with_items.shipping_address\n-        or checkout_with_items.billing_address,\n     }\n \n \n SALE = Decimal(\"1.0\")\n@@ -406,9 +405,8 @@\n         checkout_info,\n         plugins_manager,\n         lines,\n         allow_sync_webhooks=allow_sync_webhooks,\n-        address=checkout.shipping_address,\n     )\n \n     # then\n     checkout.refresh_from_db()\n@@ -634,9 +632,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address or checkout.billing_address,\n     }\n \n     # when\n     fetch_checkout_data(**fetch_kwargs)\n@@ -692,9 +689,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": checkout_info,\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address or checkout.billing_address,\n     }\n \n     # when\n     fetch_checkout_data(**fetch_kwargs)\n@@ -748,9 +744,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address or checkout.billing_address,\n     }\n \n     # when\n     fetch_checkout_data(**fetch_kwargs)\n@@ -789,9 +784,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address or checkout.billing_address,\n         \"allow_sync_webhooks\": True,\n     }\n \n     # when\n@@ -835,9 +829,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": checkout_info,\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address or checkout.billing_address,\n         \"allow_sync_webhooks\": False,\n     }\n     assert (\n         checkout_info.tax_configuration.tax_calculation_strategy\n@@ -877,9 +870,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address or checkout.billing_address,\n     }\n \n     # when\n     fetch_checkout_data(**fetch_kwargs)\n@@ -888,8 +880,63 @@\n     assert checkout.total.gross.amount > 0\n     assert checkout_with_items.tax_error == \"Empty tax data.\"\n \n \n+def test_fetch_checkout_data_flat_rates_shipping_tax_differs_from_default(\n+    checkout_with_items,\n+    address,\n+    plugins_manager,\n+):\n+    # given the checkout with the shipping country and tax different than the channel\n+    # default country\n+    checkout = checkout_with_items\n+    tc = checkout.channel.tax_configuration\n+    tc.prices_entered_with_tax = True\n+    tc.tax_calculation_strategy = TaxCalculationStrategy.FLAT_RATES\n+    tc.country_exceptions.all().delete()\n+    tc.save()\n+\n+    default_country = checkout.channel.default_country\n+    default_country_rate = 21\n+    shipping_address_country = \"PL\"\n+    shipping_address_rate = 23\n+    tax_class = TaxClass.objects.create(name=\"Product\")\n+    tax_class.country_rates.bulk_create(\n+        [\n+            TaxClassCountryRate(country=default_country, rate=default_country_rate),\n+            TaxClassCountryRate(\n+                country=shipping_address_country, rate=shipping_address_rate\n+            ),\n+        ]\n+    )\n+    for line in checkout.lines.all():\n+        product = line.variant.product\n+        product.tax_class = tax_class\n+        product.save(update_fields=[\"tax_class\"])\n+\n+    checkout.shipping_address = address\n+    checkout.billing_address = address\n+    checkout.save(update_fields=[\"shipping_address\", \"billing_address\"])\n+\n+    lines, _ = fetch_checkout_lines(checkout_with_items)\n+    fetch_kwargs = {\n+        \"checkout_info\": fetch_checkout_info(\n+            checkout_with_items, lines, plugins_manager\n+        ),\n+        \"manager\": plugins_manager,\n+        \"lines\": lines,\n+    }\n+\n+    # when\n+    fetch_checkout_data(**fetch_kwargs, allow_sync_webhooks=False)\n+\n+    # then\n+    checkout.refresh_from_db()\n+    assert round(checkout.total.tax / checkout.total.net * 100) == shipping_address_rate\n+    for line in checkout.lines.all():\n+        assert line.tax_rate * 100 == shipping_address_rate\n+\n+\n @patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_external_shipping_method_called_only_once_during_tax_calculations(\n     mock_send_webhook_request_sync,\n     checkout_with_single_item,\n@@ -1225,10 +1272,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout_with_items, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout_with_items.shipping_address\n-        or checkout_with_items.billing_address,\n     }\n \n     # when\n     fetch_checkout_data(**fetch_kwargs)\n@@ -1259,10 +1304,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout_with_items, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout_with_items.shipping_address\n-        or checkout_with_items.billing_address,\n     }\n \n     # when\n     fetch_checkout_data(**fetch_kwargs)\n@@ -1279,12 +1322,8 @@\n     # given\n     lines, _ = fetch_checkout_lines(checkout_with_item_total_0)\n     manager = get_plugins_manager(allow_replica=False)\n     checkout_info = fetch_checkout_info(checkout_with_item_total_0, lines, manager)\n-    address = (\n-        checkout_with_item_total_0.shipping_address\n-        or checkout_with_item_total_0.billing_address,\n-    )\n \n     assert checkout_with_item_total_0.total.gross == zero_money(\n         checkout_with_item_total_0.total.currency\n     )\n@@ -1296,9 +1335,8 @@\n     fetch_checkout_data(\n         checkout_info=checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n     )\n \n     # then\n     checkout_with_item_total_0.refresh_from_db()\n@@ -1351,9 +1389,8 @@\n     fetch_checkout_data(\n         checkout_info=checkout_info,\n         manager=manager,\n         lines=lines,\n-        address=address,\n     )\n \n     # then\n     checkout.refresh_from_db()\n@@ -1377,9 +1414,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address,\n     }\n \n     # when\n     def delete_checkout(*args, **kwargs):\n@@ -1426,9 +1462,8 @@\n     fetch_kwargs = {\n         \"checkout_info\": fetch_checkout_info(checkout, lines_info, manager),\n         \"manager\": manager,\n         \"lines\": lines_info,\n-        \"address\": checkout.shipping_address,\n     }\n     expected_email = \"new_email@example.com\"\n \n     # when\n"
        },
        {
          "path": "saleor/graphql/account/tests/queries/test_me.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/tests/queries/test_me.py\n===================================================================\n--- saleor/graphql/account/tests/queries/test_me.py\tc31fb4c (parent)\n+++ saleor/graphql/account/tests/queries/test_me.py\t2c770c6 (commit)\n@@ -197,9 +197,8 @@\n     mocked_calculate_and_add_tax.assert_not_called()\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n@@ -245,15 +244,13 @@\n         checkout_with_item,\n         mock.ANY,\n         lines,\n         tax_configuration_flat_rates.prices_entered_with_tax,\n-        None,\n         database_connection_name=mock.ANY,\n     )\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkout.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkout.py\tc31fb4c (parent)\n+++ saleor/graphql/checkout/tests/test_checkout.py\t2c770c6 (commit)\n@@ -3688,9 +3688,8 @@\n     calculations.fetch_checkout_data(\n         checkout_info,\n         manager,\n         lines,\n-        checkout_with_item.shipping_address,\n         force_update=True,\n     )\n \n     line = lines[0]\n@@ -3767,9 +3766,8 @@\n     calculations.fetch_checkout_data(\n         checkout_info,\n         manager,\n         lines,\n-        checkout_with_item.shipping_address,\n         force_update=True,\n     )\n     checkout_with_item.price_expiration = timezone.now() - datetime.timedelta(days=1)\n     checkout_with_item.save(update_fields=[\"price_expiration\"])\n@@ -3973,9 +3971,8 @@\n     mocked_calculate_and_add_tax.assert_not_called()\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n@@ -4020,15 +4017,13 @@\n         checkout_with_item,\n         mock.ANY,\n         lines,\n         tax_configuration_flat_rates.prices_entered_with_tax,\n-        None,\n         database_connection_name=mock.ANY,\n     )\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n@@ -4122,9 +4117,8 @@\n     mocked_calculate_and_add_tax.assert_not_called()\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n@@ -4165,15 +4159,13 @@\n         checkout_with_item,\n         mock.ANY,\n         lines,\n         tax_configuration_flat_rates.prices_entered_with_tax,\n-        None,\n         database_connection_name=mock.ANY,\n     )\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/test_checkout_line_problems.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/test_checkout_line_problems.py\n===================================================================\n--- saleor/graphql/checkout/tests/test_checkout_line_problems.py\tc31fb4c (parent)\n+++ saleor/graphql/checkout/tests/test_checkout_line_problems.py\t2c770c6 (commit)\n@@ -603,9 +603,8 @@\n     mocked_calculate_and_add_tax.assert_not_called()\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n@@ -656,9 +655,8 @@\n         checkout_with_item,\n         mock.ANY,\n         lines,\n         tax_configuration_flat_rates.prices_entered_with_tax,\n-        None,\n         database_connection_name=mock.ANY,\n     )\n     mocked_fetch_checkout_prices_if_expired.assert_called_once()\n \n@@ -712,9 +710,8 @@\n     mocked_calculate_and_add_tax.assert_not_called()\n     mocked_fetch_checkout_prices_if_expired.assert_called_once_with(\n         checkout_info=mock.ANY,\n         allow_sync_webhooks=False,\n-        address=None,\n         database_connection_name=mock.ANY,\n         force_update=False,\n         lines=lines,\n         manager=mock.ANY,\n@@ -771,8 +768,7 @@\n         checkout_with_item,\n         mock.ANY,\n         lines,\n         tax_configuration_flat_rates.prices_entered_with_tax,\n-        None,\n         database_connection_name=mock.ANY,\n     )\n     mocked_fetch_checkout_prices_if_expired.assert_called_once()\n"
        },
        {
          "path": "saleor/graphql/checkout/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/types.py\n===================================================================\n--- saleor/graphql/checkout/types.py\tc31fb4c (parent)\n+++ saleor/graphql/checkout/types.py\t2c770c6 (commit)\n@@ -1481,9 +1481,8 @@\n             fetch_checkout_data(\n                 checkout_info=checkout_info,\n                 manager=manager,\n                 lines=lines,\n-                address=address,\n                 checkout_transactions=transactions,\n                 force_status_update=True,\n                 database_connection_name=database_connection_name,\n                 pregenerated_subscription_payloads=tax_payloads,\n@@ -1519,9 +1518,8 @@\n             fetch_checkout_data(\n                 checkout_info=checkout_info,\n                 manager=manager,\n                 lines=lines,\n-                address=address,\n                 checkout_transactions=transactions,\n                 force_status_update=True,\n                 database_connection_name=database_connection_name,\n                 pregenerated_subscription_payloads=tax_payloads,\n"
        },
        {
          "path": "saleor/tax/calculations/checkout.py",
          "status": "modified",
          "diff": "Index: saleor/tax/calculations/checkout.py\n===================================================================\n--- saleor/tax/calculations/checkout.py\tc31fb4c (parent)\n+++ saleor/tax/calculations/checkout.py\t2c770c6 (commit)\n@@ -1,24 +1,23 @@\n from decimal import Decimal\n-from typing import TYPE_CHECKING, Optional\n+from typing import TYPE_CHECKING\n \n from django.conf import settings\n from prices import TaxedMoney\n \n from ...checkout import base_calculations\n from ...core.prices import quantize_price\n from ...core.taxes import zero_taxed_money\n-from ...core.utils.country import get_active_country\n from ..models import TaxClassCountryRate\n from ..utils import (\n+    get_checkout_active_country,\n     get_shipping_tax_rate_for_checkout,\n     get_tax_rate_for_country,\n     normalize_tax_rate_for_db,\n )\n from . import calculate_flat_rate_tax\n \n if TYPE_CHECKING:\n-    from ...account.models import Address\n     from ...checkout.fetch import CheckoutInfo, CheckoutLineInfo\n     from ...checkout.models import Checkout\n \n \n@@ -26,12 +25,11 @@\n     checkout: \"Checkout\",\n     checkout_info: \"CheckoutInfo\",\n     lines: list[\"CheckoutLineInfo\"],\n     prices_entered_with_tax: bool,\n-    address: Optional[\"Address\"] = None,\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n ):\n-    country_code = get_active_country(checkout_info.channel, address)\n+    country_code = get_checkout_active_country(checkout_info)\n     default_country_rate_obj = (\n         TaxClassCountryRate.objects.using(database_connection_name)\n         .filter(country=country_code, tax_class=None)\n         .first()\n"
        },
        {
          "path": "saleor/tax/tests/test_checkout_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/tax/tests/test_checkout_calculations.py\n===================================================================\n--- saleor/tax/tests/test_checkout_calculations.py\tc31fb4c (parent)\n+++ saleor/tax/tests/test_checkout_calculations.py\t2c770c6 (commit)\n@@ -140,9 +140,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     for line_info in lines:\n@@ -202,9 +202,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     assert checkout.total == TaxedMoney(\n@@ -259,9 +259,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     assert checkout.shipping_tax_rate == Decimal(\"0.2300\")\n@@ -317,9 +317,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     weighted_tax_amount = sum(\n@@ -379,9 +379,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     assert checkout.total == TaxedMoney(\n@@ -411,9 +410,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     assert checkout.total == TaxedMoney(\n@@ -444,9 +443,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     assert checkout.total == TaxedMoney(\n@@ -493,9 +492,9 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n \n     # when\n     update_checkout_prices_with_flat_rates(\n-        checkout, checkout_info, lines, prices_entered_with_tax, address\n+        checkout, checkout_info, lines, prices_entered_with_tax\n     )\n \n     # then\n     assert checkout.total == TaxedMoney(\n@@ -546,9 +545,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     assert checkout.total == TaxedMoney(\n@@ -594,9 +592,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     assert checkout.subtotal == TaxedMoney(\n@@ -633,9 +630,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     subtotal = Decimal(\"0.00\")\n@@ -678,9 +674,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     subtotal = Decimal(\"0.00\")\n@@ -719,9 +714,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     subtotal = Decimal(\"0.00\")\n@@ -760,9 +754,8 @@\n         checkout,\n         checkout_info,\n         lines,\n         prices_entered_with_tax,\n-        address,\n     )\n \n     # then\n     subtotal = Decimal(\"0.00\")\n"
        },
        {
          "path": "saleor/tax/utils.py",
          "status": "modified",
          "diff": "Index: saleor/tax/utils.py\n===================================================================\n--- saleor/tax/utils.py\tc31fb4c (parent)\n+++ saleor/tax/utils.py\t2c770c6 (commit)\n@@ -155,13 +155,9 @@\n     checkout_info: \"CheckoutInfo\",\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n ) -> tuple[\"TaxConfiguration\", Optional[\"TaxConfigurationPerCountry\"]]:\n     tax_configuration = checkout_info.tax_configuration\n-    country_code = get_active_country(\n-        checkout_info.channel,\n-        checkout_info.shipping_address,\n-        checkout_info.billing_address,\n-    )\n+    country_code = get_checkout_active_country(checkout_info)\n     country_tax_configuration = next(\n         (\n             tc\n             for tc in tax_configuration.country_exceptions.using(\n@@ -173,8 +169,25 @@\n     )\n     return tax_configuration, country_tax_configuration\n \n \n+def get_checkout_active_country(checkout_info: \"CheckoutInfo\") -> str:\n+    \"\"\"Get active checkout country for the given checkout info.\n+\n+    Return country code based on the following rules:\n+    - use country code from shipping address if it's provided in the first place\n+    - use country code from billing address if shipping address is not provided\n+    - if both shipping and billing addresses are not provided use the default country\n+    from channel\n+    \"\"\"\n+\n+    return get_active_country(\n+        channel=checkout_info.channel,\n+        shipping_address=checkout_info.shipping_address,\n+        billing_address=checkout_info.billing_address,\n+    )\n+\n+\n def get_charge_taxes_for_checkout(\n     checkout_info: \"CheckoutInfo\",\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n ):\n"
        },
        {
          "path": "saleor/webhook/transport/asynchronous/tests/test_deferred_payload.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/asynchronous/tests/test_deferred_payload.py\n===================================================================\n--- saleor/webhook/transport/asynchronous/tests/test_deferred_payload.py\tc31fb4c (parent)\n+++ saleor/webhook/transport/asynchronous/tests/test_deferred_payload.py\t2c770c6 (commit)\n@@ -27,10 +27,8 @@\n             checkout_with_items, lines, plugins_manager\n         ),\n         \"manager\": plugins_manager,\n         \"lines\": lines,\n-        \"address\": checkout_with_items.shipping_address\n-        or checkout_with_items.billing_address,\n     }\n \n \n @mock.patch(\n"
        }
      ]
    },
    {
      "id": "fix-giftcard-status",
      "sha": "940b8d83ec5c09aa19416c8bcf38d5c28696a991",
      "parentSha": "f6d2a71ff9620a40017dc8a634a7822cbcc19285",
      "spec": "Implement the following changes across the codebase to make checkout status updates gift-card-aware and to reliably trigger recalculations:\n\n1) Recalculate checkout statuses using total minus gift card balance\n- In saleor/checkout/actions.py, function transaction_amounts_for_checkout_updated_without_price_recalculation:\n  - Import zero_money from saleor.core.taxes.\n  - Before calling update_checkout_payment_statuses, compute checkout_total_gross as checkout.total.gross minus checkout.get_total_gift_cards_balance(). Clamp it to not go below zero using zero_money(currency).\n  - Pass this adjusted checkout_total_gross to update_checkout_payment_statuses.\n\n2) Update fetch_checkout_data to trigger status updates on price invalidation and to consider gift cards\n- In saleor/checkout/calculations.py, function fetch_checkout_data:\n  - Capture the previous value of checkout.price_expiration before calling _fetch_checkout_prices_if_expired.\n  - After fetching/recalculating prices, recompute whether to update statuses based on either:\n    - price_expiration changed compared to the captured value, or\n    - force_status_update is True, or\n    - current_total_gross is zero AND checkout has lines AND authorize_status is not FULL.\n  - When updating statuses, compute checkout_total_gross as checkout.total.gross minus checkout.get_total_gift_cards_balance(database_connection_name). Clamp it to zero using zero_money(currency). Pass this to update_checkout_payment_statuses along with checkout_has_lines and checkout_transactions.\n  - Ensure zero_money is imported.\n\n3) Invalidate other checkouts when a gift card is used in an order\n- In saleor/order/utils.py, function add_gift_cards_to_order:\n  - After updating the gift cards’ balances and creating events, invalidate prices for any other Checkout records that are linked to the used gift cards (exclude the current checkout) by setting price_expiration=timezone.now(). Use a queryset like Checkout.objects.filter(gift_cards__in=gift_cards_to_update).exclude(token=current_checkout.token).update(price_expiration=timezone.now()).\n  - Import Checkout in this module if needed.\n\n4) Tests and test utilities adjustments\n- saleor/checkout/tests/test_actions.py:\n  - Add a parametrized test to assert transaction_amounts_for_checkout_updated_without_price_recalculation updates authorize/charge statuses correctly across multiple gift card balances with a transaction present.\n- saleor/checkout/tests/test_calculations.py:\n  - Add a parametrized test to assert fetch_checkout_data considers gift card balance when updating statuses with a transaction present.\n  - Maintain the existing test for zero-amount checkout with lines and ensure it still updates statuses to FULL.\n- GraphQL benchmark tests (saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py):\n  - Increment expected query counts by +1 where applicable (as gift card/price recalculation adds one query) to preserve assertions.\n- GraphQL mutations/tests (saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py):\n  - In prepare_checkout_for_test test helper, force price recalculation by setting checkout.price_expiration = timezone.now() instead of pre-calling update_checkout_payment_statuses.\n  - Fix redirectUrl typo if present and adjust stock setup where necessary for realistic availability conditions.\n- E2E tests:\n  - Add tests under saleor/tests/e2e/checkout/ to validate:\n    a) Completing a checkout with partial transaction and gift card results in a completed order with zero total (no CHECKOUT_NOT_FULLY_PAID).\n    b) Completing a checkout with only a gift card behaves correctly, including initial UNCONFIRMED status switching to UNFULFILLED after transaction commit hook; verify by re-querying the order.\n    c) Completing a checkout that consumes a gift card invalidates other checkouts linked to that gift card, causing their statuses to drop to NONE and a subsequent completion attempt to return CHECKOUT_NOT_FULLY_PAID.\n  - Ensure test GraphQL query for checkout includes authorizeStatus and chargeStatus fields for assertions.\n\n5) Changelog\n- Update CHANGELOG.md with a brief description of the bugfix: Checkout partially paid by Transactions and Gift Cards can be completed; statuses are recalculated using available gift card balance.\n\nBehavioral outcomes:\n- Whenever checkout statuses are recalculated (via actions or fetch), the required funds are computed as checkout total minus available gift cards balance, clamped to zero.\n- Price invalidation (price_expiration change) reliably triggers a payment status refresh.\n- Using a gift card on one checkout invalidates prices for any other checkout sharing that gift card, forcing their statuses to be recomputed on next access.\n- GraphQL tests can assert authorizeStatus and chargeStatus, and e2e flows no longer raise CHECKOUT_NOT_FULLY_PAID when transactions plus gift cards fully cover the total.",
      "prompt": "Improve checkout payment status handling to correctly account for gift card balances and ensure reliable status recalculation:\n\n- Update status computations so that the amount to cover is the checkout total minus the available gift card balance, never below zero. Apply this both when updating statuses after transaction changes and when fetching checkout data.\n- Change the condition that decides when to refresh payment statuses during checkout data fetch to react to price invalidation rather than raw total differences, and still handle the zero-total-with-lines case.\n- When a gift card is used during checkout completion, invalidate pricing for any other checkout that also has that gift card so their statuses update on next access.\n- Extend tests to cover these scenarios, including e2e flows combining transactions and gift cards, and expose authorizeStatus and chargeStatus in the checkout query used by tests. Adjust expected query counts in benchmarks as needed and fix minor test setup issues.\n\nKeep the solution consistent with existing models, helpers, and payment status logic. Don’t introduce new APIs; integrate with the current checkout payment status update utilities and gift card balance methods.",
      "supplementalFiles": [
        "saleor/checkout/payment_utils.py",
        "saleor/checkout/models.py",
        "saleor/checkout/fetch.py",
        "saleor/core/taxes.py",
        "saleor/checkout/base_calculations.py",
        "saleor/graphql/schema.graphql"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\tf6d2a71 (parent)\n+++ CHANGELOG.md\t940b8d8 (commit)\n@@ -135,8 +135,10 @@\n - Checkouts having total gross amount equal to 0 will get their authorization statuses updated to `CheckoutAuthorizeStatus.FULL` upon fetching checkout data.\n \n - Fixed a bug that could prevent rich text attributes written in scripts using combining diacritical marks (for example, Arabic) from being saved properly.\n \n+- Fixed a bug where a Checkout partially paid by Transaction(s) and partially paid by Gift Card(s) could not be completed due to `CHECKOUT_NOT_FULLY_PAID` error. Checkout authorize and charge statuses are now recalculcated more reliably. Status calculcation is now taking into account available gift cards balance.\n+\n ### Deprecations\n \n Following plugins are now marked as deprecated:\n \n"
        },
        {
          "path": "saleor/checkout/actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/actions.py\n===================================================================\n--- saleor/checkout/actions.py\tf6d2a71 (parent)\n+++ saleor/checkout/actions.py\t940b8d8 (commit)\n@@ -3,8 +3,9 @@\n from typing import TYPE_CHECKING, Optional, cast\n \n from django.utils import timezone\n \n+from ..core.taxes import zero_money\n from ..core.utils.events import (\n     call_event_including_protected_events,\n     webhook_async_event_requires_sync_webhooks_to_trigger,\n )\n@@ -240,9 +241,16 @@\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n     previous_charge_status = checkout_info.checkout.charge_status\n     previous_authorize_status = checkout_info.checkout.authorize_status\n \n-    current_total_gross = checkout_info.checkout.total.gross\n+    current_total_gross = (\n+        checkout_info.checkout.total.gross\n+        - checkout_info.checkout.get_total_gift_cards_balance()\n+    )\n+    current_total_gross = max(\n+        current_total_gross, zero_money(current_total_gross.currency)\n+    )\n+\n     update_checkout_payment_statuses(\n         checkout=checkout_info.checkout,\n         checkout_total_gross=current_total_gross,\n         checkout_has_lines=bool(lines),\n"
        },
        {
          "path": "saleor/checkout/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/calculations.py\n===================================================================\n--- saleor/checkout/calculations.py\tf6d2a71 (parent)\n+++ saleor/checkout/calculations.py\t940b8d8 (commit)\n@@ -801,9 +801,9 @@\n     changed as a result, it will update the payment statuses accordingly.\n     \"\"\"\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n-    previous_total_gross = checkout_info.checkout.total.gross\n+    previous_checkout_price_expiration = checkout_info.checkout.price_expiration\n     checkout_info, lines = _fetch_checkout_prices_if_expired(\n         checkout_info=checkout_info,\n         manager=manager,\n         lines=lines,\n@@ -814,9 +814,9 @@\n         allow_sync_webhooks=allow_sync_webhooks,\n     )\n     current_total_gross = checkout_info.checkout.total.gross\n     if (\n-        current_total_gross != previous_total_gross\n+        checkout_info.checkout.price_expiration != previous_checkout_price_expiration\n         or force_status_update\n         or (\n             # Checkout with total being zero is fully authorized therefore\n             # if authorized status was not yet updated, do it now.\n@@ -824,8 +824,17 @@\n             and checkout_info.checkout.authorize_status != CheckoutAuthorizeStatus.FULL\n             and bool(lines)\n         )\n     ):\n+        current_total_gross = (\n+            checkout_info.checkout.total.gross\n+            - checkout_info.checkout.get_total_gift_cards_balance(\n+                database_connection_name\n+            )\n+        )\n+        current_total_gross = max(\n+            current_total_gross, zero_money(current_total_gross.currency)\n+        )\n         update_checkout_payment_statuses(\n             checkout=checkout_info.checkout,\n             checkout_total_gross=current_total_gross,\n             checkout_has_lines=bool(lines),\n"
        },
        {
          "path": "saleor/checkout/tests/test_actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_actions.py\n===================================================================\n--- saleor/checkout/tests/test_actions.py\tf6d2a71 (parent)\n+++ saleor/checkout/tests/test_actions.py\t940b8d8 (commit)\n@@ -17,10 +17,11 @@\n     call_checkout_event,\n     call_checkout_events,\n     call_checkout_info_event,\n     transaction_amounts_for_checkout_updated,\n+    transaction_amounts_for_checkout_updated_without_price_recalculation,\n )\n-from ..calculations import fetch_checkout_data\n+from ..calculations import calculate_checkout_total, fetch_checkout_data\n from ..fetch import fetch_checkout_info, fetch_checkout_lines\n \n \n @patch(\"saleor.checkout.tasks.automatic_checkout_completion_task.delay\")\n@@ -1679,4 +1680,56 @@\n             ),\n             call(plugins_manager.checkout_updated, checkout_with_items, webhooks=set()),\n         ]\n     )\n+\n+\n+@pytest.mark.parametrize(\n+    (\"gift_card_balance\", \"expected_authorize_status\", \"expected_charge_status\"),\n+    [\n+        (0, CheckoutAuthorizeStatus.PARTIAL, CheckoutChargeStatus.PARTIAL),\n+        (10, CheckoutAuthorizeStatus.PARTIAL, CheckoutChargeStatus.PARTIAL),\n+        (20, CheckoutAuthorizeStatus.FULL, CheckoutChargeStatus.FULL),\n+        (40, CheckoutAuthorizeStatus.FULL, CheckoutChargeStatus.OVERCHARGED),\n+    ],\n+)\n+def test_transaction_amounts_for_checkout_updated_without_price_recalculation_considers_gift_cards_balance_when_updating_checkout_payment_status(\n+    checkout_with_gift_card,\n+    gift_card_balance,\n+    expected_authorize_status,\n+    expected_charge_status,\n+    transaction_item_generator,\n+):\n+    # given\n+    checkout = checkout_with_gift_card\n+    gift_card = checkout.gift_cards.first()\n+    gift_card.initial_balance_amount = Decimal(gift_card_balance)\n+    gift_card.current_balance_amount = Decimal(gift_card_balance)\n+    gift_card.save()\n+\n+    lines, _ = fetch_checkout_lines(checkout)\n+    manager = get_plugins_manager(allow_replica=False)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    address = checkout.shipping_address or checkout.billing_address\n+\n+    assert checkout.authorize_status == CheckoutAuthorizeStatus.NONE\n+    assert checkout.charge_status == CheckoutChargeStatus.NONE\n+\n+    transaction = transaction_item_generator(\n+        checkout_id=checkout.pk,\n+        charged_value=Decimal(10),\n+    )\n+\n+    total = calculate_checkout_total(\n+        manager=manager, checkout_info=checkout_info, lines=lines, address=address\n+    )\n+    assert total.gross.amount == Decimal(30)\n+\n+    # when\n+    transaction_amounts_for_checkout_updated_without_price_recalculation(\n+        transaction, checkout, manager, None, None\n+    )\n+\n+    # then\n+    checkout.refresh_from_db()\n+    assert checkout.authorize_status == expected_authorize_status\n+    assert checkout.charge_status == expected_charge_status\n"
        },
        {
          "path": "saleor/checkout/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_calculations.py\n===================================================================\n--- saleor/checkout/tests/test_calculations.py\tf6d2a71 (parent)\n+++ saleor/checkout/tests/test_calculations.py\t940b8d8 (commit)\n@@ -38,8 +38,9 @@\n from ..calculations import (\n     _apply_tax_data,\n     _calculate_and_add_tax,\n     _set_checkout_base_prices,\n+    calculate_checkout_total,\n     fetch_checkout_data,\n     logger,\n )\n from ..fetch import CheckoutLineInfo, fetch_checkout_info, fetch_checkout_lines\n@@ -1304,8 +1305,63 @@\n     assert checkout_with_item_total_0.authorize_status == CheckoutAuthorizeStatus.FULL\n     assert checkout_with_item_total_0.charge_status == CheckoutChargeStatus.FULL\n \n \n+@pytest.mark.parametrize(\n+    (\"gift_card_balance\", \"expected_authorize_status\", \"expected_charge_status\"),\n+    [\n+        (0, CheckoutAuthorizeStatus.PARTIAL, CheckoutChargeStatus.PARTIAL),\n+        (10, CheckoutAuthorizeStatus.PARTIAL, CheckoutChargeStatus.PARTIAL),\n+        (20, CheckoutAuthorizeStatus.FULL, CheckoutChargeStatus.FULL),\n+        (40, CheckoutAuthorizeStatus.FULL, CheckoutChargeStatus.OVERCHARGED),\n+    ],\n+)\n+def test_fetch_checkout_data_considers_gift_cards_balance_when_updating_checkout_payment_status(\n+    checkout_with_gift_card,\n+    gift_card_balance,\n+    expected_authorize_status,\n+    expected_charge_status,\n+    transaction_item_generator,\n+):\n+    # given\n+    checkout = checkout_with_gift_card\n+    gift_card = checkout.gift_cards.first()\n+    gift_card.initial_balance_amount = Decimal(gift_card_balance)\n+    gift_card.current_balance_amount = Decimal(gift_card_balance)\n+    gift_card.save()\n+\n+    lines, _ = fetch_checkout_lines(checkout)\n+    manager = get_plugins_manager(allow_replica=False)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    address = checkout.shipping_address or checkout.billing_address\n+\n+    assert checkout.authorize_status == CheckoutAuthorizeStatus.NONE\n+    assert checkout.charge_status == CheckoutChargeStatus.NONE\n+\n+    transaction_item_generator(\n+        checkout_id=checkout.pk,\n+        charged_value=Decimal(10),\n+    )\n+\n+    total = calculate_checkout_total(\n+        manager=manager, checkout_info=checkout_info, lines=lines, address=address\n+    )\n+    assert total.gross.amount == Decimal(30)\n+\n+    # when\n+    fetch_checkout_data(\n+        checkout_info=checkout_info,\n+        manager=manager,\n+        lines=lines,\n+        address=address,\n+    )\n+\n+    # then\n+    checkout.refresh_from_db()\n+    assert checkout.authorize_status == expected_authorize_status\n+    assert checkout.charge_status == expected_charge_status\n+\n+\n def test_fetch_checkout_data_checkout_removed_before_save(\n     checkout_with_prices,\n ):\n     # given\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\n===================================================================\n--- saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\tf6d2a71 (parent)\n+++ saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\t940b8d8 (commit)\n@@ -421,9 +421,9 @@\n             \"shippingAddress\": shipping_address,\n         }\n     }\n \n-    with django_assert_num_queries(84):\n+    with django_assert_num_queries(85):\n         response = api_client.post_graphql(query, variables)\n         assert get_graphql_content(response)[\"data\"][\"checkoutCreate\"]\n         assert Checkout.objects.first().lines.count() == 1\n \n@@ -439,9 +439,9 @@\n             \"shippingAddress\": shipping_address,\n         }\n     }\n \n-    with django_assert_num_queries(84):\n+    with django_assert_num_queries(85):\n         response = api_client.post_graphql(query, variables)\n         assert get_graphql_content(response)[\"data\"][\"checkoutCreate\"]\n         assert Checkout.objects.first().lines.count() == 10\n \n@@ -571,9 +571,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(90):\n+    with django_assert_num_queries(91):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_CREATE, variables)\n \n     # then\n     assert Checkout.objects.get().discounts.exists()\n@@ -827,9 +827,9 @@\n         reservation_length=5,\n     )\n \n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(106):\n+    with django_assert_num_queries(107):\n         variant_id = graphene.Node.to_global_id(\"ProductVariant\", variants[0].pk)\n         variables = {\n             \"id\": to_global_id_or_none(checkout),\n             \"lines\": [{\"quantity\": 3, \"variantId\": variant_id}],\n@@ -841,9 +841,9 @@\n         data = content[\"data\"][\"checkoutLinesUpdate\"]\n         assert not data[\"errors\"]\n \n     # Updating multiple lines in checkout has same query count as updating one\n-    with django_assert_num_queries(106):\n+    with django_assert_num_queries(107):\n         variables = {\n             \"id\": to_global_id_or_none(checkout),\n             \"lines\": [],\n         }\n@@ -1102,9 +1102,9 @@\n         new_lines.append({\"quantity\": 2, \"variantId\": variant_id})\n \n     user_api_client.ensure_access_token()\n     # Adding multiple lines to checkout has same query count as adding one\n-    with django_assert_num_queries(103):\n+    with django_assert_num_queries(104):\n         variables = {\n             \"id\": Node.to_global_id(\"Checkout\", checkout.pk),\n             \"lines\": [new_lines[0]],\n             \"channelSlug\": checkout.channel.slug,\n@@ -1115,9 +1115,9 @@\n         assert not data[\"errors\"]\n \n     checkout.lines.exclude(id=line.id).delete()\n \n-    with django_assert_num_queries(103):\n+    with django_assert_num_queries(104):\n         variables = {\n             \"id\": Node.to_global_id(\"Checkout\", checkout.pk),\n             \"lines\": new_lines,\n             \"channelSlug\": checkout.channel.slug,\n@@ -1166,9 +1166,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(94):\n+    with django_assert_num_queries(95):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     content = get_graphql_content(response)\n@@ -1252,9 +1252,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(94):\n+    with django_assert_num_queries(95):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     content = get_graphql_content(response)\n@@ -1288,9 +1288,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(100):\n+    with django_assert_num_queries(101):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     assert checkout.discounts.exists()\n@@ -1323,9 +1323,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(127):\n+    with django_assert_num_queries(128):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     assert checkout.lines.count() == 2\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\tf6d2a71 (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete_with_transactions.py\t940b8d8 (commit)\n@@ -155,13 +155,14 @@\n             total.gross.amount,\n         ],\n     )\n     recalculate_transaction_amounts(transaction)\n-    update_checkout_payment_statuses(\n-        checkout=checkout_info.checkout,\n-        checkout_total_gross=total.gross,\n-        checkout_has_lines=bool(lines),\n-    )\n+\n+    # Set price expiration to force payment status recalculcation upon fetching checkout\n+    # data.\n+    checkout.price_expiration = timezone.now()\n+    checkout.save()\n+\n     return checkout\n \n \n def test_checkout_without_any_transaction(\n@@ -1022,8 +1023,18 @@\n         shipping_method,\n         transaction_item_generator,\n         transaction_events_generator,\n     )\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    calculations.fetch_checkout_data(\n+        checkout_info,\n+        manager,\n+        lines,\n+    )\n+\n     Voucher.objects.all().delete()\n \n     redirect_url = \"https://www.example.com\"\n     variables = {\"id\": to_global_id_or_none(checkout), \"redirectUrl\": redirect_url}\n@@ -1057,8 +1068,18 @@\n         shipping_method,\n         transaction_item_generator,\n         transaction_events_generator,\n     )\n+\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    calculations.fetch_checkout_data(\n+        checkout_info,\n+        manager,\n+        lines,\n+    )\n+\n     code.is_active = False\n     code.save(update_fields=[\"is_active\"])\n \n     redirect_url = \"https://www.example.com\"\n@@ -1091,13 +1112,13 @@\n         shipping_method,\n         transaction_item_generator,\n         transaction_events_generator,\n     )\n+\n     checkout_line = checkout.lines.first()\n     stock = Stock.objects.get(product_variant=checkout_line.variant)\n-    quantity_available = get_available_quantity_for_stock(stock)\n-    checkout_line.quantity = quantity_available + 1\n-    checkout_line.save()\n+    stock.quantity = 0\n+    stock.save(update_fields=[\"quantity\"])\n \n     redirect_url = \"https://www.example.com\"\n     variables = {\"id\": to_global_id_or_none(checkout), \"redirectUrl\": redirect_url}\n \n@@ -3733,23 +3754,25 @@\n     transaction_events_generator,\n     transaction_item_generator,\n ):\n     # given\n+    checkout = checkout_with_item\n+    checkout_line = checkout.lines.first()\n+    stock = Stock.objects.get(product_variant=checkout_line.variant)\n+    quantity_available = get_available_quantity_for_stock(stock)\n+\n+    checkout_line.quantity = quantity_available\n+    checkout_line.save()\n+\n     checkout = prepare_checkout_for_test(\n         checkout_with_item,\n         address,\n         address,\n         shipping_method,\n         transaction_item_generator,\n         transaction_events_generator,\n     )\n-    checkout_line = checkout.lines.first()\n-    stock = Stock.objects.get(product_variant=checkout_line.variant)\n-    quantity_available = get_available_quantity_for_stock(stock)\n \n-    checkout_line.quantity = quantity_available\n-    checkout_line.save()\n-\n     reservation = Reservation.objects.create(\n         checkout_line=checkout_line,\n         stock=stock,\n         quantity_reserved=quantity_available,\n@@ -4088,25 +4111,27 @@\n     transaction_events_generator,\n     transaction_item_generator,\n ):\n     # given\n+    checkout = checkout_with_item_for_cc\n+    checkout_line = checkout.lines.first()\n+    stock = Stock.objects.get(product_variant=checkout_line.variant)\n+    quantity_available = get_available_quantity_for_stock(stock)\n+    checkout_line.quantity = quantity_available + 1\n+    checkout_line.save()\n+\n     checkout = prepare_checkout_for_test(\n         checkout_with_item_for_cc,\n         None,\n         address,\n         None,\n         transaction_item_generator,\n         transaction_events_generator,\n     )\n-    checkout_line = checkout.lines.first()\n-    stock = Stock.objects.get(product_variant=checkout_line.variant)\n-    quantity_available = get_available_quantity_for_stock(stock)\n-    checkout_line.quantity = quantity_available + 1\n-    checkout_line.save()\n \n     variables = {\n         \"id\": to_global_id_or_none(checkout),\n-        \"rediirectUrl\": \"https://www.example.com\",\n+        \"redirectUrl\": \"https://www.example.com\",\n     }\n \n     checkout.collection_point = warehouse_for_cc\n     checkout.save(\n@@ -4133,23 +4158,24 @@\n     transaction_events_generator,\n     transaction_item_generator,\n ):\n     # given\n+    checkout = checkout_with_item_for_cc\n+    checkout_line = checkout.lines.first()\n+    stock = Stock.objects.get(\n+        product_variant=checkout_line.variant, warehouse=warehouse_for_cc\n+    )\n+    quantity_available = get_available_quantity_for_stock(stock)\n+    checkout_line.quantity = quantity_available + 1\n+    checkout_line.save()\n     checkout = prepare_checkout_for_test(\n         checkout_with_item_for_cc,\n         None,\n         address,\n         None,\n         transaction_item_generator,\n         transaction_events_generator,\n     )\n-    checkout_line = checkout.lines.first()\n-    stock = Stock.objects.get(\n-        product_variant=checkout_line.variant, warehouse=warehouse_for_cc\n-    )\n-    quantity_available = get_available_quantity_for_stock(stock)\n-    checkout_line.quantity = quantity_available + 1\n-    checkout_line.save()\n \n     warehouse_for_cc.click_and_collect_option = (\n         WarehouseClickAndCollectOption.ALL_WAREHOUSES\n     )\n@@ -4181,24 +4207,25 @@\n     transaction_events_generator,\n     transaction_item_generator,\n ):\n     # given\n-    checkout = prepare_checkout_for_test(\n-        checkout_with_item_for_cc,\n-        None,\n-        address,\n-        None,\n-        transaction_item_generator,\n-        transaction_events_generator,\n-    )\n+    checkout = checkout_with_item_for_cc\n     checkout_line = checkout.lines.first()\n     overall_stock_quantity = (\n         Stock.objects.filter(product_variant=checkout_line.variant).aggregate(\n             Sum(\"quantity\")\n         )\n     ).pop(\"quantity__sum\")\n     checkout_line.quantity = overall_stock_quantity + 1\n     checkout_line.save()\n+    checkout = prepare_checkout_for_test(\n+        checkout_with_item_for_cc,\n+        None,\n+        address,\n+        None,\n+        transaction_item_generator,\n+        transaction_events_generator,\n+    )\n     warehouse_for_cc.click_and_collect_option = (\n         WarehouseClickAndCollectOption.ALL_WAREHOUSES\n     )\n     warehouse_for_cc.save()\n"
        },
        {
          "path": "saleor/order/tests/test_order_utils.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_order_utils.py\n===================================================================\n--- saleor/order/tests/test_order_utils.py\tf6d2a71 (parent)\n+++ saleor/order/tests/test_order_utils.py\t940b8d8 (commit)\n@@ -1,11 +1,14 @@\n+import datetime\n from decimal import Decimal\n \n import graphene\n import pytest\n+from django.utils import timezone\n from prices import Money, TaxedMoney\n \n from ...checkout.fetch import fetch_checkout_info, fetch_checkout_lines\n+from ...checkout.models import Checkout\n from ...discount import DiscountType, DiscountValueType\n from ...giftcard import GiftCardEvents\n from ...giftcard.models import GiftCardEvent\n from ...graphql.order.utils import OrderLineData\n@@ -453,8 +456,40 @@\n         },\n     }\n \n \n+def test_add_gift_cards_to_order_invalidates_prices_for_other_checkout_attached_to_the_same_gift_card(\n+    checkout_with_gift_card,\n+    gift_card,\n+    order,\n+    staff_user,\n+    channel_USD,\n+):\n+    # given\n+    checkout = checkout_with_gift_card\n+    assert gift_card in checkout.gift_cards.all()\n+    manager = get_plugins_manager(allow_replica=False)\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+\n+    other_checkout = Checkout.objects.create(\n+        currency=channel_USD.currency_code, channel=channel_USD\n+    )\n+    other_checkout.gift_cards.add(gift_card)\n+    initial_price_expiration = timezone.now() + datetime.timedelta(minutes=30)\n+    other_checkout.price_expiration = initial_price_expiration\n+    other_checkout.save(update_fields=[\"price_expiration\"])\n+\n+    # when\n+    add_gift_cards_to_order(\n+        checkout_info, order, Money(30, gift_card.currency), staff_user, None\n+    )\n+\n+    # then\n+    other_checkout.refresh_from_db()\n+    assert other_checkout.price_expiration != initial_price_expiration\n+\n+\n def test_get_total_order_discount_excluding_shipping(order, voucher_shipping_type):\n     # given\n     order.discounts.create(\n         type=DiscountType.VOUCHER,\n"
        },
        {
          "path": "saleor/order/utils.py",
          "status": "modified",
          "diff": "Index: saleor/order/utils.py\n===================================================================\n--- saleor/order/utils.py\tf6d2a71 (parent)\n+++ saleor/order/utils.py\t940b8d8 (commit)\n@@ -15,8 +15,9 @@\n \n from ..account.models import User\n from ..account.utils import store_user_address\n from ..checkout import AddressType\n+from ..checkout.models import Checkout\n from ..core.prices import quantize_price\n from ..core.taxes import zero_money\n from ..core.tracing import traced_atomic_transaction\n from ..core.utils.country import get_active_country\n@@ -495,8 +496,15 @@\n     ]\n     GiftCard.objects.bulk_update(gift_cards_to_update, update_fields)\n     gift_card_events.gift_cards_used_in_order_event(balance_data, order, user, app)\n \n+    # Invalidate prices for checkouts attached to gift cards used by this order.\n+    # This will ensure the checkout status gets recalculcated to accomodate gift cards\n+    # balance changes.\n+    Checkout.objects.filter(gift_cards__in=gift_cards_to_update).exclude(\n+        token=checkout_info.checkout.token\n+    ).update(price_expiration=timezone.now())\n+\n     gift_card_compensation = total_before_gift_card_compensation - total_price_left\n     if gift_card_compensation.amount > 0:\n         details = {\n             \"checkout_id\": graphene.Node.to_global_id(\n"
        },
        {
          "path": "saleor/tests/e2e/checkout/test_checkout_complete_with_gift_card_recalculcates_status_for_other_checkout.py",
          "status": "added",
          "diff": "Index: saleor/tests/e2e/checkout/test_checkout_complete_with_gift_card_recalculcates_status_for_other_checkout.py\n===================================================================\n--- saleor/tests/e2e/checkout/test_checkout_complete_with_gift_card_recalculcates_status_for_other_checkout.py\tf6d2a71 (parent)\n+++ saleor/tests/e2e/checkout/test_checkout_complete_with_gift_card_recalculcates_status_for_other_checkout.py\t940b8d8 (commit)\n@@ -0,0 +1,181 @@\n+import pytest\n+\n+from ..gift_cards.utils import create_gift_card\n+from ..product.utils.preparing_product import prepare_product\n+from ..shop.utils import prepare_shop\n+from ..utils import assign_permissions\n+from .utils import (\n+    checkout_add_promo_code,\n+    checkout_complete,\n+    checkout_create,\n+    checkout_delivery_method_update,\n+    get_checkout,\n+    raw_checkout_complete,\n+)\n+\n+\n+@pytest.mark.e2e\n+@pytest.mark.parametrize(\n+    \"query_second_checkout_status_before_checkout_complete\",\n+    [\n+        True,\n+        False,\n+    ],\n+)\n+def test_checkout_complete_with_gift_card_recalculcates_status_for_other_checkout(\n+    e2e_app_api_client,\n+    e2e_not_logged_api_client,\n+    permission_manage_product_types_and_attributes,\n+    permission_manage_orders,\n+    permission_manage_checkouts,\n+    permission_manage_gift_card,\n+    shop_permissions,\n+    query_second_checkout_status_before_checkout_complete,\n+):\n+    # Before\n+    permissions = [\n+        *shop_permissions,\n+        permission_manage_product_types_and_attributes,\n+        permission_manage_orders,\n+        permission_manage_checkouts,\n+        permission_manage_gift_card,\n+    ]\n+    assign_permissions(e2e_app_api_client, permissions)\n+\n+    shop_data, _ = prepare_shop(\n+        e2e_app_api_client,\n+        channels=[\n+            {\n+                \"shipping_zones\": [\n+                    {\n+                        \"shipping_methods\": [{}],\n+                    },\n+                ],\n+                \"order_settings\": {\n+                    \"allowUnpaidOrders\": False,\n+                    \"markAsPaidStrategy\": \"TRANSACTION_FLOW\",\n+                },\n+            }\n+        ],\n+    )\n+    channel_id = shop_data[0][\"id\"]\n+    channel_slug = shop_data[0][\"slug\"]\n+    warehouse_id = shop_data[0][\"warehouse_id\"]\n+    shipping_method_id = shop_data[0][\"shipping_zones\"][0][\"shipping_methods\"][0][\"id\"]\n+\n+    variant_price = 10\n+\n+    (\n+        _,\n+        product_variant_id,\n+        _,\n+    ) = prepare_product(\n+        e2e_app_api_client,\n+        warehouse_id,\n+        channel_id,\n+        variant_price,\n+    )\n+\n+    assert shipping_method_id is not None\n+\n+    gift_card = create_gift_card(e2e_app_api_client, 20, \"USD\", active=True)\n+    gift_card_code = gift_card[\"code\"]\n+    gift_card_id = gift_card[\"id\"]\n+\n+    # Step 1 - Create first checkout\n+    lines = [\n+        {\"variantId\": product_variant_id, \"quantity\": 1},\n+    ]\n+    checkout_data = checkout_create(\n+        e2e_not_logged_api_client,\n+        lines,\n+        channel_slug,\n+        email=\"testEmail@example.com\",\n+    )\n+    first_checkout_id = checkout_data[\"id\"]\n+\n+    # Step 2 - Update delivery method for first checkout\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_not_logged_api_client,\n+        first_checkout_id,\n+        shipping_method_id,\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n+\n+    # Step 3 - Add gift card to first checkout\n+    checkout_data = checkout_add_promo_code(\n+        e2e_not_logged_api_client,\n+        first_checkout_id,\n+        gift_card_code,\n+    )\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    assert total_gross_amount == 0\n+    assert checkout_data[\"giftCards\"][0][\"id\"] == gift_card_id\n+    assert checkout_data[\"giftCards\"][0][\"last4CodeChars\"] == gift_card_code[-4:]\n+\n+    # Step 4 - Check first checkout status\n+    checkout_data = get_checkout(e2e_not_logged_api_client, first_checkout_id)\n+    assert checkout_data[\"authorizeStatus\"] == \"FULL\"\n+    assert checkout_data[\"chargeStatus\"] == \"FULL\"\n+\n+    # Step 5 - Create second checkout\n+    lines = [\n+        {\"variantId\": product_variant_id, \"quantity\": 1},\n+    ]\n+    checkout_data = checkout_create(\n+        e2e_not_logged_api_client,\n+        lines,\n+        channel_slug,\n+        email=\"testEmail@example.com\",\n+    )\n+    second_checkout_id = checkout_data[\"id\"]\n+\n+    # Step 6 - Update delivery method for second checkout\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_not_logged_api_client,\n+        second_checkout_id,\n+        shipping_method_id,\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n+\n+    # Step 7 - Add gift card to second checkout\n+    checkout_data = checkout_add_promo_code(\n+        e2e_not_logged_api_client,\n+        second_checkout_id,\n+        gift_card_code,\n+    )\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    assert total_gross_amount == 0\n+    assert checkout_data[\"giftCards\"][0][\"id\"] == gift_card_id\n+    assert checkout_data[\"giftCards\"][0][\"last4CodeChars\"] == gift_card_code[-4:]\n+\n+    # Step 8 - Check second checkout status\n+    checkout_data = get_checkout(e2e_not_logged_api_client, second_checkout_id)\n+    assert checkout_data[\"authorizeStatus\"] == \"FULL\"\n+    assert checkout_data[\"chargeStatus\"] == \"FULL\"\n+\n+    # Step 9 - Complete first checkout\n+    order_data = checkout_complete(\n+        e2e_not_logged_api_client,\n+        first_checkout_id,\n+    )\n+    assert order_data[\"id\"] is not None\n+\n+    # # Step 10 - Check second checkout status once again\n+    if query_second_checkout_status_before_checkout_complete:\n+        checkout_data = get_checkout(e2e_not_logged_api_client, second_checkout_id)\n+        assert checkout_data[\"authorizeStatus\"] == \"NONE\"\n+        assert checkout_data[\"chargeStatus\"] == \"NONE\"\n+\n+    # Step 11 - Attempt to complete second checkout\n+    response = raw_checkout_complete(\n+        e2e_not_logged_api_client,\n+        second_checkout_id,\n+    )\n+    errors = response[\"errors\"]\n+    assert len(errors) == 1\n+    assert errors[0] == {\n+        \"code\": \"CHECKOUT_NOT_FULLY_PAID\",\n+        \"field\": None,\n+        \"message\": \"Provided payment methods can not cover the checkout's total amount\",\n+    }\n"
        },
        {
          "path": "saleor/tests/e2e/checkout/test_checkout_complete_with_transaction_and_gift_card.py",
          "status": "added",
          "diff": "Index: saleor/tests/e2e/checkout/test_checkout_complete_with_transaction_and_gift_card.py\n===================================================================\n--- saleor/tests/e2e/checkout/test_checkout_complete_with_transaction_and_gift_card.py\tf6d2a71 (parent)\n+++ saleor/tests/e2e/checkout/test_checkout_complete_with_transaction_and_gift_card.py\t940b8d8 (commit)\n@@ -0,0 +1,371 @@\n+import pytest\n+\n+from ..gift_cards.utils import create_gift_card\n+from ..orders.utils import order_query\n+from ..product.utils.preparing_product import prepare_product\n+from ..shop.utils import prepare_shop\n+from ..transactions.utils import create_transaction\n+from ..utils import assign_permissions\n+from .utils import (\n+    checkout_add_promo_code,\n+    checkout_complete,\n+    checkout_create,\n+    checkout_delivery_method_update,\n+)\n+\n+\n+@pytest.mark.e2e\n+def test_checkout_complete_with_transaction_and_gift_card(\n+    e2e_app_api_client,\n+    e2e_not_logged_api_client,\n+    permission_manage_product_types_and_attributes,\n+    permission_manage_orders,\n+    permission_manage_checkouts,\n+    permission_manage_payments,\n+    permission_manage_gift_card,\n+    shop_permissions,\n+):\n+    # Before\n+    permissions = [\n+        *shop_permissions,\n+        permission_manage_product_types_and_attributes,\n+        permission_manage_orders,\n+        permission_manage_checkouts,\n+        permission_manage_payments,\n+        permission_manage_gift_card,\n+    ]\n+    assign_permissions(e2e_app_api_client, permissions)\n+\n+    shop_data, _ = prepare_shop(\n+        e2e_app_api_client,\n+        channels=[\n+            {\n+                \"shipping_zones\": [\n+                    {\n+                        \"shipping_methods\": [{}],\n+                    },\n+                ],\n+                \"order_settings\": {\n+                    \"allowUnpaidOrders\": False,\n+                    \"markAsPaidStrategy\": \"TRANSACTION_FLOW\",\n+                },\n+            }\n+        ],\n+    )\n+    channel_id = shop_data[0][\"id\"]\n+    channel_slug = shop_data[0][\"slug\"]\n+    warehouse_id = shop_data[0][\"warehouse_id\"]\n+    shipping_method_id = shop_data[0][\"shipping_zones\"][0][\"shipping_methods\"][0][\"id\"]\n+\n+    variant_price = 10\n+\n+    (\n+        _,\n+        product_variant_id,\n+        _,\n+    ) = prepare_product(\n+        e2e_app_api_client,\n+        warehouse_id,\n+        channel_id,\n+        variant_price,\n+    )\n+\n+    assert shipping_method_id is not None\n+\n+    gift_card = create_gift_card(e2e_app_api_client, 100, \"USD\", active=True)\n+    gift_card_code = gift_card[\"code\"]\n+    gift_card_id = gift_card[\"id\"]\n+\n+    # Step 1 - Create checkout\n+    lines = [\n+        {\"variantId\": product_variant_id, \"quantity\": 1},\n+    ]\n+    checkout_data = checkout_create(\n+        e2e_not_logged_api_client,\n+        lines,\n+        channel_slug,\n+        email=\"testEmail@example.com\",\n+    )\n+    checkout_id = checkout_data[\"id\"]\n+\n+    subtotal_gross_amount = checkout_data[\"subtotalPrice\"][\"gross\"][\"amount\"]\n+    assert subtotal_gross_amount == float(variant_price)\n+\n+    # Step 2 - Update delivery method\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+        shipping_method_id,\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    shipping_price = checkout_data[\"deliveryMethod\"][\"price\"][\"amount\"]\n+    assert shipping_price == 10\n+    assert total_gross_amount == subtotal_gross_amount + shipping_price\n+    assert checkout_data[\"chargeStatus\"] == \"NONE\"\n+    assert checkout_data[\"authorizeStatus\"] == \"NONE\"\n+\n+    # Step 3 - Create transaction that partially authorize payment\n+    create_transaction(\n+        e2e_app_api_client,\n+        checkout_id,\n+        transaction_name=\"transaction\",\n+        psp_reference=\"PSP-test\",\n+        available_actions=[\"CHARGE\", \"CANCEL\"],\n+        amount_authorized=subtotal_gross_amount,\n+    )\n+\n+    # Step 4 - Add gift card to checkout\n+    checkout_data = checkout_add_promo_code(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+        gift_card_code,\n+    )\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    assert total_gross_amount == 0\n+    assert checkout_data[\"giftCards\"][0][\"id\"] == gift_card_id\n+    assert checkout_data[\"giftCards\"][0][\"last4CodeChars\"] == gift_card_code[-4:]\n+\n+    # Step 5 - Complete checkout.\n+    order_data = checkout_complete(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+    )\n+    assert order_data[\"status\"] == \"UNFULFILLED\"\n+    assert order_data[\"total\"][\"gross\"][\"amount\"] == 0\n+\n+\n+@pytest.mark.e2e\n+def test_checkout_complete_with_gift_card_and_transaction(\n+    e2e_app_api_client,\n+    e2e_not_logged_api_client,\n+    permission_manage_product_types_and_attributes,\n+    permission_manage_orders,\n+    permission_manage_checkouts,\n+    permission_manage_payments,\n+    permission_manage_gift_card,\n+    shop_permissions,\n+):\n+    # Before\n+    permissions = [\n+        *shop_permissions,\n+        permission_manage_product_types_and_attributes,\n+        permission_manage_orders,\n+        permission_manage_checkouts,\n+        permission_manage_payments,\n+        permission_manage_gift_card,\n+    ]\n+    assign_permissions(e2e_app_api_client, permissions)\n+\n+    shop_data, _ = prepare_shop(\n+        e2e_app_api_client,\n+        channels=[\n+            {\n+                \"shipping_zones\": [\n+                    {\n+                        \"shipping_methods\": [{}],\n+                    },\n+                ],\n+                \"order_settings\": {\n+                    \"allowUnpaidOrders\": False,\n+                    \"markAsPaidStrategy\": \"TRANSACTION_FLOW\",\n+                },\n+            }\n+        ],\n+    )\n+    channel_id = shop_data[0][\"id\"]\n+    channel_slug = shop_data[0][\"slug\"]\n+    warehouse_id = shop_data[0][\"warehouse_id\"]\n+    shipping_method_id = shop_data[0][\"shipping_zones\"][0][\"shipping_methods\"][0][\"id\"]\n+\n+    variant_price = 10\n+\n+    (\n+        _,\n+        product_variant_id,\n+        _,\n+    ) = prepare_product(\n+        e2e_app_api_client,\n+        warehouse_id,\n+        channel_id,\n+        variant_price,\n+    )\n+\n+    assert shipping_method_id is not None\n+\n+    gift_card = create_gift_card(e2e_app_api_client, 100, \"USD\", active=True)\n+    gift_card_code = gift_card[\"code\"]\n+    gift_card_id = gift_card[\"id\"]\n+\n+    # Step 1 - Create checkout\n+    lines = [\n+        {\"variantId\": product_variant_id, \"quantity\": 1},\n+    ]\n+    checkout_data = checkout_create(\n+        e2e_not_logged_api_client,\n+        lines,\n+        channel_slug,\n+        email=\"testEmail@example.com\",\n+    )\n+    checkout_id = checkout_data[\"id\"]\n+\n+    subtotal_gross_amount = checkout_data[\"subtotalPrice\"][\"gross\"][\"amount\"]\n+    assert subtotal_gross_amount == float(variant_price)\n+\n+    # Step 2 - Update delivery method\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+        shipping_method_id,\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    shipping_price = checkout_data[\"deliveryMethod\"][\"price\"][\"amount\"]\n+    assert shipping_price == 10\n+    assert total_gross_amount == subtotal_gross_amount + shipping_price\n+    assert checkout_data[\"chargeStatus\"] == \"NONE\"\n+    assert checkout_data[\"authorizeStatus\"] == \"NONE\"\n+\n+    # Step 3 - Add gift card to checkout\n+    checkout_data = checkout_add_promo_code(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+        gift_card_code,\n+    )\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    assert total_gross_amount == 0\n+    assert checkout_data[\"giftCards\"][0][\"id\"] == gift_card_id\n+    assert checkout_data[\"giftCards\"][0][\"last4CodeChars\"] == gift_card_code[-4:]\n+\n+    # Step 4 - Create transaction that partially authorize payment\n+    create_transaction(\n+        e2e_app_api_client,\n+        checkout_id,\n+        transaction_name=\"transaction\",\n+        psp_reference=\"PSP-test\",\n+        available_actions=[\"CHARGE\", \"CANCEL\"],\n+        amount_authorized=subtotal_gross_amount,\n+    )\n+\n+    # Step 5 - Complete checkout.\n+    order_data = checkout_complete(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+    )\n+    assert order_data[\"status\"] == \"UNFULFILLED\"\n+    assert order_data[\"total\"][\"gross\"][\"amount\"] == 0\n+\n+\n+@pytest.mark.e2e\n+def test_checkout_complete_with_only_gift_card(\n+    e2e_app_api_client,\n+    e2e_not_logged_api_client,\n+    permission_manage_product_types_and_attributes,\n+    permission_manage_orders,\n+    permission_manage_checkouts,\n+    permission_manage_payments,\n+    permission_manage_gift_card,\n+    shop_permissions,\n+):\n+    # Before\n+    permissions = [\n+        *shop_permissions,\n+        permission_manage_product_types_and_attributes,\n+        permission_manage_orders,\n+        permission_manage_checkouts,\n+        permission_manage_payments,\n+        permission_manage_gift_card,\n+    ]\n+    assign_permissions(e2e_app_api_client, permissions)\n+\n+    shop_data, _ = prepare_shop(\n+        e2e_app_api_client,\n+        channels=[\n+            {\n+                \"shipping_zones\": [\n+                    {\n+                        \"shipping_methods\": [{}],\n+                    },\n+                ],\n+                \"order_settings\": {\n+                    \"allowUnpaidOrders\": False,\n+                    \"markAsPaidStrategy\": \"TRANSACTION_FLOW\",\n+                },\n+            }\n+        ],\n+    )\n+    channel_id = shop_data[0][\"id\"]\n+    channel_slug = shop_data[0][\"slug\"]\n+    warehouse_id = shop_data[0][\"warehouse_id\"]\n+    shipping_method_id = shop_data[0][\"shipping_zones\"][0][\"shipping_methods\"][0][\"id\"]\n+\n+    variant_price = 10\n+\n+    (\n+        _,\n+        product_variant_id,\n+        _,\n+    ) = prepare_product(\n+        e2e_app_api_client,\n+        warehouse_id,\n+        channel_id,\n+        variant_price,\n+    )\n+\n+    assert shipping_method_id is not None\n+\n+    gift_card = create_gift_card(e2e_app_api_client, 100, \"USD\", active=True)\n+    gift_card_code = gift_card[\"code\"]\n+    gift_card_id = gift_card[\"id\"]\n+\n+    # Step 1 - Create checkout\n+    lines = [\n+        {\"variantId\": product_variant_id, \"quantity\": 1},\n+    ]\n+    checkout_data = checkout_create(\n+        e2e_not_logged_api_client,\n+        lines,\n+        channel_slug,\n+        email=\"testEmail@example.com\",\n+    )\n+    checkout_id = checkout_data[\"id\"]\n+\n+    subtotal_gross_amount = checkout_data[\"subtotalPrice\"][\"gross\"][\"amount\"]\n+    assert subtotal_gross_amount == float(variant_price)\n+\n+    # Step 2 - Update delivery method\n+    checkout_data = checkout_delivery_method_update(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+        shipping_method_id,\n+    )\n+    assert checkout_data[\"deliveryMethod\"][\"id\"] == shipping_method_id\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    shipping_price = checkout_data[\"deliveryMethod\"][\"price\"][\"amount\"]\n+    assert shipping_price == 10\n+    assert total_gross_amount == subtotal_gross_amount + shipping_price\n+    assert checkout_data[\"chargeStatus\"] == \"NONE\"\n+    assert checkout_data[\"authorizeStatus\"] == \"NONE\"\n+\n+    # Step 3 - Add gift card to checkout\n+    checkout_data = checkout_add_promo_code(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+        gift_card_code,\n+    )\n+    total_gross_amount = checkout_data[\"totalPrice\"][\"gross\"][\"amount\"]\n+    assert total_gross_amount == 0\n+    assert checkout_data[\"giftCards\"][0][\"id\"] == gift_card_id\n+    assert checkout_data[\"giftCards\"][0][\"last4CodeChars\"] == gift_card_code[-4:]\n+\n+    # Step 4 - Complete checkout.\n+    order_data = checkout_complete(\n+        e2e_not_logged_api_client,\n+        checkout_id,\n+    )\n+    assert order_data[\"status\"] == \"UNCONFIRMED\"\n+    assert order_data[\"total\"][\"gross\"][\"amount\"] == 0\n+\n+    # Step 5 - Check order status\n+    order_data = order_query(e2e_app_api_client, order_data[\"id\"])\n+    assert order_data[\"status\"] == \"UNFULFILLED\"\n"
        },
        {
          "path": "saleor/tests/e2e/checkout/utils/query_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/checkout/utils/query_checkout.py\n===================================================================\n--- saleor/tests/e2e/checkout/utils/query_checkout.py\tf6d2a71 (parent)\n+++ saleor/tests/e2e/checkout/utils/query_checkout.py\t940b8d8 (commit)\n@@ -51,8 +51,10 @@\n       gross {\n         amount\n       }\n     }\n+    authorizeStatus\n+    chargeStatus\n   }\n }\n \"\"\"\n \n"
        },
        {
          "path": "saleor/tests/e2e/checkout/zero_total/test_pay_for_total_checkout_with_gift_card.py",
          "status": "modified",
          "diff": "Index: saleor/tests/e2e/checkout/zero_total/test_pay_for_total_checkout_with_gift_card.py\n===================================================================\n--- saleor/tests/e2e/checkout/zero_total/test_pay_for_total_checkout_with_gift_card.py\tf6d2a71 (parent)\n+++ saleor/tests/e2e/checkout/zero_total/test_pay_for_total_checkout_with_gift_card.py\t940b8d8 (commit)\n@@ -1,8 +1,9 @@\n import pytest\n \n from ...channel.utils import update_channel\n from ...gift_cards.utils import create_gift_card\n+from ...orders.utils.order_query import order_query\n from ...product.utils.preparing_product import prepare_products\n from ...shop.utils.preparing_shop import prepare_default_shop\n from ...utils import assign_permissions\n from ..utils import (\n@@ -27,15 +28,17 @@\n     e2e_staff_api_client,\n     shop_permissions,\n     permission_manage_product_types_and_attributes,\n     permission_manage_gift_card,\n+    permission_manage_orders,\n     mark_as_paid_strategy,\n ):\n     # Before\n     permissions = [\n         *shop_permissions,\n         permission_manage_product_types_and_attributes,\n         permission_manage_gift_card,\n+        permission_manage_orders,\n     ]\n     assign_permissions(e2e_staff_api_client, permissions)\n \n     shop_data = prepare_default_shop(e2e_staff_api_client)\n@@ -140,8 +143,12 @@\n     order_data = checkout_complete(\n         e2e_logged_api_client,\n         checkout_id,\n     )\n-    assert order_data[\"status\"] == \"UNFULFILLED\"\n+    assert order_data[\"status\"] == \"UNCONFIRMED\"\n     assert order_data[\"total\"][\"gross\"][\"amount\"] == 0\n     assert order_data[\"giftCards\"][0][\"id\"] == gift_card_id\n     assert order_data[\"giftCards\"][0][\"last4CodeChars\"] == gift_card_code[-4:]\n+\n+    # Step 5 - Check order status\n+    order_data = order_query(e2e_staff_api_client, order_data[\"id\"])\n+    assert order_data[\"status\"] == \"UNFULFILLED\"\n"
        }
      ]
    },
    {
      "id": "fix-transaction-race",
      "sha": "ccd3960acd1d058528d9796c2b9ff096f28d848e",
      "parentSha": "43f5ba1b48e59ef66cf2fe4f490b45e61aaa7222",
      "spec": "Implement lock-safe transaction event processing and handle checkout/order race conditions as follows:\n\n1) saleor/checkout/actions.py\n- Update imports to include update_checkout_payment_statuses from .payment_utils.\n- Refactor transaction_amounts_for_checkout_updated(transaction, manager, user, app) to delegate business logic to a new private helper, after computing previous statuses and calling fetch_checkout_data with force_status_update=True:\n  - Add: _transaction_amounts_for_checkout_updated(transaction, previous_charge_status, previous_authorize_status, checkout_info, lines, manager, user, app), which encapsulates the existing logic from transaction_amounts_for_checkout_updated (including triggering CHECKOUT_FULLY_PAID events, setting last_transaction_modified_at, updating automatically_refundable, and scheduling automatic checkout completion when Fully Authorized and channel allows). Import automatic_checkout_completion_task lazily inside this helper to avoid import cycles.\n- Add: transaction_amounts_for_checkout_updated_without_price_recalculation(transaction, checkout, manager, user, app):\n  - Fetch lines and checkout_info for the provided checkout.\n  - Store previous charge/authorize statuses.\n  - Without recalculating prices, update checkout charge/authorize statuses by calling update_checkout_payment_statuses(checkout=checkout_info.checkout, checkout_total_gross=checkout_info.checkout.total.gross, checkout_has_lines=bool(lines)).\n  - Call _transaction_amounts_for_checkout_updated with the captured previous statuses and fetched checkout_info/lines.\n\n2) saleor/graphql/payment/mutations/transaction/transaction_event_report.py\n- Update imports: add from decimal import Decimal; import Checkout model from .....checkout.models. If type-checking is used, ensure User typing is imported as needed; keep get_plugin_manager_promise usage consistent.\n- Add on TransactionEventReport class the following classmethods:\n  a) process_order_with_transaction(transaction, manager, user, app, previous_authorized_value, previous_charged_value, previous_refunded_value, related_granted_refund):\n     - Inside a traced_atomic_transaction: lock and refresh the Order (prefetch payments, payment_transactions, granted_refunds and select_for_update), lock the TransactionItem row (select_for_update(of=(\"self\",))), and call updates_amounts_for_order(order).\n     - After commit: call update_order_search_vector(order), then build order_info via fetch_order_info(order), and call order_transaction_updated(order_info=..., transaction_item=transaction, manager=manager, user=user, app=app, previous_authorized_value=..., previous_charged_value=..., previous_refunded_value=...). If related_granted_refund is provided, call calculate_order_granted_refund_status.\n  b) process_order_or_checkout_with_transaction(transaction, manager, user, app, previous_authorized_value, previous_charged_value, previous_refunded_value, related_granted_refund):\n     - Initialize checkout_deleted=False. If transaction.checkout_id is set, within a traced_atomic_transaction: select_for_update the Checkout row (by pk) and re-lock the TransactionItem row. If the checkout row exists, call transaction_amounts_for_checkout_updated_without_price_recalculation(transaction, locked_checkout, manager, user, app). If it does not exist (because the checkout was converted to order concurrently), set checkout_deleted=True.\n     - If transaction.order_id is set or checkout_deleted is True, call process_order_with_transaction with the same arguments.\n- In perform_mutation, after saving the new/updated TransactionEvent and calling cls.update_transaction(...), replace the previous inline order/checkout update logic with a single call to cls.process_order_or_checkout_with_transaction(transaction, manager, user, app, previous_authorized_value, previous_charged_value, previous_refunded_value, related_granted_refund).\n\n3) saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\n- Import additional modules used by new tests: from django.db import transaction as database_transaction; from psycopg.errors import QueryCanceled; from .....tests import race_condition; from .....checkout.complete_checkout import create_order_from_checkout.\n- Adjust the existing test_transaction_event_updates_checkout_payment_statuses to fetch checkout lines and info and call fetch_checkout_data prior to reporting the event (to ensure totals are current).\n- Add new tests to verify locking and race safety:\n  a) test_lock_order_during_updating_order_amounts (pytest.mark.django_db(transaction=True)): set up an order and transaction; hook race_condition.RunBefore(\"saleor.order.utils.update_order_charge_data\", check_if_order_is_locked) where check_if_order_is_locked opens a new DB connection and attempts to SELECT ... FOR UPDATE on the same order id with a very short statement_timeout, asserting QueryCanceled. Run the mutation CHARGE_SUCCESS and expect the lock to be held.\n  b) test_lock_checkout_during_updating_checkout_amounts (pytest.mark.django_db(transaction=True)): prepare a checkout, precompute totals via fetch_checkout_data, and hook race_condition.RunBefore(\"saleor.graphql.payment.mutations.transaction.transaction_event_report.transaction_amounts_for_checkout_updated_without_price_recalculation\", check_if_checkout_is_locked). In the hook, open a new DB connection and attempt to SELECT ... FOR UPDATE the same checkout row with a short statement_timeout, asserting QueryCanceled. Run the mutation and validate it completes.\n  c) test_transaction_event_report_checkout_completed_race_condition: prepare checkout totals; hook race_condition.RunBefore(\"saleor.graphql.payment.mutations.transaction.transaction_event_report.recalculate_transaction_amounts\", complete_checkout) where complete_checkout calls create_order_from_checkout(checkout_info, plugins_manager, user=None, app=app_api_client.app). After mutation CHARGE_SUCCESS, assert the order created from the checkout (Order.objects.get(checkout_token=checkout.pk)) is UNFULFILLED, fully charged, and total_charged equals the original checkout total gross amount.\n\nNotes and constraints:\n- Ensure the checkout fully-paid/fully-authorized webhook and automatic completion logic remains intact via the shared _transaction_amounts_for_checkout_updated helper.\n- Maintain existing behavior for updating refundable status and last_transaction_modified_at.\n- Use select_for_update locks exactly where specified to satisfy the new lock tests.\n- Do not recalculate checkout prices inside transaction_amounts_for_checkout_updated_without_price_recalculation; only update payment statuses using current totals and transaction values.\n- Preserve all existing semantics for permissions, error handling, metadata updates, and event save paths in the mutation.",
      "prompt": "The transaction event reporting flow must be made safe under concurrent checkout completion. Update the checkout actions to support updating payment/authorization statuses without recalculating prices, and refactor the transaction event GraphQL mutation to acquire row locks and handle both checkout and order updates, even if the checkout is converted to an order during processing. Add tests that prove the order and checkout rows are locked while amounts are being updated and that the mutation correctly updates the order when a checkout completes mid-flight. Keep existing webhook calls and automatic completion behavior unchanged. Implement this end-to-end with clear separation of responsibilities between checkout actions and the mutation.",
      "supplementalFiles": [
        "saleor/checkout/payment_utils.py",
        "saleor/checkout/complete_checkout.py",
        "saleor/checkout/tasks.py",
        "saleor/order/utils.py",
        "saleor/order/actions.py",
        "saleor/payment/transaction_item_calculations.py",
        "saleor/tests/race_condition.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/actions.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/actions.py\n===================================================================\n--- saleor/checkout/actions.py\t43f5ba1 (parent)\n+++ saleor/checkout/actions.py\tccd3960 (commit)\n@@ -19,9 +19,12 @@\n     fetch_checkout_info,\n     fetch_checkout_lines,\n )\n from .models import Checkout\n-from .payment_utils import update_refundable_for_checkout\n+from .payment_utils import (\n+    update_checkout_payment_statuses,\n+    update_refundable_for_checkout,\n+)\n \n if TYPE_CHECKING:\n     from ..account.models import Address, User\n     from ..app.models import App\n@@ -205,18 +208,73 @@\n     manager: \"PluginsManager\",\n     user: Optional[\"User\"],\n     app: Optional[\"App\"],\n ):\n-    from .tasks import automatic_checkout_completion_task\n-\n     if not transaction.checkout_id:\n         return\n     checkout = cast(Checkout, transaction.checkout)\n     lines, _ = fetch_checkout_lines(checkout)\n     checkout_info = fetch_checkout_info(checkout, lines, manager)\n     previous_charge_status = checkout_info.checkout.charge_status\n     previous_authorize_status = checkout_info.checkout.authorize_status\n     fetch_checkout_data(checkout_info, manager, lines, force_status_update=True)\n+    _transaction_amounts_for_checkout_updated(\n+        transaction,\n+        previous_charge_status,\n+        previous_authorize_status,\n+        checkout_info,\n+        lines,\n+        manager,\n+        user,\n+        app,\n+    )\n+\n+\n+def transaction_amounts_for_checkout_updated_without_price_recalculation(\n+    transaction: TransactionItem,\n+    checkout: Checkout,\n+    manager: \"PluginsManager\",\n+    user: Optional[\"User\"],\n+    app: Optional[\"App\"],\n+):\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    previous_charge_status = checkout_info.checkout.charge_status\n+    previous_authorize_status = checkout_info.checkout.authorize_status\n+\n+    current_total_gross = checkout_info.checkout.total.gross\n+    update_checkout_payment_statuses(\n+        checkout=checkout_info.checkout,\n+        checkout_total_gross=current_total_gross,\n+        checkout_has_lines=bool(lines),\n+    )\n+\n+    _transaction_amounts_for_checkout_updated(\n+        transaction,\n+        previous_charge_status,\n+        previous_authorize_status,\n+        checkout_info,\n+        lines,\n+        manager,\n+        user,\n+        app,\n+    )\n+\n+\n+def _transaction_amounts_for_checkout_updated(\n+    transaction: TransactionItem,\n+    previous_charge_status: str,\n+    previous_authorize_status: str,\n+    checkout_info: CheckoutInfo,\n+    lines: list[CheckoutLineInfo],\n+    manager: \"PluginsManager\",\n+    user: Optional[\"User\"],\n+    app: Optional[\"App\"],\n+):\n+    from .tasks import automatic_checkout_completion_task\n+\n+    checkout = checkout_info.checkout\n+\n     previous_charge_status_is_fully_paid = previous_charge_status in [\n         CheckoutChargeStatus.FULL,\n         CheckoutChargeStatus.OVERCHARGED,\n     ]\n"
        },
        {
          "path": "saleor/graphql/payment/mutations/transaction/transaction_event_report.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/mutations/transaction/transaction_event_report.py\n===================================================================\n--- saleor/graphql/payment/mutations/transaction/transaction_event_report.py\t43f5ba1 (parent)\n+++ saleor/graphql/payment/mutations/transaction/transaction_event_report.py\tccd3960 (commit)\n@@ -1,12 +1,16 @@\n+from decimal import Decimal\n from typing import TYPE_CHECKING, Optional, cast\n \n import graphene\n from django.core.exceptions import ValidationError\n from django.utils import timezone\n \n from .....app.models import App\n-from .....checkout.actions import transaction_amounts_for_checkout_updated\n+from .....checkout.actions import (\n+    transaction_amounts_for_checkout_updated_without_price_recalculation,\n+)\n+from .....checkout.models import Checkout\n from .....core.exceptions import PermissionDenied\n from .....core.prices import quantize_price\n from .....core.tracing import traced_atomic_transaction\n from .....core.utils.events import call_event\n@@ -48,8 +52,9 @@\n from ...utils import check_if_requestor_has_access\n from .utils import get_transaction_item\n \n if TYPE_CHECKING:\n+    from .....accounts.models import User\n     from .....plugins.manager import PluginsManager\n \n \n class TransactionEventReport(DeprecatedModelMutation):\n@@ -272,8 +277,90 @@\n                 ) from e\n         return quantize_price(amount, currency)\n \n     @classmethod\n+    def process_order_with_transaction(\n+        cls,\n+        transaction: payment_models.TransactionItem,\n+        manager: \"PluginsManager\",\n+        user: Optional[\"User\"],\n+        app: App | None,\n+        previous_authorized_value: Decimal,\n+        previous_charged_value: Decimal,\n+        previous_refunded_value: Decimal,\n+        related_granted_refund: order_models.OrderGrantedRefund | None,\n+    ):\n+        order = cast(order_models.Order, transaction.order)\n+        with traced_atomic_transaction():\n+            order = (\n+                order_models.Order.objects.prefetch_related(\n+                    \"payments\", \"payment_transactions\", \"granted_refunds\"\n+                )\n+                .select_for_update()\n+                .get(pk=order.pk)\n+            )\n+            transaction = payment_models.TransactionItem.objects.select_for_update(\n+                of=(\"self\",)\n+            ).get(pk=transaction.pk)\n+            updates_amounts_for_order(order)\n+        update_order_search_vector(order)\n+        order_info = fetch_order_info(order)\n+        order_transaction_updated(\n+            order_info=order_info,\n+            transaction_item=transaction,\n+            manager=manager,\n+            user=user,\n+            app=app,\n+            previous_authorized_value=previous_authorized_value,\n+            previous_charged_value=previous_charged_value,\n+            previous_refunded_value=previous_refunded_value,\n+        )\n+        if related_granted_refund:\n+            calculate_order_granted_refund_status(related_granted_refund)\n+\n+    @classmethod\n+    def process_order_or_checkout_with_transaction(\n+        cls,\n+        transaction: payment_models.TransactionItem,\n+        manager: \"PluginsManager\",\n+        user: Optional[\"User\"],\n+        app: App | None,\n+        previous_authorized_value: Decimal,\n+        previous_charged_value: Decimal,\n+        previous_refunded_value: Decimal,\n+        related_granted_refund: order_models.OrderGrantedRefund | None,\n+    ):\n+        checkout_deleted = False\n+        if transaction.checkout_id:\n+            with traced_atomic_transaction():\n+                locked_checkout = (\n+                    Checkout.objects.select_for_update()\n+                    .filter(pk=transaction.checkout_id)\n+                    .first()\n+                )\n+                transaction = payment_models.TransactionItem.objects.select_for_update(\n+                    of=(\"self\",)\n+                ).get(pk=transaction.pk)\n+                if transaction.checkout_id and locked_checkout:\n+                    transaction_amounts_for_checkout_updated_without_price_recalculation(\n+                        transaction, locked_checkout, manager, user, app\n+                    )\n+                else:\n+                    checkout_deleted = True\n+                    # If the checkout was deleted, we still want to update the order associated with the transaction.\n+        if transaction.order_id or checkout_deleted:\n+            cls.process_order_with_transaction(\n+                transaction,\n+                manager,\n+                user,\n+                app,\n+                previous_authorized_value,\n+                previous_charged_value,\n+                previous_refunded_value,\n+                related_granted_refund,\n+            )\n+\n+    @classmethod\n     def perform_mutation(  # type: ignore[override]\n         cls,\n         root,\n         info: ResolveInfo,\n@@ -417,40 +504,18 @@\n                 app=app,\n                 metadata=transaction_metadata,\n                 private_metadata=transaction_private_metadata,\n             )\n-            if transaction.order_id:\n-                order = cast(order_models.Order, transaction.order)\n-                update_order_search_vector(order, save=False)\n-                updates_amounts_for_order(order, save=False)\n-                order.save(\n-                    update_fields=[\n-                        \"total_charged_amount\",\n-                        \"charge_status\",\n-                        \"updated_at\",\n-                        \"total_authorized_amount\",\n-                        \"authorize_status\",\n-                        \"search_vector\",\n-                    ]\n-                )\n-                order_info = fetch_order_info(order)\n-                order_transaction_updated(\n-                    order_info=order_info,\n-                    transaction_item=transaction,\n-                    manager=manager,\n-                    user=user,\n-                    app=app,\n-                    previous_authorized_value=previous_authorized_value,\n-                    previous_charged_value=previous_charged_value,\n-                    previous_refunded_value=previous_refunded_value,\n-                )\n-                if related_granted_refund:\n-                    calculate_order_granted_refund_status(related_granted_refund)\n-            if transaction.checkout_id:\n-                manager = get_plugin_manager_promise(info.context).get()\n-                transaction_amounts_for_checkout_updated(\n-                    transaction, manager, user, app\n-                )\n+            cls.process_order_or_checkout_with_transaction(\n+                transaction,\n+                manager,\n+                user,\n+                app,\n+                previous_authorized_value,\n+                previous_charged_value,\n+                previous_refunded_value,\n+                related_granted_refund,\n+            )\n         elif available_actions is not None and set(\n             transaction.available_actions\n         ) != set(available_actions):\n             transaction.available_actions = available_actions\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_event_report.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\t43f5ba1 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\tccd3960 (commit)\n@@ -4,20 +4,24 @@\n from uuid import uuid4\n \n import graphene\n import pytest\n+from django.db import transaction as database_transaction\n from django.utils import timezone\n from freezegun import freeze_time\n+from psycopg.errors import QueryCanceled\n \n from .....checkout import CheckoutAuthorizeStatus, CheckoutChargeStatus\n from .....checkout.calculations import fetch_checkout_data\n+from .....checkout.complete_checkout import create_order_from_checkout\n from .....checkout.fetch import fetch_checkout_info, fetch_checkout_lines\n from .....checkout.models import Checkout\n from .....order import OrderEvents, OrderGrantedRefundStatus, OrderStatus\n from .....order.models import Order\n from .....payment import OPTIONAL_AMOUNT_EVENTS, TransactionEventType\n from .....payment.models import TransactionEvent\n from .....payment.transaction_item_calculations import recalculate_transaction_amounts\n+from .....tests import race_condition\n from ....core.enums import TransactionEventReportErrorCode\n from ....core.utils import to_global_id_or_none\n from ....order.enums import OrderAuthorizeStatusEnum, OrderChargeStatusEnum\n from ....tests.utils import assert_no_permission, get_graphql_content\n@@ -1236,11 +1240,18 @@\n     transaction_item_generator,\n     app_api_client,\n     permission_manage_payments,\n     checkout_with_items,\n+    plugins_manager,\n ):\n     # given\n     checkout = checkout_with_items\n+\n+    # Fetch checkout lines and info to recalculate checkout total prices\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, plugins_manager)\n+    fetch_checkout_data(checkout_info, plugins_manager, lines)\n+\n     current_charged_value = Decimal(\"20\")\n     psp_reference = \"111-abc\"\n     amount = Decimal(\"11.00\")\n     transaction = transaction_item_generator(\n@@ -3303,4 +3314,227 @@\n     assert event.app_identifier == app_api_client.app.identifier\n     assert event.app == app_api_client.app\n     assert event.user is None\n     assert event.message == \"\"\n+\n+\n+# transaction=True is required to ensure that the order is locked without it second context will not\n+# be able to trying to acquire a lock on the order.\n+@pytest.mark.django_db(transaction=True)\n+def test_lock_order_during_updating_order_amounts(\n+    transaction_item_generator,\n+    app_api_client,\n+    permission_manage_payments,\n+    order_with_lines,\n+):\n+    # given\n+    order = order_with_lines\n+    psp_reference = \"111-abc\"\n+    amount = order.total.gross.amount\n+    transaction = transaction_item_generator(\n+        app=app_api_client.app,\n+        order_id=order.pk,\n+    )\n+    transaction_id = graphene.Node.to_global_id(\"TransactionItem\", transaction.token)\n+    variables = {\n+        \"id\": transaction_id,\n+        \"type\": TransactionEventTypeEnum.CHARGE_SUCCESS.name,\n+        \"amount\": amount,\n+        \"pspReference\": psp_reference,\n+    }\n+    query = (\n+        MUTATION_DATA_FRAGMENT\n+        + \"\"\"\n+    mutation TransactionEventReport(\n+        $id: ID\n+        $type: TransactionEventTypeEnum!\n+        $amount: PositiveDecimal!\n+        $pspReference: String!\n+    ) {\n+        transactionEventReport(\n+            id: $id\n+            type: $type\n+            amount: $amount\n+            pspReference: $pspReference\n+        ) {\n+            ...TransactionEventData\n+        }\n+    }\n+    \"\"\"\n+    )\n+\n+    # when & then\n+    def check_if_order_is_locked(*args, **kwargs):\n+        # This function will be called when the order amounts are being updated\n+        # We will try to acquire a lock on the order row to check if it's locked.\n+        cxn = database_transaction.get_connection()\n+        new_cxn = cxn.get_new_connection(cxn.get_connection_params())\n+        with new_cxn.cursor() as cursor:\n+            cursor.execute(\"SET statement_timeout = 100\")\n+            with pytest.raises(QueryCanceled):\n+                cursor.execute(\n+                    \"\"\"\n+                    SELECT *\n+                    FROM \"order_order\"\n+                    WHERE \"order_order\".\"id\" = %s\n+                    FOR UPDATE\n+                    \"\"\",\n+                    [order.pk],\n+                )\n+\n+    with race_condition.RunBefore(\n+        \"saleor.order.utils.update_order_charge_data\",\n+        check_if_order_is_locked,\n+    ):\n+        app_api_client.post_graphql(\n+            query,\n+            variables,\n+            permissions=[permission_manage_payments],\n+            check_no_permissions=False,\n+        )\n+\n+\n+# transaction=True is required to ensure that the order is locked without it second context will not\n+# be able to trying to acquire a lock on the order.\n+@pytest.mark.django_db(transaction=True)\n+def test_lock_checkout_during_updating_checkout_amounts(\n+    transaction_item_generator,\n+    app_api_client,\n+    permission_manage_payments,\n+    checkout_with_items,\n+    plugins_manager,\n+):\n+    # given\n+    checkout = checkout_with_items\n+\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, plugins_manager)\n+    checkout_info, _ = fetch_checkout_data(checkout_info, plugins_manager, lines)\n+\n+    psp_reference = \"111-abc\"\n+    transaction = transaction_item_generator(\n+        app=app_api_client.app, checkout_id=checkout.pk\n+    )\n+    transaction_id = graphene.Node.to_global_id(\"TransactionItem\", transaction.token)\n+    variables = {\n+        \"id\": transaction_id,\n+        \"type\": TransactionEventTypeEnum.CHARGE_SUCCESS.name,\n+        \"amount\": checkout_info.checkout.total.gross.amount,\n+        \"pspReference\": psp_reference,\n+    }\n+    query = (\n+        MUTATION_DATA_FRAGMENT\n+        + \"\"\"\n+    mutation TransactionEventReport(\n+        $id: ID\n+        $type: TransactionEventTypeEnum!\n+        $amount: PositiveDecimal!\n+        $pspReference: String!\n+    ) {\n+        transactionEventReport(\n+            id: $id\n+            type: $type\n+            amount: $amount\n+            pspReference: $pspReference\n+        ) {\n+            ...TransactionEventData\n+        }\n+    }\n+    \"\"\"\n+    )\n+\n+    # when & then\n+    def check_if_checkout_is_locked(*args, **kwargs):\n+        # This function will be called when the order amounts are being updated\n+        # We will try to acquire a lock on the order row to check if it's locked.\n+        cxn = database_transaction.get_connection()\n+        new_cxn = cxn.get_new_connection(cxn.get_connection_params())\n+        with new_cxn.cursor() as cursor:\n+            cursor.execute(\"SET statement_timeout = 100\")\n+            with pytest.raises(QueryCanceled):\n+                cursor.execute(\n+                    \"\"\"\n+                    SELECT *\n+                    FROM \"checkout_checkout\"\n+                    WHERE \"checkout_checkout\".\"token\" = %s\n+                    FOR UPDATE\n+                    \"\"\",\n+                    [checkout.pk],\n+                )\n+\n+    with race_condition.RunBefore(\n+        \"saleor.graphql.payment.mutations.transaction.\"\n+        \"transaction_event_report.transaction_amounts_for_checkout_updated_without_price_recalculation\",\n+        check_if_checkout_is_locked,\n+    ):\n+        app_api_client.post_graphql(\n+            query, variables, permissions=[permission_manage_payments]\n+        )\n+\n+\n+def test_transaction_event_report_checkout_completed_race_condition(\n+    transaction_item_generator,\n+    app_api_client,\n+    permission_manage_payments,\n+    checkout_with_items,\n+    plugins_manager,\n+):\n+    # given\n+    checkout = checkout_with_items\n+\n+    lines, _ = fetch_checkout_lines(checkout)\n+    checkout_info = fetch_checkout_info(checkout, lines, plugins_manager)\n+    checkout_info, _ = fetch_checkout_data(checkout_info, plugins_manager, lines)\n+\n+    psp_reference = \"111-abc\"\n+    transaction = transaction_item_generator(\n+        app=app_api_client.app, checkout_id=checkout.pk\n+    )\n+    transaction_id = graphene.Node.to_global_id(\"TransactionItem\", transaction.token)\n+    variables = {\n+        \"id\": transaction_id,\n+        \"type\": TransactionEventTypeEnum.CHARGE_SUCCESS.name,\n+        \"amount\": checkout_info.checkout.total.gross.amount,\n+        \"pspReference\": psp_reference,\n+    }\n+    query = (\n+        MUTATION_DATA_FRAGMENT\n+        + \"\"\"\n+    mutation TransactionEventReport(\n+        $id: ID\n+        $type: TransactionEventTypeEnum!\n+        $amount: PositiveDecimal!\n+        $pspReference: String!\n+    ) {\n+        transactionEventReport(\n+            id: $id\n+            type: $type\n+            amount: $amount\n+            pspReference: $pspReference\n+        ) {\n+            ...TransactionEventData\n+        }\n+    }\n+    \"\"\"\n+    )\n+\n+    # when\n+    def complete_checkout(*args, **kwargs):\n+        create_order_from_checkout(\n+            checkout_info, plugins_manager, user=None, app=app_api_client.app\n+        )\n+\n+    with race_condition.RunBefore(\n+        \"saleor.graphql.payment.mutations.transaction.transaction_event_report.recalculate_transaction_amounts\",\n+        complete_checkout,\n+    ):\n+        response = app_api_client.post_graphql(\n+            query, variables, permissions=[permission_manage_payments]\n+        )\n+\n+    # then\n+    get_graphql_content(response)\n+    order = Order.objects.get(checkout_token=checkout.pk)\n+\n+    assert order.status == OrderStatus.UNFULFILLED\n+    assert order.charge_status == OrderChargeStatusEnum.FULL.value\n+    assert order.total_charged.amount == checkout.total.gross.amount\n"
        }
      ]
    },
    {
      "id": "fix-voucher-usage",
      "sha": "3c50ec999a4734279ce4685941d0c7f7575d7ad6",
      "parentSha": "8497cde463fd8e369af437f4680c48e47911687e",
      "spec": "Implement voucher usage release for draft order deletions and ensure non-negative usage counts.\n\nRequired changes:\n\n1) Add a Celery task to release voucher usage for multiple draft orders\n- File: saleor/discount/tasks.py\n- Implement a new task function release_voucher_code_usage_of_draft_orders(voucher_codes_with_emails: list[tuple[str, str]]).\n- Behavior:\n  - Accept a list of (code, customer_email) tuples. If the list is empty, return immediately.\n  - Fetch all VoucherCode records for the provided codes.\n  - For codes whose related Voucher is single_use=True, set VoucherCode.is_active=True (reactivate the codes).\n  - For codes whose related Voucher has a non-null usage_limit, decrement the VoucherCode.used count by the number of occurrences of that code in the input list. Use a frequency counter over the input to compute per-code decrements. Do not allow used to go below 0.\n  - Persist the used changes with a bulk update of the affected VoucherCode records.\n  - Delete VoucherCustomer records matching any of the provided (code, customer_email) pairs using a combined OR query over Q(voucher_code__code=code, customer_email=email).\n  - Ensure proper imports: Counter from collections, Voucher, VoucherCode, VoucherCustomer, Q and F from django.db.models, and the task decorators already used in the module.\n\n2) Prevent negative voucher usage on single decrement\n- File: saleor/discount/utils/voucher.py\n- Modify decrease_voucher_code_usage_value(code) to perform a conditional update that clamps used at 0. Use an update with Case/When: When(used__gt=0, then=F(\"used\") - 1), else Value(0), output field IntegerField.\n- This must avoid reading and saving the model instance directly to prevent race conditions and ensure atomicity.\n\n3) Release voucher usage on draft order bulk delete only when enabled per channel\n- File: saleor/graphql/order/bulk_mutations/draft_orders.py\n- Import release_voucher_code_usage_of_draft_orders (Celery task) and get_customer_email_for_voucher_usage.\n- In the bulk delete flow, collect voucher codes and corresponding customer emails for each instance that:\n  - Has a voucher_code set, and\n  - Is in a channel where include_draft_order_in_voucher_usage is True.\n- Return these collected pairs from the clean_input path so they are available to the bulk mutation executor.\n- Override/adjust perform_mutation to:\n  - Resolve instances and check channel permissions as before.\n  - Use the extended clean_input to obtain voucher_codes_with_emails alongside clean_instance_ids and errors.\n  - Perform the bulk deletion via the queryset if there are instances to delete.\n  - After scheduling the deletion, enqueue release_voucher_code_usage_of_draft_orders.delay(voucher_codes_with_emails) so voucher usage is released asynchronously.\n\n4) Release voucher usage on single draft order delete only when enabled per channel and with customer email\n- File: saleor/graphql/order/mutations/draft_order_delete.py\n- Import get_customer_email_for_voucher_usage in addition to existing voucher helpers.\n- In post_save_action, if the order has a voucher_code and the order.channel.include_draft_order_in_voucher_usage is True, fetch the corresponding VoucherCode, derive user_email via get_customer_email_for_voucher_usage(order), and call release_voucher_code_usage(voucher_code, voucher_code.voucher, user_email).\n\n5) Minor ordering for draft order update voucher handling\n- File: saleor/graphql/order/mutations/draft_order_update.py\n- Ensure that voucher usage handling is performed only when the channel’s include_draft_order_in_voucher_usage flag is True. Compute user_email via get_customer_email_for_voucher_usage(instance) inside that conditional block so it only runs when needed.\n\nFunctional acceptance criteria:\n- Deleting draft orders in bulk on channels with include_draft_order_in_voucher_usage=False does not change voucher usage.\n- Deleting draft orders in bulk on channels with include_draft_order_in_voucher_usage=True reactivates single-use codes and decrements multi-use code ‘used’ counts by the number of relevant deleted draft orders using those codes, without going below zero.\n- Customer-specific voucher usage (VoucherCustomer) entries for the deleted draft orders are removed.\n- Single draft order delete honors the include_draft_order_in_voucher_usage flag and uses the customer email to clear per-customer usage when applicable.\n- Standalone voucher usage decrements never produce negative ‘used’ values.",
      "prompt": "Implement robust voucher usage release when deleting draft orders and ensure usage counters never go negative.\n\n- Add a background task that accepts a list of voucher code and customer email pairs coming from bulk draft order deletion. It must reactivate single-use voucher codes, decrement usage-limited codes by the number of times they appear in the list (not below zero), and remove any customer-specific usage entries for those pairs.\n- Update the draft order bulk delete mutation to collect code and email pairs only when the channel is configured to include draft orders in voucher usage, and schedule the background task after deletion.\n- Update the single draft order delete mutation so that voucher usage is released only when the channel is configured to include draft orders in voucher usage, and pass the order’s customer email into the release logic.\n- Adjust the single-step voucher usage decrement utility to clamp the used count at zero.\n\nEnsure the changes are consistent across the codebase and maintain existing behavior when the channel setting disables including draft orders in voucher usage.",
      "supplementalFiles": [
        "saleor/discount/models.py",
        "saleor/channel/models.py",
        "saleor/order/models.py",
        "saleor/checkout/complete_checkout.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/discount/tasks.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tasks.py\n===================================================================\n--- saleor/discount/tasks.py\t8497cde (parent)\n+++ saleor/discount/tasks.py\t3c50ec9 (commit)\n@@ -1,6 +1,6 @@\n import datetime\n-from collections import defaultdict\n+from collections import Counter, defaultdict\n from typing import TYPE_CHECKING\n \n import graphene\n from celery.utils.log import get_task_logger\n@@ -28,9 +28,11 @@\n     OrderDiscount,\n     OrderLineDiscount,\n     Promotion,\n     PromotionRule,\n+    Voucher,\n     VoucherCode,\n+    VoucherCustomer,\n )\n from .utils.promotion import mark_catalogue_promotion_rules_as_dirty\n \n if TYPE_CHECKING:\n@@ -213,8 +215,41 @@\n         PromotionRuleVariant.objects.filter(pk__in=rule_variants_id).delete()\n         clear_promotion_rule_variants_task.delay()\n \n \n+@app.task\n+@allow_writer()\n+def release_voucher_code_usage_of_draft_orders(\n+    voucher_codes_with_emails: list[tuple[str, str]],\n+):\n+    voucher_codes = [code for code, _ in voucher_codes_with_emails]\n+    if not voucher_codes:\n+        return\n+    codes = VoucherCode.objects.filter(code__in=voucher_codes)\n+\n+    # activate single use vouchers\n+    single_use_vouchers = Voucher.objects.filter(single_use=True)\n+    codes.filter(voucher__in=single_use_vouchers).update(is_active=True)\n+\n+    # decrease usage for vouchers with usage limit\n+    voucher_with_usage_limit = Voucher.objects.filter(usage_limit__isnull=False)\n+    codes_to_release = codes.filter(voucher__in=voucher_with_usage_limit)\n+    code_counter = Counter(voucher_codes)\n+    for voucher_code in codes_to_release:\n+        usage_decrease = code_counter[voucher_code.code]\n+        if voucher_code.used < usage_decrease:\n+            voucher_code.used = 0\n+        else:\n+            voucher_code.used = F(\"used\") - usage_decrease\n+    VoucherCode.objects.bulk_update(codes_to_release, [\"used\"])\n+\n+    # drop customer usage\n+    lookup = Q()\n+    for code, email in voucher_codes_with_emails:\n+        lookup |= Q(voucher_code__code=code, customer_email=email)\n+    VoucherCustomer.objects.filter(lookup).delete()\n+\n+\n def decrease_voucher_code_usage_of_draft_orders(channel_id: int):\n     codes = (\n         Order.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME)\n         .filter(\n"
        },
        {
          "path": "saleor/discount/tests/test_discounts.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tests/test_discounts.py\n===================================================================\n--- saleor/discount/tests/test_discounts.py\t8497cde (parent)\n+++ saleor/discount/tests/test_discounts.py\t3c50ec9 (commit)\n@@ -232,8 +232,31 @@\n     code_instance.refresh_from_db(fields=[\"used\"])\n     assert code_instance.used == 9\n \n \n+def test_decrease_voucher_usage_used_0(channel_USD):\n+    # given\n+    code = \"unique\"\n+    voucher = Voucher.objects.create(\n+        type=VoucherType.ENTIRE_ORDER,\n+        discount_value_type=DiscountValueType.FIXED,\n+        usage_limit=100,\n+    )\n+    code_instance = VoucherCode.objects.create(code=code, voucher=voucher, used=0)\n+    VoucherChannelListing.objects.create(\n+        voucher=voucher,\n+        channel=channel_USD,\n+        discount=Money(10, channel_USD.currency_code),\n+    )\n+\n+    # when\n+    decrease_voucher_code_usage_value(code_instance)\n+\n+    # then\n+    code_instance.refresh_from_db(fields=[\"used\"])\n+    assert code_instance.used == 0\n+\n+\n def test_deactivate_voucher_code(voucher):\n     # given\n     code_instance = voucher.codes.first()\n \n"
        },
        {
          "path": "saleor/discount/tests/test_tasks.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tests/test_tasks.py\n===================================================================\n--- saleor/discount/tests/test_tasks.py\t8497cde (parent)\n+++ saleor/discount/tests/test_tasks.py\t3c50ec9 (commit)\n@@ -10,16 +10,24 @@\n \n from ...order.models import Order\n from ...product.models import ProductChannelListing, ProductVariant\n from .. import DiscountType, RewardValueType\n-from ..models import OrderDiscount, OrderLineDiscount, Promotion, PromotionRule\n+from ..models import (\n+    OrderDiscount,\n+    OrderLineDiscount,\n+    Promotion,\n+    PromotionRule,\n+    VoucherCode,\n+    VoucherCustomer,\n+)\n from ..tasks import (\n     clear_promotion_rule_variants_task,\n     decrease_voucher_code_usage_of_draft_orders,\n     decrease_voucher_codes_usage_task,\n     disconnect_voucher_codes_from_draft_orders_task,\n     fetch_promotion_variants_and_product_ids,\n     handle_promotion_toggle,\n+    release_voucher_code_usage_of_draft_orders,\n     set_promotion_rule_variants_task,\n )\n from ..utils.promotion import mark_catalogue_promotion_rules_as_dirty\n \n@@ -367,4 +375,102 @@\n     with pytest.raises(line_discount._meta.model.DoesNotExist):\n         line_discount.refresh_from_db()\n     with pytest.raises(order_discount._meta.model.DoesNotExist):\n         order_discount.refresh_from_db()\n+\n+\n+def test_release_voucher_code_usage_of_draft_orders_single_use(voucher_single_use):\n+    # given\n+    single_use_code_1 = voucher_single_use.codes.first()\n+    single_use_code_2 = voucher_single_use.codes.last()\n+    single_use_code_1.is_active = False\n+    single_use_code_2.is_active = False\n+    VoucherCode.objects.bulk_update(\n+        [single_use_code_1, single_use_code_2], [\"is_active\"]\n+    )\n+\n+    voucher_codes_with_emails = [\n+        (single_use_code_1.code, \"test@example.com\"),\n+        (single_use_code_2.code, \"test2@example.com\"),\n+    ]\n+\n+    # when\n+    release_voucher_code_usage_of_draft_orders(voucher_codes_with_emails)\n+\n+    # then\n+    single_use_code_2.refresh_from_db()\n+    assert single_use_code_2.is_active is True\n+    single_use_code_1.refresh_from_db()\n+    assert single_use_code_1.is_active is True\n+\n+\n+@pytest.mark.parametrize(\"used\", [1, 2, 3, 4])\n+def test_release_voucher_code_usage_of_draft_orders_multiple_use(\n+    used, voucher_multiple_use\n+):\n+    # given\n+    multiple_use_code = voucher_multiple_use.codes.first()\n+    multiple_use_code.used = used\n+    multiple_use_code.save(update_fields=[\"used\"])\n+\n+    voucher_codes_with_emails = [\n+        (multiple_use_code.code, \"test@example.com\"),\n+        (multiple_use_code.code, \"test2@example.com\"),\n+        (multiple_use_code.code, \"test3@example.com\"),\n+    ]\n+\n+    # when\n+    release_voucher_code_usage_of_draft_orders(voucher_codes_with_emails)\n+\n+    # then\n+    multiple_use_code.refresh_from_db()\n+    assert multiple_use_code.used == max(used - len(voucher_codes_with_emails), 0)\n+\n+\n+def test_release_voucher_code_usage_of_draft_orders_clears_voucher_customers(\n+    voucher_single_use,\n+):\n+    # given\n+    single_use_code_1 = voucher_single_use.codes.first()\n+    single_use_code_2 = voucher_single_use.codes.last()\n+    email_1 = \"customer1@example.com\"\n+    email_2 = \"customer2@example.com\"\n+    email_3 = \"customer3@example.com\"\n+    VoucherCustomer.objects.bulk_create(\n+        [\n+            VoucherCustomer(voucher_code=single_use_code_1, customer_email=email_1),\n+            VoucherCustomer(voucher_code=single_use_code_1, customer_email=email_2),\n+            VoucherCustomer(voucher_code=single_use_code_2, customer_email=email_3),\n+        ]\n+    )\n+    voucher_codes_with_emails = [\n+        (single_use_code_1.code, email_1),\n+        (single_use_code_2.code, email_3),\n+        (single_use_code_2.code, email_2),\n+    ]\n+\n+    # when\n+    release_voucher_code_usage_of_draft_orders(voucher_codes_with_emails)\n+\n+    # then\n+    assert not VoucherCustomer.objects.filter(\n+        voucher_code=single_use_code_1, customer_email=email_1\n+    ).exists()\n+    assert not VoucherCustomer.objects.filter(\n+        voucher_code=single_use_code_2, customer_email=email_3\n+    ).exists()\n+    assert VoucherCustomer.objects.filter(\n+        voucher_code=single_use_code_1, customer_email=email_2\n+    ).exists()\n+\n+\n+def test_release_voucher_code_usage_of_draft_orders_no_codes():\n+    # given\n+    voucher_codes_with_emails = []\n+\n+    # when\n+    # Should not raise or do anything\n+    release_voucher_code_usage_of_draft_orders(voucher_codes_with_emails)\n+\n+    # then\n+    assert VoucherCode.objects.count() == 0\n+    assert VoucherCustomer.objects.count() == 0\n"
        },
        {
          "path": "saleor/discount/utils/voucher.py",
          "status": "modified",
          "diff": "Index: saleor/discount/utils/voucher.py\n===================================================================\n--- saleor/discount/utils/voucher.py\t8497cde (parent)\n+++ saleor/discount/utils/voucher.py\t3c50ec9 (commit)\n@@ -3,9 +3,9 @@\n from decimal import Decimal\n from typing import TYPE_CHECKING, Optional, Union, cast\n from uuid import UUID\n \n-from django.db.models import Exists, F, OuterRef\n+from django.db.models import Case, Exists, F, IntegerField, OuterRef, Value, When\n from django.utils import timezone\n from prices import Money\n \n from ... import settings\n@@ -87,10 +87,15 @@\n \n \n def decrease_voucher_code_usage_value(code: \"VoucherCode\") -> None:\n     \"\"\"Decrease voucher code uses by 1.\"\"\"\n-    code.used = F(\"used\") - 1\n-    code.save(update_fields=[\"used\"])\n+    VoucherCode.objects.filter(pk=code.pk).update(\n+        used=Case(\n+            When(used__gt=0, then=F(\"used\") - 1),\n+            default=Value(0),\n+            output_field=IntegerField(),\n+        )\n+    )\n \n \n def deactivate_voucher_code(code: \"VoucherCode\") -> None:\n     \"\"\"Mark voucher code as used.\"\"\"\n"
        },
        {
          "path": "saleor/graphql/order/bulk_mutations/draft_orders.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/bulk_mutations/draft_orders.py\n===================================================================\n--- saleor/graphql/order/bulk_mutations/draft_orders.py\t8497cde (parent)\n+++ saleor/graphql/order/bulk_mutations/draft_orders.py\t3c50ec9 (commit)\n@@ -4,8 +4,10 @@\n import graphene\n from django.core.exceptions import ValidationError\n \n from ....channel import models as channel_models\n+from ....discount.tasks import release_voucher_code_usage_of_draft_orders\n+from ....discount.utils.voucher import get_customer_email_for_voucher_usage\n from ....order import OrderStatus, models\n from ....order.error_codes import OrderErrorCode\n from ....payment.models import Payment, TransactionItem\n from ....permission.enums import OrderPermissions\n@@ -80,8 +82,9 @@\n         errors_dict: dict[str, list[ValidationError]] = {}\n \n         instances_ids = [instance.id for instance in instances]\n         related_objects = cls.get_ids_with_related_objects(instances_ids)\n+        voucher_codes_with_emails = []\n         for instance, node_id in zip(instances, ids, strict=False):\n             instance_errors = []\n \n             # catch individual validation errors to raise them later as\n@@ -99,16 +102,52 @@\n                 # FIXME we are not propagating code error from the raised ValidationError\n                 ValidationError({node_id: instance_errors_msg}).update_error_dict(\n                     errors_dict\n                 )\n-        return clean_instance_ids, errors_dict\n \n+            if instance.channel.include_draft_order_in_voucher_usage and (\n+                code := instance.voucher_code\n+            ):\n+                voucher_codes_with_emails.append(\n+                    (code, get_customer_email_for_voucher_usage(instance))\n+                )\n+        return clean_instance_ids, errors_dict, voucher_codes_with_emails\n+\n     @classmethod\n     def get_channel_ids(cls, instances) -> Iterable[UUID | int]:\n         \"\"\"Get the instances channel ids for channel permission accessible check.\"\"\"\n         return [order.channel_id for order in instances]\n \n+    @classmethod\n+    def perform_mutation(  # type: ignore[override]\n+        cls, _root, info: ResolveInfo, /, *, ids, **data\n+    ) -> tuple[int, ValidationError | None]:\n+        \"\"\"Perform a mutation that deletes a list of model instances.\"\"\"\n+        if not ids:\n+            return 0, None\n+        try:\n+            instances = cls.get_nodes_or_error(ids, \"id\", Order, schema=info.schema)\n+        except ValidationError as error:\n+            return 0, error\n \n+        channel_ids = cls.get_channel_ids(instances)\n+        cls.check_channel_permissions(info, channel_ids)\n+\n+        clean_instance_ids, errors_dict, voucher_codes_with_emails = cls.clean_input(\n+            info, instances, ids\n+        )\n+        if errors_dict:\n+            errors = ValidationError(errors_dict)\n+        else:\n+            errors = None\n+        count = len(clean_instance_ids)\n+        if count:\n+            qs = models.Order.objects.filter(pk__in=clean_instance_ids)\n+            cls.bulk_action(info, qs, **data)\n+        release_voucher_code_usage_of_draft_orders.delay(voucher_codes_with_emails)\n+        return count, errors\n+\n+\n class DraftOrderLinesBulkDelete(\n     ModelBulkDeleteMutation, BaseBulkWithRestrictedChannelAccessMutation\n ):\n     class Arguments:\n"
        },
        {
          "path": "saleor/graphql/order/mutations/draft_order_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_delete.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_delete.py\t8497cde (parent)\n+++ saleor/graphql/order/mutations/draft_order_delete.py\t3c50ec9 (commit)\n@@ -2,9 +2,12 @@\n from django.core.exceptions import ValidationError\n \n from ....core.tracing import traced_atomic_transaction\n from ....discount.models import VoucherCode\n-from ....discount.utils.voucher import release_voucher_code_usage\n+from ....discount.utils.voucher import (\n+    get_customer_email_for_voucher_usage,\n+    release_voucher_code_usage,\n+)\n from ....order import OrderStatus, models\n from ....order.actions import call_order_event\n from ....order.error_codes import OrderErrorCode\n from ....payment.models import Payment, TransactionItem\n@@ -82,11 +85,15 @@\n \n     @classmethod\n     def post_save_action(cls, info, instance, _):\n         if code := instance.voucher_code:\n-            if voucher_code := VoucherCode.objects.filter(code=code).first():\n+            channel = instance.channel\n+            if channel.include_draft_order_in_voucher_usage and (\n+                voucher_code := VoucherCode.objects.filter(code=code).first()\n+            ):\n+                user_email = get_customer_email_for_voucher_usage(instance)\n                 voucher = voucher_code.voucher\n-                release_voucher_code_usage(voucher_code, voucher, None)\n+                release_voucher_code_usage(voucher_code, voucher, user_email)\n \n     @classmethod\n     def success_response(cls, order):\n         \"\"\"Return a success response.\"\"\"\n"
        },
        {
          "path": "saleor/graphql/order/mutations/draft_order_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_update.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_update.py\t8497cde (parent)\n+++ saleor/graphql/order/mutations/draft_order_update.py\t3c50ec9 (commit)\n@@ -313,15 +313,15 @@\n \n         # create or update voucher discount object\n         create_or_update_voucher_discount_objects_for_order(instance)\n \n-        # handle voucher usage\n-        user_email = get_customer_email_for_voucher_usage(instance)\n-\n         channel = instance.channel\n         if not channel.include_draft_order_in_voucher_usage:\n             return\n \n+        # handle voucher usage\n+        user_email = get_customer_email_for_voucher_usage(instance)\n+\n         if voucher:\n             code_instance = cleaned_input.pop(\"voucher_code_instance\", None)\n             increase_voucher_usage(\n                 voucher,\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_draft_order_bulk_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_draft_order_bulk_delete.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_draft_order_bulk_delete.py\t8497cde (parent)\n+++ saleor/graphql/order/tests/mutations/test_draft_order_bulk_delete.py\t3c50ec9 (commit)\n@@ -1,6 +1,7 @@\n import graphene\n \n+from .....discount.models import VoucherCode\n from .....order import OrderStatus\n from .....order import models as order_models\n from .....order.error_codes import OrderErrorCode\n from ....tests.utils import assert_no_permission, get_graphql_content\n@@ -63,9 +64,12 @@\n \n     query = DRAFT_ORDER_BULK_DELETE\n \n     variables = {\n-        \"ids\": [graphene.Node.to_global_id(\"Order\", order.id) for order in order_list]\n+        \"ids\": [\n+            graphene.Node.to_global_id(\"Order\", order.id)\n+            for order in [order_1, order_2]\n+        ]\n     }\n \n     # when\n     response = staff_api_client.post_graphql(query, variables)\n@@ -145,8 +149,98 @@\n         id__in=[order.id for order in order_list]\n     ).count() == len(order_list)\n \n \n+def test_draft_order_bulk_delete_with_voucher_and_include_draft_order_in_voucher_usage_false(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    voucher,\n+):\n+    # given\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    voucher_code = voucher.codes.first()\n+\n+    for order in order_list:\n+        order.voucher_code = voucher_code.code\n+        order.status = OrderStatus.DRAFT\n+        order.save(update_fields=[\"status\", \"voucher_code\"])\n+\n+    order_ids = [order.id for order in order_list]\n+\n+    channel = order.channel\n+    channel.include_draft_order_in_voucher_usage = False\n+    channel.save(update_fields=[\"include_draft_order_in_voucher_usage\"])\n+\n+    voucher.usage_limit = 1\n+    voucher.save(update_fields=[\"usage_limit\"])\n+    assert voucher_code.used == 0\n+\n+    query = DRAFT_ORDER_BULK_DELETE\n+    variables = {\n+        \"ids\": [graphene.Node.to_global_id(\"Order\", order.id) for order in order_list]\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"draftOrderBulkDelete\"][\"count\"] == len(order_list)\n+    assert not order_models.Order.objects.filter(id__in=order_ids).exists()\n+\n+    voucher_code.refresh_from_db()\n+    assert voucher_code.used == 0\n+\n+\n+def test_draft_order_bulk_delete_with_voucher_and_include_draft_order_in_voucher_usage_true(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_list,\n+    voucher_with_many_codes,\n+):\n+    # given\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    voucher_codes = []\n+    voucher = voucher_with_many_codes\n+\n+    for order, voucher_code in zip(order_list, voucher.codes.all(), strict=False):\n+        order.voucher_code = voucher_code.code\n+        order.status = OrderStatus.DRAFT\n+\n+        voucher_codes.append(voucher_code)\n+        voucher_code.used = 1\n+\n+    order_models.Order.objects.bulk_update(order_list, [\"voucher_code\", \"status\"])\n+    VoucherCode.objects.bulk_update(voucher_codes, [\"used\"])\n+\n+    order_ids = [order.id for order in order_list]\n+\n+    channel = order.channel\n+    channel.include_draft_order_in_voucher_usage = True\n+    channel.save(update_fields=[\"include_draft_order_in_voucher_usage\"])\n+\n+    voucher.usage_limit = 1\n+    voucher.save(update_fields=[\"usage_limit\"])\n+\n+    query = DRAFT_ORDER_BULK_DELETE\n+    variables = {\n+        \"ids\": [graphene.Node.to_global_id(\"Order\", order.id) for order in order_list]\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(query, variables)\n+\n+    # then\n+    content = get_graphql_content(response)\n+    assert content[\"data\"][\"draftOrderBulkDelete\"][\"count\"] == len(order_list)\n+    assert not order_models.Order.objects.filter(id__in=order_ids).exists()\n+\n+    for code in voucher_codes:\n+        code.refresh_from_db()\n+        assert code.used == 0\n+\n+\n MUTATION_DELETE_ORDER_LINES = \"\"\"\n     mutation draftOrderLinesBulkDelete($ids: [ID!]!) {\n         draftOrderLinesBulkDelete(ids: $ids) {\n             count\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_draft_order_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_draft_order_delete.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_draft_order_delete.py\t8497cde (parent)\n+++ saleor/graphql/order/tests/mutations/test_draft_order_delete.py\t3c50ec9 (commit)\n@@ -254,8 +254,13 @@\n     # given\n     query = DRAFT_ORDER_DELETE_MUTATION\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     order = draft_order_list_with_multiple_use_voucher[0]\n+\n+    channel = order.channel\n+    channel.include_draft_order_in_voucher_usage = True\n+    channel.save(update_fields=[\"include_draft_order_in_voucher_usage\"])\n+\n     voucher_code = VoucherCode.objects.get(code=order.voucher_code)\n     assert voucher_code.used == 1\n \n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n@@ -277,8 +282,13 @@\n     # given\n     query = DRAFT_ORDER_DELETE_MUTATION\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     order = draft_order_list_with_single_use_voucher[0]\n+\n+    channel = order.channel\n+    channel.include_draft_order_in_voucher_usage = True\n+    channel.save(update_fields=[\"include_draft_order_in_voucher_usage\"])\n+\n     voucher_code = VoucherCode.objects.get(code=order.voucher_code)\n     assert voucher_code.is_active is False\n \n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n@@ -346,4 +356,80 @@\n         MessageGroupId=\"example.com:saleorappadditional\",\n     )\n     assert not mocked_send_webhook_request_sync.called\n     assert wrapped_call_order_event.called\n+\n+\n+def test_draft_order_delete_with_voucher_and_include_draft_order_in_voucher_usage_false(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    draft_order,\n+    voucher,\n+):\n+    # given\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    order = draft_order\n+    voucher_code = voucher.codes.first()\n+    order.voucher_code = voucher_code.code\n+    order.save(update_fields=[\"voucher_code\"])\n+\n+    # Ensure the channel flag is False\n+    channel = order.channel\n+    channel.include_draft_order_in_voucher_usage = False\n+    channel.save(update_fields=[\"include_draft_order_in_voucher_usage\"])\n+\n+    voucher.usage_limit = 1\n+    voucher.save(update_fields=[\"usage_limit\"])\n+    assert voucher_code.used == 0\n+\n+    query = DRAFT_ORDER_DELETE_MUTATION\n+    order_id = graphene.Node.to_global_id(\"Order\", order.id)\n+    variables = {\"id\": order_id}\n+\n+    # when\n+    staff_api_client.post_graphql(query, variables)\n+\n+    # then\n+    with pytest.raises(order._meta.model.DoesNotExist):\n+        order.refresh_from_db()\n+\n+    voucher_code.refresh_from_db()\n+    assert voucher_code.used == 0\n+\n+\n+def test_draft_order_delete_with_voucher_and_include_draft_order_in_voucher_usage_true(\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    draft_order,\n+    voucher,\n+):\n+    # given\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    order = draft_order\n+    voucher_code = voucher.codes.first()\n+    order.voucher_code = voucher_code.code\n+    order.save(update_fields=[\"voucher_code\", \"channel\"])\n+\n+    # Ensure the channel flag is False\n+    channel = order.channel\n+    channel.include_draft_order_in_voucher_usage = True\n+    channel.save(update_fields=[\"include_draft_order_in_voucher_usage\"])\n+\n+    voucher.usage_limit = 1\n+    voucher.save(update_fields=[\"usage_limit\"])\n+\n+    voucher_code.used = 1\n+    voucher_code.save(update_fields=[\"used\"])\n+\n+    query = DRAFT_ORDER_DELETE_MUTATION\n+    order_id = graphene.Node.to_global_id(\"Order\", order.id)\n+    variables = {\"id\": order_id}\n+\n+    # when\n+    staff_api_client.post_graphql(query, variables)\n+\n+    # then\n+    with pytest.raises(order._meta.model.DoesNotExist):\n+        order.refresh_from_db()\n+    voucher_code.refresh_from_db()\n+    # Voucher usage should be decremented\n+    assert voucher_code.used == 0\n"
        }
      ]
    },
    {
      "id": "honor-price-override",
      "sha": "4a044c694fb67cc2a6fbbe1f700bfa716f752507",
      "parentSha": "836d01d8429ff250a78abbc5439743c28bc1f772",
      "spec": "Implement price override precedence in checkout price computation and validate via tests.\n\nChanges to implement:\n1) Update CheckoutLineInfo price selection logic\n- File: saleor/checkout/fetch.py\n- In the property that returns the variant discounted price for a checkout line (variant_discounted_price), add an early return that, when line.price_override is not None, returns a Money constructed from price_override and line.currency.\n- Preserve existing behavior as fallback: if channel_listing has a discounted_price, return it; otherwise compute from undiscounted_unit_price minus catalogue promotion discounts.\n- Add a short comment explaining that price_override takes precedence for further calculations.\n\n2) Add/adjust unit tests for fetch logic\n- File: saleor/checkout/tests/test_fetch.py\n- Ensure Decimal and Money are imported where needed.\n- Add a new test named test_checkout_line_info_variant_discounted_price_with_price_override which:\n  - Retrieves a line from a checkout with an item on promotion, sets price_override to a small Decimal value (e.g., 5), and saves it.\n  - Builds a CheckoutLineInfo using the existing pattern in the file.\n  - Asserts that variant_discounted_price equals Money(price_override, checkout_line.currency) even when the channel listing has a non-None discounted_price.\n\n3) Add GraphQL mutation test to cover voucher calculation with override\n- File: saleor/graphql/checkout/tests/mutations/test_checkout_add_promo_code.py\n- Update imports to include DiscountValueType from the discount module because the test configures a percentage voucher.\n- Add a new test named test_add_promo_code_with_price_override_set which:\n  - Sets checkout_line.price_override to a Decimal value and saves it.\n  - Configures a voucher of type SPECIFIC_PRODUCT with discount_value_type set to PERCENTAGE and a 10% channel discount, and associates it with the product on the checkout line.\n  - Calculates expected_discount as 10% of the price_override multiplied by the line quantity and expected_subtotal as price_override * quantity - expected_discount.\n  - Calls the checkoutAddPromoCode mutation and asserts no errors, that voucherCode is set, discount amount equals expected_discount, and subtotal gross amount equals expected_subtotal.\n\nBehavioral expectations:\n- When price_override is set on a checkout line, it must be the source of truth for unit price used in discount/voucher computations and subtotals, regardless of any variant/channel listing discounted price.\n- GraphQL mutation checkoutAddPromoCode should reflect the discount and subtotal computed from the overridden price.\n\nDo not modify other files or pricing flows beyond the described precedence change and tests.",
      "prompt": "Ensure that a manually overridden checkout line price is respected across pricing and discount flows. Specifically, make the checkout line's effective unit price come from the price override when it is set, even if a channel listing discounted price is available. Update the logic that provides the line's discounted unit price to honor this precedence, and add tests that verify both the fetch-layer unit price and the GraphQL checkoutAddPromoCode mutation compute discounts and subtotals based on the override.",
      "supplementalFiles": [
        "saleor/checkout/base_calculations.py",
        "saleor/checkout/calculations.py",
        "saleor/checkout/models.py",
        "saleor/graphql/checkout/mutations/checkout_add_promo_code.py",
        "saleor/discount/utils/checkout.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/fetch.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/fetch.py\n===================================================================\n--- saleor/checkout/fetch.py\t836d01d (parent)\n+++ saleor/checkout/fetch.py\t4a044c6 (commit)\n@@ -72,10 +72,17 @@\n         If listing is present return the discounted price from the listing,\n         if listing is not present, calculate current unit price based on\n         `undiscounted_unit_price` and catalogue promotion discounts.\n         \"\"\"\n+\n+        # if price_override is set, it takes precedence over any other price for\n+        # further calculations\n+        if self.line.price_override is not None:\n+            return Money(self.line.price_override, self.line.currency)\n+\n         if self.channel_listing and self.channel_listing.discounted_price is not None:\n             return self.channel_listing.discounted_price\n+\n         catalogue_discounts = self.get_catalogue_discounts()\n         total_price = self.undiscounted_unit_price * self.line.quantity\n         for discount in catalogue_discounts:\n             total_price -= discount.amount\n"
        },
        {
          "path": "saleor/checkout/tests/test_fetch.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_fetch.py\n===================================================================\n--- saleor/checkout/tests/test_fetch.py\t836d01d (parent)\n+++ saleor/checkout/tests/test_fetch.py\t4a044c6 (commit)\n@@ -1,5 +1,8 @@\n+from decimal import Decimal\n+\n import pytest\n+from prices import Money\n \n from ...product.models import ProductChannelListing, ProductVariantChannelListing\n from ..fetch import CheckoutLineInfo, fetch_checkout_lines\n \n@@ -216,8 +219,47 @@\n         checkout_line_info.variant_discounted_price == expected_discounted_variant_price\n     )\n \n \n+def test_checkout_line_info_variant_discounted_price_with_price_override(\n+    checkout_with_item_on_promotion,\n+):\n+    # given\n+    checkout_line = checkout_with_item_on_promotion.lines.first()\n+    channel = checkout_with_item_on_promotion.channel\n+    variant = checkout_line.variant\n+    variant_channel_listing = variant.channel_listings.get(channel_id=channel.id)\n+    product = variant.product\n+    product_type = product.product_type\n+    discounts = checkout_line.discounts.all()\n+    checkout_line.price_override = Decimal(5)\n+    checkout_line.save(update_fields=[\"price_override\"])\n+\n+    expected_discounted_variant_price = checkout_line.price_override\n+    assert variant_channel_listing.discounted_price != variant_channel_listing.price\n+\n+    # when\n+    checkout_line_info = CheckoutLineInfo(\n+        line=checkout_line,\n+        variant=variant,\n+        channel_listing=variant_channel_listing,\n+        product=product,\n+        product_type=product_type,\n+        collections=[],\n+        tax_class=product.tax_class or product_type.tax_class,\n+        discounts=discounts,\n+        rules_info=[],\n+        channel=channel,\n+        voucher=None,\n+        voucher_code=None,\n+    )\n+\n+    # then\n+    assert checkout_line_info.variant_discounted_price == Money(\n+        expected_discounted_variant_price, checkout_line.currency\n+    )\n+\n+\n def test_fetch_checkout_lines_info(checkout_with_item_on_promotion):\n     # given\n     lines = list(checkout_with_item_on_promotion.lines.all())\n \n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_add_promo_code.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_add_promo_code.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_add_promo_code.py\t836d01d (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_add_promo_code.py\t4a044c6 (commit)\n@@ -17,9 +17,9 @@\n     add_variant_to_checkout,\n     assign_external_shipping_to_checkout,\n )\n from .....core.models import EventDelivery\n-from .....discount import VoucherType\n+from .....discount import DiscountValueType, VoucherType\n from .....plugins.manager import get_plugins_manager\n from .....product.models import (\n     Collection,\n     ProductChannelListing,\n@@ -1456,4 +1456,43 @@\n     assert filter_shipping_call.kwargs[\"timeout\"] == settings.WEBHOOK_SYNC_TIMEOUT\n \n     tax_delivery = tax_delivery_call.args[0]\n     assert tax_delivery.webhook_id == tax_webhook.id\n+\n+\n+def test_add_promo_code_with_price_override_set(\n+    user_api_client, checkout_with_item, voucher\n+):\n+    # given\n+    checkout_line = checkout_with_item.lines.first()\n+    price_override = Decimal(\"5.00\")\n+    checkout_line.price_override = price_override\n+    checkout_line.save(update_fields=[\"price_override\"])\n+    product = checkout_line.variant.product\n+\n+    voucher.type = VoucherType.SPECIFIC_PRODUCT\n+    voucher.discount_value_type = DiscountValueType.PERCENTAGE\n+    cl = voucher.channel_listings.get(channel=checkout_with_item.channel)\n+    cl.discount_value = Decimal(\"10.00\")  # 10% discount\n+    cl.save(update_fields=[\"discount_value\"])\n+    voucher.save(update_fields=[\"type\", \"discount_value_type\"])\n+    voucher.products.add(product)\n+\n+    # total expected discount is 10% of price override\n+    expected_discount = price_override * Decimal(\"0.10\") * checkout_line.quantity\n+    expected_subtotal = price_override * checkout_line.quantity - expected_discount\n+\n+    variables = {\n+        \"id\": to_global_id_or_none(checkout_with_item),\n+        \"promoCode\": voucher.code,\n+    }\n+\n+    # when\n+    response = user_api_client.post_graphql(MUTATION_CHECKOUT_ADD_PROMO_CODE, variables)\n+    content = get_graphql_content(response)\n+    data = content[\"data\"][\"checkoutAddPromoCode\"]\n+\n+    # then\n+    assert not data[\"errors\"]\n+    assert data[\"checkout\"][\"voucherCode\"] == voucher.code\n+    assert data[\"checkout\"][\"discount\"][\"amount\"] == expected_discount\n+    assert data[\"checkout\"][\"subtotalPrice\"][\"gross\"][\"amount\"] == expected_subtotal\n"
        }
      ]
    },
    {
      "id": "list-nested-filters",
      "sha": "3d60089ec6f98c7109fcdeaf58996cad087a5db5",
      "parentSha": "45bc8dfacdc2e166339e4cf967917aeed26481b6",
      "spec": "Implement list-based where filters for nested Order relationships with AND semantics across items.\n\nFiles to change:\n1) saleor/graphql/order/filters.py\n- Update filter_fulfillments(qs, value):\n  - If not value: return qs.none().\n  - Treat value as a list of input objects. For each input_data, construct a Fulfillment queryset constrained by the provided fields:\n    - If status is provided: use filter_where_by_value_field on Fulfillment.status.\n    - If metadata is provided: use filter_where_metadata on the same queryset.\n  - For each constructed fulfillment_qs, AND into a cumulative lookup using Q(Exists(fulfillment_qs.filter(order_id=OuterRef(\"id\")))) so all list items must be satisfied by at least one related fulfillment each.\n  - If lookup is non-empty at the end, return qs.filter(lookup); otherwise return qs.none().\n\n- Update filter_where_lines signature and behavior:\n  - def filter_where_lines(qs, _, value: list | None):\n  - If not value: return qs.none().\n  - Treat value as a list of input objects. For each input_data with metadata, build lines_qs = filter_where_metadata(OrderLine.objects.using(qs.db), None, metadata_value) and AND into lookup with Q(Exists(lines_qs.filter(order_id=OuterRef(\"id\")))).\n  - If lookup is non-empty, return qs.filter(lookup); else return qs.none().\n\n- Update filter_where_events signature and behavior:\n  - def filter_where_events(qs, _, value: list | None):\n  - If not value: return qs.none().\n  - Treat value as a list of input objects. For each input_data, if neither \"date\" nor \"type\" present return qs.none(). Otherwise build an OrderEvent queryset:\n    - If date provided: events = filter_where_by_range_field(OrderEvent.objects.using(qs.db), \"date\", filter_value).\n    - If type provided: events = filter_where_by_value_field(events or OrderEvent.objects.using(qs.db), \"type\", filter_value).\n  - AND each per-item events Exists condition into a cumulative lookup. If lookup exists return qs.filter(lookup), else qs.none().\n\n- Update OrderWhere field definitions:\n  - invoices: change ObjectTypeWhereFilter to ListObjectTypeWhereFilter with input_class=InvoiceFilterInput and method=\"filter_invoices\". Update help_text to state that each list item is a group of conditions for a single invoice and that all groups must be met by related objects.\n  - fulfillments: change ObjectTypeWhereFilter to ListObjectTypeWhereFilter and update help_text similarly.\n  - lines: change ObjectTypeWhereFilter to ListObjectTypeWhereFilter and update help_text similarly.\n  - events: change ObjectTypeWhereFilter to ListObjectTypeWhereFilter and update help_text similarly.\n\n- Update OrderWhere.filter_invoices(qs, _, value):\n  - If not value: return qs.none().\n  - Treat value as a list of objects; for each input_data, if created_at present, build invoices = filter_where_by_range_field(Invoice.objects.using(qs.db), \"created_at\", filter_value) and AND into a cumulative lookup with Exists(invoices.filter(order_id=OuterRef(\"id\"))).\n  - If lookup exists, return qs.filter(lookup); else qs.none().\n\n- Update DraftOrderWhere field definitions similarly to OrderWhere for:\n  - lines: use ListObjectTypeWhereFilter with updated help_text.\n  - events: use ListObjectTypeWhereFilter with updated help_text.\n\n2) saleor/graphql/schema.graphql\n- Update input OrderWhereInput fields and descriptions:\n  - invoices: InvoiceFilterInput -> [InvoiceFilterInput!] with description explaining list semantics (each item must be satisfied by a single invoice; all groups must be met).\n  - fulfillments: FulfillmentFilterInput -> [FulfillmentFilterInput!] with analogous description.\n  - lines: LinesFilterInput -> [LinesFilterInput!] with analogous description.\n  - events: OrderEventFilterInput -> [OrderEventFilterInput!] with analogous description.\n- Update input DraftOrderWhereInput analogously:\n  - lines: LinesFilterInput -> [LinesFilterInput!]\n  - events: OrderEventFilterInput -> [OrderEventFilterInput!]\n  - Update descriptions to match list semantics.\n\nBehavioral requirements:\n- For invoices, fulfillments, lines, and events list filters:\n  - Non-empty list input requires that for each list item there exists at least one related row satisfying that group (AND across items; conditions within one item apply to the same related row).\n  - If the filter value is None, empty dict, or an empty list, return qs.none().\n- Continue to use helpers filter_where_by_range_field, filter_where_by_value_field, filter_where_metadata and combine via Exists(… order_id=OuterRef(\"id\")) wrapped in Q and ANDed together.\n- Keep hasFulfillments and hasInvoices boolean filters unchanged.\n- Respect camelCase<->snake_case mapping (e.g., createdAt -> created_at in Python input dicts).\n\nType hints:\n- Add annotations value: list | None to updated filter functions as shown in the diff.",
      "prompt": "Add support for list-based nested where filters on orders and draft orders. The where input should accept lists for invoices, fulfillments, lines, and events. Each list item represents a group of conditions that must be satisfied by a single related object, and all provided groups must be satisfied across the related set (logical AND across list items). Update the filtering logic to iterate list items, build per-item subqueries using the existing helper filters and Exists, and combine them with AND. Update the GraphQL schema to change these fields to list input types and revise descriptions to explain the list semantics. Ensure empty or None inputs for these fields yield no results, and keep existing boolean flags like hasFulfillments and hasInvoices working as before.",
      "supplementalFiles": [
        "saleor/graphql/core/filters/where_filters.py",
        "saleor/graphql/utils/filters.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/order/filters.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/filters.py\n===================================================================\n--- saleor/graphql/order/filters.py\t45bc8df (parent)\n+++ saleor/graphql/order/filters.py\t3d60089 (commit)\n@@ -282,21 +282,26 @@\n     return qs.filter(~Exists(fulfillments))\n \n \n def filter_fulfillments(qs, value):\n-    if value is None:\n+    if not value:\n         return qs.none()\n-    fulfillment_qs = None\n-    if status_value := value.get(\"status\"):\n-        fulfillment_qs = filter_where_by_value_field(\n-            Fulfillment.objects.using(qs.db), \"status\", status_value\n-        )\n-    if metadata_value := value.get(\"metadata\"):\n-        fulfillment_qs = filter_where_metadata(\n-            fulfillment_qs or Fulfillment.objects.using(qs.db), None, metadata_value\n-        )\n-    if fulfillment_qs is not None:\n-        return qs.filter(Exists(fulfillment_qs.filter(order_id=OuterRef(\"id\"))))\n+\n+    lookup = Q()\n+    for input_data in value:\n+        fulfillment_qs = None\n+        if status_value := input_data.get(\"status\"):\n+            fulfillment_qs = filter_where_by_value_field(\n+                Fulfillment.objects.using(qs.db), \"status\", status_value\n+            )\n+        if metadata_value := input_data.get(\"metadata\"):\n+            fulfillment_qs = filter_where_metadata(\n+                fulfillment_qs or Fulfillment.objects.using(qs.db), None, metadata_value\n+            )\n+        if fulfillment_qs is not None:\n+            lookup &= Q(Exists(fulfillment_qs.filter(order_id=OuterRef(\"id\"))))\n+    if lookup:\n+        return qs.filter(lookup)\n     return qs.none()\n \n \n class DraftOrderFilter(MetadataFilterBase):\n@@ -625,16 +630,21 @@\n         return qs.filter(lookup)\n     return qs.none()\n \n \n-def filter_where_lines(qs, _, value):\n+def filter_where_lines(qs, _, value: list | None):\n     if not value:\n-        return qs\n-    if metadata_value := value.get(\"metadata\"):\n-        lines_qs = filter_where_metadata(\n-            OrderLine.objects.using(qs.db), None, metadata_value\n-        )\n-        return qs.filter(Exists(lines_qs.filter(order_id=OuterRef(\"id\"))))\n+        return qs.none()\n+\n+    lookup = Q()\n+    for input_data in value:\n+        if metadata_value := input_data.get(\"metadata\"):\n+            lines_qs = filter_where_metadata(\n+                OrderLine.objects.using(qs.db), None, metadata_value\n+            )\n+            lookup &= Q(Exists(lines_qs.filter(order_id=OuterRef(\"id\"))))\n+    if lookup:\n+        return qs.filter(lookup)\n     return qs.none()\n \n \n def filter_where_product_type_id(qs, _, value):\n@@ -646,26 +656,33 @@\n     )\n     return qs.filter(Exists(line_qs.filter(order_id=OuterRef(\"id\"))))\n \n \n-def filter_where_events(qs, _, value):\n+def filter_where_events(qs, _, value: list | None):\n     if not value:\n         return qs.none()\n-    if not {\"date\", \"type\"}.intersection(value.keys()):\n-        return qs.none()\n-    if filter_value := value.get(\"date\"):\n-        events = filter_where_by_range_field(\n-            OrderEvent.objects.using(qs.db), \"date\", filter_value\n-        )\n-        qs = qs.filter(Exists(events.filter(order_id=OuterRef(\"id\"))))\n-    if filter_value := value.get(\"type\"):\n-        events = filter_where_by_value_field(\n-            OrderEvent.objects.using(qs.db), \"type\", filter_value\n-        )\n-        qs = qs.filter(Exists(events.filter(order_id=OuterRef(\"id\"))))\n-    return qs\n \n+    lookup = Q()\n+    for input_data in value:\n+        if not {\"date\", \"type\"}.intersection(input_data.keys()):\n+            return qs.none()\n \n+        event_qs = None\n+        if filter_value := input_data.get(\"date\"):\n+            event_qs = filter_where_by_range_field(\n+                OrderEvent.objects.using(qs.db), \"date\", filter_value\n+            )\n+        if filter_value := input_data.get(\"type\"):\n+            event_qs = filter_where_by_value_field(\n+                event_qs or OrderEvent.objects.using(qs.db), \"type\", filter_value\n+            )\n+        if event_qs is not None:\n+            lookup &= Q(Exists(event_qs.filter(order_id=OuterRef(\"id\"))))\n+    if lookup:\n+        return qs.filter(lookup)\n+    return qs.none()\n+\n+\n def filter_where_billing_address(qs, _, value):\n     if not value:\n         return qs.none()\n     address_qs = filter_address(value)\n@@ -756,26 +773,41 @@\n     has_invoices = BooleanWhereFilter(\n         method=\"filter_has_invoices\",\n         help_text=\"Filter by whether the order has any invoices.\",\n     )\n-    invoices = ObjectTypeWhereFilter(\n+    invoices = ListObjectTypeWhereFilter(\n         input_class=InvoiceFilterInput,\n         method=\"filter_invoices\",\n-        help_text=\"Filter by invoice data associated with the order.\",\n+        help_text=(\n+            \"Filter by invoice data associated with the order. \"\n+            \"Each list item represents conditions that must be satisfied by a single \"\n+            \"invoice. The filter matches orders that have related objects \"\n+            \"meeting all specified groups of conditions.\"\n+        ),\n     )\n     has_fulfillments = BooleanWhereFilter(\n         method=\"filter_has_fulfillments\",\n         help_text=\"Filter by whether the order has any fulfillments.\",\n     )\n-    fulfillments = ObjectTypeWhereFilter(\n+    fulfillments = ListObjectTypeWhereFilter(\n         input_class=FulfillmentFilterInput,\n         method=\"filter_fulfillments\",\n-        help_text=\"Filter by fulfillment data associated with the order.\",\n+        help_text=(\n+            \"Filter by fulfillment data associated with the order.\"\n+            \"Each list item specifies conditions that must be satisfied by a single \"\n+            \"fulfillment. The filter matches orders that have related objects \"\n+            \"meeting all specified groups of conditions.\"\n+        ),\n     )\n-    lines = ObjectTypeWhereFilter(\n+    lines = ListObjectTypeWhereFilter(\n         input_class=LinesFilterInput,\n         method=filter_where_lines,\n-        help_text=\"Filter by metadata fields of order lines.\",\n+        help_text=(\n+            \"Filter by line items associated with the order. \"\n+            \"Each list item specifies conditions that must be satisfied by a single \"\n+            \"line. The filter matches orders that have related objects \"\n+            \"meeting all specified groups of conditions.\"\n+        ),\n     )\n     lines_count = OperationObjectTypeWhereFilter(\n         input_class=IntFilterInput,\n         method=filter_where_lines_count,\n@@ -805,12 +837,16 @@\n         input_class=GlobalIDFilterInput,\n         method=filter_where_product_type_id,\n         help_text=\"Filter by the product type of related order lines.\",\n     )\n-    events = ObjectTypeWhereFilter(\n+    events = ListObjectTypeWhereFilter(\n         input_class=OrderEventFilterInput,\n         method=filter_where_events,\n-        help_text=\"Filter by order events.\",\n+        help_text=(\n+            \"Filter by order events. Each list item specifies conditions that must be \"\n+            \"satisfied by a single event. The filter matches orders that have related \"\n+            \"objects meeting all specified groups of conditions.\"\n+        ),\n     )\n     billing_address = ObjectTypeWhereFilter(\n         input_class=AddressFilterInput,\n         method=filter_where_billing_address,\n@@ -851,15 +887,20 @@\n         return filter_has_invoices(qs, value)\n \n     @staticmethod\n     def filter_invoices(qs, _, value):\n-        if value is None:\n+        if not value:\n             return qs.none()\n-        if filter_value := value.get(\"created_at\"):\n-            invoices = filter_where_by_range_field(\n-                Invoice.objects.using(qs.db), \"created_at\", filter_value\n-            )\n-            return qs.filter(Exists(invoices.filter(order_id=OuterRef(\"id\"))))\n+\n+        lookup = Q()\n+        for input_data in value:\n+            if filter_value := input_data.get(\"created_at\"):\n+                invoices = filter_where_by_range_field(\n+                    Invoice.objects.using(qs.db), \"created_at\", filter_value\n+                )\n+                lookup &= Q(Exists(invoices.filter(order_id=OuterRef(\"id\"))))\n+        if lookup:\n+            return qs.filter(lookup)\n         return qs.none()\n \n     @staticmethod\n     def filter_has_fulfillments(qs, _, value):\n@@ -926,12 +967,17 @@\n         input_class=StringFilterInput,\n         method=filter_where_voucher_code,\n         help_text=\"Filter by voucher code used in the order.\",\n     )\n-    lines = ObjectTypeWhereFilter(\n+    lines = ListObjectTypeWhereFilter(\n         input_class=LinesFilterInput,\n         method=filter_where_lines,\n-        help_text=\"Filter by metadata fields of order lines.\",\n+        help_text=(\n+            \"Filter by line items associated with the order. \"\n+            \"Each list item specifies conditions that must be satisfied by a single \"\n+            \"line. The filter matches orders that have related objects \"\n+            \"meeting all specified groups of conditions.\"\n+        ),\n     )\n     lines_count = OperationObjectTypeWhereFilter(\n         input_class=IntFilterInput,\n         method=filter_where_lines_count,\n@@ -961,12 +1007,16 @@\n         input_class=GlobalIDFilterInput,\n         method=filter_where_product_type_id,\n         help_text=\"Filter by the product type of related order lines.\",\n     )\n-    events = ObjectTypeWhereFilter(\n+    events = ListObjectTypeWhereFilter(\n         input_class=OrderEventFilterInput,\n         method=filter_where_events,\n-        help_text=\"Filter by order events.\",\n+        help_text=(\n+            \"Filter by order events. Each list item specifies conditions that must be \"\n+            \"satisfied by a single event. The filter matches orders that have related \"\n+            \"objects meeting all specified groups of conditions.\"\n+        ),\n     )\n     billing_address = ObjectTypeWhereFilter(\n         input_class=AddressFilterInput,\n         method=filter_where_billing_address,\n"
        },
        {
          "path": "saleor/graphql/order/tests/queries/test_draft_order_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/queries/test_draft_order_with_where.py\n===================================================================\n--- saleor/graphql/order/tests/queries/test_draft_order_with_where.py\t45bc8df (parent)\n+++ saleor/graphql/order/tests/queries/test_draft_order_with_where.py\t3d60089 (commit)\n@@ -843,32 +843,59 @@\n     assert len(orders) == 0\n \n \n @pytest.mark.parametrize(\n-    (\"metadata\", \"expected_indexes\"),\n+    (\"filter_input\", \"expected_indexes\"),\n     [\n-        ({\"key\": \"foo\"}, [0, 1]),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}, [0]),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}, []),\n-        ({\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}, [0, 1]),\n-        ({\"key\": \"notfound\"}, []),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": None}}, []),\n-        ({\"key\": \"foo\", \"value\": {\"oneOf\": []}}, []),\n+        ([{\"metadata\": {\"key\": \"foo\"}}], [0, 1]),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}}], [0]),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}}], [0, 1]),\n+        ([{\"metadata\": {\"key\": \"notfound\"}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": None}}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": []}}}], []),\n         (None, []),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}},\n+            ],\n+            [0],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"baz\", \"value\": {\"eq\": \"zaz\"}}},\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}},\n+            ],\n+            [],\n+        ),\n     ],\n )\n def test_draft_orders_filter_by_lines_metadata(\n-    metadata,\n+    filter_input,\n     expected_indexes,\n     draft_order_list,\n     staff_api_client,\n     permission_group_manage_orders,\n ):\n     # given\n     lines = []\n     metadata_values = [\n-        {\"foo\": \"bar\"},\n-        {\"foo\": \"zaz\"},\n+        {\n+            \"foo\": \"bar\",\n+            \"baz\": \"zaz\",\n+        },\n+        {\n+            \"foo\": \"zaz\",\n+            \"baz\": \"zaz\",\n+        },\n         {},\n     ]\n     for order, metadata_value in zip(draft_order_list, metadata_values, strict=True):\n         lines.append(\n@@ -888,9 +915,9 @@\n         )\n     OrderLine.objects.bulk_create(lines)\n \n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    variables = {\"where\": {\"lines\": {\"metadata\": metadata}}}\n+    variables = {\"where\": {\"lines\": filter_input}}\n \n     # when\n     response = staff_api_client.post_graphql(DRAFT_ORDERS_WHERE_QUERY, variables)\n \n@@ -1261,44 +1288,90 @@\n @pytest.mark.parametrize(\n     (\"event_input\", \"expected_indexes\"),\n     [\n         (\n-            {\n-                \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n-                \"type\": {\"eq\": OrderEvents.NOTE_ADDED.upper()},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"eq\": OrderEvents.NOTE_ADDED.upper()},\n+                }\n+            ],\n             [0, 1, 2],\n         ),\n         (\n-            {\n-                \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n-                \"type\": {\"eq\": OrderEvents.ORDER_FULLY_PAID.upper()},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"eq\": OrderEvents.ORDER_FULLY_PAID.upper()},\n+                }\n+            ],\n             [0, 1],\n         ),\n         (\n-            {\n-                \"date\": {\"gte\": \"2026-01-01T00:00:00Z\"},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2026-01-01T00:00:00Z\"},\n+                }\n+            ],\n             [],\n         ),\n         (\n-            {\n-                \"date\": {\"gte\": \"2020-01-01T00:00:00Z\"},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2020-01-01T00:00:00Z\"},\n+                }\n+            ],\n             [0, 1, 2],\n         ),\n         (\n-            {\n-                \"type\": {\n-                    \"oneOf\": [\n-                        OrderEvents.NOTE_ADDED.upper(),\n-                        OrderEvents.ORDER_FULLY_PAID.upper(),\n-                    ]\n-                },\n-            },\n+            [\n+                {\n+                    \"type\": {\n+                        \"oneOf\": [\n+                            OrderEvents.NOTE_ADDED.upper(),\n+                            OrderEvents.ORDER_FULLY_PAID.upper(),\n+                        ]\n+                    },\n+                }\n+            ],\n             [0, 1, 2],\n         ),\n+        (\n+            [\n+                {\n+                    \"type\": {\"eq\": OrderEvents.NOTE_ADDED.upper()},\n+                },\n+                {\n+                    \"type\": {\"eq\": OrderEvents.ORDER_FULLY_PAID.upper()},\n+                },\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"oneOf\": [OrderEvents.NOTE_ADDED.upper()]},\n+                },\n+                {\n+                    \"date\": {\"gte\": \"2025-02-01T00:00:00Z\"},\n+                    \"type\": {\"oneOf\": [OrderEvents.ORDER_FULLY_PAID.upper()]},\n+                },\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"eq\": OrderEvents.NOTE_ADDED.upper()},\n+                },\n+                {\n+                    \"date\": {\"gte\": \"2025-02-02T00:00:00Z\"},\n+                },\n+            ],\n+            [0, 1],\n+        ),\n     ],\n )\n def test_draft_orders_filter_by_order_events(\n     event_input,\n"
        },
        {
          "path": "saleor/graphql/order/tests/queries/test_order_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/queries/test_order_with_where.py\n===================================================================\n--- saleor/graphql/order/tests/queries/test_order_with_where.py\t45bc8df (parent)\n+++ saleor/graphql/order/tests/queries/test_order_with_where.py\t3d60089 (commit)\n@@ -1381,37 +1381,77 @@\n @pytest.mark.parametrize(\n     (\"where\", \"indexes\"),\n     [\n         (\n-            {\n-                \"lte\": (timezone.now() - datetime.timedelta(days=3)).isoformat(),\n-                \"gte\": (timezone.now() - datetime.timedelta(days=25)).isoformat(),\n-            },\n+            [\n+                {\n+                    \"createdAt\": {\n+                        \"lte\": (\n+                            timezone.now() - datetime.timedelta(days=3)\n+                        ).isoformat(),\n+                        \"gte\": (\n+                            timezone.now() - datetime.timedelta(days=25)\n+                        ).isoformat(),\n+                    }\n+                },\n+                {\n+                    \"createdAt\": {\n+                        \"gte\": (\n+                            timezone.now() - datetime.timedelta(days=15)\n+                        ).isoformat(),\n+                    }\n+                },\n+            ],\n             [1, 2],\n         ),\n         (\n-            {\n-                \"lte\": (timezone.now() - datetime.timedelta(days=4)).isoformat(),\n-            },\n+            [\n+                {\n+                    \"createdAt\": {\n+                        \"lte\": (\n+                            timezone.now() - datetime.timedelta(days=4)\n+                        ).isoformat(),\n+                    }\n+                },\n+                {\n+                    \"createdAt\": {\n+                        \"gte\": (\n+                            timezone.now() - datetime.timedelta(days=9)\n+                        ).isoformat(),\n+                    }\n+                },\n+            ],\n             [1, 2],\n         ),\n         (\n-            {\n-                \"gte\": (timezone.now() - datetime.timedelta(days=25)).isoformat(),\n-            },\n-            [0, 1, 2],\n+            [\n+                {\n+                    \"createdAt\": {\n+                        \"lte\": (\n+                            timezone.now() - datetime.timedelta(days=9)\n+                        ).isoformat(),\n+                    }\n+                }\n+            ],\n+            [2],\n         ),\n         (\n-            {\n-                \"lte\": (timezone.now() - datetime.timedelta(days=25)).isoformat(),\n-            },\n-            [],\n+            [\n+                {\n+                    \"createdAt\": {\n+                        \"gte\": (\n+                            timezone.now() - datetime.timedelta(days=2)\n+                        ).isoformat(),\n+                    }\n+                }\n+            ],\n+            [0],\n         ),\n         (None, []),\n-        ({\"gte\": None}, []),\n-        ({\"lte\": None}, []),\n-        ({\"lte\": None, \"gte\": None}, []),\n-        ({}, []),\n+        ([{\"createdAt\": {\"gte\": None}}], []),\n+        ([{\"createdAt\": {\"lte\": None}}], []),\n+        ([{\"createdAt\": {\"lte\": None, \"gte\": None}}], []),\n+        ([{}], []),\n     ],\n )\n def test_orders_filter_by_invoices(\n     where,\n@@ -1424,14 +1464,15 @@\n     Invoice.objects.create(order=order_list[0])\n \n     with freeze_time((timezone.now() - datetime.timedelta(days=5)).isoformat()):\n         Invoice.objects.create(order=order_list[1])\n+        Invoice.objects.create(order=order_list[2])\n \n     with freeze_time((timezone.now() - datetime.timedelta(days=10)).isoformat()):\n         Invoice.objects.create(order=order_list[2])\n \n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    variables = {\"where\": {\"invoices\": {\"createdAt\": where}}}\n+    variables = {\"where\": {\"invoices\": where}}\n \n     # when\n     response = staff_api_client.post_graphql(ORDERS_WHERE_QUERY, variables)\n \n@@ -1512,33 +1553,41 @@\n \n @pytest.mark.parametrize(\n     (\"where\", \"indexes\"),\n     [\n-        ({\"eq\": FulfillmentStatus.FULFILLED.upper()}, [0]),\n-        ({\"eq\": FulfillmentStatus.REFUNDED.upper()}, [1]),\n-        ({\"eq\": FulfillmentStatus.RETURNED.upper()}, [2]),\n+        ([{\"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()}}], [0]),\n+        ([{\"status\": {\"eq\": FulfillmentStatus.REFUNDED.upper()}}], [1]),\n+        ([{\"status\": {\"eq\": FulfillmentStatus.RETURNED.upper()}}], [2]),\n         (\n-            {\n-                \"oneOf\": [\n-                    FulfillmentStatus.FULFILLED.upper(),\n-                    FulfillmentStatus.REFUNDED.upper(),\n-                ]\n-            },\n+            [\n+                {\n+                    \"status\": {\n+                        \"oneOf\": [\n+                            FulfillmentStatus.FULFILLED.upper(),\n+                            FulfillmentStatus.REFUNDED.upper(),\n+                        ]\n+                    }\n+                }\n+            ],\n             [0, 1],\n         ),\n         (\n-            {\n-                \"oneOf\": [\n-                    FulfillmentStatus.REPLACED.upper(),\n-                    FulfillmentStatus.CANCELED.upper(),\n-                ]\n-            },\n+            [\n+                {\n+                    \"status\": {\n+                        \"oneOf\": [\n+                            FulfillmentStatus.REPLACED.upper(),\n+                            FulfillmentStatus.CANCELED.upper(),\n+                        ]\n+                    }\n+                }\n+            ],\n             [],\n         ),\n-        ({\"eq\": FulfillmentStatus.WAITING_FOR_APPROVAL.upper()}, []),\n-        ({}, []),\n-        ({\"oneOf\": []}, []),\n-        ({\"eq\": None}, []),\n+        ([{\"status\": {\"eq\": FulfillmentStatus.WAITING_FOR_APPROVAL.upper()}}], []),\n+        ([{}], []),\n+        ([{\"status\": {\"oneOf\": []}}], []),\n+        ([{\"status\": {\"eq\": None}}], []),\n         (None, []),\n     ],\n )\n def test_orders_filter_by_fulfillment_status(\n@@ -1557,9 +1606,9 @@\n     for order, status in zip(order_list, statuses, strict=True):\n         order.fulfillments.create(tracking_number=\"123\", status=status)\n \n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    variables = {\"where\": {\"fulfillments\": {\"status\": where}}}\n+    variables = {\"where\": {\"fulfillments\": where}}\n \n     # when\n     response = staff_api_client.post_graphql(ORDERS_WHERE_QUERY, variables)\n \n@@ -1571,38 +1620,73 @@\n     assert numbers == {str(order_list[index].number) for index in indexes}\n \n \n @pytest.mark.parametrize(\n-    (\"metadata\", \"expected_indexes\"),\n+    (\"where\", \"expected_indexes\"),\n     [\n-        ({\"key\": \"foo\"}, [0, 1]),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}, [0]),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}, []),\n-        ({\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}, [0, 1]),\n-        ({\"key\": \"notfound\"}, []),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": None}}, []),\n-        ({\"key\": \"foo\", \"value\": {\"oneOf\": []}}, []),\n+        ([{\"metadata\": {\"key\": \"foo\"}}], [0, 1]),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}}], [0]),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}}], [0, 1]),\n+        ([{\"metadata\": {\"key\": \"notfound\"}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": None}}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": []}}}], []),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}},\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"notfound\"}},\n+            ],\n+            [],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}},\n+                {\"metadata\": {\"key\": \"baz\", \"value\": {\"eq\": \"zaz\"}}},\n+            ],\n+            [],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"baz\"}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"zaz\"}}},\n+            ],\n+            [1],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}},\n+                {\"metadata\": {\"key\": \"baz\"}},\n+            ],\n+            [1],\n+        ),\n         (None, []),\n     ],\n )\n def test_orders_filter_by_fulfillment_metadata(\n-    metadata,\n+    where,\n     expected_indexes,\n     order_list,\n     staff_api_client,\n     permission_group_manage_orders,\n ):\n     # given\n     metadata_values = [\n         {\"foo\": \"bar\"},\n-        {\"foo\": \"zaz\"},\n+        {\"foo\": \"zaz\", \"baz\": \"zaz\"},\n         {},\n     ]\n     for order, metadata_value in zip(order_list, metadata_values, strict=True):\n         order.fulfillments.create(tracking_number=\"123\", metadata=metadata_value)\n \n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    variables = {\"where\": {\"fulfillments\": {\"metadata\": metadata}}}\n+    variables = {\"where\": {\"fulfillments\": where}}\n \n     # when\n     response = staff_api_client.post_graphql(ORDERS_WHERE_QUERY, variables)\n \n@@ -1613,31 +1697,93 @@\n     numbers = {node[\"node\"][\"number\"] for node in orders}\n     assert numbers == {str(order_list[i].number) for i in expected_indexes}\n \n \n+@pytest.mark.parametrize(\n+    (\"fulfillment_filter\", \"expected_indexes\"),\n+    [\n+        (\n+            [\n+                {\"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()}},\n+                {\"metadata\": {\"key\": \"foo\"}},\n+            ],\n+            [0],\n+        ),\n+        (\n+            [\n+                {\"status\": {\"eq\": FulfillmentStatus.REFUNDED.upper()}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"zaz\"}}},\n+            ],\n+            [1],\n+        ),\n+        (\n+            [\n+                {\"status\": {\"eq\": FulfillmentStatus.RETURNED.upper()}},\n+                {\"metadata\": {\"key\": \"baz\"}},\n+            ],\n+            [],\n+        ),\n+        (\n+            [\n+                {\n+                    \"status\": {\n+                        \"oneOf\": [\n+                            FulfillmentStatus.FULFILLED.upper(),\n+                            FulfillmentStatus.REFUNDED.upper(),\n+                        ]\n+                    }\n+                },\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}},\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()}},\n+                {\"metadata\": {\"key\": \"notfound\"}},\n+            ],\n+            [],\n+        ),\n+        (\n+            [\n+                {\"status\": {\"eq\": FulfillmentStatus.RETURNED.upper()}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}},\n+            ],\n+            [],\n+        ),\n+        (\n+            [\n+                {\"status\": {}},\n+                {\"metadata\": {\"key\": \"foo\"}},\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [],\n+            [],\n+        ),\n+    ],\n+)\n def test_orders_filter_fulfillment_status_and_metadata_both_match(\n-    orders_with_fulfillments, staff_api_client, permission_group_manage_orders\n+    fulfillment_filter,\n+    expected_indexes,\n+    orders_with_fulfillments,\n+    staff_api_client,\n+    permission_group_manage_orders,\n ):\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    variables = {\n-        \"where\": {\n-            \"fulfillments\": {\n-                \"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()},\n-                \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}},\n-            }\n-        }\n-    }\n+    variables = {\"where\": {\"fulfillments\": fulfillment_filter}}\n \n     # when\n     response = staff_api_client.post_graphql(ORDERS_WHERE_QUERY, variables)\n     content = get_graphql_content(response)\n     orders = content[\"data\"][\"orders\"][\"edges\"]\n \n     # then\n-    assert len(orders) == 1\n+    assert len(orders) == len(expected_indexes)\n     assert {node[\"node\"][\"number\"] for node in orders} == {\n-        str(orders_with_fulfillments[0].number)\n+        str(orders_with_fulfillments[i].number) for i in expected_indexes\n     }\n \n \n def test_orders_filter_fulfillment_status_matches_metadata_not(\n@@ -1646,12 +1792,14 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()},\n-                \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"notfound\"}},\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()},\n+                    \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"notfound\"}},\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1669,12 +1817,14 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": {\"eq\": FulfillmentStatus.REFUNDED.upper()},\n-                \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}},\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": {\"eq\": FulfillmentStatus.REFUNDED.upper()},\n+                    \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}},\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1692,12 +1842,14 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": {\"eq\": FulfillmentStatus.RETURNED.upper()},\n-                \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}},\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": {\"eq\": FulfillmentStatus.RETURNED.upper()},\n+                    \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}},\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1715,12 +1867,14 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()},\n-                \"metadata\": None,\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": {\"eq\": FulfillmentStatus.FULFILLED.upper()},\n+                    \"metadata\": None,\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1741,12 +1895,14 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": None,\n-                \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}},\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": None,\n+                    \"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}},\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1767,12 +1923,14 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": None,\n-                \"metadata\": None,\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": None,\n+                    \"metadata\": None,\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1790,17 +1948,19 @@\n     # given\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n     variables = {\n         \"where\": {\n-            \"fulfillments\": {\n-                \"status\": {\n-                    \"oneOf\": [\n-                        FulfillmentStatus.FULFILLED.upper(),\n-                        FulfillmentStatus.REFUNDED.upper(),\n-                    ]\n-                },\n-                \"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}},\n-            }\n+            \"fulfillments\": [\n+                {\n+                    \"status\": {\n+                        \"oneOf\": [\n+                            FulfillmentStatus.FULFILLED.upper(),\n+                            FulfillmentStatus.REFUNDED.upper(),\n+                        ]\n+                    },\n+                    \"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}},\n+                }\n+            ]\n         }\n     }\n \n     # when\n@@ -1816,32 +1976,59 @@\n     }\n \n \n @pytest.mark.parametrize(\n-    (\"metadata\", \"expected_indexes\"),\n+    (\"filter_input\", \"expected_indexes\"),\n     [\n-        ({\"key\": \"foo\"}, [0, 1]),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}, [0]),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}, []),\n-        ({\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}, [0, 1]),\n-        ({\"key\": \"notfound\"}, []),\n-        ({\"key\": \"foo\", \"value\": {\"eq\": None}}, []),\n-        ({\"key\": \"foo\", \"value\": {\"oneOf\": []}}, []),\n+        ([{\"metadata\": {\"key\": \"foo\"}}], [0, 1]),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}}], [0]),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": [\"bar\", \"zaz\"]}}}], [0, 1]),\n+        ([{\"metadata\": {\"key\": \"notfound\"}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": None}}}], []),\n+        ([{\"metadata\": {\"key\": \"foo\", \"value\": {\"oneOf\": []}}}], []),\n         (None, []),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"bar\"}}},\n+            ],\n+            [0],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"baz\", \"value\": {\"eq\": \"zaz\"}}},\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\"metadata\": {\"key\": \"foo\"}},\n+                {\"metadata\": {\"key\": \"foo\", \"value\": {\"eq\": \"baz\"}}},\n+            ],\n+            [],\n+        ),\n     ],\n )\n def test_orders_filter_by_lines_metadata(\n-    metadata,\n+    filter_input,\n     expected_indexes,\n     order_list,\n     staff_api_client,\n     permission_group_manage_orders,\n ):\n     # given\n     lines = []\n     metadata_values = [\n-        {\"foo\": \"bar\"},\n-        {\"foo\": \"zaz\"},\n+        {\n+            \"foo\": \"bar\",\n+            \"baz\": \"zaz\",\n+        },\n+        {\n+            \"foo\": \"zaz\",\n+            \"baz\": \"zaz\",\n+        },\n         {},\n     ]\n     for order, metadata_value in zip(order_list, metadata_values, strict=True):\n         lines.append(\n@@ -1861,9 +2048,9 @@\n         )\n     OrderLine.objects.bulk_create(lines)\n \n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n-    variables = {\"where\": {\"lines\": {\"metadata\": metadata}}}\n+    variables = {\"where\": {\"lines\": filter_input}}\n \n     # when\n     response = staff_api_client.post_graphql(ORDERS_WHERE_QUERY, variables)\n \n@@ -2234,44 +2421,90 @@\n @pytest.mark.parametrize(\n     (\"event_input\", \"expected_indexes\"),\n     [\n         (\n-            {\n-                \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n-                \"type\": {\"eq\": OrderEvents.PLACED.upper()},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"eq\": OrderEvents.PLACED.upper()},\n+                }\n+            ],\n             [0, 1, 2],\n         ),\n         (\n-            {\n-                \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n-                \"type\": {\"eq\": OrderEvents.ORDER_FULLY_PAID.upper()},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"eq\": OrderEvents.ORDER_FULLY_PAID.upper()},\n+                }\n+            ],\n             [0, 1],\n         ),\n         (\n-            {\n-                \"date\": {\"gte\": \"2026-01-01T00:00:00Z\"},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2026-01-01T00:00:00Z\"},\n+                }\n+            ],\n             [],\n         ),\n         (\n-            {\n-                \"date\": {\"gte\": \"2020-01-01T00:00:00Z\"},\n-            },\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2020-01-01T00:00:00Z\"},\n+                }\n+            ],\n             [0, 1, 2],\n         ),\n         (\n-            {\n-                \"type\": {\n-                    \"oneOf\": [\n-                        OrderEvents.PLACED.upper(),\n-                        OrderEvents.ORDER_FULLY_PAID.upper(),\n-                    ]\n-                },\n-            },\n+            [\n+                {\n+                    \"type\": {\n+                        \"oneOf\": [\n+                            OrderEvents.PLACED.upper(),\n+                            OrderEvents.ORDER_FULLY_PAID.upper(),\n+                        ]\n+                    },\n+                }\n+            ],\n             [0, 1, 2],\n         ),\n+        (\n+            [\n+                {\n+                    \"type\": {\"eq\": OrderEvents.PLACED.upper()},\n+                },\n+                {\n+                    \"type\": {\"eq\": OrderEvents.ORDER_FULLY_PAID.upper()},\n+                },\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"oneOf\": [OrderEvents.PLACED.upper()]},\n+                },\n+                {\n+                    \"date\": {\"gte\": \"2025-02-01T00:00:00Z\"},\n+                    \"type\": {\"oneOf\": [OrderEvents.ORDER_FULLY_PAID.upper()]},\n+                },\n+            ],\n+            [0, 1],\n+        ),\n+        (\n+            [\n+                {\n+                    \"date\": {\"gte\": \"2025-01-01T00:00:00Z\"},\n+                    \"type\": {\"eq\": OrderEvents.PLACED.upper()},\n+                },\n+                {\n+                    \"date\": {\"gte\": \"2025-02-02T00:00:00Z\"},\n+                },\n+            ],\n+            [0, 1],\n+        ),\n     ],\n )\n def test_orders_filter_by_order_events(\n     event_input,\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\t45bc8df (parent)\n+++ saleor/graphql/schema.graphql\t3d60089 (commit)\n@@ -13255,19 +13255,25 @@\n \n   \"\"\"Filter by whether the order has any invoices.\"\"\"\n   hasInvoices: Boolean\n \n-  \"\"\"Filter by invoice data associated with the order.\"\"\"\n-  invoices: InvoiceFilterInput\n+  \"\"\"\n+  Filter by invoice data associated with the order. Each list item represents conditions that must be satisfied by a single invoice. The filter matches orders that have related objects meeting all specified groups of conditions.\n+  \"\"\"\n+  invoices: [InvoiceFilterInput!]\n \n   \"\"\"Filter by whether the order has any fulfillments.\"\"\"\n   hasFulfillments: Boolean\n \n-  \"\"\"Filter by fulfillment data associated with the order.\"\"\"\n-  fulfillments: FulfillmentFilterInput\n+  \"\"\"\n+  Filter by fulfillment data associated with the order.Each list item specifies conditions that must be satisfied by a single fulfillment. The filter matches orders that have related objects meeting all specified groups of conditions.\n+  \"\"\"\n+  fulfillments: [FulfillmentFilterInput!]\n \n-  \"\"\"Filter by metadata fields of order lines.\"\"\"\n-  lines: LinesFilterInput\n+  \"\"\"\n+  Filter by line items associated with the order. Each list item specifies conditions that must be satisfied by a single line. The filter matches orders that have related objects meeting all specified groups of conditions.\n+  \"\"\"\n+  lines: [LinesFilterInput!]\n \n   \"\"\"Filter by number of lines in the order.\"\"\"\n   linesCount: IntFilterInput\n \n@@ -13284,10 +13290,12 @@\n \n   \"\"\"Filter by the product type of related order lines.\"\"\"\n   productTypeId: GlobalIDFilterInput\n \n-  \"\"\"Filter by order events.\"\"\"\n-  events: OrderEventFilterInput\n+  \"\"\"\n+  Filter by order events. Each list item specifies conditions that must be satisfied by a single event. The filter matches orders that have related objects meeting all specified groups of conditions.\n+  \"\"\"\n+  events: [OrderEventFilterInput!]\n \n   \"\"\"Filter by billing address of the order.\"\"\"\n   billingAddress: AddressFilterInput\n \n@@ -13510,10 +13518,12 @@\n \n   \"\"\"Filter by voucher code used in the order.\"\"\"\n   voucherCode: StringFilterInput\n \n-  \"\"\"Filter by metadata fields of order lines.\"\"\"\n-  lines: LinesFilterInput\n+  \"\"\"\n+  Filter by line items associated with the order. Each list item specifies conditions that must be satisfied by a single line. The filter matches orders that have related objects meeting all specified groups of conditions.\n+  \"\"\"\n+  lines: [LinesFilterInput!]\n \n   \"\"\"Filter by number of lines in the order.\"\"\"\n   linesCount: IntFilterInput\n \n@@ -13530,10 +13540,12 @@\n \n   \"\"\"Filter by the product type of related order lines.\"\"\"\n   productTypeId: GlobalIDFilterInput\n \n-  \"\"\"Filter by order events.\"\"\"\n-  events: OrderEventFilterInput\n+  \"\"\"\n+  Filter by order events. Each list item specifies conditions that must be satisfied by a single event. The filter matches orders that have related objects meeting all specified groups of conditions.\n+  \"\"\"\n+  events: [OrderEventFilterInput!]\n \n   \"\"\"Filter by billing address of the order.\"\"\"\n   billingAddress: AddressFilterInput\n \n"
        }
      ]
    },
    {
      "id": "optimize-order-update",
      "sha": "d7b84876a56ecb31156bd87230295cacd525a9aa",
      "parentSha": "ddc959bae9795fd1203f73d64a5216c5d8f4df81",
      "spec": "Implement partial updates and webhook suppression for order mutations.\n\nScope\n- CHANGELOG\n- GraphQL order mutations: DraftOrderComplete and OrderUpdate\n- GraphQL order mutations utilities\n- Order model helpers for diffing\n- Tests (already provided) expect the new GraphQL input shape and behavior\n\nRequirements\n1) CHANGELOG.md\n- Under Unreleased, add a bullet noting that OrderUpdate no longer calls ORDER_UPDATED when no fields changed.\n\n2) saleor/graphql/order/mutations/draft_order_complete.py\n- Update DraftOrderComplete.update_user_fields signature to annotate order: models.Order and return list[str] of updated field names.\n- Behavior:\n  - If order.user is set, copy email to order.user_email and include \"user_email\" in returned update_fields.\n  - Else if order.user_email exists, attempt to set order.user to the active user with that email; include \"user_id\" in returned update_fields (even if set to None when not found).\n- In mutate flow where order is finalized:\n  - Build a local list update_fields initially containing: \"status\", \"search_vector\", \"display_gross_prices\", \"updated_at\".\n  - Call update_user_fields(order) and extend update_fields with its result.\n  - If order.shipping_method is None and a shipping address existed and is being removed during completion, delete order.shipping_address and set it to None, then extend update_fields with:\n    - \"shipping_method_name\"\n    - \"shipping_price_net_amount\"\n    - \"shipping_price_gross_amount\"\n    - \"shipping_address_id\" (use the FK id field when clearing the relation)\n  - Recompute search_vector from prepare_order_search_vector_value and call update_order_display_gross_prices(order).\n  - Save with order.save(update_fields=update_fields).\n\n3) saleor/graphql/order/mutations/order_update.py\n- Refactor class base:\n  - Replace inheritance from DraftOrderCreate with AddressMetadataMixin, ModelWithExtRefMutation, I18nMixin.\n- Imports to add: UUID, AddressType, I18nMixin, AddressMetadataMixin, SyncWebhookControlContext, AddressInput (existing), get_plugin_manager_promise, FlatConcatSearchVector, traced_atomic_transaction, AddressType enum from checkout.\n- Replace use of DraftOrderCreate address helpers with a shared utility (see point 4).\n- Implement clean_input(info, instance, data):\n  - Pop shipping_address and billing_address inputs from data before calling super().clean_input.\n  - Handle user email:\n    - If userEmail equals instance.user_email, drop it from cleaned_input.\n    - Else attempt to find an active User by email; if found and different from instance.user_id, set cleaned_input[\"user\"] to that User; if not found and instance.user_id is set, set cleaned_input[\"user\"] = None.\n  - Validate addresses using I18nMixin.validate_address with AddressType.SHIPPING / AddressType.BILLING and info.\n  - Put validated Address instances back into cleaned_input under \"shipping_address\" and/or \"billing_address\" when provided.\n- Implement get_instance_channel_id(instance, **data) -> UUID | int returning instance.channel_id for channel permission checks.\n- Implement perform_mutation:\n  - Fetch instance via get_instance (supports id or externalReference).\n  - Check channel permissions with the instance’s channel_id.\n  - Serialize old state with instance.serialize_for_comparison().\n  - Build cleaned_input via clean_input.\n  - Extract metadata and private_metadata from cleaned_input and convert them to collections via create_metadata_from_graphql_input.\n  - Construct instance with construct_instance(cleaned_input) and validate_and_update_metadata.\n  - Clean the instance.\n  - Serialize new state with instance.serialize_for_comparison().\n  - Compute changed_fields with diff_instance_data_fields(instance.comparison_fields, old_instance_data, new_instance_data).\n  - Call internal _save(info, instance, cleaned_input, changed_fields).\n  - Return OrderUpdate(order=SyncWebhookControlContext(instance)).\n- Implement _save(info, instance, cleaned_input, changed_fields):\n  - Start with update_fields = changed_fields (list[str]).\n  - Within traced_atomic_transaction:\n    - Save addresses via utils.save_addresses(instance, cleaned_input) and extend update_fields with returned fields.\n    - If prices should be invalidated based on inputs (reuse existing should_invalidate_prices logic: calling invalidate_order_prices when needed), append \"should_refresh_prices\" to update_fields.\n    - If update_fields is non-empty:\n      - Recompute instance.search_vector via FlatConcatSearchVector(*prepare_order_search_vector_value(instance)).\n      - Extend update_fields with [\"updated_at\", \"search_vector\"].\n      - Persist with instance.save(update_fields=update_fields).\n      - Trigger call_order_event(manager, WebhookEventAsyncType.ORDER_UPDATED, instance).\n    - If update_fields is empty: do not save and do not trigger ORDER_UPDATED.\n\n4) saleor/graphql/order/mutations/utils.py\n- Add models import from ....order.\n- Add a save_addresses(instance: models.Order, cleaned_input: dict) -> list[str] helper:\n  - If cleaned_input contains a validated \"shipping_address\": save() the address, assign to instance.shipping_address, and add \"shipping_address\" to update_fields.\n  - If cleaned_input contains a validated \"billing_address\": save() the address, assign to instance.billing_address, and add \"billing_address\" to update_fields.\n  - Return the accumulated update_fields list.\n\n5) saleor/order/models.py\n- Add imports: copy and django.forms.models.model_to_dict.\n- Add a property on Order named comparison_fields that returns a list of fields to compare for changes:\n  - [\"discount\", \"voucher\", \"voucher_code\", \"customer_note\", \"redirect_url\", \"external_reference\", \"user\", \"user_email\", \"channel\", \"metadata\", \"private_metadata\"].\n- Add serialize_for_comparison(self) -> dict that returns a deep copy of model_to_dict(self, fields=self.comparison_fields).\n\n6) GraphQL tests expectations (already updated in test diff):\n- Update the orderUpdate mutation shape to accept a single required input argument: input: OrderUpdateInput! and pass all fields within it.\n- Add tests to ensure that:\n  - When input is empty, no errors and no ORDER_UPDATED webhook is called.\n  - When input sets a field to its current value (e.g., externalReference unchanged), no ORDER_UPDATED webhook is called.\n\nAcceptance criteria\n- OrderUpdate saves only when there are actual changes to any comparison field or to addresses; otherwise it does not save nor trigger ORDER_UPDATED.\n- OrderUpdate triggers ORDER_UPDATED exactly once per mutation that results in updates.\n- DraftOrderComplete saves orders using update_fields that only include modified columns.\n- Tests in saleor/graphql/order/tests/mutations/test_order_update.py pass with the new input signature and webhook suppression cases.\n- CHANGELOG entry present describing webhook suppression for OrderUpdate.",
      "prompt": "Refactor the order update flow to perform partial updates and avoid unnecessary webhooks. Specifically, make OrderUpdate accept a single input object, validate and apply address and user email changes directly, compute which fields actually changed by comparing pre/post state, and only save those fields and emit ORDER_UPDATED when something changed. Similarly, update the draft order completion flow to save only the fields that changed. Add a small helper to save addresses and extend the Order model with utilities to define comparison fields and serialize for comparison. Update the changelog accordingly. Keep the behavior of invalidating prices and search vector updates consistent and ensure tests cover that no webhook fires for empty or no-op updates.",
      "supplementalFiles": [
        "saleor/graphql/core/mutations.py",
        "saleor/graphql/core/context.py",
        "saleor/graphql/account/i18n.py",
        "saleor/graphql/account/mixins.py",
        "saleor/webhook/event_types.py",
        "saleor/order/actions.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\tddc959b (parent)\n+++ CHANGELOG.md\td7b8487 (commit)\n@@ -38,8 +38,9 @@\n - Queries `checkouts`, `checkoutLines`, and `me.checkouts` will no longer trigger external calls to fetch shipping methods (`SHIPPING_LIST_METHODS_FOR_CHECKOUT`) or to filter the available shipping methods (`CHECKOUT_FILTER_SHIPPING_METHODS`) - #17387 by @korycins\n - Queries: `orders`, `draftOrders` and `me.orders` will no longer trigger external calls to calculate taxes: the `ORDER_CALCULATE_TAXES` webhooks and plugins (including AvataxPlugin) - #17421 by @korycins\n - Queries: `orders`, `draftOrders` and `me.orders` will no longer trigger external calls to filter the available shipping methods (`ORDER_FILTER_SHIPPING_METHODS`) - #17425 by @korycins\n - Drop `change_user_address` method from plugin manager - #17495 by @IKarbowiak\n+- `OrderUpdate` mutation do not call `ORDER_UPDATED` anymore in case nothing changed - #17507 by @IKarbowiak\n \n ### GraphQL API\n \n - Add `CheckoutCustomerNoteUpdate` mutation - #16315 by @pitkes22\n"
        },
        {
          "path": "saleor/graphql/order/mutations/draft_order_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_complete.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_complete.py\tddc959b (parent)\n+++ saleor/graphql/order/mutations/draft_order_complete.py\td7b8487 (commit)\n@@ -56,16 +56,20 @@\n         error_type_class = OrderError\n         error_type_field = \"order_errors\"\n \n     @classmethod\n-    def update_user_fields(cls, order):\n+    def update_user_fields(cls, order: models.Order):\n+        update_fields = []\n         if order.user:\n             order.user_email = order.user.email\n+            update_fields.append(\"user_email\")\n         elif order.user_email:\n             try:\n                 order.user = User.objects.get(email=order.user_email)\n             except User.DoesNotExist:\n                 order.user = None\n+            update_fields.append(\"user_id\")\n+        return update_fields\n \n     @classmethod\n     def validate_order(cls, order):\n         if not order.is_draft():\n@@ -118,9 +122,16 @@\n \n         country = get_order_country(order)\n         validate_draft_order(order, order.lines.all(), country, manager)\n         with traced_atomic_transaction():\n-            cls.update_user_fields(order)\n+            update_fields = [\n+                \"status\",\n+                \"search_vector\",\n+                \"display_gross_prices\",\n+                \"updated_at\",\n+            ]\n+            update_user_fields = cls.update_user_fields(order)\n+            update_fields.extend(update_user_fields)\n             channel = order.channel\n             order.status = (\n                 OrderStatus.UNFULFILLED\n                 if channel.automatically_confirm_all_new_orders\n@@ -132,14 +143,22 @@\n                 order.shipping_price = zero_taxed_money(order.currency)\n                 if order.shipping_address:\n                     order.shipping_address.delete()\n                     order.shipping_address = None\n+                update_fields.extend(\n+                    [\n+                        \"shipping_method_name\",\n+                        \"shipping_price_net_amount\",\n+                        \"shipping_price_gross_amount\",\n+                        \"shipping_address_id\",\n+                    ]\n+                )\n \n             order.search_vector = FlatConcatSearchVector(\n                 *prepare_order_search_vector_value(order)\n             )\n             update_order_display_gross_prices(order)\n-            order.save()\n+            order.save(update_fields=update_fields)\n \n             cls.setup_voucher_customer(order, channel)\n             order_lines_info = []\n             lines = order.lines.all()\n"
        },
        {
          "path": "saleor/graphql/order/mutations/order_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/order_update.py\n===================================================================\n--- saleor/graphql/order/mutations/order_update.py\tddc959b (parent)\n+++ saleor/graphql/order/mutations/order_update.py\td7b8487 (commit)\n@@ -1,8 +1,11 @@\n+from uuid import UUID\n+\n import graphene\n from django.core.exceptions import ValidationError\n \n from ....account.models import User\n+from ....checkout import AddressType\n from ....core.postgres import FlatConcatSearchVector\n from ....core.tracing import traced_atomic_transaction\n from ....order import OrderStatus, models\n from ....order.actions import call_order_event\n@@ -10,18 +13,21 @@\n from ....order.search import prepare_order_search_vector_value\n from ....order.utils import invalidate_order_prices\n from ....permission.enums import OrderPermissions\n from ....webhook.event_types import WebhookEventAsyncType\n+from ...account.i18n import I18nMixin\n+from ...account.mixins import AddressMetadataMixin\n from ...account.types import AddressInput\n from ...core import ResolveInfo\n+from ...core.context import SyncWebhookControlContext\n from ...core.descriptions import ADDED_IN_321\n from ...core.doc_category import DOC_CATEGORY_ORDERS\n from ...core.mutations import ModelWithExtRefMutation\n from ...core.types import BaseInputObjectType, NonNullList, OrderError\n from ...meta.inputs import MetadataInput, MetadataInputDescription\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ..types import Order\n-from .draft_order_create import DraftOrderCreate\n+from .utils import save_addresses\n \n \n class OrderUpdateInput(BaseInputObjectType):\n     billing_address = AddressInput(description=\"Billing address of the customer.\")\n@@ -51,9 +57,9 @@\n     class Meta:\n         doc_category = DOC_CATEGORY_ORDERS\n \n \n-class OrderUpdate(DraftOrderCreate, ModelWithExtRefMutation):\n+class OrderUpdate(AddressMetadataMixin, ModelWithExtRefMutation, I18nMixin):\n     class Arguments:\n         id = graphene.ID(required=False, description=\"ID of an order to update.\")\n         external_reference = graphene.String(\n             required=False,\n@@ -73,27 +79,8 @@\n         support_meta_field = True\n         support_private_meta_field = True\n \n     @classmethod\n-    def clean_input(cls, info: ResolveInfo, instance, data, **kwargs):\n-        draft_order_cleaned_input = super().clean_input(info, instance, data, **kwargs)\n-\n-        # We must to filter out field added by DraftOrderUpdate\n-        editable_fields = [\n-            \"billing_address\",\n-            \"shipping_address\",\n-            \"user_email\",\n-            \"external_reference\",\n-            \"metadata\",\n-            \"private_metadata\",\n-        ]\n-        cleaned_input = {}\n-        for key in draft_order_cleaned_input:\n-            if key in editable_fields:\n-                cleaned_input[key] = draft_order_cleaned_input[key]\n-        return cleaned_input\n-\n-    @classmethod\n     def get_instance(cls, info: ResolveInfo, **data):\n         instance = super().get_instance(info, **data)\n         if instance.status == OrderStatus.DRAFT:\n             raise ValidationError(\n@@ -114,23 +101,100 @@\n             for field in [\"shipping_address\", \"billing_address\"]\n         )\n \n     @classmethod\n-    def save(cls, info: ResolveInfo, instance, cleaned_input):\n+    def _save(cls, info: ResolveInfo, instance, cleaned_input, changed_fields):\n+        update_fields = changed_fields\n         with traced_atomic_transaction():\n-            cls._save_addresses(instance, cleaned_input)\n-            if instance.user_email:\n-                user = User.objects.filter(email=instance.user_email).first()\n-                instance.user = user\n-            instance.search_vector = FlatConcatSearchVector(\n-                *prepare_order_search_vector_value(instance)\n-            )\n+            address_fields = save_addresses(instance, cleaned_input)\n+            update_fields.extend(address_fields)\n+\n             manager = get_plugin_manager_promise(info.context).get()\n             if cls.should_invalidate_prices(cleaned_input):\n                 invalidate_order_prices(instance)\n+                update_fields.append(\"should_refresh_prices\")\n \n-            instance.save()\n-            call_order_event(\n-                manager,\n-                WebhookEventAsyncType.ORDER_UPDATED,\n-                instance,\n+            if update_fields:\n+                instance.search_vector = FlatConcatSearchVector(\n+                    *prepare_order_search_vector_value(instance)\n+                )\n+                update_fields.extend([\"updated_at\", \"search_vector\"])\n+\n+                instance.save(update_fields=update_fields)\n+                call_order_event(\n+                    manager,\n+                    WebhookEventAsyncType.ORDER_UPDATED,\n+                    instance,\n+                )\n+\n+    @classmethod\n+    def clean_input(cls, info: ResolveInfo, instance, data, **kwargs):\n+        shipping_address_data = data.pop(\"shipping_address\", None)\n+        billing_address_data = data.pop(\"billing_address\", None)\n+        cleaned_input = super().clean_input(info, instance, data, **kwargs)\n+\n+        if email := cleaned_input.get(\"user_email\", None):\n+            if email == instance.user_email:\n+                cleaned_input.pop(\"user_email\")\n+            try:\n+                user = User.objects.get(email=email, is_active=True)\n+                if user.id != instance.user_id:\n+                    cleaned_input[\"user\"] = user\n+            except User.DoesNotExist:\n+                if instance.user_id:\n+                    cleaned_input[\"user\"] = None\n+\n+        if shipping_address_data:\n+            cleaned_input[\"shipping_address\"] = cls.validate_address(\n+                shipping_address_data,\n+                address_type=AddressType.SHIPPING,\n+                info=info,\n             )\n+\n+        if billing_address_data:\n+            cleaned_input[\"billing_address\"] = cls.validate_address(\n+                billing_address_data,\n+                address_type=AddressType.BILLING,\n+                info=info,\n+            )\n+\n+        return cleaned_input\n+\n+    @classmethod\n+    def get_instance_channel_id(cls, instance, **data) -> UUID | int:\n+        return instance.channel_id\n+\n+    @classmethod\n+    def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n+        instance = cls.get_instance(info, **data)\n+        channel_id = cls.get_instance_channel_id(instance, **data)\n+        cls.check_channel_permissions(info, [channel_id])\n+        old_instance_data = instance.serialize_for_comparison()\n+        data = data.get(\"input\")\n+        cleaned_input = cls.clean_input(info, instance, data)\n+\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n+        instance = cls.construct_instance(instance, cleaned_input)\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n+\n+        cls.clean_instance(info, instance)\n+        new_instance_data = instance.serialize_for_comparison()\n+        changed_fields = cls.diff_instance_data_fields(\n+            instance.comparison_fields,\n+            old_instance_data,\n+            new_instance_data,\n+        )\n+        cls._save(info, instance, cleaned_input, changed_fields)\n+        return OrderUpdate(order=SyncWebhookControlContext(instance))\n"
        },
        {
          "path": "saleor/graphql/order/mutations/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/utils.py\n===================================================================\n--- saleor/graphql/order/mutations/utils.py\tddc959b (parent)\n+++ saleor/graphql/order/mutations/utils.py\td7b8487 (commit)\n@@ -8,9 +8,9 @@\n from ....core.taxes import zero_money, zero_taxed_money\n from ....discount import VoucherType\n from ....discount.interface import VariantPromotionRuleInfo, fetch_variant_rules_info\n from ....discount.utils.manual_discount import apply_discount_to_value\n-from ....order import ORDER_EDITABLE_STATUS, OrderStatus, events\n+from ....order import ORDER_EDITABLE_STATUS, OrderStatus, events, models\n from ....order.actions import call_order_event\n from ....order.error_codes import OrderErrorCode\n from ....order.utils import invalidate_order_prices\n from ....payment import PaymentError\n@@ -234,4 +234,19 @@\n             graphene.Node.to_global_id(\"ProductVariant\", variant.pk)\n         ] = VariantData(variant=variant, rules_info=rules_info)\n \n     return variant_id_to_variant_and_rules_info_map\n+\n+\n+def save_addresses(instance: models.Order, cleaned_input: dict) -> list[str]:\n+    update_fields = []\n+    shipping_address = cleaned_input.get(\"shipping_address\")\n+    if shipping_address:\n+        shipping_address.save()\n+        instance.shipping_address = shipping_address\n+        update_fields.append(\"shipping_address\")\n+    billing_address = cleaned_input.get(\"billing_address\")\n+    if billing_address:\n+        billing_address.save()\n+        instance.billing_address = billing_address\n+        update_fields.append(\"billing_address\")\n+    return update_fields\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_update.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_update.py\tddc959b (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_update.py\td7b8487 (commit)\n@@ -12,20 +12,13 @@\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n ORDER_UPDATE_MUTATION = \"\"\"\n     mutation orderUpdate(\n-        $id: ID!, $email: String, $address: AddressInput, $externalReference: String, $privateMetadata: [MetadataInput!], $metadata: [MetadataInput!]\n+        $id: ID!, $input: OrderUpdateInput!\n     ) {\n         orderUpdate(\n             id: $id,\n-            input: {\n-                userEmail: $email,\n-                externalReference: $externalReference,\n-                shippingAddress: $address,\n-                billingAddress: $address,\n-                metadata: $metadata,\n-                privateMetadata: $privateMetadata,\n-                }\n+            input: $input,\n             ) {\n             errors {\n                 field\n                 code\n@@ -62,11 +55,14 @@\n     external_reference = \"test-ext-ref\"\n \n     variables = {\n         \"id\": order_id,\n-        \"email\": email,\n-        \"address\": graphql_address_data,\n-        \"externalReference\": external_reference,\n+        \"input\": {\n+            \"userEmail\": email,\n+            \"shippingAddress\": graphql_address_data,\n+            \"billingAddress\": graphql_address_data,\n+            \"externalReference\": external_reference,\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -117,11 +113,14 @@\n     external_reference = \"test-ext-ref\"\n \n     variables = {\n         \"id\": order_id,\n-        \"email\": email,\n-        \"address\": graphql_address_data,\n-        \"externalReference\": external_reference,\n+        \"input\": {\n+            \"userEmail\": email,\n+            \"shippingAddress\": graphql_address_data,\n+            \"billingAddress\": graphql_address_data,\n+            \"externalReference\": external_reference,\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -150,11 +149,14 @@\n     external_reference = \"test-ext-ref\"\n \n     variables = {\n         \"id\": order_id,\n-        \"email\": email,\n-        \"address\": graphql_address_data,\n-        \"externalReference\": external_reference,\n+        \"input\": {\n+            \"userEmail\": email,\n+            \"shippingAddress\": graphql_address_data,\n+            \"billingAddress\": graphql_address_data,\n+            \"externalReference\": external_reference,\n+        },\n     }\n \n     # when\n     response = app_api_client.post_graphql(\n@@ -193,9 +195,16 @@\n     order.user = None\n     order.save()\n     email = \"not_default@example.com\"\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n-    variables = {\"id\": order_id, \"email\": email, \"address\": graphql_address_data}\n+    variables = {\n+        \"id\": order_id,\n+        \"input\": {\n+            \"userEmail\": email,\n+            \"shippingAddress\": graphql_address_data,\n+            \"billingAddress\": graphql_address_data,\n+        },\n+    }\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n     content = get_graphql_content(response)\n     error = content[\"data\"][\"orderUpdate\"][\"errors\"][0]\n     assert error[\"field\"] == \"id\"\n@@ -222,9 +231,16 @@\n     assert not order.user_email == email\n     assert not order.shipping_address.first_name == graphql_address_data[\"firstName\"]\n     assert not order.billing_address.last_name == graphql_address_data[\"lastName\"]\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n-    variables = {\"id\": order_id, \"email\": email, \"address\": graphql_address_data}\n+    variables = {\n+        \"id\": order_id,\n+        \"input\": {\n+            \"userEmail\": email,\n+            \"shippingAddress\": graphql_address_data,\n+            \"billingAddress\": graphql_address_data,\n+        },\n+    }\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n     content = get_graphql_content(response)\n     assert not content[\"data\"][\"orderUpdate\"][\"errors\"]\n     data = content[\"data\"][\"orderUpdate\"][\"order\"]\n@@ -557,9 +573,12 @@\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n \n     variables = {\n         \"id\": order_id,\n-        \"address\": graphql_address_data,\n+        \"input\": {\n+            \"shippingAddress\": graphql_address_data,\n+            \"billingAddress\": graphql_address_data,\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -617,9 +636,11 @@\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n \n     variables = {\n         \"id\": order_id,\n-        \"metadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+        \"input\": {\n+            \"metadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -653,9 +674,11 @@\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n \n     variables = {\n         \"id\": order_id,\n-        \"privateMetadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+        \"input\": {\n+            \"privateMetadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -689,10 +712,12 @@\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n \n     variables = {\n         \"id\": order_id,\n-        \"privateMetadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n-        \"metadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+        \"input\": {\n+            \"privateMetadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+            \"metadata\": [{\"key\": \"meta key\", \"value\": \"meta value\"}],\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -727,10 +752,12 @@\n     order_id = graphene.Node.to_global_id(\"Order\", order.id)\n \n     variables = {\n         \"id\": order_id,\n-        # Empty key is invalid\n-        \"metadata\": [{\"key\": \"\", \"value\": \"meta value\"}],\n+        \"input\": {\n+            # Empty key is invalid\n+            \"metadata\": [{\"key\": \"\", \"value\": \"meta value\"}],\n+        },\n     }\n \n     # when\n     response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n@@ -743,4 +770,67 @@\n     assert errors[0][\"code\"] == \"REQUIRED\"\n \n     order.refresh_from_db()\n     assert order.metadata == {}\n+\n+\n+@patch(\"saleor.plugins.manager.PluginsManager.order_updated\")\n+def test_order_update_empty_input(\n+    order_updated_webhook_mock,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_with_lines,\n+):\n+    # given\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    order = order_with_lines\n+    order_id = graphene.Node.to_global_id(\"Order\", order.id)\n+\n+    variables = {\n+        \"id\": order_id,\n+        \"input\": {},\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n+    content = get_graphql_content(response)\n+\n+    # then\n+    assert not content[\"data\"][\"orderUpdate\"][\"errors\"]\n+    data = content[\"data\"][\"orderUpdate\"]\n+    assert not data[\"errors\"]\n+\n+    order_updated_webhook_mock.assert_not_called()\n+\n+\n+@patch(\"saleor.plugins.manager.PluginsManager.order_updated\")\n+def test_order_update_nothing_changed(\n+    order_updated_webhook_mock,\n+    staff_api_client,\n+    permission_group_manage_orders,\n+    order_with_lines,\n+):\n+    # given\n+    permission_group_manage_orders.user_set.add(staff_api_client.user)\n+    order = order_with_lines\n+    order.external_reference = \"test-ext-ref\"\n+    order.save(update_fields=[\"external_reference\"])\n+\n+    order_id = graphene.Node.to_global_id(\"Order\", order.id)\n+\n+    variables = {\n+        \"id\": order_id,\n+        \"input\": {\n+            \"externalReference\": order.external_reference,\n+        },\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(ORDER_UPDATE_MUTATION, variables)\n+    content = get_graphql_content(response)\n+\n+    # then\n+    assert not content[\"data\"][\"orderUpdate\"][\"errors\"]\n+    data = content[\"data\"][\"orderUpdate\"]\n+    assert not data[\"errors\"]\n+\n+    order_updated_webhook_mock.assert_not_called()\n"
        },
        {
          "path": "saleor/order/models.py",
          "status": "modified",
          "diff": "Index: saleor/order/models.py\n===================================================================\n--- saleor/order/models.py\tddc959b (parent)\n+++ saleor/order/models.py\td7b8487 (commit)\n@@ -1,4 +1,5 @@\n+import copy\n from decimal import Decimal\n from operator import attrgetter\n from re import match\n from typing import TYPE_CHECKING, cast\n@@ -10,8 +11,9 @@\n from django.core.validators import MinValueValidator\n from django.db import connection, models\n from django.db.models import F, JSONField, Max\n from django.db.models.expressions import Exists, OuterRef\n+from django.forms.models import model_to_dict\n from django.utils.timezone import now\n from django_measurement.models import MeasurementField\n from django_prices.models import MoneyField, TaxedMoneyField\n from measurement.measures import Weight\n@@ -391,8 +393,27 @@\n             ),\n             BTreeIndex(fields=[\"checkout_token\"], name=\"checkout_token_btree_idx\"),\n         ]\n \n+    @property\n+    def comparison_fields(self):\n+        return [\n+            \"discount\",\n+            \"voucher\",\n+            \"voucher_code\",\n+            \"customer_note\",\n+            \"redirect_url\",\n+            \"external_reference\",\n+            \"user\",\n+            \"user_email\",\n+            \"channel\",\n+            \"metadata\",\n+            \"private_metadata\",\n+        ]\n+\n+    def serialize_for_comparison(self):\n+        return copy.deepcopy(model_to_dict(self, fields=self.comparison_fields))\n+\n     def is_fully_paid(self):\n         return self.total_charged >= self.total.gross\n \n     def is_partly_paid(self):\n"
        }
      ]
    },
    {
      "id": "page-channel-context",
      "sha": "bf1860ea03ab90f96ad0def1aca7611b3b72dbf7",
      "parentSha": "94492e45d9d2ae7c074ffe4ff8e6346d22edb442",
      "spec": "Implement channel-aware Page GraphQL behavior across the schema.\n\nScope and required changes:\n\n1) Page type becomes channel-aware\n- File: saleor/graphql/page/types.py\n  - Change Page to inherit from ChannelContextType instead of ModelObjectType.\n  - Set Meta.default_resolver to ChannelContextType.resolver_with_context.\n  - Update translation field for Page to use resolver=ChannelContextType.resolve_translation.\n  - Update all Page field resolvers to accept ChannelContext[models.Page] as root:\n    - resolve_publication_date, resolve_created, resolve_page_type, resolve_content_json should use root.node instead of root, and where applicable load via root.node IDs.\n    - In resolve_attributes and resolve_attribute:\n      - Use page = root.node and wrap returned Attribute and AttributeValue objects in ChannelContext with channel_slug=root.channel_slug when building SelectedAttribute structures.\n      - Ensure dataloaders use page.id, not root.id.\n\n2) Page queries wrap nodes and querysets with channel context\n- File: saleor/graphql/page/schema.py\n  - resolve_page: Wrap the resolved page with ChannelContext(page, channel_slug=None); return None if not found.\n  - resolve_pages: Wrap the queryset with ChannelQsContext(qs, channel_slug=None) before filter_connection_queryset/create_connection_slice.\n\n3) MenuItem.page returns channel-aware Page\n- File: saleor/graphql/menu/types.py\n  - In MenuItem.resolve_page, when a page is loaded by PageByIdLoader:\n    - Apply existing requestor permission/is_visible logic.\n    - If allowed, return ChannelContext(node=page, channel_slug=root.channel_slug); otherwise return None.\n\n4) AttributeValue.referenced_object wraps Page with ChannelContext\n- File: saleor/graphql/attribute/types.py\n  - In AttributeValue.resolve_referenced_object, for AttributeEntityType.PAGE, change the loader chain to PageByIdLoader(...).load(reference_pk).then(wrap_with_channel_context), using the same wrap_with_channel_context closure used for other entities and passing root.channel_slug.\n\n5) Mutations return ChannelContext-wrapped Page in payloads\n- File: saleor/graphql/page/mutations/page_create.py\n  - Import ChannelContext and override success_response to assign response.page = ChannelContext(instance, channel_slug=None).\n- File: saleor/graphql/page/mutations/page_update.py\n  - Import ChannelContext and override success_response similarly as PageCreate; response.page must be ChannelContext(instance, channel_slug=None).\n- File: saleor/graphql/page/mutations/page_delete.py\n  - Import ChannelContext and after calling plugin event, set response.page = ChannelContext(page, channel_slug=None) before returning.\n- File: saleor/graphql/page/mutations/page_reorder_attribute_values.py\n  - Import ChannelContext and make perform_mutation return PageReorderAttributeValues(page=ChannelContext(page, channel_slug=None)).\n\n6) Metadata base mutation recognizes Page as channel-aware\n- File: saleor/graphql/meta/mutations/base.py\n  - Import page_models.\n  - Include page_models.Page in the isinstance union that triggers wrapping the instance with ChannelContext(node=instance, channel_slug=None) in success_response.\n\n7) Translations return channel-aware Page on nested page field\n- File: saleor/graphql/translations/types.py\n  - In PageTranslatableContent.resolve_page, after fetching the page visible to the user, return ChannelContext(page, channel_slug=None) or None if not found.\n\n8) Webhook subscription payloads return channel-aware Page\n- File: saleor/graphql/webhook/subscription_types.py\n  - In PageBase.resolve_page, wrap the page with ChannelContext(page, channel_slug=None).\n\nAcceptance criteria:\n- All resolvers returning a Page node directly return ChannelContext-wrapped nodes.\n- All connections returning Page lists propagate ChannelContext via ChannelQsContext so edges’ nodes are wrapped with the provided channel_slug.\n- SelectedAttribute structures in Page resolvers propagate the same channel context to embedded Attribute and AttributeValue.\n- MenuItem.page and AttributeValue.referenced_object (for PAGE reference) return ChannelContext-wrapped pages.\n- Mutations (create/update/delete/reorder attribute values) expose ChannelContext-wrapped Page in their response objects.\n- Base metadata mutation wraps Page instances as channel-aware, consistent with other channel entities.\n- Translations and webhook subscription types return ChannelContext-wrapped Pages.\n- Behavior matches patterns used by Product/Collection channel context handling.",
      "prompt": "Make the Page GraphQL API channel-aware, consistent with how Product and Collection are handled.\n\nSpecifically:\n- Update the Page GraphQL type to be channel-aware and to propagate the channel through its resolvers and selected attributes.\n- Ensure single-page queries return a channel-wrapped node and page lists use a channel-scoped queryset wrapper.\n- Make menu items and attribute referenced objects return channel-aware pages when resolving related pages.\n- Ensure page mutations return channel-aware pages in their results, and metadata mutations recognize Page as channel-aware.\n- Align translations and webhook subscription types so they return channel-aware Page objects.\n\nFollow existing channel context patterns already present in the schema (ChannelContext, ChannelContextType, ChannelQsContext) and mirror how they’re used for other types.",
      "supplementalFiles": [
        "saleor/graphql/core/context.py",
        "saleor/graphql/core/types/context.py",
        "saleor/graphql/core/connection.py",
        "saleor/graphql/page/dataloaders.py",
        "saleor/graphql/attribute/dataloaders.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/attribute/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/types.py\n===================================================================\n--- saleor/graphql/attribute/types.py\t94492e4 (parent)\n+++ saleor/graphql/attribute/types.py\tbf1860e (commit)\n@@ -136,9 +136,13 @@\n                     .load(reference_pk)\n                     .then(wrap_with_channel_context)\n                 )\n             if attribute.entity_type == AttributeEntityType.PAGE:\n-                return PageByIdLoader(info.context).load(reference_pk)\n+                return (\n+                    PageByIdLoader(info.context)\n+                    .load(reference_pk)\n+                    .then(wrap_with_channel_context)\n+                )\n             return None\n \n         return (\n             AttributesByAttributeId(info.context)\n"
        },
        {
          "path": "saleor/graphql/menu/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/menu/types.py\n===================================================================\n--- saleor/graphql/menu/types.py\t94492e4 (parent)\n+++ saleor/graphql/menu/types.py\tbf1860e (commit)\n@@ -223,16 +223,18 @@\n                 requestor\n                 and requestor.is_active\n                 and requestor.has_perm(PagePermissions.MANAGE_PAGES)\n             )\n+\n+            def resolve_page_with_channel(page):\n+                if requestor_has_access_to_all or page.is_visible:\n+                    return ChannelContext(node=page, channel_slug=root.channel_slug)\n+                return None\n+\n             return (\n                 PageByIdLoader(info.context)\n                 .load(root.node.page_id)\n-                .then(\n-                    lambda page: (\n-                        page if requestor_has_access_to_all or page.is_visible else None\n-                    )\n-                )\n+                .then(resolve_page_with_channel)\n             )\n         return None\n \n \n"
        },
        {
          "path": "saleor/graphql/meta/mutations/base.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/meta/mutations/base.py\n===================================================================\n--- saleor/graphql/meta/mutations/base.py\t94492e4 (parent)\n+++ saleor/graphql/meta/mutations/base.py\tbf1860e (commit)\n@@ -11,8 +11,9 @@\n from ....discount import models as discount_models\n from ....discount.models import Promotion\n from ....menu import models as menu_models\n from ....order import models as order_models\n+from ....page import models as page_models\n from ....product import models as product_models\n from ....shipping import models as shipping_models\n from ...core import ResolveInfo\n from ...core.context import BaseContext, ChannelContext, SyncWebhookControlContext\n@@ -258,9 +259,10 @@\n             | product_models.ProductVariant\n             | shipping_models.ShippingMethod\n             | shipping_models.ShippingZone\n             | attribute_models.Attribute\n-            | attribute_models.AttributeValue,\n+            | attribute_models.AttributeValue\n+            | page_models.Page,\n         )\n \n         use_channel_context = use_channel_context or (\n             # For old sales migrated into promotions\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_create.py\n===================================================================\n--- saleor/graphql/page/mutations/page_create.py\t94492e4 (parent)\n+++ saleor/graphql/page/mutations/page_create.py\tbf1860e (commit)\n@@ -9,8 +9,9 @@\n from ....permission.enums import PagePermissions\n from ...attribute.types import AttributeValueInput\n from ...attribute.utils import PageAttributeAssignmentMixin\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.descriptions import DEPRECATED_IN_3X_INPUT, RICH_CONTENT\n from ...core.doc_category import DOC_CATEGORY_PAGES\n from ...core.fields import JSONString\n from ...core.mutations import DeprecatedModelMutation\n@@ -133,4 +134,10 @@\n     def save(cls, info: ResolveInfo, instance, cleaned_input):\n         super().save(info, instance, cleaned_input)\n         manager = get_plugin_manager_promise(info.context).get()\n         cls.call_event(manager.page_created, instance)\n+\n+    @classmethod\n+    def success_response(cls, instance):\n+        response = super().success_response(instance)\n+        response.page = ChannelContext(instance, channel_slug=None)\n+        return response\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_delete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_delete.py\n===================================================================\n--- saleor/graphql/page/mutations/page_delete.py\t94492e4 (parent)\n+++ saleor/graphql/page/mutations/page_delete.py\tbf1860e (commit)\n@@ -6,8 +6,9 @@\n from ....core.tracing import traced_atomic_transaction\n from ....page import models\n from ....permission.enums import PagePermissions\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.mutations import ModelDeleteMutation\n from ...core.types import PageError\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ..types import Page\n@@ -34,8 +35,9 @@\n             cls.delete_assigned_attribute_values(page)\n             response = super().perform_mutation(_root, info, **data)\n             page.page_type = page_type\n             cls.call_event(manager.page_deleted, page)\n+        response.page = ChannelContext(page, channel_slug=None)\n         return response\n \n     @staticmethod\n     def delete_assigned_attribute_values(instance):\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_reorder_attribute_values.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_reorder_attribute_values.py\n===================================================================\n--- saleor/graphql/page/mutations/page_reorder_attribute_values.py\t94492e4 (parent)\n+++ saleor/graphql/page/mutations/page_reorder_attribute_values.py\tbf1860e (commit)\n@@ -7,8 +7,9 @@\n from ....permission.enums import PagePermissions\n from ...attribute.mutations import BaseReorderAttributeValuesMutation\n from ...attribute.types import Attribute\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.doc_category import DOC_CATEGORY_PAGES\n from ...core.inputs import ReorderInput\n from ...core.types import NonNullList, PageError\n from ...core.utils.reordering import perform_reordering\n@@ -43,9 +44,9 @@\n     @classmethod\n     def perform_mutation(cls, _root, _info: ResolveInfo, /, **data):\n         page_id = data[\"page_id\"]\n         page = cls.perform(page_id, \"page\", data, \"attributevalues\", PageErrorCode)\n-        return PageReorderAttributeValues(page=page)\n+        return PageReorderAttributeValues(page=ChannelContext(page, channel_slug=None))\n \n     @classmethod\n     def perform(\n         cls,\n"
        },
        {
          "path": "saleor/graphql/page/mutations/page_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/mutations/page_update.py\n===================================================================\n--- saleor/graphql/page/mutations/page_update.py\t94492e4 (parent)\n+++ saleor/graphql/page/mutations/page_update.py\tbf1860e (commit)\n@@ -3,8 +3,9 @@\n from ....page import models\n from ....permission.enums import PagePermissions\n from ...attribute.utils import PageAttributeAssignmentMixin\n from ...core import ResolveInfo\n+from ...core.context import ChannelContext\n from ...core.types import PageError\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ..types import Page\n from .page_create import PageCreate, PageInput\n@@ -37,4 +38,10 @@\n     def save(cls, info: ResolveInfo, instance, cleaned_input):\n         super(PageCreate, cls).save(info, instance, cleaned_input)\n         manager = get_plugin_manager_promise(info.context).get()\n         cls.call_event(manager.page_updated, instance)\n+\n+    @classmethod\n+    def success_response(cls, instance):\n+        response = super().success_response(instance)\n+        response.page = ChannelContext(instance, channel_slug=None)\n+        return response\n"
        },
        {
          "path": "saleor/graphql/page/schema.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/schema.py\n===================================================================\n--- saleor/graphql/page/schema.py\t94492e4 (parent)\n+++ saleor/graphql/page/schema.py\tbf1860e (commit)\n@@ -1,8 +1,9 @@\n import graphene\n \n from ..core import ResolveInfo\n from ..core.connection import create_connection_slice, filter_connection_queryset\n+from ..core.context import ChannelContext, ChannelQsContext\n from ..core.descriptions import ADDED_IN_321, ADDED_IN_322, DEPRECATED_IN_3X_INPUT\n from ..core.doc_category import DOC_CATEGORY_PAGES\n from ..core.enums import LanguageCodeEnum\n from ..core.fields import BaseField, FilterConnectionField\n@@ -82,16 +83,20 @@\n     @staticmethod\n     def resolve_page(\n         _root, info: ResolveInfo, *, id=None, slug=None, slug_language_code=None\n     ):\n-        return resolve_page(info, id, slug, slug_language_code)\n+        page = resolve_page(info, id, slug, slug_language_code)\n+        if not page:\n+            return None\n+        return ChannelContext(page, channel_slug=None)\n \n     @staticmethod\n     def resolve_pages(_root, info: ResolveInfo, **kwargs):\n         qs = resolve_pages(info)\n         search = kwargs.get(\"search\") or kwargs.get(\"filter\", {}).get(\"search\")\n         if search:\n             qs = search_pages(qs, search)\n+        qs = ChannelQsContext(qs, channel_slug=None)\n         qs = filter_connection_queryset(\n             qs, kwargs, allow_replica=info.context.allow_replica\n         )\n         return create_connection_slice(qs, info, kwargs, PageCountableConnection)\n"
        },
        {
          "path": "saleor/graphql/page/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/page/types.py\n===================================================================\n--- saleor/graphql/page/types.py\t94492e4 (parent)\n+++ saleor/graphql/page/types.py\tbf1860e (commit)\n@@ -25,8 +25,9 @@\n from ..core.federation import federated_entity, resolve_federation_references\n from ..core.fields import FilterConnectionField, JSONString, PermissionsField\n from ..core.scalars import Date, DateTime\n from ..core.types import ModelObjectType, NonNullList\n+from ..core.types.context import ChannelContextType\n from ..meta.types import ObjectWithMetadata\n from ..translations.fields import TranslationField\n from ..translations.types import PageTranslation\n from ..utils import get_user_or_app_from_context\n@@ -145,9 +146,9 @@\n         doc_category = DOC_CATEGORY_PAGES\n         node = PageType\n \n \n-class Page(ModelObjectType[models.Page]):\n+class Page(ChannelContextType[models.Page]):\n     id = graphene.GlobalID(required=True, description=\"ID of the page.\")\n     seo_title = graphene.String(description=\"Title of the page for SEO.\")\n     seo_description = graphene.String(description=\"Description of the page for SEO.\")\n     title = graphene.String(required=True, description=\"Title of the page.\")\n@@ -170,9 +171,13 @@\n         description=\"Content of the page.\" + RICH_CONTENT,\n         deprecation_reason=\"Use the `content` field instead.\",\n         required=True,\n     )\n-    translation = TranslationField(PageTranslation, type_name=\"page\")\n+    translation = TranslationField(\n+        PageTranslation,\n+        type_name=\"page\",\n+        resolver=ChannelContextType.resolve_translation,\n+    )\n     attribute = graphene.Field(\n         SelectedAttribute,\n         slug=graphene.Argument(\n             graphene.String,\n@@ -187,44 +192,48 @@\n         description=\"List of attributes assigned to this page.\",\n     )\n \n     class Meta:\n+        default_resolver = ChannelContextType.resolver_with_context\n         description = (\n             \"A static page that can be manually added by a shop operator through the \"\n             \"dashboard.\"\n         )\n         interfaces = [graphene.relay.Node, ObjectWithMetadata]\n         model = models.Page\n \n     @staticmethod\n-    def resolve_publication_date(root: models.Page, _info: ResolveInfo):\n-        return root.published_at\n+    def resolve_publication_date(root: ChannelContext[models.Page], _info: ResolveInfo):\n+        return root.node.published_at\n \n     @staticmethod\n-    def resolve_created(root: models.Page, _info: ResolveInfo):\n-        return root.created_at\n+    def resolve_created(root: ChannelContext[models.Page], _info: ResolveInfo):\n+        return root.node.created_at\n \n     @staticmethod\n-    def resolve_page_type(root: models.Page, info: ResolveInfo):\n-        return PageTypeByIdLoader(info.context).load(root.page_type_id)\n+    def resolve_page_type(root: ChannelContext[models.Page], info: ResolveInfo):\n+        return PageTypeByIdLoader(info.context).load(root.node.page_type_id)\n \n     @staticmethod\n-    def resolve_content_json(root: models.Page, _info: ResolveInfo):\n-        content = root.content\n+    def resolve_content_json(root: ChannelContext[models.Page], _info: ResolveInfo):\n+        content = root.node.content\n         return content if content is not None else {}\n \n     @staticmethod\n-    def resolve_attributes(root: models.Page, info: ResolveInfo):\n+    def resolve_attributes(root: ChannelContext[models.Page], info: ResolveInfo):\n+        page = root.node\n+\n         def wrap_with_channel_context(\n             attributes: list[dict[str, list]] | None,\n         ) -> list[SelectedAttribute] | None:\n             if attributes is None:\n                 return None\n             return [\n                 SelectedAttribute(\n-                    attribute=ChannelContext(attribute[\"attribute\"], None),\n+                    attribute=ChannelContext(attribute[\"attribute\"], root.channel_slug),\n                     values=[\n-                        ChannelContext(value, None) for value in attribute[\"values\"]\n+                        ChannelContext(value, root.channel_slug)\n+                        for value in attribute[\"values\"]\n                     ],\n                 )\n                 for attribute in attributes\n             ]\n@@ -236,28 +245,35 @@\n             and requestor.has_perm(PagePermissions.MANAGE_PAGES)\n         ):\n             return (\n                 SelectedAttributesAllByPageIdLoader(info.context)\n-                .load(root.id)\n+                .load(page.id)\n                 .then(wrap_with_channel_context)\n             )\n         return (\n             SelectedAttributesVisibleInStorefrontPageIdLoader(info.context)\n-            .load(root.id)\n+            .load(page.id)\n             .then(wrap_with_channel_context)\n         )\n \n     @staticmethod\n-    def resolve_attribute(root: models.Page, info: ResolveInfo, slug: str):\n+    def resolve_attribute(\n+        root: ChannelContext[models.Page], info: ResolveInfo, slug: str\n+    ):\n+        page = root.node\n+\n         def wrap_with_channel_context(\n             attribute_data: dict[str, dict | list[dict]] | None,\n         ) -> SelectedAttribute | None:\n             if attribute_data is None:\n                 return None\n             return SelectedAttribute(\n-                attribute=ChannelContext(attribute_data[\"attribute\"], None),\n+                attribute=ChannelContext(\n+                    attribute_data[\"attribute\"], root.channel_slug\n+                ),\n                 values=[\n-                    ChannelContext(value, None) for value in attribute_data[\"values\"]\n+                    ChannelContext(value, root.channel_slug)\n+                    for value in attribute_data[\"values\"]\n                 ],\n             )\n \n         requestor = get_user_or_app_from_context(info.context)\n@@ -267,14 +283,14 @@\n             and requestor.has_perm(PagePermissions.MANAGE_PAGES)\n         ):\n             return (\n                 SelectedAttributeAllByPageIdAttributeSlugLoader(info.context)\n-                .load((root.id, slug))\n+                .load((page.id, slug))\n                 .then(wrap_with_channel_context)\n             )\n         return (\n             SelectedAttributeVisibleInStorefrontPageIdAttributeSlugLoader(info.context)\n-            .load((root.id, slug))\n+            .load((page.id, slug))\n             .then(wrap_with_channel_context)\n         )\n \n \n"
        },
        {
          "path": "saleor/graphql/translations/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/translations/types.py\n===================================================================\n--- saleor/graphql/translations/types.py\t94492e4 (parent)\n+++ saleor/graphql/translations/types.py\tbf1860e (commit)\n@@ -655,14 +655,17 @@\n         )\n \n     @staticmethod\n     def resolve_page(root: page_models.Page, info):\n-        return (\n+        page = (\n             page_models.Page.objects.using(get_database_connection_name(info.context))\n             .visible_to_user(info.context.user)\n             .filter(pk=root.id)\n             .first()\n         )\n+        if not page:\n+            return None\n+        return ChannelContext(page, channel_slug=None)\n \n     @staticmethod\n     def resolve_content_json(root: page_models.Page, _info):\n         content = root.content\n"
        },
        {
          "path": "saleor/graphql/webhook/subscription_types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/subscription_types.py\n===================================================================\n--- saleor/graphql/webhook/subscription_types.py\t94492e4 (parent)\n+++ saleor/graphql/webhook/subscription_types.py\tbf1860e (commit)\n@@ -1529,9 +1529,9 @@\n \n     @staticmethod\n     def resolve_page(root, _info: ResolveInfo):\n         _, page = root\n-        return page\n+        return ChannelContext(page, channel_slug=None)\n \n \n class PageCreated(SubscriptionObjectType, PageBase):\n     class Meta:\n"
        }
      ]
    },
    {
      "id": "refactor-draft-update",
      "sha": "df270700f16ed5d6bfad55d8bafb87c8e6e8ad3f",
      "parentSha": "5ff8b6eeb9dd9093acb7527a96460319b9f51bb2",
      "spec": "Implement a refactor of the DraftOrderUpdate mutation and a minor change in DraftOrderCreate as follows.\n\nFiles to modify:\n- saleor/graphql/order/mutations/draft_order_update.py\n- saleor/graphql/order/mutations/draft_order_create.py\n\nDraftOrderUpdate changes (saleor/graphql/order/mutations/draft_order_update.py):\n1) clean_input adjustments\n- Remove obtaining the plugin manager inside clean_input.\n- Pop redirect_url with an empty-string default: redirect_url = data.pop(\"redirect_url\", \"\").\n- Replace the inline shipping_method resolution block with a call to a new classmethod clean_shipping_method (see below) and merge its returned dict into cleaned_input.\n- Update the call to clean_addresses to no longer pass a manager parameter; the method signature is changed accordingly (see point 2).\n\n2) clean_addresses signature\n- Change the clean_addresses method signature to remove the manager parameter. Ensure all internal logic remains the same (validate shipping and billing addresses, set draft_save_* flags, and raise when a save_* flag is provided without a corresponding address). Update all invocations in this module to match the new signature.\n\n3) New helper: clean_shipping_method\n- Add a @classmethod clean_shipping_method(cls, instance, cleaned_input) that:\n  - If \"shipping_method\" is present in cleaned_input, resolves it via get_shipping_model_by_object_id(object_id=cleaned_input.pop(\"shipping_method\", None), error_field=\"shipping_method\") and returns a dict {\"shipping_method\": <resolved_or_None>}.\n  - Returns an empty dict when no shipping_method provided.\n\n4) Saving and side-effect refactor\n- Modify _save(...) to accept the following parameters: (info, instance, cleaned_input, changed_fields). Remove old_voucher and old_voucher_code parameters.\n- In _save:\n  - Process addresses with save_addresses; extend updated_fields accordingly.\n  - Do not process the shipping method here. If \"shipping_method\" is provided in cleaned_input, only extend updated_fields with SHIPPING_METHOD_UPDATE_FIELDS (no shipping action in this method).\n  - Remove assigning instance.undiscounted_base_shipping_price_amount; this must no longer be set here.\n  - Remove voucher handling from _save.\n  - If updated_fields is empty, return False (no changes and no post-processing).\n  - If shipping or billing address changed, call update_order_display_gross_prices(instance) and append \"display_gross_prices\" to updated_fields.\n  - Call update_order_search_vector(instance, save=False) and append \"search_vector\" to updated_fields (do not append \"updated_at\" here).\n  - If should_invalidate_prices(cleaned_input) returns True, call invalidate_order_prices(instance) and append \"should_refresh_prices\" to updated_fields.\n  - Persist changes by delegating to a new helper _save_order_instance(instance, updated_fields). Return True if saved.\n\n5) New helpers for persistence and events\n- Add @classmethod _save_order_instance(cls, instance, modified_instance_fields) that saves with update_fields=[\"updated_at\"] + modified_instance_fields.\n- Add @classmethod _post_save_action(cls, instance, manager) that triggers the webhook event via call_order_event(manager, WebhookEventAsyncType.DRAFT_ORDER_UPDATED, instance).\n\n6) Voucher handling guard\n- In handle_order_voucher, add an early return: if \"voucher\" not in cleaned_input: return.\n\n7) Shipping processing extraction\n- Add @classmethod handle_shipping(cls, cleaned_input, instance, manager) that:\n  - If \"shipping_method\" not in cleaned_input, return immediately.\n  - If shipping_method is None, call ShippingMethodUpdateMixin.clear_shipping_method_from_order(instance).\n  - Otherwise, call ShippingMethodUpdateMixin.process_shipping_method(instance, method, manager, update_shipping_discount=True).\n\n8) Metadata handling extraction\n- Add @classmethod handle_metadata(cls, instance, cleaned_input) that:\n  - Pops metadata and private_metadata from cleaned_input.\n  - Builds metadata collections using create_metadata_from_graphql_input.\n  - Calls validate_and_update_metadata(instance, ...).\n\n9) perform_mutation flow update\n- Reorder the perform_mutation steps to:\n  - Load instance and check channel permissions.\n  - Snapshot old_instance_data, old_voucher, old_voucher_code.\n  - Clean input via clean_input(...).\n  - Call handle_metadata(instance, cleaned_input).\n  - Construct the instance via construct_instance(instance, cleaned_input).\n  - Validate via clean_instance.\n  - Obtain manager via get_plugin_manager_promise(info.context).get().\n  - Call handle_shipping(cleaned_input, instance, manager).\n  - Call handle_order_voucher(cleaned_input, instance, old_voucher, old_voucher_code).\n  - Compute changed_fields from serialize_for_comparison.\n  - Call order_modified = _save(info, instance, cleaned_input, changed_fields).\n  - If order_modified is True, call _post_save_action(instance, manager).\n  - Return DraftOrderUpdate(order=SyncWebhookControlContext(node=instance)).\n- Remove the call to _save_m2m in perform_mutation.\n\nDraftOrderCreate change (saleor/graphql/order/mutations/draft_order_create.py):\n10) Remove undiscounted shipping assignment in save\n- In DraftOrderCreate.save, delete the following block entirely:\n  - if instance.undiscounted_base_shipping_price_amount is None:\n      instance.undiscounted_base_shipping_price_amount = instance.base_shipping_price_amount\n\nNotes and expectations:\n- Ensure imports remain consistent: get_plugin_manager_promise is still needed (used in perform_mutation). get_shipping_model_by_object_id is used by clean_shipping_method. ShippingMethodUpdateMixin and SHIPPING_METHOD_UPDATE_FIELDS come from .utils and remain unchanged.\n- Avoid passing manager into DraftOrderUpdate.clean_addresses after the signature change; do not change DraftOrderCreate.clean_addresses signature.\n- The event call WebhookEventAsyncType.DRAFT_ORDER_UPDATED must be triggered only when the order was actually modified (order_modified True).\n- No new behavior is added beyond restructuring; ensure price invalidation, search vector updates, and display_gross_prices update behavior match the described points.",
      "prompt": "Refactor the draft order update flow to separate concerns and only trigger webhook events when actual changes occur. Specifically: restructure the draftOrderUpdate mutation so shipping method processing, metadata updates, and persistence/event triggering are handled by dedicated methods; update input cleaning to normalize redirect_url and to resolve shipping methods via a helper; stop assigning an undiscounted base shipping price on both draft create and update paths; and ensure price invalidation and search indexing are still updated appropriately. Keep the external behavior the same but make the logic clearer and more granular, and remove unnecessary manager plumbing from address cleaning in the update flow.",
      "supplementalFiles": [
        "saleor/graphql/plugins/dataloaders.py",
        "saleor/graphql/order/mutations/utils.py",
        "saleor/graphql/order/mutations/draft_order_cleaner.py",
        "saleor/order/search.py",
        "saleor/order/utils.py",
        "saleor/shipping/utils.py",
        "saleor/order/actions.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/order/mutations/draft_order_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_create.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_create.py\t5ff8b6e (parent)\n+++ saleor/graphql/order/mutations/draft_order_create.py\tdf27070 (commit)\n@@ -421,13 +421,8 @@\n                     ShippingMethodUpdateMixin.process_shipping_method(\n                         instance, method, manager, update_shipping_discount=False\n                     )\n \n-            if instance.undiscounted_base_shipping_price_amount is None:\n-                instance.undiscounted_base_shipping_price_amount = (\n-                    instance.base_shipping_price_amount\n-                )\n-\n             if \"voucher\" in cleaned_input:\n                 cls.handle_order_voucher(\n                     cleaned_input,\n                     instance,\n"
        },
        {
          "path": "saleor/graphql/order/mutations/draft_order_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_update.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_update.py\t5ff8b6e (parent)\n+++ saleor/graphql/order/mutations/draft_order_update.py\tdf27070 (commit)\n@@ -101,19 +101,13 @@\n     def clean_input(\n         cls, info: ResolveInfo, instance: models.Order, data: dict, **kwargs\n     ):\n         cls.clean_channel_id(instance, data)\n-        manager = get_plugin_manager_promise(info.context).get()\n         shipping_address = data.pop(\"shipping_address\", None)\n         billing_address = data.pop(\"billing_address\", None)\n-        redirect_url = data.pop(\"redirect_url\", None)\n+        redirect_url = data.pop(\"redirect_url\", \"\")\n \n-        shipping_method_input = {}\n-        if \"shipping_method\" in data:\n-            shipping_method_input[\"shipping_method\"] = get_shipping_model_by_object_id(\n-                object_id=data.pop(\"shipping_method\", None),\n-                error_field=\"shipping_method\",\n-            )\n+        shipping_method_input = cls.clean_shipping_method(instance, data)\n \n         if email := data.get(\"user_email\", None):\n             try:\n                 user = User.objects.get(email=email, is_active=True)\n@@ -128,9 +122,9 @@\n         channel = instance.channel or cleaned_input.get(\"channel_id\")\n         draft_order_cleaner.clean_voucher_and_voucher_code(channel, cleaned_input)\n \n         cls.clean_addresses(\n-            info, instance, cleaned_input, shipping_address, billing_address, manager\n+            info, instance, cleaned_input, shipping_address, billing_address\n         )\n \n         draft_order_cleaner.clean_redirect_url(redirect_url, cleaned_input)\n \n@@ -149,16 +143,27 @@\n                     }\n                 )\n \n     @classmethod\n+    def clean_shipping_method(cls, instance, cleaned_input):\n+        shipping_method_input = {}\n+        if \"shipping_method\" in cleaned_input:\n+            shipping_method = get_shipping_model_by_object_id(\n+                object_id=cleaned_input.pop(\"shipping_method\", None),\n+                error_field=\"shipping_method\",\n+            )\n+            shipping_method_input[\"shipping_method\"] = shipping_method\n+\n+        return shipping_method_input\n+\n+    @classmethod\n     def clean_addresses(\n         cls,\n         info: ResolveInfo,\n         instance,\n         cleaned_input,\n         shipping_address,\n         billing_address,\n-        manager,\n     ):\n         save_shipping_address = cleaned_input.get(\"save_shipping_address\")\n         save_billing_address = cleaned_input.get(\"save_billing_address\")\n         if shipping_address:\n@@ -207,47 +212,23 @@\n         cls,\n         info: ResolveInfo,\n         instance,\n         cleaned_input,\n-        old_voucher,\n-        old_voucher_code,\n         changed_fields,\n     ):\n         updated_fields = changed_fields\n-        manager = get_plugin_manager_promise(info.context).get()\n         with traced_atomic_transaction():\n             # Process addresses\n             address_fields = save_addresses(instance, cleaned_input)\n             updated_fields.extend(address_fields)\n \n             if \"shipping_method\" in cleaned_input:\n-                method = cleaned_input[\"shipping_method\"]\n-                if method is None:\n-                    ShippingMethodUpdateMixin.clear_shipping_method_from_order(instance)\n-                else:\n-                    ShippingMethodUpdateMixin.process_shipping_method(\n-                        instance, method, manager, update_shipping_discount=True\n-                    )\n                 updated_fields.extend(SHIPPING_METHOD_UPDATE_FIELDS)\n \n-            if instance.undiscounted_base_shipping_price_amount is None:\n-                instance.undiscounted_base_shipping_price_amount = (\n-                    instance.base_shipping_price_amount\n-                )\n-                updated_fields.append(\"undiscounted_base_shipping_price_amount\")\n-\n-            if \"voucher\" in cleaned_input:\n-                cls.handle_order_voucher(\n-                    cleaned_input,\n-                    instance,\n-                    old_voucher,\n-                    old_voucher_code,\n-                )\n-\n             # In case nothing change, do not update perform post-process actions;\n             # do not call the `DRAFT_ORDER_UPDATED` event.\n             if not updated_fields:\n-                return\n+                return False\n \n             if (\n                 \"shipping_address\" in updated_fields\n                 or \"billing_address\" in updated_fields\n@@ -255,36 +236,42 @@\n                 update_order_display_gross_prices(instance)\n                 updated_fields.append(\"display_gross_prices\")\n \n             update_order_search_vector(instance, save=False)\n-            # Post-process the results\n-            updated_fields.extend(\n-                [\n-                    \"search_vector\",\n-                    \"updated_at\",\n-                ]\n-            )\n+            updated_fields.append(\"search_vector\")\n \n             if cls.should_invalidate_prices(cleaned_input):\n                 invalidate_order_prices(instance)\n-                updated_fields.extend([\"should_refresh_prices\"])\n+                updated_fields.append(\"should_refresh_prices\")\n \n-            instance.save(update_fields=updated_fields)\n+            cls._save_order_instance(instance, updated_fields)\n \n-            call_order_event(\n-                manager,\n-                WebhookEventAsyncType.DRAFT_ORDER_UPDATED,\n-                instance,\n-            )\n+            return True\n \n     @classmethod\n+    def _save_order_instance(cls, instance, modified_instance_fields):\n+        update_fields = [\"updated_at\"] + modified_instance_fields\n+        instance.save(update_fields=update_fields)\n+\n+    @classmethod\n+    def _post_save_action(cls, instance, manager):\n+        call_order_event(\n+            manager,\n+            WebhookEventAsyncType.DRAFT_ORDER_UPDATED,\n+            instance,\n+        )\n+\n+    @classmethod\n     def handle_order_voucher(\n         cls,\n         cleaned_input,\n         instance: models.Order,\n         old_voucher,\n         old_voucher_code,\n     ):\n+        if \"voucher\" not in cleaned_input:\n+            return\n+\n         voucher = cleaned_input[\"voucher\"]\n         if voucher is None and old_voucher is None:\n             return\n \n@@ -313,19 +300,22 @@\n             voucher_code = VoucherCode.objects.filter(code=old_voucher_code).first()\n             release_voucher_code_usage(voucher_code, old_voucher, user_email)\n \n     @classmethod\n-    def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n-        instance = cls.get_instance(info, **data)\n-        channel_id = cls.get_instance_channel_id(instance, **data)\n+    def handle_shipping(cls, cleaned_input, instance: models.Order, manager):\n+        if \"shipping_method\" not in cleaned_input:\n+            return\n \n-        cls.check_channel_permissions(info, [channel_id])\n+        method = cleaned_input[\"shipping_method\"]\n+        if method is None:\n+            ShippingMethodUpdateMixin.clear_shipping_method_from_order(instance)\n+        else:\n+            ShippingMethodUpdateMixin.process_shipping_method(\n+                instance, method, manager, update_shipping_discount=True\n+            )\n \n-        old_instance_data = instance.serialize_for_comparison()\n-        old_voucher = instance.voucher\n-        old_voucher_code = instance.voucher_code\n-        data = data[\"input\"]\n-        cleaned_input = cls.clean_input(info, instance, data)\n+    @classmethod\n+    def handle_metadata(cls, instance: models.Order, cleaned_input):\n         metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n         private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n             \"private_metadata\", None\n         )\n@@ -335,26 +325,46 @@\n         )\n         private_metadata_collection = cls.create_metadata_from_graphql_input(\n             private_metadata_list, error_field_name=\"private_metadata\"\n         )\n-\n-        instance = cls.construct_instance(instance, cleaned_input)\n-\n         cls.validate_and_update_metadata(\n             instance, metadata_collection, private_metadata_collection\n         )\n+\n+    @classmethod\n+    def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n+        instance = cls.get_instance(info, **data)\n+        channel_id = cls.get_instance_channel_id(instance, **data)\n+\n+        cls.check_channel_permissions(info, [channel_id])\n+\n+        old_instance_data = instance.serialize_for_comparison()\n+        old_voucher = instance.voucher\n+        old_voucher_code = instance.voucher_code\n+        data = data[\"input\"]\n+        cleaned_input = cls.clean_input(info, instance, data)\n+\n+        cls.handle_metadata(instance, cleaned_input)\n+\n+        instance = cls.construct_instance(instance, cleaned_input)\n+\n         cls.clean_instance(info, instance)\n+\n+        manager = get_plugin_manager_promise(info.context).get()\n+        cls.handle_shipping(cleaned_input, instance, manager)\n+        cls.handle_order_voucher(cleaned_input, instance, old_voucher, old_voucher_code)\n+\n         new_instance_data = instance.serialize_for_comparison()\n         changed_fields = cls.diff_instance_data_fields(\n             instance.comparison_fields,\n             old_instance_data,\n             new_instance_data,\n         )\n-        cls._save(\n-            info, instance, cleaned_input, old_voucher, old_voucher_code, changed_fields\n-        )\n-        cls._save_m2m(info, instance, cleaned_input)\n \n+        order_modified = cls._save(info, instance, cleaned_input, changed_fields)\n+        if order_modified:\n+            cls._post_save_action(instance, manager)\n+\n         return DraftOrderUpdate(order=SyncWebhookControlContext(node=instance))\n \n     @classmethod\n     def get_instance_channel_id(cls, instance, **data):\n"
        }
      ]
    },
    {
      "id": "refactor-metadata-flow",
      "sha": "70b525fad70205efb9826c0dc270b58824cefe83",
      "parentSha": "7f44e1ed66cb9d971fed7b16f828771bacf67f25",
      "spec": "Implement centralized, typed metadata handling and adjust GraphQL mutations and tests to use it.\n\n1) Core metadata manager\n- Add saleor/core/utils/metadata_manager.py providing:\n  - Enum MetadataType with values PUBLIC and PRIVATE.\n  - Exception MetadataEmptyKeyError raised when a metadata key is empty or whitespace-only.\n  - Dataclass MetadataItem validating key non-emptiness in __init__ and storing key/value.\n  - Dataclass MetadataItemCollection wrapping a list[MetadataItem]. For None/empty inputs, represent as an empty collection.\n  - Function create_from_graphql_input(items: list[graphql.meta.inputs.MetadataInput] | None) -> MetadataItemCollection converting GraphQL inputs to MetadataItem, propagating MetadataEmptyKeyError. Return empty collection if items is falsy.\n  - Function store_on_instance(collection: MetadataItemCollection, instance: core.models.ModelWithMetadata, target: MetadataType) which for:\n    - PUBLIC: calls instance.store_value_in_metadata with a dict of key->value from the collection.\n    - PRIVATE: calls instance.store_value_in_private_metadata with a dict of key->value from the collection.\n    - Any other value: raise ValueError with message: \"Unknown argument, provide MetadataType.PRIVATE or MetadataType.PUBLIC\".\n\n2) GraphQL BaseMutation refactor\n- In saleor/graphql/core/mutations.py:\n  - Import metadata_manager and MetadataInput (graphql/meta/inputs.py) and use MetadataErrorCode from graphql/core/enums.\n  - Remove/stop using previous update_metadata and validate_metadata_keys helpers.\n  - Add classmethod create_metadata_from_graphql_input(metadata_list: list[MetadataInput] | None, *, error_field_name: str) -> metadata_manager.MetadataItemCollection which:\n    - Calls metadata_manager.create_from_graphql_input.\n    - If MetadataEmptyKeyError is raised, re-raise django.core.exceptions.ValidationError mapping the error to error_field_name with message \"Metadata key cannot be empty.\" and code MetadataErrorCode.REQUIRED.\n  - Update validate_and_update_metadata signature to accept two MetadataItemCollection instances (public and private). For each, if items exist, call metadata_manager.store_on_instance with MetadataType.PUBLIC/PRIVATE respectively.\n\n3) Replace validation/storage usage across mutations\n- In all affected mutations, replace direct handling of metadata lists and previous validate/update helpers with the new flow:\n  - Pop metadata/private_metadata from inputs as typed list[MetadataInput].\n  - Build collections via cls.create_metadata_from_graphql_input(..., error_field_name=\"metadata\") and for private use error_field_name=\"private_metadata\".\n  - Store on instances/addresses via metadata_manager.store_on_instance(collection, instance, MetadataType.PUBLIC/PRIVATE) instead of prior update_metadata.\n- Apply the above in these files (adjusting imports accordingly):\n  - saleor/graphql/account/bulk_mutations/customer_bulk_update.py (also address nested address.metadata handling)\n  - saleor/graphql/account/mixins.py (AddressMetadataMixin.construct_instance)\n  - saleor/graphql/account/mutations/account/account_register.py\n  - saleor/graphql/account/mutations/base.py (BaseAddressUpdate and BaseCustomerCreate address metadata handling)\n  - saleor/graphql/account/mutations/staff/customer_update.py\n  - saleor/graphql/account/mutations/staff/staff_create.py\n  - saleor/graphql/checkout/mutations/checkout_complete.py (validate metadata by creating collection)\n  - saleor/graphql/checkout/mutations/checkout_create.py (shipping/billing address metadata)\n  - saleor/graphql/checkout/mutations/order_create_from_checkout.py (validate metadata/private_metadata by creating collections before proceeding)\n  - saleor/graphql/discount/mutations/voucher/voucher_create.py\n  - saleor/graphql/giftcard/mutations/gift_card_update.py\n  - saleor/graphql/invoice/mutations/invoice_create.py\n  - saleor/graphql/invoice/mutations/invoice_update.py\n  - saleor/graphql/meta/mutations/update_metadata.py (validate with create_metadata_from_graphql_input using error_field_name=\"input\")\n  - saleor/graphql/meta/mutations/update_private_metadata.py (validate with create_metadata_from_graphql_input using error_field_name=\"input\")\n  - saleor/graphql/order/bulk_mutations/order_bulk_create.py (addresses inside bulk orders)\n  - saleor/graphql/order/mutations/draft_order_update.py\n  - saleor/graphql/payment/mutations/transaction/transaction_event_report.py (declare typed MetadataInput for transaction metadata and use BaseMutation helpers)\n  - saleor/graphql/product/bulk_mutations/product_bulk_create.py (product and variant sections)\n  - saleor/graphql/product/bulk_mutations/product_variant_bulk_create.py\n  - saleor/graphql/product/bulk_mutations/product_variant_bulk_update.py\n  - saleor/graphql/product/mutations/digital_contents.py (both create and update)\n  - saleor/graphql/product/mutations/product_variant/product_variant_update.py\n  - saleor/graphql/shop/mutations/shop_settings_update.py\n\n4) Deprecate legacy metadata key validator in payments\n- In saleor/graphql/payment/utils.py, rename metadata_contains_empty_key to deprecated_metadata_contains_empty_key and mark it deprecated in the docstring.\n- Update imports at remaining use sites that still rely on raw list[dict] validations to reference deprecated_metadata_contains_empty_key:\n  - saleor/graphql/account/bulk_mutations/customer_bulk_update.py\n  - saleor/graphql/order/bulk_mutations/order_bulk_create.py\n  - saleor/graphql/payment/mutations/payment/checkout_payment_create.py\n  - saleor/graphql/payment/mutations/transaction/transaction_create.py\n- Keep TODO comments in those call sites indicating future unification with metadata_manager.\n\n5) Metadata-specific base mutation cleanup\n- In saleor/graphql/meta/mutations/base.py, remove the old validate_metadata_keys and ensure mutations use BaseMutation.create_metadata_from_graphql_input where validation is needed (as done in update_metadata and update_private_metadata files).\n\n6) Error field mapping behavior\n- Ensure that when an invalid (empty/whitespace) metadata key is provided, the resulting GraphQL error has error.field equal to the specific metadata field being validated:\n  - For top-level metadata/private_metadata inputs: \"metadata\" or \"privateMetadata\".\n  - For nested metadata (e.g., address metadata inside other inputs): \"metadata\" for that nested input path.\n  - For meta mutations taking \"input\": error.field should be \"input\".\n\n7) Tests\n- Add saleor/core/tests/test_metadata_manager.py to cover:\n  - Creating empty and non-empty MetadataItemCollection from GraphQL inputs.\n  - Raising MetadataEmptyKeyError on empty or whitespace-only keys.\n  - Writing public and private metadata to a ModelWithMetadata subclass via store_on_instance.\n  - Overwriting duplicate keys (last item wins).\n  - Raising ValueError on invalid target with the specified error message.\n- Update saleor/graphql/account/tests/mutations/staff/test_customer_create.py:\n  - For empty metadata key in customer creation, expect a single error with errors[0][\"field\"] == \"metadata\" and errors[0][\"code\"] == AccountErrorCode.REQUIRED.\n\n8) Changelog\n- Append to CHANGELOG.md under unreleased changes: a line noting that invalid metadata now returns error.field as \"metadata\" or \"privateMetadata\" instead of generic \"input\".\n\nNotes/typing:\n- Where popping metadata/private_metadata, annotate as list[MetadataInput] | None to improve clarity and static checking.\n- Keep imports consistent with the new locations (e.g., MetadataErrorCode from graphql/core/enums, not core.error_codes).\n- Preserve existing permission checks around metadata/private metadata operations.\n",
      "prompt": "Refactor metadata handling across the API to use a single, typed metadata manager and return more precise error fields.\n\n- Introduce a core metadata manager that converts GraphQL metadata input into a validated collection and stores it on models (public/private), rejecting empty or whitespace-only keys.\n- Update GraphQL mutations to build metadata collections from inputs, validate them centrally, and store via the manager instead of ad-hoc dict handling.\n- Make error responses point to the exact field being validated (e.g., metadata, privateMetadata, or input), not a generic input.\n- Deprecate the legacy metadata key validator in payment utils and adjust callers accordingly.\n- Add tests for the metadata manager and fix existing tests to expect the new error.field behavior.\n- Update the changelog to describe the improved error handling.\n\nKeep the implementation consistent with existing model methods for storing metadata and existing permission checks. Use existing GraphQL MetadataInput type and error enums. Apply the pattern to all relevant account, checkout, order, product, voucher, gift card, invoice, payment transaction, and shop settings mutations.",
      "supplementalFiles": [
        "saleor/core/models.py",
        "saleor/graphql/meta/inputs.py",
        "saleor/graphql/core/enums.py",
        "saleor/graphql/meta/permissions.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t7f44e1e (parent)\n+++ CHANGELOG.md\t70b525f (commit)\n@@ -53,8 +53,9 @@\n - Add `breakerState` and `breakerLastStateChange` to the `App` type - #16658 by @tomaszszymanski129\n - Mutation `draftOrderCreate` and `draftOrderUpdate` now supports adding metadata & privateMetadata (via `DraftOrderCreateInput`) - #17358 by @lkostrowski\n - Deprecate `draftOrderInput.discount` field - #17294 by @zedzior\n - `GiftCardCreate` and `GiftCardUpdate` mutations now allows to set `metadata` and `privateMetadata` fields via `GiftCardCreateInput` and `GiftCardUpdateInput` - #17399 by @lkostrowski\n+- Improved error handling when trying to set invalid metadata. Now, invalid metadata should properly return `error.field` containing `metadata` or `privateMetadata`, instead generic `input` - #17470 by @lkostrowski\n \n ### Webhooks\n \n - Fixed webhookTrigger payload type for events related to ProductVariant - #16956 by @delemeator\n"
        },
        {
          "path": "saleor/core/tests/test_metadata_manager.py",
          "status": "added",
          "diff": "Index: saleor/core/tests/test_metadata_manager.py\n===================================================================\n--- saleor/core/tests/test_metadata_manager.py\t7f44e1e (parent)\n+++ saleor/core/tests/test_metadata_manager.py\t70b525f (commit)\n@@ -0,0 +1,163 @@\n+import pytest\n+\n+from ...graphql.meta.inputs import MetadataInput\n+from ..models import ModelWithMetadata\n+from ..utils.metadata_manager import (\n+    MetadataEmptyKeyError,\n+    MetadataItem,\n+    MetadataItemCollection,\n+    MetadataType,\n+    create_from_graphql_input,\n+    store_on_instance,\n+)\n+\n+\n+@pytest.fixture\n+def valid_metadata_input() -> MetadataInput:\n+    valid_metadata_item = MetadataInput()\n+\n+    # Graphene doesn't accept params in constructor\n+    valid_metadata_item.key = \"key\"\n+    valid_metadata_item.value = \"value\"\n+\n+    return valid_metadata_item\n+\n+\n+@pytest.fixture\n+def invalid_metadata_input() -> MetadataInput:\n+    invalid_metadata_item = MetadataInput()\n+\n+    # Key can't be empty\n+    invalid_metadata_item.key = \"\"\n+    invalid_metadata_item.value = \"value\"\n+\n+    return invalid_metadata_item\n+\n+\n+@pytest.fixture\n+def valid_metadata_input_list(valid_metadata_input) -> list[MetadataInput]:\n+    return [valid_metadata_input]\n+\n+\n+@pytest.fixture\n+def invalid_metadata_input_list(invalid_metadata_input) -> list[MetadataInput]:\n+    return [invalid_metadata_input]\n+\n+\n+@pytest.fixture\n+def invalid_metadata_input_list_with_one_valid(\n+    valid_metadata_input, invalid_metadata_input\n+) -> list[MetadataInput]:\n+    return [valid_metadata_input, invalid_metadata_input]\n+\n+\n+def test_create_collection_empty():\n+    collection = MetadataItemCollection([])\n+\n+    assert collection.items == []\n+\n+\n+def test_create_collection_valid(valid_metadata_input_list):\n+    collection = MetadataItemCollection(\n+        [\n+            MetadataItem(\n+                valid_metadata_input_list[0].key, valid_metadata_input_list[0].value\n+            )\n+        ]\n+    )\n+\n+    assert collection.items[0].key == valid_metadata_input_list[0].key\n+    assert collection.items[0].value == valid_metadata_input_list[0].value\n+\n+\n+def test_create_collection(valid_metadata_input_list):\n+    collection = create_from_graphql_input(valid_metadata_input_list)\n+\n+    assert collection.items[0].key == valid_metadata_input_list[0].key\n+    assert collection.items[0].value == valid_metadata_input_list[0].value\n+\n+\n+def test_write_on_model_public(valid_metadata_input_list):\n+    class TestModelWithMetadata(ModelWithMetadata):\n+        pass\n+\n+    instance = TestModelWithMetadata()\n+\n+    collection = create_from_graphql_input(valid_metadata_input_list)\n+\n+    store_on_instance(collection, instance, MetadataType.PUBLIC)\n+\n+    assert (\n+        instance.metadata.get(valid_metadata_input_list[0].key)\n+        == valid_metadata_input_list[0].value\n+    )\n+\n+\n+def test_write_on_model_private(valid_metadata_input_list):\n+    class TestModelWithMetadata(ModelWithMetadata):\n+        pass\n+\n+    instance = TestModelWithMetadata()\n+\n+    collection = create_from_graphql_input(valid_metadata_input_list)\n+\n+    store_on_instance(collection, instance, MetadataType.PRIVATE)\n+\n+    assert (\n+        instance.private_metadata.get(valid_metadata_input_list[0].key)\n+        == valid_metadata_input_list[0].value\n+    )\n+\n+\n+def test_throw_on_empty_key(invalid_metadata_input_list):\n+    with pytest.raises(MetadataEmptyKeyError):\n+        create_from_graphql_input(invalid_metadata_input_list)\n+\n+\n+def test_throw_on_empty_key_with_whitespaces():\n+    item = MetadataInput()\n+    item.key = \"  \"\n+    item.value = \"ok\"\n+\n+    with pytest.raises(MetadataEmptyKeyError):\n+        create_from_graphql_input([item])\n+\n+\n+def test_store_multiple_keys():\n+    overwritten_value = \"value1-overwrite\"\n+\n+    metadata_list = [\n+        MetadataItem(key=\"key1\", value=\"value1\"),\n+        MetadataItem(key=\"key2\", value=\"value2\"),\n+        # Test key with the same value to be overwritten\n+        MetadataItem(key=\"key1\", value=overwritten_value),\n+    ]\n+\n+    class TestModelWithMetadata(ModelWithMetadata):\n+        pass\n+\n+    instance = TestModelWithMetadata()\n+\n+    collection = MetadataItemCollection(items=metadata_list)\n+\n+    store_on_instance(collection, instance, MetadataType.PUBLIC)\n+\n+    assert instance.metadata.get(metadata_list[1].key) == metadata_list[1].value\n+\n+    # Check if the key with the same value was overwritten\n+    assert instance.metadata.get(metadata_list[0].key) == overwritten_value\n+\n+\n+def test_throws_for_invalid_metadata_target():\n+    class TestModelWithMetadata(ModelWithMetadata):\n+        pass\n+\n+    with pytest.raises(\n+        ValueError,\n+        match=\"Unknown argument, provide MetadataType.PRIVATE or MetadataType.PUBLIC\",\n+    ):\n+        store_on_instance(\n+            MetadataItemCollection(items=[MetadataItem(key=\"a\", value=\"b\")]),\n+            TestModelWithMetadata(),\n+            \"invalid_target\",\n+        )\n"
        },
        {
          "path": "saleor/core/utils/metadata_manager.py",
          "status": "added",
          "diff": "Index: saleor/core/utils/metadata_manager.py\n===================================================================\n--- saleor/core/utils/metadata_manager.py\t7f44e1e (parent)\n+++ saleor/core/utils/metadata_manager.py\t70b525f (commit)\n@@ -0,0 +1,75 @@\n+from dataclasses import dataclass\n+from enum import Enum\n+\n+from ...graphql.meta.inputs import MetadataInput\n+from ..models import ModelWithMetadata\n+\n+\n+class MetadataType(Enum):\n+    PUBLIC = \"PUBLIC\"\n+    PRIVATE = \"PRIVATE\"\n+\n+\n+class MetadataEmptyKeyError(Exception):\n+    pass\n+\n+\n+@dataclass\n+class MetadataItem:\n+    key: str\n+    value: str\n+\n+    def __init__(self, key: str, value: str):\n+        if not key.strip():\n+            raise MetadataEmptyKeyError()\n+\n+        self.key = key\n+        self.value = value\n+\n+\n+@dataclass\n+class MetadataItemCollection:\n+    items: list[MetadataItem]\n+\n+\n+def store_on_instance(\n+    metadata_collection: MetadataItemCollection,\n+    instance: ModelWithMetadata,\n+    target: MetadataType,\n+):\n+    if not metadata_collection.items:\n+        return\n+\n+    match target:\n+        case MetadataType.PUBLIC:\n+            instance.store_value_in_metadata(\n+                {item.key: item.value for item in metadata_collection.items}\n+            )\n+        case MetadataType.PRIVATE:\n+            instance.store_value_in_private_metadata(\n+                {item.key: item.value for item in metadata_collection.items}\n+            )\n+        case _:\n+            raise ValueError(\n+                \"Unknown argument, provide MetadataType.PRIVATE or MetadataType.PUBLIC\"\n+            )\n+\n+\n+def create_from_graphql_input(\n+    items: list[MetadataInput] | None,\n+) -> MetadataItemCollection:\n+    \"\"\"Create MetadataItemCollection from graphQL input.\n+\n+    Use with care.\n+\n+    This method is eventually raising MetadataEmptyKeyError, so if it's used directly\n+    in mutation, error will not be handled.\n+\n+    Use BaseMutation.create_metadata_from_graphql_input to include error translation.\n+    \"\"\"\n+    if not items:\n+        return MetadataItemCollection([])\n+\n+    return MetadataItemCollection(\n+        [MetadataItem(item.key, item.value) for item in items]\n+    )\n"
        },
        {
          "path": "saleor/graphql/account/bulk_mutations/customer_bulk_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/bulk_mutations/customer_bulk_update.py\n===================================================================\n--- saleor/graphql/account/bulk_mutations/customer_bulk_update.py\t7f44e1e (parent)\n+++ saleor/graphql/account/bulk_mutations/customer_bulk_update.py\t70b525f (commit)\n@@ -10,8 +10,9 @@\n from ....account.events import CustomerEvents\n from ....account.search import prepare_user_search_document_value\n from ....checkout import AddressType\n from ....core.tracing import traced_atomic_transaction\n+from ....core.utils import metadata_manager\n from ....giftcard.search import mark_gift_cards_search_index_as_dirty_by_users\n from ....giftcard.utils import assign_user_gift_cards\n from ....order.utils import match_orders_with_new_user\n from ....permission.enums import AccountPermissions\n@@ -27,9 +28,10 @@\n     NonNullList,\n )\n from ...core.utils import WebhookEventInfo, get_duplicated_values\n from ...core.validators import validate_one_of_args_is_in_mutation\n-from ...payment.utils import metadata_contains_empty_key\n+from ...meta.inputs import MetadataInput\n+from ...payment.utils import deprecated_metadata_contains_empty_key\n from ...plugins.dataloaders import get_app_promise, get_plugin_manager_promise\n from ..i18n import I18nMixin\n from ..mutations.base import (\n     BILLING_ADDRESS_FIELD,\n@@ -207,9 +209,9 @@\n         errors_count: int,\n         index: int,\n         index_error_map: dict,\n     ):\n-        if metadata_contains_empty_key(metadata_list):\n+        if deprecated_metadata_contains_empty_key(metadata_list):\n             index_error_map[index].append(\n                 CustomerBulkUpdateError(\n                     path=f\"input.{field_name}\",\n                     message=\"Metadata key cannot be empty.\",\n@@ -359,10 +361,18 @@\n \n     @classmethod\n     def update_address(cls, info, instance, data, field):\n         address = getattr(instance, field) or models.Address()\n-        address_metadata = data.pop(\"metadata\", [])\n-        cls.update_metadata(address, address_metadata)\n+        address_metadata: list[MetadataInput] = data.pop(\"metadata\", [])\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            address_metadata, error_field_name=\"metadata\"\n+        )\n+\n+        metadata_manager.store_on_instance(\n+            metadata_collection, address, metadata_manager.MetadataType.PUBLIC\n+        )\n+\n         address = cls.construct_instance(address, data)\n         cls.clean_instance(info, address)\n         return address\n \n@@ -382,10 +392,12 @@\n             external_ref = cleaned_input.get(\"external_reference\")\n             data = cleaned_input[\"input\"]\n             shipping_address_input = data.pop(SHIPPING_ADDRESS_FIELD, None)\n             billing_address_input = data.pop(BILLING_ADDRESS_FIELD, None)\n-            metadata_list = data.pop(\"metadata\", None)\n-            private_metadata_list = data.pop(\"private_metadata\", None)\n+            metadata_list: list[MetadataInput] = data.pop(\"metadata\", None)\n+            private_metadata_list: list[MetadataInput] = data.pop(\n+                \"private_metadata\", None\n+            )\n \n             filtered_customers = list(\n                 filter(\n                     cls._get_customer(customer_id, external_ref),\n@@ -416,15 +428,32 @@\n                             BILLING_ADDRESS_FIELD,\n                         )\n \n                     if metadata_list is not None:\n-                        cls.update_metadata(new_instance, metadata_list)\n+                        metadata_collection = cls.create_metadata_from_graphql_input(\n+                            metadata_list, error_field_name=\"metadata\"\n+                        )\n \n+                        metadata_manager.store_on_instance(\n+                            metadata_collection,\n+                            new_instance,\n+                            metadata_manager.MetadataType.PUBLIC,\n+                        )\n+\n                     if private_metadata_list is not None:\n-                        cls.update_metadata(\n-                            new_instance, private_metadata_list, is_private=True\n+                        private_metadata_collection = (\n+                            cls.create_metadata_from_graphql_input(\n+                                private_metadata_list,\n+                                error_field_name=\"private_metadata\",\n+                            )\n                         )\n \n+                        metadata_manager.store_on_instance(\n+                            private_metadata_collection,\n+                            new_instance,\n+                            metadata_manager.MetadataType.PRIVATE,\n+                        )\n+\n                     instances_data_and_errors_list.append(\n                         {\n                             \"instance\": new_instance,\n                             \"old_instance\": old_instance,\n"
        },
        {
          "path": "saleor/graphql/account/mixins.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mixins.py\n===================================================================\n--- saleor/graphql/account/mixins.py\t7f44e1e (parent)\n+++ saleor/graphql/account/mixins.py\t70b525f (commit)\n@@ -1,17 +1,28 @@\n from ...account import models\n from ...account.error_codes import AccountErrorCode\n from ...app.models import App\n from ...core.exceptions import PermissionDenied\n+from ...core.utils import metadata_manager\n from ...permission.enums import AccountPermissions\n from ..core.utils import raise_validation_error\n+from ..meta.inputs import MetadataInput\n from ..utils import get_user_or_app_from_context\n \n \n class AddressMetadataMixin:\n     @classmethod\n     def construct_instance(cls, instance, cleaned_data):\n-        cls.update_metadata(instance, cleaned_data.pop(\"metadata\", []))  # type: ignore[attr-defined] # noqa: E501\n+        metadata: list[MetadataInput] = cleaned_data.pop(\"metadata\", [])\n+\n+        metadata_collection = super().create_metadata_from_graphql_input(  # type: ignore[misc] # noqa: E501\n+            metadata, error_field_name=\"metadata\"\n+        )\n+\n+        metadata_manager.store_on_instance(\n+            metadata_collection, instance, metadata_manager.MetadataType.PUBLIC\n+        )\n+\n         return super().construct_instance(instance, cleaned_data)  # type: ignore[misc] # noqa: E501\n \n \n class AppImpersonateMixin:\n"
        },
        {
          "path": "saleor/graphql/account/mutations/account/account_register.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/account/account_register.py\n===================================================================\n--- saleor/graphql/account/mutations/account/account_register.py\t7f44e1e (parent)\n+++ saleor/graphql/account/mutations/account/account_register.py\t70b525f (commit)\n@@ -160,16 +160,31 @@\n     def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n         instance = models.User()\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, instance, data)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         instance = cls.construct_instance(instance, cleaned_input)\n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n+\n         user_exists = cls.clean_instance(info, instance)\n+\n         context_data = RequestorAwareContext.create_context_data(info.context)\n         cls.save_and_create_task(user_exists, instance, cleaned_input, context_data)\n+\n         return cls.success_response(instance)\n \n     @classmethod\n     def save_and_create_task(cls, user_exists, instance, cleaned_input, context_data):\n"
        },
        {
          "path": "saleor/graphql/account/mutations/base.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/base.py\n===================================================================\n--- saleor/graphql/account/mutations/base.py\t7f44e1e (parent)\n+++ saleor/graphql/account/mutations/base.py\t70b525f (commit)\n@@ -11,8 +11,9 @@\n from ....account.search import prepare_user_search_document_value\n from ....checkout import AddressType\n from ....core.exceptions import PermissionDenied\n from ....core.tracing import traced_atomic_transaction\n+from ....core.utils import metadata_manager\n from ....core.utils.url import prepare_url, validate_storefront_url\n from ....giftcard.search import mark_gift_cards_search_index_as_dirty\n from ....giftcard.utils import get_user_gift_cards\n from ....graphql.utils import get_user_or_app_from_context\n@@ -91,9 +92,17 @@\n         instance = cls.get_instance(info, **data)\n         cleaned_input = cls.clean_input(\n             info=info, instance=instance, data=data.get(\"input\")\n         )\n-        cls.update_metadata(instance, cleaned_input.pop(\"metadata\", []))\n+\n+        metadata = cleaned_input.pop(\"metadata\", [])\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata, error_field_name=\"metadata\"\n+        )\n+        metadata_manager.store_on_instance(\n+            metadata_collection, instance, metadata_manager.MetadataType.PUBLIC\n+        )\n+\n         address = cls.validate_address(cleaned_input, instance=instance, info=info)\n         cls.clean_instance(info, address)\n         cls.save(info, address, cleaned_input)\n         cls._save_m2m(info, address, cleaned_input)\n@@ -263,27 +272,57 @@\n         billing_address_data = data.pop(BILLING_ADDRESS_FIELD, None)\n         cleaned_input = super().clean_input(info, instance, data, **kwargs)\n \n         if shipping_address_data:\n-            address_metadata = shipping_address_data.pop(\"metadata\", [])\n+            shipping_address_metadata: list[MetadataInput] = shipping_address_data.pop(\n+                \"metadata\", []\n+            )\n+            shipping_address_metadata_collection = (\n+                cls.create_metadata_from_graphql_input(\n+                    shipping_address_metadata,\n+                    error_field_name=\"metadata\",\n+                )\n+            )\n+\n             shipping_address = cls.validate_address(\n                 shipping_address_data,\n                 address_type=AddressType.SHIPPING,\n                 instance=getattr(instance, SHIPPING_ADDRESS_FIELD),\n                 info=info,\n             )\n-            cls.update_metadata(shipping_address, address_metadata)\n+\n+            metadata_manager.store_on_instance(\n+                shipping_address_metadata_collection,\n+                shipping_address,\n+                metadata_manager.MetadataType.PUBLIC,\n+            )\n+\n             cleaned_input[SHIPPING_ADDRESS_FIELD] = shipping_address\n \n         if billing_address_data:\n-            address_metadata = billing_address_data.pop(\"metadata\", [])\n+            billing_address_metadata: list[MetadataInput] = billing_address_data.pop(\n+                \"metadata\", []\n+            )\n+            billing_address_metadata_collection = (\n+                cls.create_metadata_from_graphql_input(\n+                    billing_address_metadata,\n+                    error_field_name=\"metadata\",\n+                )\n+            )\n+\n             billing_address = cls.validate_address(\n                 billing_address_data,\n                 address_type=AddressType.BILLING,\n                 instance=getattr(instance, BILLING_ADDRESS_FIELD),\n                 info=info,\n             )\n-            cls.update_metadata(billing_address, address_metadata)\n+\n+            metadata_manager.store_on_instance(\n+                billing_address_metadata_collection,\n+                billing_address,\n+                metadata_manager.MetadataType.PUBLIC,\n+            )\n+\n             cleaned_input[BILLING_ADDRESS_FIELD] = billing_address\n \n         if cleaned_input.get(\"redirect_url\"):\n             try:\n"
        },
        {
          "path": "saleor/graphql/account/mutations/staff/customer_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/staff/customer_update.py\n===================================================================\n--- saleor/graphql/account/mutations/staff/customer_update.py\t7f44e1e (parent)\n+++ saleor/graphql/account/mutations/staff/customer_update.py\t70b525f (commit)\n@@ -16,8 +16,9 @@\n from ....core.doc_category import DOC_CATEGORY_USERS\n from ....core.mutations import ModelWithExtRefMutation\n from ....core.types import AccountError\n from ....core.utils import WebhookEventInfo\n+from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ..base import CustomerInput\n from .customer_create import CustomerCreate\n \n@@ -124,14 +125,23 @@\n         data = data.get(\"input\")\n \n         # Clean the input and generate a new instance from the new data\n         cleaned_input = cls.clean_input(info, original_instance, data)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         new_instance = cls.construct_instance(copy(original_instance), cleaned_input)\n         cls.validate_and_update_metadata(\n-            new_instance, metadata_list, private_metadata_list\n+            new_instance, metadata_collection, private_metadata_collection\n         )\n \n         # Save the new instance data\n         cls.clean_instance(info, new_instance)\n"
        },
        {
          "path": "saleor/graphql/account/mutations/staff/staff_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/mutations/staff/staff_create.py\n===================================================================\n--- saleor/graphql/account/mutations/staff/staff_create.py\t7f44e1e (parent)\n+++ saleor/graphql/account/mutations/staff/staff_create.py\t70b525f (commit)\n@@ -21,8 +21,9 @@\n from ....core.doc_category import DOC_CATEGORY_USERS\n from ....core.mutations import DeprecatedModelMutation\n from ....core.types import NonNullList, StaffError\n from ....core.utils import WebhookEventInfo\n+from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...utils import get_groups_which_user_can_manage\n from ..base import UserInput\n \n@@ -225,13 +226,25 @@\n     def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n         instance, send_notification = cls.get_instance(info, **data)\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, instance, data)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         instance = cls.construct_instance(instance, cleaned_input)\n \n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         cls.clean_instance(info, instance)\n         cls.save(info, instance, cleaned_input, send_notification)\n         cls._save_m2m(info, instance, cleaned_input)\n         cls.post_save_action(info, instance, cleaned_input)\n"
        },
        {
          "path": "saleor/graphql/account/tests/mutations/staff/test_customer_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/account/tests/mutations/staff/test_customer_create.py\n===================================================================\n--- saleor/graphql/account/tests/mutations/staff/test_customer_create.py\t7f44e1e (parent)\n+++ saleor/graphql/account/tests/mutations/staff/test_customer_create.py\t70b525f (commit)\n@@ -415,9 +415,9 @@\n     # then\n     content = get_graphql_content(response)\n     errors = content[\"data\"][\"customerCreate\"][\"errors\"]\n     assert len(errors) == 1\n-    assert errors[0][\"field\"] == \"input\"\n+    assert errors[0][\"field\"] == \"metadata\"\n     assert errors[0][\"code\"] == AccountErrorCode.REQUIRED.name\n \n \n def test_customer_create_without_send_password(\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_complete.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_complete.py\t7f44e1e (parent)\n+++ saleor/graphql/checkout/mutations/checkout_complete.py\t70b525f (commit)\n@@ -277,9 +277,11 @@\n             cls.check_metadata_permissions(\n                 info,\n                 id or checkout_id or graphene.Node.to_global_id(\"Checkout\", token),\n             )\n-            cls.validate_metadata_keys(metadata)\n+            cls.create_metadata_from_graphql_input(\n+                metadata, error_field_name=\"metadata\"\n+            )\n \n         validate_checkout_email(checkout)\n \n         manager = get_plugin_manager_promise(info.context).get()\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/checkout_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/checkout_create.py\n===================================================================\n--- saleor/graphql/checkout/mutations/checkout_create.py\t7f44e1e (parent)\n+++ saleor/graphql/checkout/mutations/checkout_create.py\t70b525f (commit)\n@@ -8,8 +8,9 @@\n from ....checkout.actions import call_checkout_event\n from ....checkout.error_codes import CheckoutErrorCode\n from ....checkout.utils import add_variants_to_checkout, create_checkout_metadata\n from ....core.tracing import traced_atomic_transaction\n+from ....core.utils import metadata_manager\n from ....core.utils.country import get_active_country\n from ....product import models as product_models\n from ....warehouse.reservations import get_reservation_length, is_reservation_enabled\n from ....webhook.event_types import WebhookEventAsyncType\n@@ -310,25 +311,42 @@\n \n         cleaned_input[\"channel\"] = channel\n         cleaned_input[\"currency\"] = channel.currency_code\n         save_shipping_address = data.get(\"save_shipping_address\")\n-        shipping_address_metadata = (\n+        shipping_address_metadata: list[MetadataInput] | None = (\n             data.get(\"shipping_address\", {}).pop(\"metadata\", [])\n             if data.get(\"shipping_address\")\n             else None\n         )\n         save_billing_address = data.get(\"save_billing_address\")\n-        billing_address_metadata = (\n+        billing_address_metadata: list[MetadataInput] | None = (\n             data.get(\"billing_address\", {}).pop(\"metadata\", [])\n             if data.get(\"billing_address\")\n             else None\n         )\n+\n+        shipping_address_metadata_collection = cls.create_metadata_from_graphql_input(\n+            shipping_address_metadata, error_field_name=\"metadata\"\n+        )\n+        billing_address_metadata_collection = cls.create_metadata_from_graphql_input(\n+            billing_address_metadata, error_field_name=\"metadata\"\n+        )\n+\n         shipping_address = cls.retrieve_shipping_address(user, data, info)\n         billing_address = cls.retrieve_billing_address(user, data, info)\n         if shipping_address:\n-            cls.update_metadata(shipping_address, shipping_address_metadata)\n+            metadata_manager.store_on_instance(\n+                shipping_address_metadata_collection,\n+                shipping_address,\n+                metadata_manager.MetadataType.PUBLIC,\n+            )\n+\n         if billing_address:\n-            cls.update_metadata(billing_address, billing_address_metadata)\n+            metadata_manager.store_on_instance(\n+                billing_address_metadata_collection,\n+                billing_address,\n+                metadata_manager.MetadataType.PUBLIC,\n+            )\n \n         if save_shipping_address is not None and not shipping_address:\n             raise ValidationError(\n                 {\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/order_create_from_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/order_create_from_checkout.py\n===================================================================\n--- saleor/graphql/checkout/mutations/order_create_from_checkout.py\t7f44e1e (parent)\n+++ saleor/graphql/checkout/mutations/order_create_from_checkout.py\t70b525f (commit)\n@@ -166,12 +166,16 @@\n         )\n \n         if cls._meta.support_meta_field and metadata is not None:\n             cls.check_metadata_permissions(info, id)\n-            cls.validate_metadata_keys(metadata)\n+            cls.create_metadata_from_graphql_input(\n+                metadata, error_field_name=\"metadata\"\n+            )\n         if cls._meta.support_private_meta_field and private_metadata is not None:\n             cls.check_metadata_permissions(info, id, private=True)\n-            cls.validate_metadata_keys(private_metadata)\n+            cls.create_metadata_from_graphql_input(\n+                metadata, error_field_name=\"private_metadata\"\n+            )\n \n         manager = get_plugin_manager_promise(info.context).get()\n         checkout_lines, unavailable_variant_pks = fetch_checkout_lines(checkout)\n         checkout_info = fetch_checkout_info(checkout, checkout_lines, manager)\n"
        },
        {
          "path": "saleor/graphql/core/mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/mutations.py\n===================================================================\n--- saleor/graphql/core/mutations.py\t7f44e1e (parent)\n+++ saleor/graphql/core/mutations.py\t70b525f (commit)\n@@ -20,10 +20,10 @@\n from graphene.types.mutation import MutationOptions\n from graphql.error import GraphQLError\n \n from ...core.db.connection import allow_writer\n-from ...core.error_codes import MetadataErrorCode\n from ...core.exceptions import PermissionDenied\n+from ...core.utils import metadata_manager\n from ...core.utils.events import call_event\n from ...permission.auth_filters import AuthorizationFilters\n from ...permission.enums import BasePermissionEnum\n from ...permission.utils import (\n@@ -34,14 +34,15 @@\n from ..account.utils import get_user_accessible_channels\n from ..app.dataloaders import get_app_promise\n from ..core.doc_category import DOC_CATEGORY_MAP\n from ..core.validators import validate_one_of_args_is_in_mutation\n+from ..meta.inputs import MetadataInput\n from ..meta.permissions import PRIVATE_META_PERMISSION_MAP, PUBLIC_META_PERMISSION_MAP\n-from ..payment.utils import metadata_contains_empty_key\n from ..utils import get_nodes, resolve_global_ids_to_primary_keys\n from . import ResolveInfo\n from .context import disallow_replica_in_context, setup_context_user\n from .descriptions import DEPRECATED_IN_3X_FIELD\n+from .enums import MetadataErrorCode\n from .types import (\n     TYPES_WITH_DOUBLE_ID_AVAILABLE,\n     File,\n     ModelObjectType,\n@@ -545,42 +546,24 @@\n     def call_event(func_obj, *func_args, **kwargs):\n         return call_event(func_obj, *func_args, **kwargs)\n \n     @classmethod\n-    def update_metadata(cls, instance, meta_data_list: list, is_private: bool = False):\n-        if is_private:\n-            instance.store_value_in_private_metadata(\n-                {data.key: data.value for data in meta_data_list}\n+    def validate_and_update_metadata(\n+        cls,\n+        instance,\n+        metadata_list: metadata_manager.MetadataItemCollection,\n+        private_metadata_list: metadata_manager.MetadataItemCollection,\n+    ):\n+        if cls._meta.support_meta_field and metadata_list.items:\n+            metadata_manager.store_on_instance(\n+                metadata_list, instance, metadata_manager.MetadataType.PUBLIC\n             )\n-        else:\n-            instance.store_value_in_metadata(\n-                {data.key: data.value for data in meta_data_list}\n+        if cls._meta.support_private_meta_field and private_metadata_list.items:\n+            metadata_manager.store_on_instance(\n+                private_metadata_list, instance, metadata_manager.MetadataType.PRIVATE\n             )\n \n     @classmethod\n-    def validate_metadata_keys(cls, metadata_list: list[dict]):\n-        if metadata_contains_empty_key(metadata_list):\n-            raise ValidationError(\n-                {\n-                    \"input\": ValidationError(\n-                        \"Metadata key cannot be empty.\",\n-                        code=MetadataErrorCode.REQUIRED.value,\n-                    )\n-                }\n-            )\n-\n-    @classmethod\n-    def validate_and_update_metadata(\n-        cls, instance, metadata_list, private_metadata_list\n-    ):\n-        if cls._meta.support_meta_field and metadata_list is not None:\n-            cls.validate_metadata_keys(metadata_list)\n-            cls.update_metadata(instance, metadata_list)\n-        if cls._meta.support_private_meta_field and private_metadata_list is not None:\n-            cls.validate_metadata_keys(private_metadata_list)\n-            cls.update_metadata(instance, private_metadata_list, is_private=True)\n-\n-    @classmethod\n     def check_metadata_permissions(cls, info: ResolveInfo, object_id, private=False):\n         type_name, db_id = graphene.Node.from_global_id(object_id)\n \n         if private:\n@@ -608,9 +591,34 @@\n             raise PermissionDenied(\n                 message=\"You don't have access to some objects' channel.\"\n             )\n \n+    @classmethod\n+    def create_metadata_from_graphql_input(\n+        cls, metadata_list: list[MetadataInput] | None, *, error_field_name: str\n+    ) -> metadata_manager.MetadataItemCollection:\n+        \"\"\"Wrap the creation of metadata and raises ValidationError.\n \n+        It maps inner error to proper layer.\n+\n+        In case of metadata - we need to pass error_field_name, because it can be nested in the other path than \"metadata\" or \"privateMetadata\"\n+        Error code is hardcoded here - only empty key is validated. If we add more validation rules, this must be refactored\n+        To inject / resolve errors matching validator\n+\n+        \"\"\"\n+        try:\n+            return metadata_manager.create_from_graphql_input(metadata_list)\n+        except metadata_manager.MetadataEmptyKeyError:\n+            raise ValidationError(\n+                {\n+                    error_field_name: ValidationError(\n+                        \"Metadata key cannot be empty.\",\n+                        code=MetadataErrorCode.REQUIRED.value,\n+                    )\n+                }\n+            ) from None\n+\n+\n def is_list_of_ids(field) -> bool:\n     if isinstance(field.type, graphene.List):\n         of_type = field.type.of_type\n         if isinstance(of_type, graphene.NonNull):\n@@ -795,13 +803,26 @@\n         \"\"\"\n         instance = cls.get_instance(info, **data)\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, instance, data)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         instance = cls.construct_instance(instance, cleaned_input)\n \n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         cls.clean_instance(info, instance)\n         cls.save(info, instance, cleaned_input)\n         cls._save_m2m(info, instance, cleaned_input)\n \n@@ -864,13 +885,24 @@\n         channel_id = cls.get_instance_channel_id(instance, **data)\n         cls.check_channel_permissions(info, [channel_id])\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, instance, data)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n         instance = cls.construct_instance(instance, cleaned_input)\n \n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         cls.clean_instance(info, instance)\n         cls.save(info, instance, cleaned_input)\n         cls._save_m2m(info, instance, cleaned_input)\n         cls.post_save_action(info, instance, cleaned_input)\n"
        },
        {
          "path": "saleor/graphql/discount/mutations/voucher/voucher_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/discount/mutations/voucher/voucher_create.py\n===================================================================\n--- saleor/graphql/discount/mutations/voucher/voucher_create.py\t7f44e1e (parent)\n+++ saleor/graphql/discount/mutations/voucher/voucher_create.py\t70b525f (commit)\n@@ -22,8 +22,9 @@\n from ....core.validators import (\n     validate_end_is_after_start,\n     validate_one_of_args_is_in_mutation,\n )\n+from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...enums import DiscountValueTypeEnum, VoucherTypeEnum\n from ...types import Voucher\n \n@@ -278,10 +279,20 @@\n         voucher_instance = cls.get_instance(info, **data)\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, voucher_instance, data)\n \n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         codes_data = cleaned_input.pop(\"add_codes\", None)\n         code = cleaned_input.pop(\"code\", None)\n \n         voucher_instance = cls.construct_instance(voucher_instance, cleaned_input)\n@@ -289,9 +300,9 @@\n             code, codes_data, cleaned_input, voucher_instance\n         )\n \n         cls.validate_and_update_metadata(\n-            voucher_instance, metadata_list, private_metadata_list\n+            voucher_instance, metadata_collection, private_metadata_collection\n         )\n \n         cls.clean_voucher_instance(info, voucher_instance)\n \n"
        },
        {
          "path": "saleor/graphql/giftcard/mutations/gift_card_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/giftcard/mutations/gift_card_update.py\n===================================================================\n--- saleor/graphql/giftcard/mutations/gift_card_update.py\t7f44e1e (parent)\n+++ saleor/graphql/giftcard/mutations/gift_card_update.py\t70b525f (commit)\n@@ -14,8 +14,9 @@\n from ...core.scalars import PositiveDecimal\n from ...core.types import GiftCardError, NonNullList\n from ...core.utils import WebhookEventInfo\n from ...core.validators import validate_price_precision\n+from ...meta.inputs import MetadataInput\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ...utils.validators import check_for_duplicates\n from ..types import GiftCard\n from .gift_card_create import GiftCardCreate, GiftCardInput\n@@ -102,13 +103,25 @@\n             old_tags = list(\n                 old_instance.tags.order_by(\"name\").values_list(\"name\", flat=True)\n             )\n \n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         instance = cls.construct_instance(instance, cleaned_input)\n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         cls.clean_instance(info, instance)\n         cls.save(info, instance, cleaned_input)\n         cls._save_m2m(info, instance, cleaned_input)\n \n"
        },
        {
          "path": "saleor/graphql/invoice/mutations/invoice_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/invoice/mutations/invoice_create.py\n===================================================================\n--- saleor/graphql/invoice/mutations/invoice_create.py\t7f44e1e (parent)\n+++ saleor/graphql/invoice/mutations/invoice_create.py\t70b525f (commit)\n@@ -97,15 +97,26 @@\n         cls.check_channel_permissions(info, [order.channel_id])\n         cls.clean_order(info, order)\n         cleaned_input = cls.clean_input(info, order, input)\n \n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         invoice = models.Invoice(**cleaned_input)\n         invoice.order = order\n         invoice.status = JobStatus.SUCCESS\n-        cls.validate_and_update_metadata(invoice, metadata_list, private_metadata_list)\n+        cls.validate_and_update_metadata(\n+            invoice, metadata_collection, private_metadata_collection\n+        )\n         invoice.save()\n \n         app = get_app_promise(info.context).get()\n         events.invoice_created_event(\n"
        },
        {
          "path": "saleor/graphql/invoice/mutations/invoice_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/invoice/mutations/invoice_update.py\n===================================================================\n--- saleor/graphql/invoice/mutations/invoice_update.py\t7f44e1e (parent)\n+++ saleor/graphql/invoice/mutations/invoice_update.py\t70b525f (commit)\n@@ -78,11 +78,23 @@\n     ):\n         instance = cls.get_instance(info, id=id)\n         cls.check_channel_permissions(info, [instance.order.channel_id])\n         cleaned_input = cls.clean_input(info, instance, input)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         instance.update_invoice(\n             number=cleaned_input.get(\"number\"), url=cleaned_input.get(\"url\")\n         )\n         instance.status = JobStatus.SUCCESS\n"
        },
        {
          "path": "saleor/graphql/meta/mutations/base.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/meta/mutations/base.py\n===================================================================\n--- saleor/graphql/meta/mutations/base.py\t7f44e1e (parent)\n+++ saleor/graphql/meta/mutations/base.py\t70b525f (commit)\n@@ -17,9 +17,8 @@\n from ...core import ResolveInfo\n from ...core.context import BaseContext, SyncWebhookControlContext\n from ...core.mutations import BaseMutation\n from ...core.utils import from_global_id_or_error\n-from ...payment.utils import metadata_contains_empty_key\n from ..extra_methods import TYPE_EXTRA_METHODS\n from ..permissions import AccountPermissions\n from ..types import ObjectWithMetadata\n from .utils import get_valid_metadata_instance\n@@ -120,20 +119,8 @@\n                 }\n             )\n \n     @classmethod\n-    def validate_metadata_keys(cls, metadata_list: list[dict]):\n-        if metadata_contains_empty_key(metadata_list):\n-            raise ValidationError(\n-                {\n-                    \"input\": ValidationError(\n-                        \"Metadata key cannot be empty.\",\n-                        code=MetadataErrorCode.REQUIRED.value,\n-                    )\n-                }\n-            )\n-\n-    @classmethod\n     def get_permissions(cls, info: ResolveInfo, type_name, object_pk, **data):\n         if object_pk is None:\n             return []\n         object_id = data.get(\"id\")\n"
        },
        {
          "path": "saleor/graphql/meta/mutations/update_metadata.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/meta/mutations/update_metadata.py\n===================================================================\n--- saleor/graphql/meta/mutations/update_metadata.py\t7f44e1e (parent)\n+++ saleor/graphql/meta/mutations/update_metadata.py\t70b525f (commit)\n@@ -38,9 +38,9 @@\n     ):\n         instance = cast(models.ModelWithMetadata, cls.get_instance(info, id=id))\n         if instance:\n             meta_instance = get_valid_metadata_instance(instance)\n-            cls.validate_metadata_keys(input)\n+            cls.create_metadata_from_graphql_input(input, error_field_name=\"input\")\n             items = {data.key: data.value for data in input}\n             meta_instance.store_value_in_metadata(items=items)\n             update_metadata(meta_instance, items)\n \n"
        },
        {
          "path": "saleor/graphql/meta/mutations/update_private_metadata.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/meta/mutations/update_private_metadata.py\n===================================================================\n--- saleor/graphql/meta/mutations/update_private_metadata.py\t7f44e1e (parent)\n+++ saleor/graphql/meta/mutations/update_private_metadata.py\t70b525f (commit)\n@@ -31,12 +31,18 @@\n \n     @classmethod\n     def perform_mutation(cls, _root, info: ResolveInfo, /, **data):\n         instance = cls.get_instance(info, **data)\n+\n         if instance:\n             meta_instance = get_valid_metadata_instance(instance)\n             metadata_list = data.pop(\"input\")\n-            cls.validate_metadata_keys(metadata_list)\n+\n+            cls.create_metadata_from_graphql_input(\n+                metadata_list, error_field_name=\"input\"\n+            )\n+\n             items = {data.key: data.value for data in metadata_list}\n             meta_instance.store_value_in_private_metadata(items=items)\n             update_private_metadata(meta_instance, items)\n+\n         return cls.success_response(instance)\n"
        },
        {
          "path": "saleor/graphql/order/bulk_mutations/order_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/bulk_mutations/order_bulk_create.py\n===================================================================\n--- saleor/graphql/order/bulk_mutations/order_bulk_create.py\t7f44e1e (parent)\n+++ saleor/graphql/order/bulk_mutations/order_bulk_create.py\t70b525f (commit)\n@@ -64,9 +64,9 @@\n from ...payment.mutations.transaction.transaction_create import (\n     TransactionCreate,\n     TransactionCreateInput,\n )\n-from ...payment.utils import metadata_contains_empty_key\n+from ...payment.utils import deprecated_metadata_contains_empty_key\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ..enums import OrderStatusEnum, StockUpdatePolicyEnum\n from ..mutations.order_discount_common import (\n     OrderDiscountCommon,\n@@ -920,9 +920,9 @@\n         errors: list[OrderBulkError],\n         path: str,\n         field: Any,\n     ):\n-        if metadata_contains_empty_key(metadata):\n+        if deprecated_metadata_contains_empty_key(metadata):\n             errors.append(\n                 OrderBulkError(\n                     message=\"Metadata key cannot be empty.\",\n                     path=path,\n@@ -1014,14 +1014,24 @@\n         )\n \n         billing_address: Address | None = None\n         billing_address_input = order_input[\"billing_address\"]\n-        metadata_list = billing_address_input.pop(\"metadata\", None)\n-        private_metadata_list = billing_address_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = billing_address_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = billing_address_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         try:\n             billing_address = cls.validate_address(billing_address_input, info=info)\n             cls.validate_and_update_metadata(\n-                billing_address, metadata_list, private_metadata_list\n+                billing_address, metadata_collection, private_metadata_collection\n             )\n         except Exception:\n             order_data.errors.append(\n                 OrderBulkError(\n@@ -1035,14 +1045,23 @@\n \n         if shipping_address_input := order_input.get(\"shipping_address\"):\n             metadata_list = shipping_address_input.pop(\"metadata\", None)\n             private_metadata_list = shipping_address_input.pop(\"private_metadata\", None)\n+\n+            metadata_collection = cls.create_metadata_from_graphql_input(\n+                metadata_list, error_field_name=\"metadata\"\n+            )\n+            private_metadata_collection = cls.create_metadata_from_graphql_input(\n+                private_metadata_list,\n+                error_field_name=\"private_metadata\",\n+            )\n+\n             try:\n                 shipping_address = cls.validate_address(\n                     shipping_address_input, info=info\n                 )\n                 cls.validate_and_update_metadata(\n-                    shipping_address, metadata_list, private_metadata_list\n+                    shipping_address, metadata_collection, private_metadata_collection\n                 )\n             except Exception:\n                 order_data.errors.append(\n                     OrderBulkError(\n"
        },
        {
          "path": "saleor/graphql/order/mutations/draft_order_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/mutations/draft_order_update.py\n===================================================================\n--- saleor/graphql/order/mutations/draft_order_update.py\t7f44e1e (parent)\n+++ saleor/graphql/order/mutations/draft_order_update.py\t70b525f (commit)\n@@ -8,8 +8,9 @@\n from ...core import ResolveInfo\n from ...core.context import SyncWebhookControlContext\n from ...core.mutations import ModelWithExtRefMutation\n from ...core.types import OrderError\n+from ...meta.inputs import MetadataInput\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ..types import Order\n from .draft_order_create import DraftOrderCreate, DraftOrderInput\n \n@@ -88,14 +89,25 @@\n         old_voucher_code = instance.voucher_code\n         data = data.get(\"input\")\n \n         cleaned_input = cls.clean_input(info, instance, data)\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         instance = cls.construct_instance(instance, cleaned_input)\n \n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         cls.clean_instance(info, instance)\n         cls.save_draft_order(\n             info, instance, cleaned_input, old_voucher, old_voucher_code\n         )\n"
        },
        {
          "path": "saleor/graphql/payment/mutations/payment/checkout_payment_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/mutations/payment/checkout_payment_create.py\n===================================================================\n--- saleor/graphql/payment/mutations/payment/checkout_payment_create.py\t7f44e1e (parent)\n+++ saleor/graphql/payment/mutations/payment/checkout_payment_create.py\t70b525f (commit)\n@@ -31,9 +31,9 @@\n from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...enums import StorePaymentMethodEnum\n from ...types import Payment\n-from ...utils import metadata_contains_empty_key\n+from ...utils import deprecated_metadata_contains_empty_key\n \n \n class PaymentInput(BaseInputObjectType):\n     gateway = graphene.Field(\n@@ -174,11 +174,13 @@\n             raise ValidationError(\n                 {\"redirect_url\": e}, code=PaymentErrorCode.INVALID.value\n             ) from e\n \n+    # TODO This should be unified with metadata_manager and MetadataItemCollection\n+    # EXT-2054\n     @classmethod\n     def validate_metadata_keys(cls, metadata_list: list[dict]):\n-        if metadata_contains_empty_key(metadata_list):\n+        if deprecated_metadata_contains_empty_key(metadata_list):\n             raise ValidationError(\n                 {\n                     \"input\": ValidationError(\n                         {\n"
        },
        {
          "path": "saleor/graphql/payment/mutations/transaction/transaction_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/mutations/transaction/transaction_create.py\n===================================================================\n--- saleor/graphql/payment/mutations/transaction/transaction_create.py\t7f44e1e (parent)\n+++ saleor/graphql/payment/mutations/transaction/transaction_create.py\t70b525f (commit)\n@@ -35,9 +35,9 @@\n from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...enums import TransactionActionEnum\n from ...types import TransactionItem\n-from ...utils import metadata_contains_empty_key\n+from ...utils import deprecated_metadata_contains_empty_key\n from ..payment.payment_check_balance import MoneyInput\n \n \n class TransactionCreateInput(BaseInputObjectType):\n@@ -124,15 +124,17 @@\n                     )\n                 }\n             ) from e\n \n+    # TODO This should be unified with metadata_manager and MetadataItemCollection\n+    # EXT-2054\n     @classmethod\n-    def validate_metadata_keys(  # type: ignore[override]\n+    def validate_metadata_keys(\n         cls, metadata_list: list[dict] | None, field_name, error_code\n     ):\n         if not metadata_list:\n             return\n-        if metadata_contains_empty_key(metadata_list):\n+        if deprecated_metadata_contains_empty_key(metadata_list):\n             raise ValidationError(\n                 {\n                     \"transaction\": ValidationError(\n                         f\"{field_name} key cannot be empty.\",\n"
        },
        {
          "path": "saleor/graphql/payment/mutations/transaction/transaction_event_report.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/mutations/transaction/transaction_event_report.py\n===================================================================\n--- saleor/graphql/payment/mutations/transaction/transaction_event_report.py\t7f44e1e (parent)\n+++ saleor/graphql/payment/mutations/transaction/transaction_event_report.py\t70b525f (commit)\n@@ -182,10 +182,10 @@\n         transaction: payment_models.TransactionItem,\n         transaction_event: payment_models.TransactionEvent,\n         available_actions: list[str] | None = None,\n         app: Optional[\"App\"] = None,\n-        metadata: list[dict] | None = None,\n-        private_metadata: list[dict] | None = None,\n+        metadata: list[MetadataInput] | None = None,\n+        private_metadata: list[MetadataInput] | None = None,\n     ):\n         fields_to_update = [\n             \"authorized_value\",\n             \"charged_value\",\n@@ -285,10 +285,10 @@\n         time=None,\n         external_url=None,\n         message=None,\n         available_actions=None,\n-        transaction_metadata: list[dict] | None = None,\n-        transaction_private_metadata: list[dict] | None = None,\n+        transaction_metadata: list[MetadataInput] | None = None,\n+        transaction_private_metadata: list[MetadataInput] | None = None,\n     ):\n         validate_one_of_args_is_in_mutation(\"id\", id, \"token\", token)\n         transaction = get_transaction_item(id, token)\n         user = info.context.user\n@@ -341,10 +341,18 @@\n         transaction_event = cls.construct_instance(\n             transaction_event, transaction_event_data\n         )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            transaction_metadata, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            transaction_private_metadata,\n+            error_field_name=\"private_metadata\",\n+        )\n+\n         cls.validate_and_update_metadata(\n-            transaction, transaction_metadata, transaction_private_metadata\n+            transaction, metadata_collection, private_metadata_collection\n         )\n         cls.clean_instance(info, transaction_event)\n \n         if available_actions is not None:\n"
        },
        {
          "path": "saleor/graphql/payment/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/utils.py\n===================================================================\n--- saleor/graphql/payment/utils.py\t7f44e1e (parent)\n+++ saleor/graphql/payment/utils.py\t70b525f (commit)\n@@ -6,9 +6,14 @@\n     from ...account.models import User\n     from ...app.models import App\n \n \n-def metadata_contains_empty_key(metadata_list: list[dict]) -> bool:\n+def deprecated_metadata_contains_empty_key(metadata_list: list[dict]) -> bool:\n+    \"\"\"Check if metadata list contains empty key.\n+\n+    Deprecated.\n+    Construct MetadataItemCollection instead, that internally validates metadata structure.\n+    \"\"\"\n     return not all(data[\"key\"].strip() for data in metadata_list)\n \n \n def check_if_requestor_has_access(\n"
        },
        {
          "path": "saleor/graphql/product/bulk_mutations/product_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/bulk_mutations/product_bulk_create.py\n===================================================================\n--- saleor/graphql/product/bulk_mutations/product_bulk_create.py\t7f44e1e (parent)\n+++ saleor/graphql/product/bulk_mutations/product_bulk_create.py\t70b525f (commit)\n@@ -642,15 +642,25 @@\n                     {\"instance\": None, \"errors\": index_error_map[index]}\n                 )\n                 continue\n             try:\n-                metadata_list = cleaned_input.pop(\"metadata\", None)\n-                private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+                metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+                private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+                    \"private_metadata\", None\n+                )\n \n+                metadata_collection = cls.create_metadata_from_graphql_input(\n+                    metadata_list, error_field_name=\"metadata\"\n+                )\n+                private_metadata_collection = cls.create_metadata_from_graphql_input(\n+                    private_metadata_list,\n+                    error_field_name=\"private_metadata\",\n+                )\n+\n                 instance = models.Product()\n                 instance = cls.construct_instance(instance, cleaned_input)\n                 cls.validate_and_update_metadata(\n-                    instance, metadata_list, private_metadata_list\n+                    instance, metadata_collection, private_metadata_collection\n                 )\n                 cls.clean_instance(info, instance)\n                 instance.search_index_dirty = True\n \n@@ -700,15 +710,30 @@\n \n         for variant_data in variants_inputs:\n             if variant_data:\n                 try:\n-                    metadata_list = variant_data.pop(\"metadata\", None)\n-                    private_metadata_list = variant_data.pop(\"private_metadata\", None)\n+                    metadata_list: list[MetadataInput] = variant_data.pop(\n+                        \"metadata\", None\n+                    )\n+                    private_metadata_list: list[MetadataInput] = variant_data.pop(\n+                        \"private_metadata\", None\n+                    )\n+\n+                    metadata_collection = cls.create_metadata_from_graphql_input(\n+                        metadata_list, error_field_name=\"metadata\"\n+                    )\n+                    private_metadata_collection = (\n+                        cls.create_metadata_from_graphql_input(\n+                            private_metadata_list,\n+                            error_field_name=\"private_metadata\",\n+                        )\n+                    )\n+\n                     variant = models.ProductVariant()\n                     variant.product = product\n                     variant = cls.construct_instance(variant, variant_data)\n                     cls.validate_and_update_metadata(\n-                        variant, metadata_list, private_metadata_list\n+                        variant, metadata_collection, private_metadata_collection\n                     )\n                     variant.full_clean(exclude=[\"product\"])\n \n                     # store variant related objects data to create related objects\n"
        },
        {
          "path": "saleor/graphql/product/bulk_mutations/product_variant_bulk_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/bulk_mutations/product_variant_bulk_create.py\n===================================================================\n--- saleor/graphql/product/bulk_mutations/product_variant_bulk_create.py\t7f44e1e (parent)\n+++ saleor/graphql/product/bulk_mutations/product_variant_bulk_create.py\t70b525f (commit)\n@@ -40,8 +40,9 @@\n     ProductVariantBulkError,\n )\n from ...core.utils import get_duplicated_values\n from ...core.validators import validate_price_precision\n+from ...meta.inputs import MetadataInput\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ...shop.utils import get_track_inventory_by_default\n from ..mutations.channels import ProductVariantChannelListingAddInput\n from ..mutations.product.product_create import StockInput\n@@ -603,15 +604,26 @@\n                     {\"instance\": None, \"errors\": index_error_map[index]}\n                 )\n                 continue\n             try:\n-                metadata_list = cleaned_input.pop(\"metadata\", None)\n-                private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+                metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+                private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+                    \"private_metadata\", None\n+                )\n+\n+                metadata_collection = cls.create_metadata_from_graphql_input(\n+                    metadata_list, error_field_name=\"metadata\"\n+                )\n+                private_metadata_collection = cls.create_metadata_from_graphql_input(\n+                    private_metadata_list,\n+                    error_field_name=\"private_metadata\",\n+                )\n+\n                 instance = models.ProductVariant()\n                 cleaned_input[\"product\"] = product\n                 instance = cls.construct_instance(instance, cleaned_input)\n                 cls.validate_and_update_metadata(\n-                    instance, metadata_list, private_metadata_list\n+                    instance, metadata_collection, private_metadata_collection\n                 )\n                 cls.clean_instance(info, instance)\n                 instances_data_and_errors_list.append(\n                     {\n"
        },
        {
          "path": "saleor/graphql/product/bulk_mutations/product_variant_bulk_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/bulk_mutations/product_variant_bulk_update.py\n===================================================================\n--- saleor/graphql/product/bulk_mutations/product_variant_bulk_update.py\t7f44e1e (parent)\n+++ saleor/graphql/product/bulk_mutations/product_variant_bulk_update.py\t70b525f (commit)\n@@ -22,8 +22,9 @@\n from ...core.mutations import BaseMutation, DeprecatedModelMutation\n from ...core.scalars import PositiveDecimal\n from ...core.types import BaseInputObjectType, NonNullList, ProductVariantBulkError\n from ...core.utils import get_duplicated_values\n+from ...meta.inputs import MetadataInput\n from ...plugins.dataloaders import get_plugin_manager_promise\n from ...utils import get_user_or_app_from_context\n from ...webhook.subscription_payload import generate_pre_save_payloads\n from ..mutations.channels import ProductVariantChannelListingAddInput\n@@ -566,14 +567,25 @@\n                     {\"instance\": None, \"errors\": index_error_map[index]}\n                 )\n                 continue\n             try:\n-                metadata_list = cleaned_input.pop(\"metadata\", None)\n-                private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+                metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+                private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+                    \"private_metadata\", None\n+                )\n+\n+                metadata_collection = cls.create_metadata_from_graphql_input(\n+                    metadata_list, error_field_name=\"metadata\"\n+                )\n+                private_metadata_collection = cls.create_metadata_from_graphql_input(\n+                    private_metadata_list,\n+                    error_field_name=\"private_metadata\",\n+                )\n+\n                 instance = cleaned_input.pop(\"id\")\n                 instance = cls.construct_instance(instance, cleaned_input)\n                 cls.validate_and_update_metadata(\n-                    instance, metadata_list, private_metadata_list\n+                    instance, metadata_collection, private_metadata_collection\n                 )\n                 cls.clean_instance(info, instance)\n                 instances_data_and_errors_list.append(\n                     {\n"
        },
        {
          "path": "saleor/graphql/product/mutations/digital_contents.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/digital_contents.py\n===================================================================\n--- saleor/graphql/product/mutations/digital_contents.py\t7f44e1e (parent)\n+++ saleor/graphql/product/mutations/digital_contents.py\t70b525f (commit)\n@@ -133,13 +133,22 @@\n         digital_content.url_valid_days = clean_input.get(\"url_valid_days\")\n         digital_content.automatic_fulfillment = clean_input.get(\n             \"automatic_fulfillment\", False\n         )\n-        metadata_list = clean_input.pop(\"metadata\", None)\n-        private_metadata_list = clean_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = clean_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = clean_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         cls.validate_and_update_metadata(\n-            digital_content, metadata_list, private_metadata_list\n+            digital_content, metadata_collection, private_metadata_collection\n         )\n \n         variant.digital_content = digital_content\n         variant.digital_content.save()\n@@ -262,10 +271,17 @@\n \n         metadata_list = clean_input.pop(\"metadata\", None)\n         private_metadata_list = clean_input.pop(\"private_metadata\", None)\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         cls.validate_and_update_metadata(\n-            digital_content, metadata_list, private_metadata_list\n+            digital_content, metadata_collection, private_metadata_collection\n         )\n \n         variant.digital_content = digital_content\n         variant.digital_content.save()\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_update.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_update.py\t7f44e1e (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_update.py\t70b525f (commit)\n@@ -15,8 +15,9 @@\n from ....core.mutations import ModelWithExtRefMutation\n from ....core.types import ProductError\n from ....core.utils import ext_ref_to_global_id_or_error\n from ....core.validators import validate_one_of_args_is_in_mutation\n+from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...types import ProductVariant\n from ...utils import get_used_attribute_values_for_variant\n from .product_variant_create import ProductVariantCreate, ProductVariantInput\n@@ -212,14 +213,23 @@\n             info, id=id, sku=sku, external_reference=external_reference, input=input\n         )\n         old_instance_data = instance.serialize_for_comparison()  # type: ignore[union-attr]\n         cleaned_input = cls.clean_input(info, instance, input)  # type: ignore[arg-type]\n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n \n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         new_instance = cls.construct_instance(instance, cleaned_input)\n         cls.validate_and_update_metadata(\n-            new_instance, metadata_list, private_metadata_list\n+            new_instance, metadata_collection, private_metadata_collection\n         )\n         cls.clean_instance(info, new_instance)\n         new_instance_data = new_instance.serialize_for_comparison()\n \n"
        },
        {
          "path": "saleor/graphql/shop/mutations/shop_settings_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/shop/mutations/shop_settings_update.py\n===================================================================\n--- saleor/graphql/shop/mutations/shop_settings_update.py\t7f44e1e (parent)\n+++ saleor/graphql/shop/mutations/shop_settings_update.py\t70b525f (commit)\n@@ -187,15 +187,27 @@\n         instance = site.settings\n         data = data.get(\"input\")\n         cleaned_input = cls.clean_input(info, instance, data)\n \n-        metadata_list = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list = cleaned_input.pop(\"private_metadata\", None)\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+\n         old_metadata = dict(instance.metadata)\n         old_private_metadata = dict(instance.private_metadata)\n \n         instance = cls.construct_instance(instance, cleaned_input)\n-        cls.validate_and_update_metadata(instance, metadata_list, private_metadata_list)\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n         cls.clean_instance(info, instance)\n         instance.save()\n \n         if (\n"
        }
      ]
    },
    {
      "id": "refactor-variant-update",
      "sha": "5ff8b6eeb9dd9093acb7527a96460319b9f51bb2",
      "parentSha": "116403716428e8d38ab710ed9e579956e9dbba36",
      "spec": "- Create a new helper module for variant input cleaning at saleor/graphql/product/mutations/product_variant/product_variant_cleaner.py with:\n  - clean_weight(cleaned_input): raise INVALID if weight.value < 0.\n  - clean_quantity_limit(cleaned_input): raise INVALID if quantity_limit_per_customer is provided and < 1.\n  - clean_preorder_settings(cleaned_input): when preorder is provided, set is_preorder=True and map global_threshold/end_date to preorder_global_threshold/preorder_end_date in cleaned_input.\n  - validate_duplicated_attribute_values(attributes_data, used_attribute_values): build a map of attribute global_id -> list of values using get_values_from_attribute_values_input for each attribute. If that map is present in used_attribute_values, raise DUPLICATED_INPUT_ITEM with attributes param; otherwise append to used_attribute_values.\n\n- In saleor/graphql/attribute/utils.py:\n  - Change the dataclass AttrValuesInput to make the annotation of global_id non-Optional: global_id: str (keep passing None at runtime where applicable; this is a typing contract change only).\n  - Import get_used_attribute_values_for_variant from ..product.utils at the top.\n  - Add function get_values_from_attribute_values_input(attribute, attribute_data) -> list[str]:\n    - If attribute.input_type is FILE, return [slugified filename from file_url] when file_url is provided; otherwise [].\n    - For other input types, return attribute_data.values or [].\n  - Add function has_input_modified_attribute_values(variant, attributes_data) -> bool:\n    - If variant.product_id is set, compute assigned_attributes via get_used_attribute_values_for_variant(variant).\n    - Build input_attribute_values as defaultdict[str, list[str]] by iterating through attributes_data, extracting values with get_values_from_attribute_values_input, and only including entries where attr_data.global_id is not None.\n    - Return True if input_attribute_values != assigned_attributes; otherwise False.\n\n- Refactor saleor/graphql/product/mutations/product_variant/product_variant_create.py to use cleaner functions and centralize attribute logic:\n  - Import the new cleaner module as \"cleaner\".\n  - In clean_input:\n    - Replace inline weight and quantity_limit_per_customer validation with cleaner.clean_weight and cleaner.clean_quantity_limit.\n    - If stocks are provided, still call check_for_duplicates_in_stocks(stocks).\n    - Call a new classmethod clean_attributes(cleaned_input) (see below).\n    - If \"sku\" present, normalize using clean_variant_sku.\n    - Call cleaner.clean_preorder_settings(cleaned_input).\n  - Add classmethod clean_attributes(cleaned_input):\n    - Retrieve product using a new helper get_product(cleaned_input) that raises INVALID if missing or empty.\n    - product_type = product.product_type and used_attribute_values = get_used_variants_attribute_values(product).\n    - Validate that provided attribute IDs are a subset of the product_type.variant_attributes IDs; otherwise raise ATTRIBUTE_CANNOT_BE_ASSIGNED with invalid IDs.\n    - If product_type.has_variants:\n      - If attributes are provided, clean via AttributeAssignmentMixin.clean_input(attributes, product_type.variant_attributes.all()).\n      - Validate duplicates by calling cleaner.validate_duplicated_attribute_values on the cleaned attribute data and the used_attribute_values list.\n      - Store cleaned attributes back to cleaned_input[\"attributes\"].\n      - Else if product_type.variant_attributes.filter(value_required=True) exists and attributes are not provided, raise REQUIRED error with message \"All required attributes must take a value.\".\n    - If product_type.has_variants is False and attributes were provided, raise INVALID with a message that attributes cannot be assigned for product type without variants.\n  - Add classmethod get_product(cleaned_input) -> models.Product to fetch and validate the product field during create.\n\n- Replace saleor/graphql/product/mutations/product_variant/product_variant_update.py with a refactored mutation:\n  - Change base class to DeprecatedModelMutation (do not inherit from ProductVariantCreate).\n  - Keep arguments: id, external_reference, sku (optional), input: ProductVariantInput.\n  - Meta remains: model=models.ProductVariant, object_type=ProductVariant, permissions=MANAGE_PRODUCTS, error_type_class=ProductError, errors_mapping as before, support meta fields.\n  - Implement get_instance(info, **data) to support fetching by id, sku, or external_reference (use ext_ref_to_global_id_or_error to convert external_reference to a global id). When attributes are present in input, prefetch product type attributes and related values for AttributeAssignmentMixin.\n  - Implement clean_input(info, instance, data):\n    - Call super().clean_input to resolve IDs/files.\n    - Run cleaner.clean_weight and cleaner.clean_quantity_limit.\n    - Run cls.clean_attributes(cleaned_input, instance) to process attributes (see below).\n    - If sku is provided, normalize via clean_variant_sku.\n    - Run cleaner.clean_preorder_settings(cleaned_input).\n  - Implement clean_attributes(cleaned_input, instance) -> bool:\n    - Determine product, product_type, and used_attribute_values for the instance's product.\n    - Validate that any provided attribute IDs are valid variant attributes; else raise ATTRIBUTE_CANNOT_BE_ASSIGNED.\n    - If product_type.has_variants and attributes are provided:\n      - Clean with AttributeAssignmentMixin.clean_input(attributes, product_type.variant_attributes.all(), creation=False) to get T_INPUT_MAP.\n      - Compute attribute_modified = has_input_modified_attribute_values(instance, cleaned_attributes).\n      - If attribute_modified, call cleaner.validate_duplicated_attribute_values with cleaned_attributes and used_attribute_values.\n      - Store cleaned attributes back in cleaned_input and return whether attributes were modified.\n    - If product_type.has_variants is False and attributes are present, raise INVALID.\n    - Return False if no attribute change to signal to the save path.\n  - Implement set_track_inventory as before (respects input track_inventory).\n  - Implement _save(info, instance, cleaned_input, changed_fields) -> (variant_modified: bool, attribute_modified: bool, metadata_modified: bool):\n    - Save instance if changed_fields, and set product.search_index_dirty when name/sku changed.\n    - If attributes are present, save with AttributeAssignmentMixin.save and mark search_index_dirty.\n    - Ensure product.default_variant is set when absent, and persist product updates.\n    - Return tuple of booleans (variant_modified based on changed_fields, attribute_modified based on presence of attributes saved, and metadata_changed if metadata/private_metadata are in changed_fields).\n    - Note: Do not create stocks here; update mutation input does not handle stocks.\n  - Implement construct_instance to fill fields and generate variant name if missing (using generate_and_set_variant_name).\n  - Implement handle_metadata(instance, cleaned_input): mutate metadata on the instance using class helpers (create_metadata_from_graphql_input and validate_and_update_metadata) and remove metadata fields from cleaned_input.\n  - Implement _post_save_action(info, instance, variant_modified, attribute_modified, metadata_modified):\n    - If any flag is True, fire manager.product_variant_updated and manager.product_variant_metadata_updated (when metadata_modified is True).\n    - Collect all channel_ids for the instance's product via ProductChannelListing, and call mark_active_catalogue_promotion_rules_as_dirty(channel_ids) via cls.call_event.\n  - Implement success_response to wrap the instance in ChannelContext(node=instance, channel_slug=None).\n  - Implement perform_mutation to:\n    - Validate exclusivity of id/sku/external_reference via validate_one_of_args_is_in_mutation.\n    - Fetch instance via get_instance.\n    - Serialize old_instance_data for comparison, clean input via clean_input.\n    - handle_metadata on the instance (updates current instance metadata before diffing), then construct_instance and clean_instance.\n    - Compute changed_fields via diff_instance_data_fields.\n    - Call _save to get (variant_modified, attributes_modified, metadata_modified), then _save_m2m.\n    - Call _post_save_action with flags and return success_response.\n\n- Update saleor/graphql/product/tests/mutations/test_product_variant_update.py in the affected test to normalize metadata dicts:\n  - For test_update_product_variant_with_existing_metadata_and_event_when_write_diff\n    - Replace variant.metadata assignment from {\"key\": metadata_key, \"value\": metadata_value} to {metadata_key: metadata_value} and similarly for private_metadata.\n\n- Ensure all imports align with the refactor:\n  - New imports in modified files: cleaner module, ChannelContext, clean_variant_sku, get_used_variants_attribute_values, mark_active_catalogue_promotion_rules_as_dirty, has_input_modified_attribute_values, get_values_from_attribute_values_input, ext_ref_to_global_id_or_error.\n  - Keep generate_and_set_variant_name import from saleor.product.utils.variants (no path changes).\n\n- Behavior to validate after implementation:\n  - ProductVariantCreate continues to validate weight, quantity limits, stocks duplication, cleans attributes with duplicate-attribute-value check against siblings, enforces required attributes at creation, sets preorder flags, normalizes SKU, and triggers promotion rules recalculation.\n  - ProductVariantUpdate validates and normalizes inputs, detects if attribute assignments effectively change before running duplicate checks, updates metadata correctly, fires appropriate plugin events, and marks catalogue promotion rules as dirty for affected channels.\n  - Attribute utils can now normalize values for FILE input and compare assigned vs input attribute maps consistently.",
      "prompt": "Refactor the product variant update flow to centralize input validation, attribute handling, and event triggering. Introduce a helper module for variant cleaning (weight, quantity limits, preorder mapping, and duplicate attribute detection) and use it in both variant create and update paths. Make sure attribute values are read uniformly across input types (including files), and skip duplicate-attribute validation when an update doesn't actually change the assigned attribute values. Update the variant update mutation to handle metadata consistently, to compute changed fields, and to trigger appropriate events and catalogue promotion recalculations for all channels where the product is listed. Finally, adapt the relevant test to use the normalized metadata key/value mapping.",
      "supplementalFiles": [
        "saleor/graphql/product/utils.py",
        "saleor/graphql/core/mutations.py",
        "saleor/discount/utils/promotion.py",
        "saleor/graphql/plugins/dataloaders.py",
        "saleor/graphql/product/bulk_mutations/product_variant_bulk_update.py",
        "saleor/graphql/product/mutations/product_variant/product_variant_delete.py",
        "saleor/graphql/product/mutations/product_variant/variant_media_assign.py",
        "saleor/graphql/product/mutations/product/product_create.py",
        "saleor/graphql/channel/__init__.py",
        "saleor/graphql/meta/extra_methods.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/graphql/attribute/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/utils.py\n===================================================================\n--- saleor/graphql/attribute/utils.py\t1164037 (parent)\n+++ saleor/graphql/attribute/utils.py\t5ff8b6e (commit)\n@@ -30,8 +30,9 @@\n from ...product import models as product_models\n from ...product.error_codes import ProductErrorCode\n from ..core.utils import from_global_id_or_error, get_duplicated_values\n from ..core.validators import validate_one_of_args_is_in_mutation\n+from ..product.utils import get_used_attribute_values_for_variant\n from ..utils import get_nodes\n from .enums import AttributeValueBulkActionEnum\n \n if TYPE_CHECKING:\n@@ -48,9 +49,9 @@\n \n \n @dataclass\n class AttrValuesInput:\n-    global_id: str | None = None\n+    global_id: str\n     external_reference: str | None = None\n     values: list[str] | None = None\n     dropdown: AttrValuesForSelectableFieldInput | None = None\n     swatch: AttrValuesForSelectableFieldInput | None = None\n@@ -1611,4 +1612,38 @@\n         )\n         errors.append(error)\n \n     return errors\n+\n+\n+def has_input_modified_attribute_values(\n+    variant: product_models.ProductVariant, attributes_data: T_INPUT_MAP\n+) -> bool:\n+    \"\"\"Compare already assigned attribute values with values from AttrValuesInput.\n+\n+    Return:\n+        `False` if the attribute values are equal, otherwise `True`.\n+\n+    \"\"\"\n+    if variant.product_id is not None:\n+        assigned_attributes = get_used_attribute_values_for_variant(variant)\n+        input_attribute_values: defaultdict[str, list[str]] = defaultdict(list)\n+        for attr, attr_data in attributes_data:\n+            values = get_values_from_attribute_values_input(attr, attr_data)\n+            if attr_data.global_id is not None:\n+                input_attribute_values[attr_data.global_id].extend(values)\n+        if input_attribute_values != assigned_attributes:\n+            return True\n+    return False\n+\n+\n+def get_values_from_attribute_values_input(\n+    attribute: attribute_models.Attribute, attribute_data: AttrValuesInput\n+) -> list[str]:\n+    \"\"\"Format attribute values of type FILE.\"\"\"\n+    if attribute.input_type == AttributeInputType.FILE:\n+        return (\n+            [slugify(attribute_data.file_url.split(\"/\")[-1])]\n+            if attribute_data.file_url\n+            else []\n+        )\n+    return attribute_data.values or []\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_cleaner.py",
          "status": "added",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_cleaner.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_cleaner.py\t1164037 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_cleaner.py\t5ff8b6e (commit)\n@@ -0,0 +1,69 @@\n+from collections import defaultdict\n+\n+from django.core.exceptions import ValidationError\n+\n+from .....attribute import models as attribute_models\n+from .....product.error_codes import ProductErrorCode\n+from ....attribute.utils import (\n+    AttrValuesInput,\n+    get_values_from_attribute_values_input,\n+)\n+\n+T_INPUT_MAP = list[tuple[attribute_models.Attribute, AttrValuesInput]]\n+\n+\n+def clean_weight(cleaned_input: dict):\n+    weight = cleaned_input.get(\"weight\")\n+    if weight and weight.value < 0:\n+        raise ValidationError(\n+            {\n+                \"weight\": ValidationError(\n+                    \"Product variant can't have negative weight.\",\n+                    code=ProductErrorCode.INVALID.value,\n+                )\n+            }\n+        )\n+\n+\n+def clean_quantity_limit(cleaned_input: dict):\n+    quantity_limit_per_customer = cleaned_input.get(\"quantity_limit_per_customer\")\n+    if quantity_limit_per_customer is not None and quantity_limit_per_customer < 1:\n+        raise ValidationError(\n+            {\n+                \"quantity_limit_per_customer\": ValidationError(\n+                    (\n+                        \"Product variant can't have \"\n+                        \"quantity_limit_per_customer lower than 1.\"\n+                    ),\n+                    code=ProductErrorCode.INVALID.value,\n+                )\n+            }\n+        )\n+\n+\n+def clean_preorder_settings(cleaned_input: dict):\n+    preorder_settings = cleaned_input.get(\"preorder\")\n+    if preorder_settings:\n+        cleaned_input[\"is_preorder\"] = True\n+        cleaned_input[\"preorder_global_threshold\"] = preorder_settings.get(\n+            \"global_threshold\"\n+        )\n+        cleaned_input[\"preorder_end_date\"] = preorder_settings.get(\"end_date\")\n+\n+\n+def validate_duplicated_attribute_values(\n+    attributes_data: T_INPUT_MAP,\n+    used_attribute_values: list[dict[str, list[str]]],\n+):\n+    attribute_values: defaultdict[str, list[str]] = defaultdict(list)\n+    for attr, attr_data in attributes_data:\n+        values = get_values_from_attribute_values_input(attr, attr_data)\n+        attribute_values[attr_data.global_id].extend(values)\n+\n+    if attribute_values in used_attribute_values:\n+        raise ValidationError(\n+            \"Duplicated attribute values for product variant.\",\n+            code=ProductErrorCode.DUPLICATED_INPUT_ITEM.value,\n+            params={\"attributes\": attribute_values.keys()},\n+        )\n+    used_attribute_values.append(attribute_values)\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_create.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_create.py\t1164037 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_create.py\t5ff8b6e (commit)\n@@ -1,11 +1,7 @@\n-from collections import defaultdict\n-\n import graphene\n from django.core.exceptions import ValidationError\n-from django.utils.text import slugify\n \n-from .....attribute import AttributeInputType\n from .....attribute import models as attribute_models\n from .....core.tracing import traced_atomic_transaction\n from .....discount.utils.promotion import mark_active_catalogue_promotion_rules_as_dirty\n from .....permission.enums import ProductPermissions\n@@ -31,8 +27,9 @@\n     create_stocks,\n     get_used_variants_attribute_values,\n )\n from ..product.product_create import StockInput\n+from . import product_variant_cleaner as cleaner\n \n T_INPUT_MAP = list[tuple[attribute_models.Attribute, AttrValuesInput]]\n \n \n@@ -131,39 +128,8 @@\n         support_meta_field = True\n         support_private_meta_field = True\n \n     @classmethod\n-    def clean_attributes(\n-        cls, attributes: dict, product_type: models.ProductType\n-    ) -> T_INPUT_MAP:\n-        attributes_qs = product_type.variant_attributes.all()\n-        attributes = AttributeAssignmentMixin.clean_input(attributes, attributes_qs)\n-        return attributes\n-\n-    @classmethod\n-    def validate_duplicated_attribute_values(\n-        cls, attributes_data, used_attribute_values, instance=None\n-    ):\n-        attribute_values = defaultdict(list)\n-        for attr, attr_data in attributes_data:\n-            if attr.input_type == AttributeInputType.FILE:\n-                values = (\n-                    [slugify(attr_data.file_url.split(\"/\")[-1])]\n-                    if attr_data.file_url\n-                    else []\n-                )\n-            else:\n-                values = attr_data.values\n-            attribute_values[attr_data.global_id].extend(values)\n-        if attribute_values in used_attribute_values:\n-            raise ValidationError(\n-                \"Duplicated attribute values for product variant.\",\n-                code=ProductErrorCode.DUPLICATED_INPUT_ITEM.value,\n-                params={\"attributes\": attribute_values.keys()},\n-            )\n-        used_attribute_values.append(attribute_values)\n-\n-    @classmethod\n     def clean_input(\n         cls,\n         info: ResolveInfo,\n         instance: models.ProductVariant,\n@@ -171,66 +137,32 @@\n         **kwargs,\n     ):\n         cleaned_input = super().clean_input(info, instance, data, **kwargs)\n \n-        weight = cleaned_input.get(\"weight\")\n-        if weight and weight.value < 0:\n-            raise ValidationError(\n-                {\n-                    \"weight\": ValidationError(\n-                        \"Product variant can't have negative weight.\",\n-                        code=ProductErrorCode.INVALID.value,\n-                    )\n-                }\n-            )\n-\n-        quantity_limit_per_customer = cleaned_input.get(\"quantity_limit_per_customer\")\n-        if quantity_limit_per_customer is not None and quantity_limit_per_customer < 1:\n-            raise ValidationError(\n-                {\n-                    \"quantity_limit_per_customer\": ValidationError(\n-                        (\n-                            \"Product variant can't have \"\n-                            \"quantity_limit_per_customer lower than 1.\"\n-                        ),\n-                        code=ProductErrorCode.INVALID.value,\n-                    )\n-                }\n-            )\n-\n-        stocks = cleaned_input.get(\"stocks\")\n-        if stocks:\n+        cleaner.clean_weight(cleaned_input)\n+        cleaner.clean_quantity_limit(cleaned_input)\n+        if stocks := cleaned_input.get(\"stocks\"):\n             cls.check_for_duplicates_in_stocks(stocks)\n+        cls.clean_attributes(cleaned_input)\n+        if \"sku\" in cleaned_input:\n+            cleaned_input[\"sku\"] = clean_variant_sku(cleaned_input.get(\"sku\"))\n+        cleaner.clean_preorder_settings(cleaned_input)\n \n-        if instance.pk:\n-            # If the variant is getting updated,\n-            # simply retrieve the associated product type\n-            product_type = instance.product.product_type\n-            used_attribute_values = get_used_variants_attribute_values(instance.product)\n-        else:\n-            # If the variant is getting created, no product type is associated yet,\n-            # retrieve it from the required \"product\" input field\n-            product = cleaned_input[\"product\"]\n-            if not product:\n-                raise ValidationError(\n-                    {\n-                        \"product\": ValidationError(\n-                            \"Product cannot be set empty.\",\n-                            code=ProductErrorCode.INVALID.value,\n-                        )\n-                    }\n-                )\n-            product_type = cleaned_input[\"product\"].product_type\n-            used_attribute_values = get_used_variants_attribute_values(\n-                cleaned_input[\"product\"]\n-            )\n+        return cleaned_input\n \n+    @classmethod\n+    def clean_attributes(cls, cleaned_input: dict):\n+        product = cls.get_product(cleaned_input)\n+        product_type = product.product_type\n+        used_attribute_values = get_used_variants_attribute_values(product)\n+\n         variant_attributes_ids = {\n             graphene.Node.to_global_id(\"Attribute\", attr_id)\n             for attr_id in list(\n                 product_type.variant_attributes.all().values_list(\"pk\", flat=True)\n             )\n         }\n+\n         attributes = cleaned_input.get(\"attributes\")\n         attributes_ids = {attr[\"id\"] for attr in attributes or []}\n         invalid_attributes = attributes_ids - variant_attributes_ids\n         if len(invalid_attributes) > 0:\n@@ -247,18 +179,17 @@\n             # `Product` model, which is HStore field that maps attribute's PK to\n             # the value's PK.\n             try:\n                 if attributes:\n-                    cleaned_attributes = cls.clean_attributes(attributes, product_type)\n-                    cls.validate_duplicated_attribute_values(\n-                        cleaned_attributes, used_attribute_values, instance\n+                    attributes_qs = product_type.variant_attributes.all()\n+                    cleaned_attributes: T_INPUT_MAP = (\n+                        AttributeAssignmentMixin.clean_input(attributes, attributes_qs)\n                     )\n+                    cleaner.validate_duplicated_attribute_values(\n+                        cleaned_attributes, used_attribute_values\n+                    )\n                     cleaned_input[\"attributes\"] = cleaned_attributes\n-                # elif not instance.pk and not attributes:\n-                elif not instance.pk and (\n-                    not attributes\n-                    and product_type.variant_attributes.filter(value_required=True)\n-                ):\n+                elif product_type.variant_attributes.filter(value_required=True):\n                     # if attributes were not provided on creation\n                     raise ValidationError(\n                         \"All required attributes must take a value.\",\n                         ProductErrorCode.REQUIRED.value,\n@@ -271,21 +202,22 @@\n                     \"Cannot assign attributes for product type without variants\",\n                     ProductErrorCode.INVALID.value,\n                 )\n \n-        if \"sku\" in cleaned_input:\n-            cleaned_input[\"sku\"] = clean_variant_sku(cleaned_input.get(\"sku\"))\n-\n-        preorder_settings = cleaned_input.get(\"preorder\")\n-        if preorder_settings:\n-            cleaned_input[\"is_preorder\"] = True\n-            cleaned_input[\"preorder_global_threshold\"] = preorder_settings.get(\n-                \"global_threshold\"\n+    @classmethod\n+    def get_product(cls, cleaned_input: dict) -> models.Product:\n+        product = cleaned_input[\"product\"]\n+        if not product:\n+            raise ValidationError(\n+                {\n+                    \"product\": ValidationError(\n+                        \"Product cannot be set empty.\",\n+                        code=ProductErrorCode.INVALID.value,\n+                    )\n+                }\n             )\n-            cleaned_input[\"preorder_end_date\"] = preorder_settings.get(\"end_date\")\n+        return product\n \n-        return cleaned_input\n-\n     @classmethod\n     def check_for_duplicates_in_stocks(cls, stocks_data):\n         warehouse_ids = [stock[\"warehouse\"] for stock in stocks_data]\n         duplicates = get_duplicated_values(warehouse_ids)\n"
        },
        {
          "path": "saleor/graphql/product/mutations/product_variant/product_variant_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/mutations/product_variant/product_variant_update.py\n===================================================================\n--- saleor/graphql/product/mutations/product_variant/product_variant_update.py\t1164037 (parent)\n+++ saleor/graphql/product/mutations/product_variant/product_variant_update.py\t5ff8b6e (commit)\n@@ -1,32 +1,36 @@\n-from collections import defaultdict\n-\n import graphene\n from django.core.exceptions import ValidationError\n-from django.utils.text import slugify\n \n-from .....attribute import AttributeInputType\n from .....attribute import models as attribute_models\n from .....core.tracing import traced_atomic_transaction\n+from .....discount.utils.promotion import mark_active_catalogue_promotion_rules_as_dirty\n from .....permission.enums import ProductPermissions\n from .....product import models\n+from .....product.error_codes import ProductErrorCode\n from .....product.utils.variants import generate_and_set_variant_name\n-from ....attribute.utils import AttributeAssignmentMixin, AttrValuesInput\n+from ....attribute.utils import (\n+    AttributeAssignmentMixin,\n+    AttrValuesInput,\n+    has_input_modified_attribute_values,\n+)\n+from ....channel import ChannelContext\n from ....core import ResolveInfo\n-from ....core.mutations import ModelWithExtRefMutation\n+from ....core.mutations import DeprecatedModelMutation\n from ....core.types import ProductError\n from ....core.utils import ext_ref_to_global_id_or_error\n from ....core.validators import validate_one_of_args_is_in_mutation\n from ....meta.inputs import MetadataInput\n from ....plugins.dataloaders import get_plugin_manager_promise\n from ...types import ProductVariant\n-from ...utils import get_used_attribute_values_for_variant\n-from .product_variant_create import ProductVariantCreate, ProductVariantInput\n+from ...utils import clean_variant_sku, get_used_variants_attribute_values\n+from . import product_variant_cleaner as cleaner\n+from .product_variant_create import ProductVariantInput\n \n T_INPUT_MAP = list[tuple[attribute_models.Attribute, AttrValuesInput]]\n \n \n-class ProductVariantUpdate(ProductVariantCreate, ModelWithExtRefMutation):\n+class ProductVariantUpdate(DeprecatedModelMutation):\n     class Arguments:\n         id = graphene.ID(required=False, description=\"ID of a product to update.\")\n         external_reference = graphene.String(\n             required=False,\n@@ -51,44 +55,8 @@\n         support_meta_field = True\n         support_private_meta_field = True\n \n     @classmethod\n-    def clean_attributes(\n-        cls, attributes: dict, product_type: models.ProductType\n-    ) -> T_INPUT_MAP:\n-        attributes_qs = product_type.variant_attributes.all()\n-        attributes = AttributeAssignmentMixin.clean_input(\n-            attributes, attributes_qs, creation=False\n-        )\n-        return attributes\n-\n-    @classmethod\n-    def validate_duplicated_attribute_values(\n-        cls, attributes_data, used_attribute_values, instance=None\n-    ):\n-        # Check if the variant is getting updated,\n-        # and the assigned attributes do not change\n-        if instance.product_id is not None:\n-            assigned_attributes = get_used_attribute_values_for_variant(instance)\n-            input_attribute_values = defaultdict(list)\n-            for attr, attr_data in attributes_data:\n-                if attr.input_type == AttributeInputType.FILE:\n-                    values = (\n-                        [slugify(attr_data.file_url.split(\"/\")[-1])]\n-                        if attr_data.file_url\n-                        else []\n-                    )\n-                else:\n-                    values = attr_data.values\n-                input_attribute_values[attr_data.global_id].extend(values)\n-            if input_attribute_values == assigned_attributes:\n-                return\n-        # if assigned attributes is getting updated run duplicated attribute validation\n-        super().validate_duplicated_attribute_values(\n-            attributes_data, used_attribute_values\n-        )\n-\n-    @classmethod\n     def get_instance(cls, info: ResolveInfo, **data) -> models.ProductVariant | None:\n         \"\"\"Prefetch related fields that are needed to process the mutation.\n \n         If we are updating an instance and want to update its attributes, prefetch them.\n@@ -130,8 +98,86 @@\n             return instance\n         return None\n \n     @classmethod\n+    def clean_input(\n+        cls,\n+        info: ResolveInfo,\n+        instance: models.ProductVariant,\n+        data: dict,\n+        **kwargs,\n+    ):\n+        cleaned_input = super().clean_input(info, instance, data, **kwargs)\n+\n+        cleaner.clean_weight(cleaned_input)\n+        cleaner.clean_quantity_limit(cleaned_input)\n+        cls.clean_attributes(cleaned_input, instance)\n+        if \"sku\" in cleaned_input:\n+            cleaned_input[\"sku\"] = clean_variant_sku(cleaned_input.get(\"sku\"))\n+        cleaner.clean_preorder_settings(cleaned_input)\n+\n+        return cleaned_input\n+\n+    @classmethod\n+    def clean_attributes(cls, cleaned_input: dict, instance: models.ProductVariant):\n+        attribute_modified = False\n+        product = instance.product\n+        product_type = product.product_type\n+        used_attribute_values = get_used_variants_attribute_values(product)\n+\n+        variant_attributes_ids = {\n+            graphene.Node.to_global_id(\"Attribute\", attr_id)\n+            for attr_id in list(\n+                product_type.variant_attributes.all().values_list(\"pk\", flat=True)\n+            )\n+        }\n+\n+        attributes = cleaned_input.get(\"attributes\")\n+        attributes_ids = {attr[\"id\"] for attr in attributes or []}\n+        invalid_attributes = attributes_ids - variant_attributes_ids\n+        if len(invalid_attributes) > 0:\n+            raise ValidationError(\n+                \"Given attributes are not a variant attributes.\",\n+                code=ProductErrorCode.ATTRIBUTE_CANNOT_BE_ASSIGNED.value,\n+                params={\"attributes\": invalid_attributes},\n+            )\n+\n+        # Run the validation only if product type is configurable\n+        if product_type.has_variants:\n+            # Attributes are provided as list of `AttributeValueInput` objects.\n+            # We need to transform them into the format they're stored in the\n+            # `Product` model, which is HStore field that maps attribute's PK to\n+            # the value's PK.\n+            try:\n+                if attributes:\n+                    attributes_qs = product_type.variant_attributes.all()\n+                    cleaned_attributes: T_INPUT_MAP = (\n+                        AttributeAssignmentMixin.clean_input(\n+                            attributes, attributes_qs, creation=False\n+                        )\n+                    )\n+                    # if assigned attributes is getting updated run duplicated attribute validation\n+                    attribute_modified = has_input_modified_attribute_values(\n+                        instance, cleaned_attributes\n+                    )\n+                    if attribute_modified:\n+                        cleaner.validate_duplicated_attribute_values(\n+                            cleaned_attributes, used_attribute_values\n+                        )\n+                    cleaned_input[\"attributes\"] = cleaned_attributes\n+\n+            except ValidationError as e:\n+                raise ValidationError({\"attributes\": e}) from e\n+        else:\n+            if attributes:\n+                raise ValidationError(\n+                    \"Cannot assign attributes for product type without variants\",\n+                    ProductErrorCode.INVALID.value,\n+                )\n+\n+        return attribute_modified\n+\n+    @classmethod\n     def set_track_inventory(cls, _info, instance, cleaned_input):\n         track_inventory = cleaned_input.get(\"track_inventory\")\n         if track_inventory is not None:\n             instance.track_inventory = track_inventory\n@@ -141,9 +187,11 @@\n         update_fields = [\"updated_at\"] + changed_fields\n         instance.save(update_fields=update_fields)\n \n     @classmethod\n-    def _save(cls, info: ResolveInfo, instance, cleaned_input, changed_fields) -> bool:\n+    def _save(\n+        cls, info: ResolveInfo, instance, cleaned_input, changed_fields\n+    ) -> tuple[bool, bool, bool]:\n         metadata_changed = (\n             \"metadata\" in changed_fields or \"private_metadata\" in changed_fields\n         )\n \n@@ -152,10 +200,9 @@\n             if changed_fields:\n                 cls._save_variant_instance(instance, changed_fields)\n                 if \"sku\" in changed_fields or \"name\" in changed_fields:\n                     refresh_product_search_index = True\n-            if stocks := cleaned_input.get(\"stocks\"):\n-                cls.create_variant_stocks(instance, stocks)\n+\n             if attributes := cleaned_input.get(\"attributes\"):\n                 AttributeAssignmentMixin.save(instance, attributes)\n                 refresh_product_search_index = True\n \n@@ -169,28 +216,62 @@\n                 product_update_fields.append(\"default_variant\")\n             if product_update_fields:\n                 instance.product.save(update_fields=product_update_fields)\n \n-            if changed_fields or stocks or attributes:\n-                manager = get_plugin_manager_promise(info.context).get()\n-                cls.call_event(manager.product_variant_updated, instance)\n+            return bool(changed_fields), bool(attributes), metadata_changed\n \n-                if metadata_changed:\n-                    cls.call_event(manager.product_variant_metadata_updated, instance)\n-\n-                return True\n-\n-            return False\n-\n     @classmethod\n-    def construct_instance(cls, instance, cleaned_input) -> ProductVariant:\n+    def construct_instance(cls, instance, cleaned_input) -> models.ProductVariant:\n         instance = super().construct_instance(instance, cleaned_input)\n         cls.set_track_inventory(None, instance, cleaned_input)\n         if not instance.name:\n             generate_and_set_variant_name(instance, cleaned_input.get(\"sku\"))\n         return instance\n \n     @classmethod\n+    def _post_save_action(\n+        cls,\n+        info: ResolveInfo,\n+        instance,\n+        variant_modified: bool,\n+        attribute_modified: bool,\n+        metadata_modified: bool,\n+    ):\n+        if variant_modified or attribute_modified or metadata_modified:\n+            manager = get_plugin_manager_promise(info.context).get()\n+            cls.call_event(manager.product_variant_updated, instance)\n+\n+            if metadata_modified:\n+                cls.call_event(manager.product_variant_metadata_updated, instance)\n+\n+            channel_ids = models.ProductChannelListing.objects.filter(\n+                product_id=instance.product_id\n+            ).values_list(\"channel_id\", flat=True)\n+            # This will recalculate discounted prices for products.\n+            cls.call_event(mark_active_catalogue_promotion_rules_as_dirty, channel_ids)\n+\n+    @classmethod\n+    def handle_metadata(cls, instance, cleaned_input):\n+        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n+        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n+            \"private_metadata\", None\n+        )\n+        metadata_collection = cls.create_metadata_from_graphql_input(\n+            metadata_list, error_field_name=\"metadata\"\n+        )\n+        private_metadata_collection = cls.create_metadata_from_graphql_input(\n+            private_metadata_list, error_field_name=\"private_metadata\"\n+        )\n+        cls.validate_and_update_metadata(\n+            instance, metadata_collection, private_metadata_collection\n+        )\n+\n+    @classmethod\n+    def success_response(cls, instance):\n+        instance = ChannelContext(node=instance, channel_slug=None)\n+        return super().success_response(instance)\n+\n+    @classmethod\n     def perform_mutation(  # type: ignore[override]\n         cls,\n         root,\n         info: ResolveInfo,\n@@ -213,42 +294,27 @@\n             info, id=id, sku=sku, external_reference=external_reference, input=input\n         )\n         old_instance_data = instance.serialize_for_comparison()  # type: ignore[union-attr]\n         cleaned_input = cls.clean_input(info, instance, input)  # type: ignore[arg-type]\n-        metadata_list: list[MetadataInput] = cleaned_input.pop(\"metadata\", None)\n-        private_metadata_list: list[MetadataInput] = cleaned_input.pop(\n-            \"private_metadata\", None\n-        )\n \n-        metadata_collection = cls.create_metadata_from_graphql_input(\n-            metadata_list, error_field_name=\"metadata\"\n-        )\n-        private_metadata_collection = cls.create_metadata_from_graphql_input(\n-            private_metadata_list, error_field_name=\"private_metadata\"\n-        )\n+        cls.handle_metadata(instance, cleaned_input)\n \n-        new_instance = cls.construct_instance(instance, cleaned_input)\n-        cls.validate_and_update_metadata(\n-            new_instance, metadata_collection, private_metadata_collection\n-        )\n-        cls.clean_instance(info, new_instance)\n-        new_instance_data = new_instance.serialize_for_comparison()\n+        instance = cls.construct_instance(instance, cleaned_input)\n \n+        cls.clean_instance(info, instance)\n+        new_instance_data = instance.serialize_for_comparison()\n+\n         changed_fields = cls.diff_instance_data_fields(\n-            new_instance.comparison_fields,\n+            instance.comparison_fields,\n             old_instance_data,\n             new_instance_data,\n         )\n \n-        variant_modified = cls._save(info, instance, cleaned_input, changed_fields)\n+        variant_modified, attributes_modified, metadata_modified = cls._save(\n+            info, instance, cleaned_input, changed_fields\n+        )\n         cls._save_m2m(info, instance, cleaned_input)\n+        cls._post_save_action(\n+            info, instance, variant_modified, attributes_modified, metadata_modified\n+        )\n \n-        if variant_modified:\n-            # add to cleaned_input popped metadata to allow running post save events\n-            # that depends on the metadata inputs\n-            if metadata_list:\n-                cleaned_input[\"metadata\"] = metadata_list\n-            if private_metadata_list:\n-                cleaned_input[\"private_metadata\"] = private_metadata_list\n-            cls.post_save_action(info, instance, cleaned_input)\n-\n         return cls.success_response(instance)\n"
        },
        {
          "path": "saleor/graphql/product/tests/mutations/test_product_variant_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/mutations/test_product_variant_update.py\n===================================================================\n--- saleor/graphql/product/tests/mutations/test_product_variant_update.py\t1164037 (parent)\n+++ saleor/graphql/product/tests/mutations/test_product_variant_update.py\t5ff8b6e (commit)\n@@ -2782,12 +2782,10 @@\n     metadata_key = \"mk\"\n     metadata_value = \"mv\"\n \n     variant.name = \"Name\"\n-    variant.metadata = {\"key\": metadata_key, \"value\": metadata_value}\n-\n-    variant.private_metadata = {\"key\": metadata_key, \"value\": metadata_value}\n-\n+    variant.metadata = {metadata_key: metadata_value}\n+    variant.private_metadata = {metadata_key: metadata_value}\n     variant.save()\n \n     # When\n     # - Metadata is updated with the same values\n"
        }
      ]
    },
    {
      "id": "relax-extension-validation",
      "sha": "b356a525ba2ab918b85b6b617ac4df499e70e247",
      "parentSha": "68e80f40e6a4f670a2a4b5265cc94db4b0a35cfa",
      "spec": "Implement migration of AppExtension validation from backend to frontend, accepting plain strings for mount and target in manifests, and simplifying URL handling.\n\nRequired changes by area:\n\n1) App manifest processing and installation\n- saleor/app/installation_utils.py\n  - When creating AppExtension during install_app():\n    - Default target to DEFAULT_APP_TARGET if not provided.\n    - Persist settings from extension_data[\"options\"], defaulting to an empty object {} when not provided.\n  - Import DEFAULT_APP_TARGET from saleor.app.types and remove reliance on AppExtensionTarget.\n\n- saleor/app/manifest_validations.py\n  - Remove enum-based validation for extension.mount and extension.target. Do not coerce to enums.\n  - In _clean_extensions():\n    - If target missing, set extension[\"target\"] = DEFAULT_APP_TARGET.\n    - Coerce both extension[\"target\"] and extension[\"mount\"] to lowercase strings to maintain compatibility with historical enum values.\n    - Do not validate or transform extension[\"options\"]. Do not enforce widget/new_tab-specific options or methods.\n    - Continue to clean extension URL and extension permissions.\n  - In _clean_extension_url():\n    - Require manifest_data[\"tokenTargetUrl\"] to be present; raise ValidationError if missing.\n    - Allow relative extension URLs (starting with '/') without further constraint when tokenTargetUrl is present.\n    - For absolute URLs (with protocol), validate only format via AppURLValidator; do not enforce https, host matching with appUrl, or APP_PAGE/relative restrictions.\n  - Remove helper functions for enum cleaning, widget mount restrictions, and options validation (including any Pydantic models/validators).\n\n2) Types and constants\n- saleor/app/types.py\n  - Rename AppExtension* enums to DeprecatedAppExtensionMount, DeprecatedAppExtensionTarget, DeprecatedAppExtensionHttpMethod to signal deprecation; keep their CHOICES for DB compatibility.\n  - Introduce constants:\n    - POPUP_EXTENSION_TARGET = \"popup\"\n    - DEFAULT_APP_TARGET = POPUP_EXTENSION_TARGET\n\n3) Models\n- saleor/app/models.py\n  - Update AppExtension.mount choices to DeprecatedAppExtensionMount.CHOICES.\n  - Update AppExtension.target choices and default to DeprecatedAppExtensionTarget.CHOICES and .POPUP respectively.\n  - Update AppExtension.http_target_method choices to DeprecatedAppExtensionHttpMethod.CHOICES.\n\n4) GraphQL resolvers and types\n- saleor/graphql/app/resolvers.py\n  - Use DEFAULT_APP_TARGET when reading target from root objects.\n  - In resolve_app_extension_url(root):\n    - If url is relative, app_url is present, and target equals POPUP_EXTENSION_TARGET, return app_url joined with the relative path; otherwise return the given url unchanged.\n\n- saleor/graphql/app/types.py\n  - Remove resolve_target() from AppManifestExtension (frontend is responsible for target semantics).\n  - In AppManifestExtension.resolve_target_name, default to DEFAULT_APP_TARGET before uppercasing.\n  - In HttpMethod GraphQL enum, map POST/GET to DeprecatedAppExtensionHttpMethod values.\n  - In AppExtension resolvers where target is compared, use DeprecatedAppExtensionTarget for compatibility and compare case-insensitively.\n\n5) Validators cleanup\n- saleor/app/validators.py\n  - Remove Pydantic models for AppExtensionOptions and associated POST/GET method validators. Keep AppURLValidator and brand_validator only.\n\n6) Tests and fixtures adjustments\n- Update tests to reflect new behavior:\n  - Use DeprecatedAppExtension* enums where enum choice names are needed (e.g., DB choices/GraphQL enums), or use plain lowercase strings for mount where appropriate.\n  - Remove or update tests that expected backend validation errors for:\n    - Incorrect enum values for mount/target.\n    - HTTPS-only enforcement for POST on NEW_TAB/WIDGET.\n    - Hostname matching between extension URL and app URL.\n    - APP_PAGE forbidding absolute URLs.\n    - Options schema/target-specific option constraints.\n  - Add/update tests to verify:\n    - Extensions without options are accepted.\n    - Relative extension URLs are accepted (including '/').\n    - Absolute URLs are validated for format only; invalid absolute URLs yield INVALID_URL_FORMAT.\n    - Defaulting of target to DEFAULT_APP_TARGET and lowercasing of mount/target during manifest clean.\n\n7) Documentation\n- CHANGELOG.md\n  - Note that AppExtension validation is removed on the backend. Saleor now accepts string values for mount and target in manifests, and JSON for options; Dashboard performs validation. Mention increased feature velocity as rationale.\n",
      "prompt": "Shift app extension validation from the backend to the frontend. Accept plain string values for extension mount and target in manifests, and stop server-side validation of extension options. Simplify extension URL handling so that only absolute URLs are format-validated, while relative URLs are allowed when a token target URL is present. Ensure a sensible default target is applied and that relative popup URLs are stitched with the app URL in GraphQL resolvers. Keep database and GraphQL compatibility by using deprecated enum classes where necessary, and adjust tests to match the new behavior.",
      "supplementalFiles": [
        "saleor/graphql/app/mutations/app_fetch_manifest.py",
        "saleor/app/app_manifest_sample.json",
        "saleor/core/http_client.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t68e80f4 (parent)\n+++ CHANGELOG.md\tb356a52 (commit)\n@@ -19,5 +19,8 @@\n - Improved page search with search vectors. Pages can now be searched by slug, title, content, attribute values, and page type information.\n \n - Fix send order confirmation email to staff - #18342 by @Shaokun-X\n \n+- Validation on `AppExtension` is now removed. Saleor will accept string values for `mount` and `target` from Manifest during App installation and JSON value for `options` field.\n+Validation is now performed on the frontend (Dashboard). This change increases velocity of features related to apps and extensions, now Dashboard is only entity that ensures the contract\n+\n ### Deprecations\n"
        },
        {
          "path": "saleor/app/installation_utils.py",
          "status": "modified",
          "diff": "Index: saleor/app/installation_utils.py\n===================================================================\n--- saleor/app/installation_utils.py\t68e80f4 (parent)\n+++ saleor/app/installation_utils.py\tb356a52 (commit)\n@@ -27,9 +27,9 @@\n from ..webhook.models import Webhook, WebhookEvent\n from .error_codes import AppErrorCode\n from .manifest_validations import clean_manifest_data\n from .models import App, AppExtension, AppInstallation\n-from .types import AppExtensionTarget, AppType\n+from .types import DEFAULT_APP_TARGET, AppType\n \n MAX_ICON_FILE_SIZE = 1024 * 1024 * 10  # 10MB\n \n logger = logging.getLogger(__name__)\n@@ -267,12 +267,11 @@\n             app=app,\n             label=extension_data.get(\"label\"),\n             url=extension_data.get(\"url\"),\n             mount=extension_data.get(\"mount\"),\n-            target=extension_data.get(\"target\", AppExtensionTarget.POPUP),\n-            # This field should be removed in 3.24, ENG-1110\n+            target=extension_data.get(\"target\", DEFAULT_APP_TARGET),\n             http_target_method=http_target_method,\n-            settings=extension_data.get(\"options\"),\n+            settings=extension_data.get(\"options\", {}),\n         )\n         extension.permissions.set(extension_data.get(\"permissions\", []))\n \n     webhooks = Webhook.objects.bulk_create(\n"
        },
        {
          "path": "saleor/app/manifest_validations.py",
          "status": "modified",
          "diff": "Index: saleor/app/manifest_validations.py\n===================================================================\n--- saleor/app/manifest_validations.py\t68e80f4 (parent)\n+++ saleor/app/manifest_validations.py\tb356a52 (commit)\n@@ -1,14 +1,11 @@\n import logging\n from collections import defaultdict\n from collections.abc import Iterable\n-from urllib.parse import urlparse\n \n-from django.conf import settings\n from django.core.exceptions import ValidationError\n from django.db.models import Value\n from django.db.models.functions import Concat\n-from pydantic import ValidationError as PydanticValidationError\n from semantic_version import NpmSpec, Version\n from semantic_version.base import Range\n \n from .. import __version__\n@@ -23,10 +20,10 @@\n from ..webhook.event_types import WebhookEventAsyncType, WebhookEventSyncType\n from ..webhook.validators import custom_headers_validator\n from .error_codes import AppErrorCode\n from .models import App\n-from .types import AppExtensionMount, AppExtensionTarget\n-from .validators import AppExtensionOptions, AppURLValidator, brand_validator\n+from .types import DEFAULT_APP_TARGET\n+from .validators import AppURLValidator, brand_validator\n \n logger = logging.getLogger(__name__)\n \n T_ERRORS = dict[str, list[ValidationError]]\n@@ -44,26 +41,8 @@\n     url_validator = AppURLValidator()\n     url_validator(url)\n \n \n-def _clean_extension_url_with_only_path(\n-    manifest_data: dict, target: str, extension_url: str\n-):\n-    if target == AppExtensionTarget.APP_PAGE:\n-        return\n-    if target == AppExtensionTarget.NEW_TAB and not manifest_data[\"appUrl\"]:\n-        raise ValidationError(\"To use relative URL, you must specify appUrl.\")\n-    if manifest_data[\"appUrl\"]:\n-        _clean_app_url(manifest_data[\"appUrl\"])\n-    else:\n-        msg = (\n-            \"Incorrect relation between extension's target and URL fields. \"\n-            \"APP_PAGE can be used only with relative URL path.\"\n-        )\n-        logger.warning(msg, extra={\"target\": target, \"url\": extension_url})\n-        raise ValidationError(msg)\n-\n-\n def _clean_extension_url(extension: dict, manifest_data: dict):\n     \"\"\"Clean assigned extension url.\n \n     Make sure that format of url is correct based on the rest of manifest fields.\n@@ -72,44 +51,18 @@\n         b) appUrl is provided\n     - url cannot start with protocol when target == \"APP_PAGE\"\n     \"\"\"\n     extension_url = extension[\"url\"]\n-    # At this point target should be already cleaned enum AppExtensionTarget\n-    target = extension.get(\"target\") or AppExtensionTarget.POPUP\n \n     # Assume app URL is the one that originally received the token.\n     app_url = manifest_data.get(\"tokenTargetUrl\")\n \n-    new_tab_method_post = (\n-        extension.get(\"options\", {}).get(\"newTabTarget\", {}).get(\"method\") == \"POST\"\n-    )\n-    widget_method_post = (\n-        extension.get(\"options\", {}).get(\"widgetTarget\", {}).get(\"method\") == \"POST\"\n-    )\n-\n     if not app_url:\n         raise ValidationError(\"Manifest is invalid, token_target_url is missing\")\n \n-    is_new_tab_post = target == AppExtensionTarget.NEW_TAB and new_tab_method_post\n-    is_widget_post = target == AppExtensionTarget.WIDGET and widget_method_post\n-\n-    if extension_url.startswith(\"/\"):\n-        _clean_extension_url_with_only_path(manifest_data, target, extension_url)\n-    elif target == AppExtensionTarget.APP_PAGE:\n-        msg = \"Url cannot start with protocol when target == APP_PAGE\"\n-        logger.warning(msg)\n-        raise ValidationError(msg)\n-    elif (is_new_tab_post) or is_widget_post:\n-        parsed_app_url = urlparse(app_url)\n-        parsed_extension_url = urlparse(extension_url)\n-\n-        if parsed_extension_url.scheme != \"https\" and settings.ENABLE_SSL:\n-            raise ValidationError(\"Extension must start with https\")\n-\n-        if parsed_app_url.hostname != parsed_extension_url.hostname:\n-            raise ValidationError(\"Extension URL must match App URL\")\n-\n-    else:\n+    # Only validate absolute URLs (with protocol)\n+    # Relative URLs (starting with '/') are allowed when tokenTargetUrl is provided\n+    if not extension_url.startswith(\"/\"):\n         _clean_app_url(extension_url)\n \n \n def clean_manifest_url(manifest_url):\n@@ -225,91 +178,20 @@\n \n     extension[\"permissions\"] = extension_permissions\n \n \n-def _clean_extension_enum_field(enum, field_name, extension, errors):\n-    if extension[field_name] in [code.upper() for code, _ in enum.CHOICES]:\n-        extension[field_name] = getattr(enum, extension[field_name])\n-    else:\n-        errors[\"extensions\"].append(\n-            ValidationError(\n-                f\"Incorrect value for field: {field_name}\",\n-                code=AppErrorCode.INVALID.value,\n-            )\n-        )\n-\n-\n-def _clean_extension_options(extension, errors):\n-    \"\"\"Validate the options field in an extension.\"\"\"\n-    options = extension.get(\"options\", {})\n-    try:\n-        validated_options = AppExtensionOptions.model_validate(options)\n-        is_widget = extension.get(\"target\") == AppExtensionTarget.WIDGET\n-        is_new_tab = extension.get(\"target\") == AppExtensionTarget.NEW_TAB\n-\n-        if validated_options.widget_target and not is_widget:\n-            raise ValidationError(\n-                \"widgetTarget options must be set only on WIDGET target\"\n-            )\n-\n-        if validated_options.new_tab_target and not is_new_tab:\n-            raise ValidationError(\n-                \"newTabTarget options must be set only on NEW_TAB target\"\n-            )\n-\n-        # Update the extension with the validated options\n-        extension[\"options\"] = validated_options.model_dump(\n-            exclude_none=True, by_alias=True\n-        )\n-    except (ValidationError, PydanticValidationError) as e:\n-        errors[\"extensions\"].append(\n-            ValidationError(\n-                f\"Invalid options field: {str(e)}\",\n-                code=AppErrorCode.INVALID.value,\n-            )\n-        )\n-\n-\n-def _validate_mounts_for_widget(mount: str):\n-    widget_available_mounts = [\n-        AppExtensionMount.ORDER_DETAILS_WIDGETS,\n-        AppExtensionMount.PRODUCT_DETAILS_WIDGETS,\n-        AppExtensionMount.VOUCHER_DETAILS_WIDGETS,\n-        AppExtensionMount.DRAFT_ORDER_DETAILS_WIDGETS,\n-        AppExtensionMount.GIFT_CARD_DETAILS_WIDGETS,\n-        AppExtensionMount.CUSTOMER_DETAILS_WIDGETS,\n-        AppExtensionMount.COLLECTION_DETAILS_WIDGETS,\n-    ]\n-\n-    if mount not in widget_available_mounts:\n-        raise ValidationError(\n-            {\n-                \"mount\": ValidationError(\n-                    f\"Mount {mount.upper()} is not available for WIDGET target.\",\n-                    code=AppErrorCode.INVALID.value,\n-                )\n-            }\n-        )\n-\n-\n def _clean_extensions(manifest_data, app_permissions, errors):\n     extensions = manifest_data.get(\"extensions\", [])\n \n     for extension in extensions:\n         if \"target\" not in extension:\n-            extension[\"target\"] = AppExtensionTarget.POPUP\n-        else:\n-            _clean_extension_enum_field(AppExtensionTarget, \"target\", extension, errors)\n+            extension[\"target\"] = DEFAULT_APP_TARGET\n \n-        _clean_extension_enum_field(AppExtensionMount, \"mount\", extension, errors)\n+        # Save in lowercase to maintain backwards compatibility with enums, that were used previously\n+        extension[\"target\"] = extension[\"target\"].lower()\n+        extension[\"mount\"] = extension[\"mount\"].lower()\n \n         try:\n-            if extension[\"target\"] == AppExtensionTarget.WIDGET:\n-                _validate_mounts_for_widget(extension[\"mount\"])\n-        except ValidationError as invalid_mount_error:\n-            errors[\"extensions\"].append(invalid_mount_error)\n-\n-        try:\n             _clean_extension_url(extension, manifest_data)\n         except (ValidationError, AttributeError):\n             errors[\"extensions\"].append(\n                 ValidationError(\n@@ -319,11 +201,9 @@\n             )\n \n         _clean_extension_permissions(extension, app_permissions, errors)\n \n-        _clean_extension_options(extension, errors)\n \n-\n def _clean_webhooks(manifest_data, errors):\n     webhooks = manifest_data.get(\"webhooks\", [])\n \n     async_types = {\n"
        },
        {
          "path": "saleor/app/models.py",
          "status": "modified",
          "diff": "Index: saleor/app/models.py\n===================================================================\n--- saleor/app/models.py\t68e80f4 (parent)\n+++ saleor/app/models.py\tb356a52 (commit)\n@@ -11,12 +11,12 @@\n from ..permission.enums import AppPermission, BasePermissionEnum\n from ..permission.models import Permission\n from ..webhook.event_types import WebhookEventAsyncType, WebhookEventSyncType\n from .types import (\n-    AppExtensionHttpMethod,\n-    AppExtensionMount,\n-    AppExtensionTarget,\n     AppType,\n+    DeprecatedAppExtensionHttpMethod,\n+    DeprecatedAppExtensionMount,\n+    DeprecatedAppExtensionTarget,\n )\n \n \n class AppQueryset(models.QuerySet[\"App\"]):\n@@ -156,13 +156,15 @@\n class AppExtension(models.Model):\n     app = models.ForeignKey(App, on_delete=models.CASCADE, related_name=\"extensions\")\n     label = models.CharField(max_length=256)\n     url = models.URLField()\n-    mount = models.CharField(choices=AppExtensionMount.CHOICES, max_length=256)\n+    mount = models.CharField(\n+        choices=DeprecatedAppExtensionMount.CHOICES, max_length=256\n+    )\n     target = models.CharField(\n-        choices=AppExtensionTarget.CHOICES,\n+        choices=DeprecatedAppExtensionTarget.CHOICES,\n         max_length=128,\n-        default=AppExtensionTarget.POPUP,\n+        default=DeprecatedAppExtensionTarget.POPUP,\n     )\n     permissions = models.ManyToManyField(\n         Permission,\n         blank=True,\n@@ -170,9 +172,9 @@\n     )\n     http_target_method = models.CharField(\n         blank=False,\n         null=True,\n-        choices=AppExtensionHttpMethod.CHOICES,\n+        choices=DeprecatedAppExtensionHttpMethod.CHOICES,\n     )\n     settings = models.JSONField(blank=True, default=dict, db_default={})\n \n \n"
        },
        {
          "path": "saleor/app/tests/fixtures/app_extension.py",
          "status": "modified",
          "diff": "Index: saleor/app/tests/fixtures/app_extension.py\n===================================================================\n--- saleor/app/tests/fixtures/app_extension.py\t68e80f4 (parent)\n+++ saleor/app/tests/fixtures/app_extension.py\tb356a52 (commit)\n@@ -1,26 +1,25 @@\n import pytest\n \n from ....app.models import AppExtension\n-from ....app.types import AppExtensionMount\n \n \n @pytest.fixture\n def app_with_extensions(app_with_token, permission_manage_products):\n     first_app_extension = AppExtension(\n         app=app_with_token,\n         label=\"Create product with App\",\n         url=\"www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=\"product_overview_more_actions\",\n     )\n     extensions = AppExtension.objects.bulk_create(\n         [\n             first_app_extension,\n             AppExtension(\n                 app=app_with_token,\n                 label=\"Update product with App\",\n                 url=\"www.example.com/app-product-update\",\n-                mount=AppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n+                mount=\"product_details_more_actions\",\n             ),\n         ]\n     )\n     first_app_extension.permissions.add(permission_manage_products)\n@@ -32,18 +31,18 @@\n     first_app_extension = AppExtension(\n         app=removed_app,\n         label=\"Create product with App\",\n         url=\"www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=\"product_overview_more_actions\",\n     )\n     extensions = AppExtension.objects.bulk_create(\n         [\n             first_app_extension,\n             AppExtension(\n                 app=removed_app,\n                 label=\"Update product with App\",\n                 url=\"www.example.com/app-product-update\",\n-                mount=AppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n+                mount=\"product_details_more_actions\",\n             ),\n         ]\n     )\n     first_app_extension.permissions.add(permission_manage_products)\n"
        },
        {
          "path": "saleor/app/tests/test_installation_utils.py",
          "status": "modified",
          "diff": "Index: saleor/app/tests/test_installation_utils.py\n===================================================================\n--- saleor/app/tests/test_installation_utils.py\t68e80f4 (parent)\n+++ saleor/app/tests/test_installation_utils.py\tb356a52 (commit)\n@@ -25,9 +25,9 @@\n     install_app,\n     validate_app_install_response,\n )\n from ..models import App\n-from ..types import AppExtensionMount, AppExtensionTarget\n+from ..types import DeprecatedAppExtensionMount, DeprecatedAppExtensionTarget\n \n \n def test_validate_app_install_response():\n     error_message = \"Test error msg\"\n@@ -303,10 +303,10 @@\n     app_extension = app.extensions.get()\n \n     assert app_extension.label == label\n     assert app_extension.url == url\n-    assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n-    assert app_extension.target == AppExtensionTarget.POPUP\n+    assert app_extension.mount == DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE\n+    assert app_extension.target == DeprecatedAppExtensionTarget.POPUP\n     assert list(app_extension.permissions.all()) == [permission_manage_products]\n     assert app_extension.http_target_method is None\n \n \n@@ -351,10 +351,10 @@\n     app_extension = app.extensions.get()\n \n     assert app_extension.label == label\n     assert app_extension.url == url\n-    assert app_extension.mount == AppExtensionMount.PRODUCT_DETAILS_WIDGETS\n-    assert app_extension.target == AppExtensionTarget.WIDGET\n+    assert app_extension.mount == DeprecatedAppExtensionMount.PRODUCT_DETAILS_WIDGETS\n+    assert app_extension.target == DeprecatedAppExtensionTarget.WIDGET\n     assert list(app_extension.permissions.all()) == [permission_manage_products]\n     assert app_extension.http_target_method == \"POST\"\n \n \n@@ -432,91 +432,14 @@\n     assert App.objects.get().id == app.id\n     app_extension = app.extensions.get()\n     assert app_extension.label == label\n     assert app_extension.url == url\n-    assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n+    assert app_extension.mount == DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE\n     assert app_extension.target == \"new_tab\"\n     assert list(app_extension.permissions.all()) == [permission_manage_products]\n     assert app_extension.http_target_method == \"GET\"\n \n \n-def test_install_app_with_extension_new_tab_target_post_url_non_https(\n-    app_manifest,\n-    app_installation,\n-    monkeypatch,\n-    permission_manage_products,\n-):\n-    # given\n-    label = \"Open in new tab\"\n-    # Non-https url is prohibited\n-    url = \"http://extenal-url.com\"\n-    options = {\"newTabTarget\": {\"method\": \"POST\"}}\n-    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n-    app_manifest[\"extensions\"] = [\n-        {\n-            \"label\": label,\n-            \"url\": url,\n-            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n-            \"permissions\": [\"MANAGE_PRODUCTS\"],\n-            \"options\": options,\n-            \"target\": \"NEW_TAB\",\n-        }\n-    ]\n-    mocked_get_response = Mock()\n-    mocked_get_response.json.return_value = app_manifest\n-\n-    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n-    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n-\n-    app_installation.permissions.set([permission_manage_products])\n-\n-    # when\n-    # then\n-    with pytest.raises(ValidationError) as error:\n-        app, _ = install_app(app_installation, activate=True)\n-\n-    assert error.value.messages[0] == \"Incorrect value for field: url.\"\n-\n-\n-def test_install_app_with_extension_new_tab_target_post_url_other_than_app(\n-    app_manifest,\n-    app_installation,\n-    monkeypatch,\n-    permission_manage_products,\n-):\n-    # given\n-    label = \"Open in new tab\"\n-    # Url other than app's URL is prohibited\n-    url = \"https://extenal-url.com\"\n-    app_manifest[\"tokenTargetUrl\"] = \"https://app-url.com\"\n-    options = {\"newTabTarget\": {\"method\": \"POST\"}}\n-    app_manifest[\"permissions\"] = [\"MANAGE_PRODUCTS\"]\n-    app_manifest[\"extensions\"] = [\n-        {\n-            \"label\": label,\n-            \"url\": url,\n-            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n-            \"permissions\": [\"MANAGE_PRODUCTS\"],\n-            \"options\": options,\n-            \"target\": \"NEW_TAB\",\n-        }\n-    ]\n-    mocked_get_response = Mock()\n-    mocked_get_response.json.return_value = app_manifest\n-\n-    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n-    monkeypatch.setattr(\"saleor.app.installation_utils.send_app_token\", Mock())\n-\n-    app_installation.permissions.set([permission_manage_products])\n-\n-    # when\n-    # then\n-    with pytest.raises(ValidationError) as error:\n-        app, _ = install_app(app_installation, activate=True)\n-\n-    assert error.value.messages[0] == \"Incorrect value for field: url.\"\n-\n-\n @pytest.mark.parametrize(\n     \"url\",\n     [\n         \"http:/127.0.0.1:8080/app\",\n@@ -661,10 +584,10 @@\n     app_extension = app.extensions.get()\n \n     assert app_extension.label == label\n     assert app_extension.url == url\n-    assert app_extension.mount == AppExtensionMount.PRODUCT_OVERVIEW_CREATE\n-    assert app_extension.target == AppExtensionTarget.NEW_TAB\n+    assert app_extension.mount == DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE\n+    assert app_extension.target == DeprecatedAppExtensionTarget.NEW_TAB\n     assert list(app_extension.permissions.all()) == [permission_manage_products]\n     assert app_extension.http_target_method == \"POST\"\n \n \n"
        },
        {
          "path": "saleor/app/tests/test_validators.py",
          "status": "modified",
          "diff": "Index: saleor/app/tests/test_validators.py\n===================================================================\n--- saleor/app/tests/test_validators.py\t68e80f4 (parent)\n+++ saleor/app/tests/test_validators.py\tb356a52 (commit)\n@@ -2,21 +2,18 @@\n from django.core.exceptions import ValidationError\n \n from ... import __version__\n from ...app.validators import (\n-    AppExtensionOptions,\n     AppURLValidator,\n )\n from ..error_codes import AppErrorCode\n from ..manifest_validations import (\n     _clean_author,\n-    _clean_extension_options,\n     _clean_extension_url,\n-    _clean_extensions,\n     _clean_required_saleor_version,\n     _parse_version,\n )\n-from ..types import AppExtensionTarget\n+from ..types import DeprecatedAppExtensionTarget\n from ..validators import brand_validator\n \n \n def test_validate_url():\n@@ -97,388 +94,17 @@\n         brand_validator({\"logo\": {\"default\": url}})\n     assert error.value.code == AppErrorCode.INVALID_URL_FORMAT.value\n \n \n-def test_clean_extensions_new_tab_valid_relative_url(app_manifest):\n-    app_manifest[\"appUrl\"] = \"https://app.example.com\"\n-    extension = {\n-        \"url\": \"/relative/path\",\n-        \"target\": AppExtensionTarget.NEW_TAB,\n-    }\n-\n-    _clean_extension_url(extension, app_manifest)\n-\n-\n-@pytest.mark.parametrize(\n-    (\"extension\", \"manifest\", \"should_raise\"),\n-    [\n-        # url starts with /, target APP_PAGE, appUrl provided\n-        (\n-            {\"url\": \"/page\", \"target\": AppExtensionTarget.APP_PAGE},\n-            {\n-                \"tokenTargetUrl\": \"https://app.example.com\",\n-                \"appUrl\": \"https://app.example.com\",\n-            },\n-            False,\n-        ),\n-        # url starts with /, target NEW_TAB, should not raise\n-        (\n-            {\"url\": \"/tab\", \"target\": AppExtensionTarget.NEW_TAB},\n-            {\n-                \"tokenTargetUrl\": \"https://app.example.com\",\n-                \"appUrl\": \"https://app.example.com\",\n-            },\n-            False,\n-        ),\n-        # url starts with protocol, target APP_PAGE, should raise\n-        (\n-            {\n-                \"url\": \"https://app.example.com/page\",\n-                \"target\": AppExtensionTarget.APP_PAGE,\n-            },\n-            {\"tokenTargetUrl\": \"https://app.example.com\"},\n-            True,\n-        ),\n-        # url starts with protocol, target NEW_TAB, method POST, valid host\n-        (\n-            {\n-                \"url\": \"https://app.example.com/page\",\n-                \"target\": AppExtensionTarget.NEW_TAB,\n-                \"options\": {\"newTabTarget\": {\"method\": \"POST\"}},\n-            },\n-            {\"tokenTargetUrl\": \"https://app.example.com\"},\n-            False,\n-        ),\n-        # url starts with protocol, target NEW_TAB, method POST, invalid host\n-        (\n-            {\n-                \"url\": \"https://other.com/page\",\n-                \"target\": AppExtensionTarget.NEW_TAB,\n-                \"options\": {\"newTabTarget\": {\"method\": \"POST\"}},\n-            },\n-            {\"tokenTargetUrl\": \"https://app.example.com\"},\n-            True,\n-        ),\n-        # url is valid absolute, target POPUP\n-        (\n-            {\"url\": \"https://app.example.com/page\", \"target\": AppExtensionTarget.POPUP},\n-            {\"tokenTargetUrl\": \"https://app.example.com\"},\n-            False,\n-        ),\n-    ],\n-)\n-def test_clean_extension_url(extension, manifest, should_raise):\n-    if should_raise:\n-        with pytest.raises(ValidationError):\n-            _clean_extension_url(extension, manifest)\n-\n-    else:\n-        _clean_extension_url(extension, manifest)\n-\n-\n def test_new_tab_relative_url_without_app_url(app_manifest):\n     # given\n     app_manifest[\"appUrl\"] = None\n \n     extension = {\n         \"url\": \"/relative/path\",\n-        \"target\": AppExtensionTarget.NEW_TAB,\n+        \"target\": DeprecatedAppExtensionTarget.NEW_TAB,\n     }\n \n     app_manifest[\"extensions\"] = [extension]\n \n     # when & then\n-    with pytest.raises(ValidationError):\n-        _clean_extension_url(extension, manifest_data=app_manifest)\n-\n-\n-def test_clean_extension_url_https_only(settings):\n-    # given\n-    settings.ENABLE_SSL = True\n-\n-    # when & then\n-    with pytest.raises(ValidationError):\n-        _clean_extension_url(\n-            {\n-                \"url\": \"http://app.example.com/page\",\n-                \"target\": AppExtensionTarget.NEW_TAB,\n-                \"options\": {\"newTabTarget\": {\"method\": \"POST\"}},\n-            },\n-            {\n-                \"tokenTargetUrl\": \"https://app.example.com\",\n-                \"appUrl\": \"https://app.example.com\",\n-            },\n-        )\n-\n-\n-def test_clean_extension_url_http_if_SSL_disabled(settings):\n-    # given\n-    settings.ENABLE_SSL = False\n-\n-    # when\n-    result = _clean_extension_url(\n-        {\"url\": \"http://app.example.com/page\", \"target\": AppExtensionTarget.NEW_TAB},\n-        {\n-            \"tokenTargetUrl\": \"https://app.example.com\",\n-            \"appUrl\": \"https://app.example.com\",\n-        },\n-    )\n-\n-    # then\n-    assert result is None\n-\n-\n-def test_app_extension_options_accepts_only_one():\n-    # Given\n-    parsed = AppExtensionOptions().model_validate({\"widgetTarget\": {\"method\": \"GET\"}})\n-\n-    assert parsed.new_tab_target is None\n-    assert parsed.widget_target is not None\n-\n-    parsed = AppExtensionOptions().model_validate({\"newTabTarget\": {\"method\": \"GET\"}})\n-\n-    assert parsed.new_tab_target is not None\n-    assert parsed.widget_target is None\n-\n-    with pytest.raises(\n-        ValueError, match=\"Only one of 'newTabTarget' or 'widgetTarget' can be set.\"\n-    ):\n-        AppExtensionOptions.model_validate(\n-            {\n-                \"newTabTarget\": {\"method\": \"GET\"},\n-                \"widgetTarget\": {\"method\": \"GET\"},\n-            }\n-        )\n-\n-    # when\n-    parsed = AppExtensionOptions().model_validate({})\n-\n-    # then\n-    assert parsed.new_tab_target is None\n-    assert parsed.widget_target is None\n-\n-\n-@pytest.mark.parametrize(\n-    (\"app_url\", \"extension_url\", \"should_raise\"),\n-    [\n-        (None, \"/some-path\", True),  # Test missing token_target_url\n-        (\"https://example.com\", \"/some-path\", False),  # Test valid token_target_url\n-    ],\n-)\n-def test_clean_extension_url_token_target_url(app_url, extension_url, should_raise):\n-    # Given\n-    extension = {\"url\": extension_url, \"target\": \"APP_PAGE\"}\n-    manifest_data = {\"tokenTargetUrl\": app_url, \"appUrl\": \"https://example.com\"}\n-\n-    # When & Then\n-    if should_raise:\n-        with pytest.raises(ValidationError, match=\"token_target_url is missing\"):\n-            _clean_extension_url(extension, manifest_data)\n-    else:\n-        # Should not raise ValidationError\n-        _clean_extension_url(extension, manifest_data)\n-\n-\n-def test_clean_extension_options_valid_widget_options():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.WIDGET,\n-        \"options\": {\"widgetTarget\": {\"method\": \"POST\"}},\n-    }\n-    errors = {\"extensions\": []}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n-    assert len(errors[\"extensions\"]) == 0\n-    assert \"options\" in extension\n-    assert \"widgetTarget\" in extension[\"options\"]\n-    assert extension[\"options\"][\"widgetTarget\"][\"method\"] == \"POST\"\n-\n-\n-def test_clean_extension_options_valid_new_tab_options():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.NEW_TAB,\n-        \"options\": {\"newTabTarget\": {\"method\": \"GET\"}},\n-    }\n-    errors = {\"extensions\": []}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n-    assert len(errors[\"extensions\"]) == 0\n-    assert \"options\" in extension\n-    assert \"newTabTarget\" in extension[\"options\"]\n-    assert extension[\"options\"][\"newTabTarget\"][\"method\"] == \"GET\"\n-\n-\n-def test_clean_extension_options_both_targets():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.NEW_TAB,\n-        \"options\": {\n-            \"newTabTarget\": {\"method\": \"GET\"},\n-            \"widgetTarget\": {\"method\": \"POST\"},\n-        },\n-    }\n-    errors = {\"extensions\": []}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n-    assert len(errors[\"extensions\"]) == 1\n-    assert (\n-        \"Only one of 'newTabTarget' or 'widgetTarget'\"\n-        in errors[\"extensions\"][0].message\n-    )\n-\n-\n-def test_clean_extension_options_widget_target_with_wrong_target():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.NEW_TAB,\n-        \"options\": {\"widgetTarget\": {\"method\": \"POST\"}},\n-    }\n-    errors = {\"extensions\": []}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n-    assert len(errors[\"extensions\"]) == 1\n-    assert (\n-        \"widgetTarget options must be set only on WIDGET target\"\n-        in errors[\"extensions\"][0].message\n-    )\n-\n-\n-def test_clean_extension_options_new_tab_target_with_wrong_target():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.WIDGET,\n-        \"options\": {\"newTabTarget\": {\"method\": \"GET\"}},\n-    }\n-    errors = {\"extensions\": []}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n-    assert len(errors[\"extensions\"]) == 1\n-    assert (\n-        \"newTabTarget options must be set only on NEW_TAB target\"\n-        in errors[\"extensions\"][0].message\n-    )\n-\n-\n-def test_clean_extension_options_invalid_options():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.WIDGET,\n-        \"options\": {\n-            \"widgetTarget\": {\n-                \"method\": \"INVALID_METHOD\"  # Only POST and GET are valid\n-            }\n-        },\n-    }\n-    errors = {\"extensions\": []}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n-    assert len(errors[\"extensions\"]) == 1\n-    assert \"Invalid options field\" in errors[\"extensions\"][0].message\n-\n-\n-def test_clean_extension_options_empty():\n-    # Given\n-    extension = {\"target\": AppExtensionTarget.WIDGET, \"options\": {}}\n-    errors = {}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" not in errors\n-    assert \"options\" in extension\n-    assert extension[\"options\"] == {}\n-\n-\n-def test_clean_extension_options_no_options():\n-    # Given\n-    extension = {\n-        \"target\": AppExtensionTarget.WIDGET,\n-    }\n-    errors = {}\n-\n-    # When\n-    _clean_extension_options(extension, errors)\n-\n-    # Then\n-    assert \"extensions\" not in errors\n-    assert \"options\" in extension\n-    assert extension[\"options\"] == {}\n-\n-\n-@pytest.mark.parametrize(\n-    \"mount\",\n-    [\n-        \"ORDER_DETAILS_WIDGETS\",\n-        \"PRODUCT_DETAILS_WIDGETS\",\n-        \"VOUCHER_DETAILS_WIDGETS\",\n-        \"DRAFT_ORDER_DETAILS_WIDGETS\",\n-        \"GIFT_CARD_DETAILS_WIDGETS\",\n-        \"CUSTOMER_DETAILS_WIDGETS\",\n-        \"COLLECTION_DETAILS_WIDGETS\",\n-    ],\n-)\n-def test_widget_target_available_mounts_valid(mount, app_manifest):\n-    # Given\n-    extension = {\n-        \"target\": \"WIDGET\",\n-        \"mount\": mount,\n-        \"url\": \"https://example.com/widget\",\n-        \"label\": \"label\",\n-    }\n-    errors = {\"extensions\": []}\n-\n-    app_manifest[\"extensions\"] = [extension]\n-\n-    # When\n-    _clean_extensions(app_manifest, [], errors)\n-\n-    # Then\n-    assert len(errors[\"extensions\"]) == 0\n-\n-\n-@pytest.mark.parametrize(\n-    \"mount\",\n-    [\"CATEGORY_OVERVIEW_CREATECATEGORY_OVERVIEW_MORE_ACTIONS\"],\n-)\n-def test_widget_target_available_mounts_invalid(mount, app_manifest):\n-    # Given\n-    extension = {\n-        \"target\": \"WIDGET\",\n-        \"mount\": mount,\n-        \"url\": \"https://example.com/widget\",\n-        \"label\": \"label\",\n-    }\n-    errors = {\"extensions\": []}\n-\n-    app_manifest[\"extensions\"] = [extension]\n-\n-    # When\n-    _clean_extensions(app_manifest, [], errors)\n-\n-    # Then\n-    assert \"extensions\" in errors\n+    _clean_extension_url(extension, manifest_data=app_manifest)\n"
        },
        {
          "path": "saleor/app/types.py",
          "status": "modified",
          "diff": "Index: saleor/app/types.py\n===================================================================\n--- saleor/app/types.py\t68e80f4 (parent)\n+++ saleor/app/types.py\tb356a52 (commit)\n@@ -4,9 +4,10 @@\n \n     CHOICES = [(LOCAL, \"local\"), (THIRDPARTY, \"thirdparty\")]\n \n \n-class AppExtensionMount:\n+# Deprecated. Remove this enum - Saleor will use plain strings in tests, and the exact values are managed by the Dashboard\n+class DeprecatedAppExtensionMount:\n     \"\"\"All places where app extension can be mounted.\"\"\"\n \n     CATEGORY_OVERVIEW_CREATE = \"category_overview_create\"\n     CATEGORY_OVERVIEW_MORE_ACTIONS = \"category_overview_more_actions\"\n@@ -125,9 +126,10 @@\n         (TRANSLATIONS_MORE_ACTIONS, \"translations_more_actions\"),\n     ]\n \n \n-class AppExtensionTarget:\n+# Deprecated. Remove this enum - Saleor will use plain strings in tests, and the exact values are managed by the Dashboard\n+class DeprecatedAppExtensionTarget:\n     \"\"\"All available ways of opening an app extension.\n \n     POPUP - app's extension will be mounted as a popup window\n     APP_PAGE - redirect to app's page\n@@ -145,9 +147,10 @@\n         (WIDGET, \"widget\"),\n     ]\n \n \n-class AppExtensionHttpMethod:\n+# Deprecated. Remove this enum in 3.24, when this field is dropped from AppExtension model\n+class DeprecatedAppExtensionHttpMethod:\n     \"\"\"HTTP methods available for app extensions.\n \n     Represents available HTTPS methods for frontend to work with extension (WIDGET and NEW_TAB)\n     \"\"\"\n@@ -155,4 +158,11 @@\n     GET = \"GET\"\n     POST = \"POST\"\n \n     CHOICES = [(\"GET\", \"GET\"), (\"POST\", \"POST\")]\n+\n+\n+# We need special handling for popup - if it declares relative extension URL, resolver will stitch if with app URL\n+POPUP_EXTENSION_TARGET = \"popup\"\n+\n+# In case of not provided, use the default value as a fallback\n+DEFAULT_APP_TARGET = POPUP_EXTENSION_TARGET\n"
        },
        {
          "path": "saleor/app/validators.py",
          "status": "modified",
          "diff": "Index: saleor/app/validators.py\n===================================================================\n--- saleor/app/validators.py\t68e80f4 (parent)\n+++ saleor/app/validators.py\tb356a52 (commit)\n@@ -1,15 +1,12 @@\n import mimetypes\n import re\n-from typing import Annotated, Literal\n \n from django.core.exceptions import ValidationError\n from django.core.validators import URLValidator\n-from pydantic import BaseModel, Field, field_validator, model_validator\n \n from ..thumbnail import ICON_MIME_TYPES\n from .error_codes import AppErrorCode\n-from .types import AppExtensionHttpMethod\n \n \n class AppURLValidator(URLValidator):\n     validator = URLValidator\n@@ -46,61 +43,4 @@\n         raise ValidationError(\n             \"Invalid file type for field: logo.default.\",\n             code=AppErrorCode.INVALID_URL_FORMAT.value,\n         )\n-\n-\n-def validate_POST_or_GET_http_method(value):\n-    \"\"\"Validate that the HTTP method is either GET or POST.\"\"\"\n-    if value not in [\n-        AppExtensionHttpMethod.GET,\n-        AppExtensionHttpMethod.POST,\n-    ]:\n-        raise ValueError(\n-            f\"Method must be either {AppExtensionHttpMethod.GET} or {AppExtensionHttpMethod.POST}\"\n-        )\n-    return value\n-\n-\n-class NewTabTargetOptions(BaseModel):\n-    method: Literal[\"GET\", \"POST\"]\n-\n-    @field_validator(\"method\")\n-    def validate_method(cls, value):\n-        return validate_POST_or_GET_http_method(value)\n-\n-\n-class WidgetTargetOptions(BaseModel):\n-    method: Literal[\"GET\", \"POST\"]\n-\n-    @field_validator(\"method\")\n-    def validate_method(cls, value):\n-        return validate_POST_or_GET_http_method(value)\n-\n-\n-class AppExtensionOptions(BaseModel):\n-    new_tab_target: Annotated[\n-        NewTabTargetOptions | None,\n-        Field(\n-            validation_alias=\"newTabTarget\",\n-            serialization_alias=\"newTabTarget\",\n-            description=\"Settings for extension target NEW_TAB\",\n-        ),\n-    ] = None\n-    widget_target: Annotated[\n-        WidgetTargetOptions | None,\n-        Field(\n-            validation_alias=\"widgetTarget\",\n-            serialization_alias=\"widgetTarget\",\n-            description=\"Settings for extension target WIDGET\",\n-        ),\n-    ] = None\n-\n-    @model_validator(mode=\"after\")\n-    def validate_either_or(cls, values):\n-        new_tab = values.new_tab_target\n-        widget = values.widget_target\n-\n-        if new_tab and widget:\n-            raise ValueError(\"Only one of 'newTabTarget' or 'widgetTarget' can be set.\")\n-\n-        return values\n"
        },
        {
          "path": "saleor/graphql/app/resolvers.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/resolvers.py\n===================================================================\n--- saleor/graphql/app/resolvers.py\t68e80f4 (parent)\n+++ saleor/graphql/app/resolvers.py\tb356a52 (commit)\n@@ -2,9 +2,9 @@\n \n from django.db.models import Exists, OuterRef\n \n from ...app import models\n-from ...app.types import AppExtensionTarget\n+from ...app.types import DEFAULT_APP_TARGET, POPUP_EXTENSION_TARGET\n from ...core.jwt import (\n     create_access_token_for_app,\n     create_access_token_for_app_extension,\n )\n@@ -88,12 +88,12 @@\n         - url starts with /\n         - target == \"POPUP\"\n         - appUrl is defined\n     \"\"\"\n-    target = root.get(\"target\", AppExtensionTarget.POPUP)\n+    target = root.get(\"target\", DEFAULT_APP_TARGET)\n     app_url = root[\"app_url\"]\n     url = root[\"url\"]\n-    if url.startswith(\"/\") and app_url and target == AppExtensionTarget.POPUP:\n+    if url.startswith(\"/\") and app_url and target == POPUP_EXTENSION_TARGET:\n         parsed_url = urlparse(app_url)\n         new_path = urljoin(parsed_url.path, url[1:])\n         return parsed_url._replace(path=new_path).geturl()\n     return url\n"
        },
        {
          "path": "saleor/graphql/app/tests/benchmarks/test_app_extensions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/benchmarks/test_app_extensions.py\n===================================================================\n--- saleor/graphql/app/tests/benchmarks/test_app_extensions.py\t68e80f4 (parent)\n+++ saleor/graphql/app/tests/benchmarks/test_app_extensions.py\tb356a52 (commit)\n@@ -1,8 +1,8 @@\n import pytest\n \n from .....app.models import AppExtension\n-from .....app.types import AppExtensionMount\n+from .....app.types import DeprecatedAppExtensionMount\n from ....tests.utils import get_graphql_content\n \n \n @pytest.mark.count_queries(autouse=False)\n@@ -38,21 +38,21 @@\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App1\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App2\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App3\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n             ),\n         ]\n     )\n     app_extensions[0].permissions.add(permission_manage_products)\n@@ -116,21 +116,21 @@\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App1\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App2\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App3\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n             ),\n         ]\n     )\n     app_extensions[0].permissions.add(permission_manage_products)\n"
        },
        {
          "path": "saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py\n===================================================================\n--- saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py\t68e80f4 (parent)\n+++ saleor/graphql/app/tests/mutations/test_app_fetch_manifest.py\tb356a52 (commit)\n@@ -383,165 +383,8 @@\n     }\n \n \n @pytest.mark.parametrize(\n-    \"incorrect_field\",\n-    [\"target\", \"mount\"],\n-)\n-def test_app_fetch_manifest_extensions_incorrect_enum_values(\n-    incorrect_field, app_manifest, monkeypatch, staff_api_client, permission_manage_apps\n-):\n-    # given\n-    app_manifest[\"extensions\"] = [\n-        {\n-            \"permissions\": [\"MANAGE_PRODUCTS\"],\n-            \"label\": \"Create product with App\",\n-            \"url\": \"http://127.0.0.1:9090/app-extension\",\n-            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n-        }\n-    ]\n-    app_manifest[\"extensions\"][0][incorrect_field] = \"INCORRECT_VALUE\"\n-\n-    mocked_get_response = Mock()\n-    mocked_get_response.json.return_value = app_manifest\n-\n-    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n-    query = APP_FETCH_MANIFEST_MUTATION\n-    manifest_url = \"http://localhost:3000/configuration/manifest\"\n-    variables = {\n-        \"manifest_url\": manifest_url,\n-    }\n-\n-    # when\n-    response = staff_api_client.post_graphql(\n-        query, variables=variables, permissions=[permission_manage_apps]\n-    )\n-\n-    # then\n-    content = get_graphql_content(response)\n-    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n-\n-    assert len(errors) == 1\n-    expected_errors = [\n-        {\n-            \"code\": \"INVALID\",\n-            \"field\": \"extensions\",\n-            \"message\": f\"Incorrect value for field: {incorrect_field}\",\n-        },\n-    ]\n-\n-    assert errors == expected_errors\n-\n-\n-@pytest.mark.parametrize(\n-    (\"url\", \"target\", \"app_url\"),\n-    [\n-        (\"/app\", \"APP_PAGE\", \"\"),\n-        (\"/app\", \"APP_PAGE\", \"https://www.example.com/app\"),\n-        (\"/app\", \"POPUP\", \"https://www.example.com/app\"),\n-        (\n-            \"https://www.example.com/app/form\",\n-            \"NEW_TAB\",\n-            \"https://www.example.com/app\",\n-        ),\n-    ],\n-)\n-def test_app_fetch_manifest_extensions_correct_url(\n-    url,\n-    target,\n-    app_url,\n-    app_manifest,\n-    monkeypatch,\n-    staff_api_client,\n-    permission_manage_apps,\n-):\n-    # given\n-    app_manifest[\"appUrl\"] = app_url\n-    app_manifest[\"extensions\"] = [\n-        {\n-            \"permissions\": [\"MANAGE_PRODUCTS\"],\n-            \"label\": \"Create product with App\",\n-            \"url\": url,\n-            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n-            \"target\": target,\n-        }\n-    ]\n-\n-    mocked_get_response = Mock()\n-    mocked_get_response.json.return_value = app_manifest\n-\n-    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n-    query = APP_FETCH_MANIFEST_MUTATION\n-    manifest_url = \"http://localhost:3000/configuration/manifest\"\n-    variables = {\n-        \"manifest_url\": manifest_url,\n-    }\n-\n-    # when\n-    response = staff_api_client.post_graphql(\n-        query, variables=variables, permissions=[permission_manage_apps]\n-    )\n-\n-    # then\n-    content = get_graphql_content(response)\n-    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n-    assert len(errors) == 0\n-\n-\n-@pytest.mark.parametrize(\n-    (\"url\", \"target\"),\n-    [\n-        (\"http:/127.0.0.1:8080/app\", \"POPUP\"),\n-        (\"127.0.0.1:8080/app\", \"POPUP\"),\n-        (\"\", \"POPUP\"),\n-        (\"/app\", \"POPUP\"),\n-        (\"www.example.com/app\", \"POPUP\"),\n-        (\"https://www.example.com/app\", \"APP_PAGE\"),\n-        (\"http://www.example.com/app\", \"APP_PAGE\"),\n-    ],\n-)\n-def test_app_fetch_manifest_extensions_incorrect_url(\n-    url, target, app_manifest, monkeypatch, staff_api_client, permission_manage_apps\n-):\n-    # given\n-    app_manifest[\"extensions\"] = [\n-        {\n-            \"permissions\": [\"MANAGE_PRODUCTS\"],\n-            \"label\": \"Create product with App\",\n-            \"url\": url,\n-            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n-            \"target\": target,\n-        }\n-    ]\n-\n-    mocked_get_response = Mock()\n-    mocked_get_response.json.return_value = app_manifest\n-\n-    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n-    query = APP_FETCH_MANIFEST_MUTATION\n-    manifest_url = \"http://localhost:3000/configuration/manifest\"\n-    variables = {\n-        \"manifest_url\": manifest_url,\n-    }\n-\n-    # when\n-    response = staff_api_client.post_graphql(\n-        query, variables=variables, permissions=[permission_manage_apps]\n-    )\n-\n-    # then\n-    content = get_graphql_content(response)\n-    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n-\n-    assert len(errors) == 1\n-    assert errors[0] == {\n-        \"code\": \"INVALID_URL_FORMAT\",\n-        \"field\": \"extensions\",\n-        \"message\": \"Incorrect value for field: url.\",\n-    }\n-\n-\n-@pytest.mark.parametrize(\n     (\"app_permissions\", \"extension_permissions\"),\n     [\n         ([], [\"MANAGE_PRODUCTS\"]),\n         ([\"MANAGE_PRODUCTS\"], [\"MANAGE_PRODUCTS\", \"MANAGE_APPS\"]),\n@@ -1030,4 +873,172 @@\n     assert not errors\n     assert manifest[\"identifier\"] == \"saleor.app.avatax\"\n     assert all_apps.not_removed().count() == 0\n     assert all_apps.marked_to_be_removed().count() == 1\n+\n+\n+def test_app_fetch_manifest_extension_without_options(\n+    staff_api_client, app_manifest, permission_manage_apps, monkeypatch\n+):\n+    # given\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"label\": \"Product Extension\",\n+            \"url\": \"http://127.0.0.1:8080/extension\",\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"target\": \"POPUP\",\n+        }\n+    ]\n+\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+\n+    query = APP_FETCH_MANIFEST_MUTATION\n+    variables = {\n+        \"manifest_url\": \"http://localhost:3000/manifest\",\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        query, variables=variables, permissions=[permission_manage_apps]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n+    manifest = content[\"data\"][\"appFetchManifest\"][\"manifest\"]\n+    extensions = manifest[\"extensions\"] if manifest else []\n+\n+    assert not errors, f\"Expected no errors, got: {errors}\"\n+    assert len(extensions) == 1\n+    assert extensions[0][\"label\"] == \"Product Extension\"\n+    assert extensions[0][\"url\"] == \"http://127.0.0.1:8080/extension\"\n+\n+\n+def test_app_fetch_manifest_extension_with_relative_url(\n+    staff_api_client, app_manifest, permission_manage_apps, monkeypatch\n+):\n+    # given\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"permissions\": [],\n+            \"label\": \"Relative URL Extension\",\n+            \"url\": \"/api/form\",\n+            \"mount\": \"PRODUCT_DETAILS_WIDGETS\",\n+            \"target\": \"NEW_TAB\",\n+        },\n+        {\n+            \"permissions\": [],\n+            \"label\": \"Root Path Extension\",\n+            \"url\": \"/\",\n+            \"mount\": \"PRODUCT_DETAILS_WIDGETS\",\n+            \"target\": \"APP_PAGE\",\n+        },\n+    ]\n+\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+\n+    query = APP_FETCH_MANIFEST_MUTATION\n+    variables = {\n+        \"manifest_url\": \"http://localhost:3000/manifest\",\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        query, variables=variables, permissions=[permission_manage_apps]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n+    manifest = content[\"data\"][\"appFetchManifest\"][\"manifest\"]\n+    extensions = manifest[\"extensions\"] if manifest else []\n+\n+    assert not errors, f\"Expected no errors, got: {errors}\"\n+    assert len(extensions) == 2\n+    assert extensions[0][\"url\"] == \"/api/form\"\n+    assert extensions[1][\"url\"] == \"/\"\n+\n+\n+def test_app_fetch_manifest_extension_with_absolute_url(\n+    staff_api_client, app_manifest, permission_manage_apps, monkeypatch\n+):\n+    # given\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"permissions\": [\"MANAGE_PRODUCTS\"],\n+            \"label\": \"Absolute URL Extension\",\n+            \"url\": \"https://example.com/extension\",\n+            \"mount\": \"PRODUCT_OVERVIEW_CREATE\",\n+            \"target\": \"POPUP\",\n+        }\n+    ]\n+\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+\n+    query = APP_FETCH_MANIFEST_MUTATION\n+    variables = {\n+        \"manifest_url\": \"http://localhost:3000/manifest\",\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        query, variables=variables, permissions=[permission_manage_apps]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n+    manifest = content[\"data\"][\"appFetchManifest\"][\"manifest\"]\n+    extensions = manifest[\"extensions\"] if manifest else []\n+\n+    assert not errors, f\"Expected no errors, got: {errors}\"\n+    assert len(extensions) == 1\n+    assert extensions[0][\"url\"] == \"https://example.com/extension\"\n+\n+\n+def test_app_fetch_manifest_extension_with_invalid_absolute_url(\n+    staff_api_client, app_manifest, permission_manage_apps, monkeypatch\n+):\n+    # given\n+    app_manifest[\"extensions\"] = [\n+        {\n+            \"permissions\": [],\n+            \"label\": \"Invalid URL Extension\",\n+            \"url\": \"not-a-valid-url\",\n+            \"mount\": \"PRODUCT_DETAILS_WIDGETS\",\n+            \"target\": \"POPUP\",\n+        }\n+    ]\n+\n+    mocked_get_response = Mock()\n+    mocked_get_response.json.return_value = app_manifest\n+\n+    monkeypatch.setattr(HTTPSession, \"request\", Mock(return_value=mocked_get_response))\n+\n+    query = APP_FETCH_MANIFEST_MUTATION\n+    variables = {\n+        \"manifest_url\": \"http://localhost:3000/manifest\",\n+    }\n+\n+    # when\n+    response = staff_api_client.post_graphql(\n+        query, variables=variables, permissions=[permission_manage_apps]\n+    )\n+\n+    # then\n+    content = get_graphql_content(response)\n+    errors = content[\"data\"][\"appFetchManifest\"][\"errors\"]\n+\n+    assert len(errors) == 1\n+    assert errors[0][\"field\"] == \"extensions\"\n+    assert errors[0][\"code\"] == AppErrorCode.INVALID_URL_FORMAT.name\n+    assert \"url\" in errors[0][\"message\"].lower()\n"
        },
        {
          "path": "saleor/graphql/app/tests/queries/test_app_extension.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/queries/test_app_extension.py\n===================================================================\n--- saleor/graphql/app/tests/queries/test_app_extension.py\t68e80f4 (parent)\n+++ saleor/graphql/app/tests/queries/test_app_extension.py\tb356a52 (commit)\n@@ -1,9 +1,13 @@\n import graphene\n import pytest\n \n from .....app.models import App, AppExtension\n-from .....app.types import AppExtensionMount, AppExtensionTarget, AppType\n+from .....app.types import (\n+    AppType,\n+    DeprecatedAppExtensionMount,\n+    DeprecatedAppExtensionTarget,\n+)\n from .....core.jwt import jwt_decode\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n QUERY_APP_EXTENSION = \"\"\"\n@@ -29,11 +33,11 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n         http_target_method=\"POST\",\n-        target=AppExtensionTarget.WIDGET,\n+        target=DeprecatedAppExtensionTarget.WIDGET,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -69,9 +73,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -108,9 +112,9 @@\n     app_extension = AppExtension.objects.create(\n         app=removed_app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -132,9 +136,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -156,9 +160,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -188,9 +192,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products, permission_manage_orders)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -230,9 +234,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products, permission_manage_orders)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -269,9 +273,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products, permission_manage_orders)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -317,9 +321,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -343,9 +347,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -385,9 +389,9 @@\n     app_extension = AppExtension.objects.create(\n         app=another_app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -410,9 +414,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -434,9 +438,9 @@\n     app_extension = AppExtension.objects.create(\n         app=external_app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n \n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -459,9 +463,9 @@\n     app_extension = AppExtension.objects.create(\n         app=external_app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n \n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n     variables = {\"id\": id}\n@@ -475,12 +479,12 @@\n \n @pytest.mark.parametrize(\n     (\"target\", \"method\"),\n     [\n-        (AppExtensionTarget.WIDGET, \"POST\"),\n-        (AppExtensionTarget.WIDGET, \"GET\"),\n-        (AppExtensionTarget.NEW_TAB, \"POST\"),\n-        (AppExtensionTarget.NEW_TAB, \"GET\"),\n+        (DeprecatedAppExtensionTarget.WIDGET, \"POST\"),\n+        (DeprecatedAppExtensionTarget.WIDGET, \"GET\"),\n+        (DeprecatedAppExtensionTarget.NEW_TAB, \"POST\"),\n+        (DeprecatedAppExtensionTarget.NEW_TAB, \"GET\"),\n     ],\n )\n def test_app_extension_type_settings_from_http_target_method(\n     target,\n@@ -492,9 +496,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.ORDER_DETAILS_WIDGETS,\n+        mount=DeprecatedAppExtensionMount.ORDER_DETAILS_WIDGETS,\n         http_target_method=method,\n         target=target,\n     )\n     id = graphene.Node.to_global_id(\"AppExtension\", app_extension.id)\n@@ -512,12 +516,12 @@\n \n     assert extension_data[\"mountName\"] == \"ORDER_DETAILS_WIDGETS\"\n     assert extension_data[\"targetName\"] == app_extension.target.upper()\n \n-    if target == AppExtensionTarget.NEW_TAB:\n+    if target == DeprecatedAppExtensionTarget.NEW_TAB:\n         assert extension_data[\"settings\"][\"newTabTarget\"][\"method\"] == method\n \n-    if target == AppExtensionTarget.WIDGET:\n+    if target == DeprecatedAppExtensionTarget.WIDGET:\n         assert extension_data[\"settings\"][\"widgetTarget\"][\"method\"] == method\n \n \n def test_app_extension_type_settings_from_native_settings(\n@@ -531,9 +535,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.ORDER_DETAILS_WIDGETS,\n+        mount=DeprecatedAppExtensionMount.ORDER_DETAILS_WIDGETS,\n         http_target_method=method,\n         settings={\"newTabTarget\": {\"method\": method}},\n         target=target,\n     )\n@@ -552,9 +556,9 @@\n \n     assert extension_data[\"mountName\"] == \"ORDER_DETAILS_WIDGETS\"\n     assert extension_data[\"targetName\"] == app_extension.target.upper()\n \n-    if target == AppExtensionTarget.NEW_TAB:\n+    if target == DeprecatedAppExtensionTarget.NEW_TAB:\n         assert extension_data[\"settings\"][\"newTabTarget\"][\"method\"] == method\n \n-    if target == AppExtensionTarget.WIDGET:\n+    if target == DeprecatedAppExtensionTarget.WIDGET:\n         assert extension_data[\"settings\"][\"widgetTarget\"][\"method\"] == method\n"
        },
        {
          "path": "saleor/graphql/app/tests/queries/test_app_extensions.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/tests/queries/test_app_extensions.py\n===================================================================\n--- saleor/graphql/app/tests/queries/test_app_extensions.py\t68e80f4 (parent)\n+++ saleor/graphql/app/tests/queries/test_app_extensions.py\tb356a52 (commit)\n@@ -1,8 +1,8 @@\n import pytest\n \n from .....app.models import AppExtension\n-from .....app.types import AppExtensionMount, AppExtensionTarget\n+from .....app.types import DeprecatedAppExtensionMount, DeprecatedAppExtensionTarget\n from .....core.jwt import jwt_decode\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n QUERY_APP_EXTENSIONS = \"\"\"\n@@ -32,11 +32,11 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n         http_target_method=\"POST\",\n-        target=AppExtensionTarget.WIDGET,\n+        target=DeprecatedAppExtensionTarget.WIDGET,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     variables = {}\n \n@@ -81,9 +81,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     variables = {}\n \n@@ -108,9 +108,9 @@\n     app_extension = AppExtension.objects.create(\n         app=removed_app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     variables = {}\n \n@@ -135,9 +135,9 @@\n     app_extension = AppExtension.objects.create(\n         app=app,\n         label=\"Create product with App\",\n         url=\"https://www.example.com/app-product\",\n-        mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+        mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n     )\n     app_extension.permissions.add(permission_manage_products)\n     variables = {}\n \n@@ -189,29 +189,29 @@\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App1\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n-                target=AppExtensionTarget.APP_PAGE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+                target=DeprecatedAppExtensionTarget.APP_PAGE,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App2\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n-                target=AppExtensionTarget.POPUP,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n+                target=DeprecatedAppExtensionTarget.POPUP,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App3\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App4\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n             ),\n         ]\n     )\n     app_extensions[0].permissions.add(permission_manage_products)\n@@ -300,29 +300,29 @@\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App1\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n-                target=AppExtensionTarget.APP_PAGE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_MORE_ACTIONS,\n+                target=DeprecatedAppExtensionTarget.APP_PAGE,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App2\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n-                target=AppExtensionTarget.POPUP,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_DETAILS_MORE_ACTIONS,\n+                target=DeprecatedAppExtensionTarget.POPUP,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App3\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n             ),\n             AppExtension(\n                 app=app,\n                 label=\"Create product with App4\",\n                 url=\"https://www.example.com/app-product\",\n-                mount=AppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n+                mount=DeprecatedAppExtensionMount.PRODUCT_OVERVIEW_CREATE,\n             ),\n         ]\n     )\n     variables = {\"filter\": filter}\n"
        },
        {
          "path": "saleor/graphql/app/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/app/types.py\n===================================================================\n--- saleor/graphql/app/types.py\t68e80f4 (parent)\n+++ saleor/graphql/app/types.py\tb356a52 (commit)\n@@ -3,9 +3,13 @@\n \n import graphene\n \n from ...app import models\n-from ...app.types import AppExtensionHttpMethod, AppExtensionTarget\n+from ...app.types import (\n+    DEFAULT_APP_TARGET,\n+    DeprecatedAppExtensionHttpMethod,\n+    DeprecatedAppExtensionTarget,\n+)\n from ...core.exceptions import PermissionDenied\n from ...core.jwt import JWT_THIRDPARTY_ACCESS_TYPE\n from ...core.utils import build_absolute_uri\n from ...permission.auth_filters import AuthorizationFilters, is_staff_user\n@@ -137,19 +141,15 @@\n     class Meta:\n         doc_category = DOC_CATEGORY_APPS\n \n     @staticmethod\n-    def resolve_target(root, _info: ResolveInfo):\n-        return root.get(\"target\") or AppExtensionTarget.POPUP\n-\n-    @staticmethod\n     def resolve_url(root, _info: ResolveInfo):\n         \"\"\"Return an extension URL.\"\"\"\n         return resolve_app_extension_url(root)\n \n     @staticmethod\n     def resolve_target_name(root, _info: ResolveInfo):\n-        return (root.get(\"target\") or \"POPUP\").upper()\n+        return (root.get(\"target\") or DEFAULT_APP_TARGET).upper()\n \n     @staticmethod\n     def resolve_mount_name(root, _info: ResolveInfo):\n         return root[\"mount\"].upper()\n@@ -159,10 +159,10 @@\n         return root.get(\"options\") or {}\n \n \n class HttpMethod(BaseEnum):\n-    POST = AppExtensionHttpMethod.POST\n-    GET = AppExtensionHttpMethod.GET\n+    POST = DeprecatedAppExtensionHttpMethod.POST\n+    GET = DeprecatedAppExtensionHttpMethod.GET\n \n \n class AppExtension(AppManifestExtension, ModelObjectType[models.AppExtension]):\n     id = graphene.GlobalID(required=True, description=\"The ID of the app extension.\")\n@@ -250,16 +250,16 @@\n             return root.settings\n \n         # Fallback if settings not propagated in DB yet\n         # Make it case-insensitive due to migration logic - enum will become uppercased in DB\n-        if root.target.upper() == AppExtensionTarget.WIDGET.upper():\n+        if root.target.upper() == DeprecatedAppExtensionTarget.WIDGET.upper():\n             return {\n                 \"widgetTarget\": {\n                     \"method\": http_method,\n                 }\n             }\n \n-        if root.target.upper() == AppExtensionTarget.NEW_TAB.upper():\n+        if root.target.upper() == DeprecatedAppExtensionTarget.NEW_TAB.upper():\n             return {\n                 \"newTabTarget\": {\n                     \"method\": http_method,\n                 }\n"
        }
      ]
    },
    {
      "id": "remove-valuenames-support",
      "sha": "8eb11da07f09437374cb82daa6f10a80a11a1c90",
      "parentSha": "bdb2f9d05d339fb0f07d9aa6946c60284b08a836",
      "spec": "Implement removal of name-based attribute value filtering from the GraphQL API and product filtering internals, leaving only slug-based filtering.\n\nScope of changes:\n1) GraphQL input type (Python/Graphene):\n- In saleor/graphql/attribute/types.py, remove the value_names field from AttributeInput (previously a NonNullList of strings with ADDED_IN_322). Ensure deprecation notes for other fields remain unchanged and that AttributeInput supports slug and the deprecated values field only for slugs.\n\n2) Filtering internals (product attribute filters):\n- In saleor/graphql/product/filters/product_attributes.py, update the attribute filter parsing and query construction to use only slug-based values.\n  - Change the signature of _clean_product_attributes_filter_input to drop the field parameter so it becomes (filter_values, queries, database_connection_name).\n  - Replace the helper that previously handled generic field-based lookups (_populate_value_map) with a slug-only variant (_populate_slug_value_map) that filters AttributeValue by slug__in and maps attribute->value slugs to value PKs. Update all call sites accordingly.\n  - Remove parsing and handling of value_names from the attribute input processing (i.e., do not detect or collect name_value_list when iterating inputs).\n  - In _filter_products_by_deprecated_attributes_input, drop the filter_name_values parameter and associated logic so only slug-based, range, boolean, date, and date_time filters are processed. Update invocations accordingly.\n\n3) GraphQL schema (SDL):\n- In saleor/graphql/schema.graphql, remove the valueNames: [String!] field from the AttributeInput definition and its accompanying description and release note. Ensure the deprecated values field for slugs remains and that descriptions reflect slug-only value filtering.\n\n4) Tests:\n- In saleor/graphql/product/tests/queries/test_products_query_with_where.py, remove the test that asserts filtering products by attributes using valueNames (GraphQL casing) from the where input. Ensure no references to valueNames/value_names remain in this suite.\n- Verify any remaining tests exercising attribute filters are updated or remain valid under slug-only filtering.\n\n5) Documentation/Changelog:\n- In CHANGELOG.md, remove the entry that announced support for filtering products by attribute value names via AttributeInput.valueNames under GraphQL API, aligning the changelog with the slug-only behavior.\n\nAcceptance criteria:\n- The GraphQL schema (both Python definition and schema.graphql) no longer exposes AttributeInput.valueNames/value_names.\n- Product filtering via AttributeInput works with slugs and deprecated slug-based fields as before; name-based filtering is not accepted and no longer parsed.\n- All helper functions and signatures compile and tests pass after removing name-based code paths.\n- No occurrences of valueNames or value_names remain in code or tests, except potentially in historical documentation outside the scope specified.",
      "prompt": "Remove name-based attribute value filtering from the GraphQL API and product filtering logic, leaving only slug-based filtering. Update the GraphQL AttributeInput input type to drop the field that allowed passing attribute value names, adjust the product attribute filtering code to only parse and resolve value slugs, and remove the corresponding tests. Ensure the SDL schema and changelog reflect this change. Keep deprecated slug-based fields working, but eliminate any code paths that parse or query by attribute value names.",
      "supplementalFiles": [
        "saleor/graphql/product/filters/product.py",
        "saleor/graphql/product/tests/queries/test_products_query_with_filter.py",
        "saleor/graphql/product/tests/queries/products_filtrations/test_over_attributes.py",
        "saleor/graphql/attribute/filters.py",
        "saleor/attribute/models/base.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\tbdb2f9d (parent)\n+++ CHANGELOG.md\t8eb11da (commit)\n@@ -7,10 +7,8 @@\n ### Breaking changes\n - Increased query cost for attribute-related operations due to the addition of `AttributeValue.referencedObject`.\n \n ### GraphQL API\n-\n-- Added support for filtering products by attribute value names. The `AttributeInput` now includes a `valueNames` field, enabling filtering by the names of attribute values, in addition to the existing filtering by value slugs.\n - You can now filter and search orders using the new `where` and `search` fields on the `pages` query.\n   - Use `where` to define complex conditions with `AND`/`OR` logic and operators like `eq`, `oneOf`, `range`.\n   - Use `search` to perform full-text search across relevant fields.\n - Add support for filtering `pages` by associated attributes\n"
        },
        {
          "path": "saleor/graphql/attribute/types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/attribute/types.py\n===================================================================\n--- saleor/graphql/attribute/types.py\tbdb2f9d (parent)\n+++ saleor/graphql/attribute/types.py\t8eb11da (commit)\n@@ -543,18 +543,8 @@\n             \"If provided more than one, the error will be raised. Cannot be combined \"\n             \"with deprecated fields of `AttributeInput`. \"\n         ),\n     )\n-    value_names = NonNullList(\n-        graphene.String,\n-        required=False,\n-        description=(\n-            \"Names corresponding to the attributeValues associated with the Attribute. \"\n-            \"When specified, it filters the results to include only records with \"\n-            \"one of the matching values.\"\n-        )\n-        + ADDED_IN_322,\n-    )\n     values = NonNullList(\n         graphene.String,\n         required=False,\n         description=(\n"
        },
        {
          "path": "saleor/graphql/product/filters/product_attributes.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/filters/product_attributes.py\n===================================================================\n--- saleor/graphql/product/filters/product_attributes.py\tbdb2f9d (parent)\n+++ saleor/graphql/product/filters/product_attributes.py\t8eb11da (commit)\n@@ -36,9 +36,9 @@\n T_PRODUCT_FILTER_QUERIES = dict[int, list[int]]\n \n \n def _clean_product_attributes_filter_input(\n-    filter_values, field, queries, database_connection_name\n+    filter_values, queries, database_connection_name\n ):\n     attribute_slugs = []\n     values = []\n \n@@ -54,31 +54,31 @@\n     for attr_slug, attr_pk in attributes.values_list(\"slug\", \"id\"):\n         attributes_slug_pk_map[attr_slug] = attr_pk\n         attributes_pk_slug_map[attr_pk] = attr_slug\n \n-    values_map = _populate_value_map(\n-        database_connection_name, field, values, attributes, attributes_pk_slug_map\n+    values_map = _populate_slug_value_map(\n+        database_connection_name, values, attributes, attributes_pk_slug_map\n     )\n \n     _update_queries(queries, filter_values, attributes_slug_pk_map, values_map)\n \n \n-def _populate_value_map(\n-    database_connection_name, field, values, attribute_qs, attributes_pk_slug_map\n+def _populate_slug_value_map(\n+    database_connection_name, slugs, attribute_qs, attributes_pk_slug_map\n ):\n     value_maps: dict[str, dict[str, list[int]]] = defaultdict(lambda: defaultdict(list))\n     for (\n         attr_pk,\n         value_pk,\n-        field_value,\n+        value_slug,\n     ) in (\n         AttributeValue.objects.using(database_connection_name)\n         .filter(Exists(attribute_qs.filter(pk=OuterRef(\"attribute_id\"))))\n-        .filter(**{f\"{field}__in\": values})\n-        .values_list(\"attribute_id\", \"pk\", field)\n+        .filter(slug__in=slugs)\n+        .values_list(\"attribute_id\", \"pk\", \"slug\")\n     ):\n         attr_slug = attributes_pk_slug_map[attr_pk]\n-        value_maps[attr_slug][field_value].append(value_pk)\n+        value_maps[attr_slug][value_slug].append(value_pk)\n \n     return value_maps\n \n \n@@ -251,24 +251,17 @@\n \n def _filter_products_by_deprecated_attributes_input(\n     qs,\n     filter_slug_values,\n-    filter_name_values,\n     filter_range_values,\n     filter_boolean_values,\n     date_range_list,\n     date_time_range_list,\n ):\n     queries: dict[int, list[int]] = defaultdict(list)\n     try:\n         if filter_slug_values:\n-            _clean_product_attributes_filter_input(\n-                filter_slug_values, \"slug\", queries, qs.db\n-            )\n-        if filter_name_values:\n-            _clean_product_attributes_filter_input(\n-                filter_name_values, \"name\", queries, qs.db\n-            )\n+            _clean_product_attributes_filter_input(filter_slug_values, queries, qs.db)\n         if filter_range_values:\n             _clean_product_attributes_range_filter_input(\n                 filter_range_values, queries, qs.db\n             )\n@@ -295,9 +288,8 @@\n     if not value:\n         return qs.none()\n \n     slug_value_list = []\n-    name_value_list = []\n     boolean_list = []\n     value_range_list = []\n     date_range_list = []\n     date_time_range_list = []\n@@ -305,10 +297,8 @@\n     for v in value:\n         slug = v[\"slug\"]\n         if \"values\" in v:\n             slug_value_list.append((slug, v[\"values\"]))\n-        elif \"value_names\" in v:\n-            name_value_list.append((slug, v[\"value_names\"]))\n         elif \"values_range\" in v:\n             value_range_list.append((slug, v[\"values_range\"]))\n         elif \"date\" in v:\n             date_range_list.append((slug, v[\"date\"]))\n@@ -319,9 +309,8 @@\n \n     qs = _filter_products_by_deprecated_attributes_input(\n         qs,\n         slug_value_list,\n-        name_value_list,\n         value_range_list,\n         boolean_list,\n         date_range_list,\n         date_time_range_list,\n"
        },
        {
          "path": "saleor/graphql/product/tests/queries/test_products_query_with_where.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/product/tests/queries/test_products_query_with_where.py\n===================================================================\n--- saleor/graphql/product/tests/queries/test_products_query_with_where.py\tbdb2f9d (parent)\n+++ saleor/graphql/product/tests/queries/test_products_query_with_where.py\t8eb11da (commit)\n@@ -743,54 +743,8 @@\n     returned_ids = {product[\"node\"][\"id\"] for product in products}\n     assert returned_ids == {product1_id, product2_id}\n \n \n-def test_products_filter_by_attributes_value_name(\n-    api_client,\n-    product_list,\n-    channel_USD,\n-):\n-    # given\n-    product_type = ProductType.objects.create(\n-        name=\"Custom Type\",\n-        slug=\"custom-type\",\n-        has_variants=True,\n-        is_shipping_required=True,\n-        kind=ProductTypeKind.NORMAL,\n-    )\n-    attribute = Attribute.objects.create(slug=\"new_attr\", name=\"Attr\")\n-    attribute.product_types.add(product_type)\n-    attr_value = AttributeValue.objects.create(\n-        attribute=attribute, name=\"First\", slug=\"first\"\n-    )\n-    product = product_list[0]\n-    product.product_type = product_type\n-    product.save()\n-    associate_attribute_values_to_instance(\n-        product,\n-        {attribute.pk: [attr_value]},\n-    )\n-\n-    variables = {\n-        \"channel\": channel_USD.slug,\n-        \"where\": {\n-            \"attributes\": [{\"slug\": attribute.slug, \"valueNames\": [attr_value.name]}],\n-        },\n-    }\n-\n-    # when\n-    response = api_client.post_graphql(PRODUCTS_WHERE_QUERY, variables)\n-    content = get_graphql_content(response)\n-\n-    # then\n-    product_id = graphene.Node.to_global_id(\"Product\", product.id)\n-    products = content[\"data\"][\"products\"][\"edges\"]\n-\n-    assert len(products) == 1\n-    assert products[0][\"node\"][\"id\"] == product_id\n-    assert products[0][\"node\"][\"name\"] == product.name\n-\n-\n def test_products_filter_by_attributes_empty_list(\n     api_client,\n     product_list,\n     channel_USD,\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\tbdb2f9d (parent)\n+++ saleor/graphql/schema.graphql\t8eb11da (commit)\n@@ -7779,15 +7779,8 @@\n   \"\"\"\n   value: AssignedAttributeValueInput\n \n   \"\"\"\n-  Names corresponding to the attributeValues associated with the Attribute. When specified, it filters the results to include only records with one of the matching values.\n-  \n-  Added in Saleor 3.22.\n-  \"\"\"\n-  valueNames: [String!]\n-\n-  \"\"\"\n   Slugs identifying the attributeValues associated with the Attribute. When specified, it filters the results to include only records with one of the matching values. Requires `slug` to be provided.\n   \"\"\"\n   values: [String!] @deprecated(reason: \"Use `value` instead.\")\n \n"
        }
      ]
    },
    {
      "id": "switch-to-transactions",
      "sha": "c62941a63c3e1cb1a9ac6b54f0eb317b05a6c7c5",
      "parentSha": "f5c6639f4126793c4efb0521d38b99a18231fe83",
      "spec": "Implement transaction-based example payments and related defaults in the populate-db helpers.\n\nMake the following changes:\n\n1) Use transactions for fake order payments (saleor/core/utils/random_data.py)\n- Replace the gateway-based create_fake_payment implementation so that it creates a TransactionItem and corresponding TransactionEvent records instead of calling payment gateway authorize/capture/refund.\n- Drive the flow by the order.channel.default_transaction_flow_strategy value:\n  - For \"authorization\": randomly create one of: Authorized only (available_actions includes CHARGE and CANCEL), Authorized + Charged (available_actions includes REFUND), or Authorized + Charged + Refunded.\n  - For \"charge\": randomly create either Charged only (available_actions includes REFUND) or Charged + Refunded.\n- Generate distinct PSP references for authorization, charge, and refund events, and persist them with include_in_calculations=True on *_SUCCESS events and False on *_REQUEST events.\n- After creating events, recalculate the transaction amounts and update the order’s transaction-derived fields by invoking payment.utils.recalculate_transaction_amounts(transaction=…) and payment.utils.update_order_with_transaction_details(…).\n- Use a dummy app identifier \"saleor.io.dummy-payment-app\" (read App by identifier if present) for app/app_identifier on the created TransactionItem and events.\n- Add a helper create_transaction_with_events(order, name, app/app_identifier, user=None, available_actions, authorized_amount, charge_amount, refund_amount, authorization_psp, charge_psp, refund_psp) that:\n  - Creates a TransactionItem assigned to the order with currency, psp_reference, available_actions.\n  - Creates TransactionEvent rows for any provided amounts (AUTHORIZATION_REQUEST/SUCCESS, CHARGE_REQUEST/SUCCESS, REFUND_REQUEST/SUCCESS) and saves them with correct fields.\n  - Bulk-creates events, recalculates the TransactionItem amounts, and updates the order fields.\n\n2) Adjust fake order creation logic (saleor/core/utils/random_data.py)\n- Reduce the chance for unconfirmed orders to 10% (unless creating preorder lines, which remain unconfirmed).\n- Compute and assign order.subtotal by summing line total_price values with a zero TaxedMoney start value.\n- After creating the fake payment (now transactions), refresh the order from DB to reflect updated totals.\n- Only create fulfillments when the order is confirmed and fully balanced (order.total_balance == Money(0, order.currency)).\n\n3) Align promotions with model enums (saleor/core/utils/random_data.py)\n- In create_fake_order_promotion, set Promotion.type to the ORDER type and set start_date to a future time (e.g., now + 1 day) so it doesn’t apply immediately.\n- Use discount.models.RewardType constants (e.g., RewardType.SUBTOTAL_DISCOUNT) for PromotionRule.reward_type instead of GraphQL enums.\n\n4) Update channel creation to include transaction strategies (saleor/core/utils/random_data.py)\n- Extend create_channel to accept mark_as_paid_strategy (default \"transaction_flow\") and default_transaction_flow_strategy (default \"charge\").\n- Use update_or_create to ensure Channel defaults include: name, currency_code, is_active, default_country, order_mark_as_paid_strategy, default_transaction_flow_strategy.\n- Use update_or_create for TaxConfiguration associated with the Channel.\n- In create_channels, set the default channel to use default_transaction_flow_strategy=\"authorization\".\n\n5) Disallow fulfilling unpaid orders by default (saleor/static/populatedb_data.json)\n- Change the seeded SiteSettings to have \"fulfillment_allow_unpaid\": false.\n\n6) Imports and references (saleor/core/utils/random_data.py)\n- Import App, PromotionType, RewardType, TransactionAction, TransactionEventType, TransactionItem, TransactionEvent, and the utility functions recalculate_transaction_amounts and update_order_with_transaction_details.\n- Remove use of RewardTypeEnum from GraphQL.\n- Ensure Money/TaxedMoney are available for subtotal and total_balance checks.\n\nObservable outcomes:\n- Example orders created by populate-db have TransactionItem + TransactionEvent history reflecting authorization/charge/refund flows and order totals derive from transactions.\n- Orders only auto-fulfill when fully paid (zero total_balance) and confirmed.\n- Promotions generated for orders use model-level enums and start in the future.\n- Channels created by populate-db are configured for transaction-based flows, and site defaults do not allow fulfilling unpaid orders.\n",
      "prompt": "Update the populate-db helpers to use transaction-based payments for example orders instead of legacy payment gateway calls. Replace the fake payment function to create transaction records and events that reflect either an authorization-first or charge-first flow, based on the channel’s default strategy. Ensure orders’ totals and statuses update from transactions and only auto-fulfill when fully paid. Also update channel creation to include sensible defaults for transaction strategies, make order promotions use model enums, compute and assign order subtotal, and set the default site setting to not allow fulfilling unpaid orders. Keep changes localized to the populate-db utilities and static seed configuration.",
      "supplementalFiles": [
        "saleor/payment/__init__.py",
        "saleor/payment/models.py",
        "saleor/payment/utils.py",
        "saleor/channel/__init__.py",
        "saleor/channel/models.py",
        "saleor/order/models.py",
        "saleor/discount/models.py",
        "saleor/app/models.py",
        "saleor/site/models.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/core/utils/random_data.py",
          "status": "modified",
          "diff": "Index: saleor/core/utils/random_data.py\n===================================================================\n--- saleor/core/utils/random_data.py\tf5c6639 (parent)\n+++ saleor/core/utils/random_data.py\tc62941a (commit)\n@@ -28,8 +28,9 @@\n     generate_address_search_document_value,\n     generate_user_fields_search_document_value,\n )\n from ...account.utils import store_user_address\n+from ...app.models import App\n from ...attribute.models import (\n     AssignedProductAttributeValue,\n     AssignedVariantAttribute,\n     AssignedVariantAttributeValue,\n@@ -48,23 +49,28 @@\n from ...discount import DiscountValueType, RewardValueType, VoucherType\n from ...discount.models import (\n     Promotion,\n     PromotionRule,\n+    PromotionType,\n+    RewardType,\n     Voucher,\n     VoucherChannelListing,\n     VoucherCode,\n )\n from ...giftcard import events as gift_card_events\n from ...giftcard.models import GiftCard, GiftCardTag\n-from ...graphql.discount.enums import RewardTypeEnum\n from ...menu.models import Menu, MenuItem\n from ...order import OrderStatus\n from ...order.models import Fulfillment, Order, OrderLine\n from ...order.search import prepare_order_search_vector_value\n from ...order.utils import update_order_status\n from ...page.models import Page, PageType\n-from ...payment import gateway\n-from ...payment.utils import create_payment\n+from ...payment import TransactionAction, TransactionEventType\n+from ...payment.models import TransactionEvent, TransactionItem\n+from ...payment.utils import (\n+    recalculate_transaction_amounts,\n+    update_order_with_transaction_details,\n+)\n from ...permission.enums import (\n     AccountPermissions,\n     CheckoutPermissions,\n     GiftcardPermissions,\n@@ -561,36 +567,194 @@\n # We don't want to spam the console with payment confirmations sent to\n # fake customers.\n @patch(\"saleor.plugins.manager.PluginsManager.notify\")\n def create_fake_payment(mock_notify, order):\n-    payment = create_payment(\n-        gateway=\"mirumee.payments.dummy\",\n-        customer_ip_address=fake.ipv4(),\n-        email=order.user_email,\n-        order=order,\n-        payment_token=str(uuid.uuid4()),\n-        total=order.total.gross.amount,\n-        currency=order.total.gross.currency,\n+    amount = order.total.gross.amount\n+    dummy_app = App.objects.filter(identifier=\"saleor.io.dummy-payment-app\").first()\n+    dummy_app_identifier = (\n+        dummy_app.identifier if dummy_app else \"saleor.io.dummy-payment-app\"\n     )\n-    manager = get_plugins_manager(allow_replica=False)\n+    flow = order.channel.default_transaction_flow_strategy.lower()\n \n-    # Create authorization transaction\n-    gateway.authorize(payment, payment.token, manager, order.channel.slug)\n-    # 20% chance to void the transaction at this stage\n-    if random.choice([0, 0, 0, 0, 1]):\n-        gateway.void(payment, manager, order.channel.slug)\n-        return payment\n-    # 25% to end the payment at the authorization stage\n-    if not random.choice([1, 1, 1, 0]):\n-        return payment\n-    # Create capture transaction\n-    gateway.capture(payment, manager, order.channel.slug)\n-    # 25% to refund the payment\n-    if random.choice([0, 0, 0, 1]):\n-        gateway.refund(payment, manager, order.channel.slug)\n-    return payment\n+    auth_psp = uuid.uuid4()\n+    charge_psp = uuid.uuid4()\n+    refund_psp = uuid.uuid4()\n+    pick = random.random()\n \n+    kwargs = {\n+        \"order\": order,\n+        \"name\": \"\",\n+        \"app\": dummy_app,\n+        \"app_identifier\": dummy_app_identifier,\n+        \"user\": None,\n+        \"available_actions\": [],\n+        \"authorized_amount\": None,\n+        \"charge_amount\": None,\n+        \"refund_amount\": None,\n+        \"authorization_psp\": None,\n+        \"charge_psp\": None,\n+        \"refund_psp\": None,\n+    }\n+    if flow == \"authorization\":\n+        if pick < 0.15:\n+            # Authorized only: actions -> CHARGE, CANCEL\n+            kwargs[\"available_actions\"] = [\n+                TransactionAction.CHARGE,\n+                TransactionAction.CANCEL,\n+            ]\n+            kwargs[\"authorized_amount\"] = amount\n+            kwargs[\"authorization_psp\"] = auth_psp\n+            return create_transaction_with_events(**kwargs)\n+        if pick < 0.75:\n+            # Authorized + Charged: actions -> REFUND\n+            kwargs[\"available_actions\"] = [TransactionAction.REFUND]\n+            kwargs[\"authorized_amount\"] = amount\n+            kwargs[\"authorization_psp\"] = auth_psp\n+            kwargs[\"charge_amount\"] = amount\n+            kwargs[\"charge_psp\"] = charge_psp\n+            return create_transaction_with_events(**kwargs)\n+        # Authorized + Charged + Refunded\n+        kwargs[\"authorized_amount\"] = amount\n+        kwargs[\"authorization_psp\"] = auth_psp\n+        kwargs[\"charge_amount\"] = amount\n+        kwargs[\"charge_psp\"] = charge_psp\n+        kwargs[\"refund_amount\"] = amount\n+        kwargs[\"refund_psp\"] = refund_psp\n+        return create_transaction_with_events(**kwargs)\n \n+    # Charge strategy:\n+    if pick < 0.8:\n+        # Charged only\n+        kwargs[\"available_actions\"] = [TransactionAction.REFUND]\n+        kwargs[\"charge_amount\"] = amount\n+        kwargs[\"charge_psp\"] = charge_psp\n+        return create_transaction_with_events(**kwargs)\n+    # Charged + Refunded\n+    kwargs[\"charge_amount\"] = amount\n+    kwargs[\"charge_psp\"] = charge_psp\n+    kwargs[\"refund_amount\"] = amount\n+    kwargs[\"refund_psp\"] = refund_psp\n+    return create_transaction_with_events(**kwargs)\n+\n+\n+def create_transaction_with_events(\n+    *,\n+    order: Order,\n+    name: str,\n+    app: App | None,\n+    app_identifier: str | None = None,\n+    user: User | None,\n+    available_actions: list[str] | None,\n+    authorized_amount: Decimal | None,\n+    charge_amount: Decimal | None,\n+    refund_amount: Decimal | None,\n+    authorization_psp: str | None,\n+    charge_psp: str | None,\n+    refund_psp: str | None,\n+) -> TransactionItem:\n+    item_psp = authorization_psp or charge_psp or str(uuid.uuid4())\n+    transaction_item = TransactionItem.objects.create(\n+        name=name,\n+        order_id=order.pk,\n+        currency=order.currency,\n+        app=app,\n+        app_identifier=(app.identifier if app else app_identifier),\n+        user=user,\n+        psp_reference=item_psp,\n+        available_actions=available_actions or [],\n+    )\n+\n+    events_to_create: list[TransactionEvent] = []\n+\n+    event_defaults = {\n+        \"currency\": order.currency,\n+        \"transaction_id\": transaction_item.pk,\n+        \"app\": app,\n+        \"app_identifier\": (app.identifier if app else app_identifier),\n+    }\n+    if authorized_amount is not None:\n+        events_to_create.append(\n+            TransactionEvent(\n+                type=TransactionEventType.AUTHORIZATION_REQUEST,\n+                amount_value=authorized_amount,\n+                psp_reference=authorization_psp or item_psp,\n+                include_in_calculations=False,\n+                created_at=timezone.now() + datetime.timedelta(microseconds=1),\n+                user=None,\n+                **event_defaults,\n+            )\n+        )\n+        events_to_create.append(\n+            TransactionEvent(\n+                type=TransactionEventType.AUTHORIZATION_SUCCESS,\n+                amount_value=authorized_amount,\n+                psp_reference=authorization_psp or item_psp,\n+                include_in_calculations=True,\n+                created_at=timezone.now() + datetime.timedelta(microseconds=1),\n+                user=user,\n+                message=\"Authorization success\",\n+                **event_defaults,\n+            )\n+        )\n+\n+    if charge_amount is not None:\n+        events_to_create.append(\n+            TransactionEvent(\n+                type=TransactionEventType.CHARGE_REQUEST,\n+                amount_value=charge_amount,\n+                psp_reference=charge_psp or item_psp,\n+                include_in_calculations=False,\n+                created_at=timezone.now() + datetime.timedelta(microseconds=1),\n+                user=user,\n+                **event_defaults,\n+            )\n+        )\n+        events_to_create.append(\n+            TransactionEvent(\n+                type=TransactionEventType.CHARGE_SUCCESS,\n+                amount_value=charge_amount,\n+                psp_reference=charge_psp or item_psp,\n+                include_in_calculations=True,\n+                created_at=timezone.now() + datetime.timedelta(microseconds=1),\n+                user=user,\n+                message=\"Charge success\",\n+                **event_defaults,\n+            )\n+        )\n+\n+    if refund_amount is not None and refund_amount > 0:\n+        events_to_create.append(\n+            TransactionEvent(\n+                type=TransactionEventType.REFUND_REQUEST,\n+                amount_value=refund_amount,\n+                psp_reference=refund_psp or item_psp,\n+                include_in_calculations=False,\n+                created_at=timezone.now() + datetime.timedelta(microseconds=1),\n+                user=user,\n+                **event_defaults,\n+            )\n+        )\n+        events_to_create.append(\n+            TransactionEvent(\n+                type=TransactionEventType.REFUND_SUCCESS,\n+                amount_value=refund_amount,\n+                psp_reference=refund_psp or item_psp,\n+                include_in_calculations=True,\n+                created_at=timezone.now() + datetime.timedelta(microseconds=1),\n+                user=user,\n+                message=\"Refund success\",\n+                **event_defaults,\n+            )\n+        )\n+\n+    if events_to_create:\n+        TransactionEvent.objects.bulk_create(events_to_create)\n+        recalculate_transaction_amounts(transaction=transaction_item)\n+        update_order_with_transaction_details(transaction_item)\n+\n+    return transaction_item\n+\n+\n def create_order_lines(order, how_many=10):\n     channel = order.channel\n     available_variant_ids = channel.variant_listings.values_list(\n         \"variant_id\", flat=True\n@@ -779,12 +943,10 @@\n         .order_by(\"?\")\n     )\n     customer = random.choice([None, customers.first()])\n \n-    # 20% chance to be unconfirmed order.\n-    will_be_unconfirmed = (\n-        random.choice([0, 0, 0, 0, 1]) if not create_preorder_lines else True\n-    )\n+    # # 10% chance to be unconfirmed order.\n+    will_be_unconfirmed = (random.random() < 0.1) if not create_preorder_lines else True\n \n     if customer and customer.default_shipping_address:\n         address = customer.default_shipping_address\n     else:\n@@ -828,8 +990,12 @@\n         lines = create_order_lines_with_preorder(order)\n     else:\n         lines = create_order_lines(order, random.randrange(1, max_order_lines))\n     order.total = sum([line.total_price for line in lines], shipping_price)\n+    order.subtotal = sum(\n+        [line.total_price for line in lines],\n+        TaxedMoney(net=Money(0, order.currency), gross=Money(0, order.currency)),\n+    )\n     weight = Weight(kg=0)\n     for line in order.lines.all():\n         if line.variant:\n             weight += line.variant.get_weight()\n@@ -841,9 +1007,13 @@\n     order.save()\n \n     create_fake_payment(order=order)\n \n-    if not will_be_unconfirmed:\n+    # Ensure totals (including total_balance) reflect the latest transactions\n+    order.refresh_from_db()\n+\n+    # Fulfill only when order is confirmed and fully balanced (total_balance == 0)\n+    if not will_be_unconfirmed and order.total_balance == Money(0, order.currency):\n         create_fulfillments(order)\n \n     return order\n \n@@ -895,16 +1065,18 @@\n \n def create_fake_order_promotion():\n     promotion = Promotion.objects.create(\n         name=f\"Happy {fake.word()} day!\",\n+        type=PromotionType.ORDER,\n+        start_date=timezone.now() + datetime.timedelta(days=1),\n     )\n     rules = PromotionRule.objects.bulk_create(\n         [\n             PromotionRule(\n                 promotion=promotion,\n                 reward_value_type=RewardValueType.PERCENTAGE,\n                 reward_value=random.choice([10, 20, 30, 40, 50]),\n-                reward_type=RewardTypeEnum.SUBTOTAL_DISCOUNT.name,\n+                reward_type=RewardType.SUBTOTAL_DISCOUNT,\n                 order_predicate={\n                     \"discountedObjectPredicate\": {\n                         \"baseSubtotalPrice\": {\"range\": {\"gte\": \"200\"}}\n                     }\n@@ -913,9 +1085,9 @@\n             PromotionRule(\n                 promotion=promotion,\n                 reward_value_type=RewardValueType.FIXED,\n                 reward_value=random.choice([10, 20, 30, 40, 50]),\n-                reward_type=RewardTypeEnum.SUBTOTAL_DISCOUNT.name,\n+                reward_type=RewardType.SUBTOTAL_DISCOUNT,\n                 order_predicate={\n                     \"discountedObjectPredicate\": {\n                         \"baseSubtotalPrice\": {\"range\": {\"gte\": \"100\"}}\n                     }\n@@ -1047,21 +1219,31 @@\n         promotion = create_fake_order_promotion()\n         yield f\"Promotion: {promotion}\"\n \n \n-def create_channel(channel_name, currency_code, slug=None, country=None):\n+def create_channel(\n+    channel_name,\n+    currency_code,\n+    slug=None,\n+    country=None,\n+    mark_as_paid_strategy=\"transaction_flow\",\n+    default_transaction_flow_strategy=\"charge\",\n+):\n     if not slug:\n         slug = slugify(channel_name)\n-    channel, _ = Channel.objects.get_or_create(\n+    defaults = {\n+        \"name\": channel_name,\n+        \"currency_code\": currency_code,\n+        \"is_active\": True,\n+        \"default_country\": country,\n+        \"order_mark_as_paid_strategy\": mark_as_paid_strategy,\n+        \"default_transaction_flow_strategy\": default_transaction_flow_strategy,\n+    }\n+    channel, _ = Channel.objects.update_or_create(\n         slug=slug,\n-        defaults={\n-            \"name\": channel_name,\n-            \"currency_code\": currency_code,\n-            \"is_active\": True,\n-            \"default_country\": country,\n-        },\n+        defaults=defaults,\n     )\n-    TaxConfiguration.objects.get_or_create(channel=channel)\n+    TaxConfiguration.objects.update_or_create(channel=channel)\n     return f\"Channel: {channel}\"\n \n \n def create_channels():\n@@ -1069,8 +1251,9 @@\n         channel_name=\"Channel-USD\",\n         currency_code=\"USD\",\n         slug=settings.DEFAULT_CHANNEL_SLUG,\n         country=settings.DEFAULT_COUNTRY,\n+        default_transaction_flow_strategy=\"authorization\",\n     )\n     yield create_channel(\n         channel_name=\"Channel-PLN\",\n         currency_code=\"PLN\",\n"
        },
        {
          "path": "saleor/static/populatedb_data.json",
          "status": "modified",
          "diff": "Index: saleor/static/populatedb_data.json\n===================================================================\n--- saleor/static/populatedb_data.json\tf5c6639 (parent)\n+++ saleor/static/populatedb_data.json\tc62941a (commit)\n@@ -9585,9 +9585,9 @@\n       \"default_mail_sender_address\": null,\n       \"customer_set_password_url\": null,\n       \"automatically_confirm_all_new_orders\": true,\n       \"fulfillment_auto_approve\": true,\n-      \"fulfillment_allow_unpaid\": true,\n+      \"fulfillment_allow_unpaid\": false,\n       \"reserve_stock_duration_anonymous_user\": null,\n       \"reserve_stock_duration_authenticated_user\": null,\n       \"limit_quantity_per_checkout\": 50,\n       \"gift_card_expiry_type\": \"never_expire\",\n"
        }
      ]
    },
    {
      "id": "trace-dataloader-span",
      "sha": "8d0cb16c5c084ff8def4d4218a67e3986514a342",
      "parentSha": "9e1838c9eb0b35bf4024c178b06482347a266f6b",
      "spec": "Implement full-lifecycle tracing for GraphQL DataLoader batch loads and report the number of objects returned.\n\nRequired changes:\n\n1) Add a new telemetry attribute constant\n- File: saleor/core/telemetry/saleor_attributes.py\n- Add a constant named GRAPHQL_RESOLVER_ROW_COUNT with the exact value \"graphql.resolver.row_count\" in the GraphQL section alongside existing GraphQL attributes. Do not remove existing constants.\n\n2) Extend DataLoader batch span to cover async resolution and report row count\n- File: saleor/graphql/core/dataloaders.py\n- In DataLoader.batch_load_fn:\n  - Start a span for the batch load that does not auto-end when exiting the context so its lifetime can include async resolution.\n  - Preserve setting OPERATION_NAME to \"dataloader.batch_load\".\n  - Execute the batch load within allow_writer_in_context(self.context).\n  - If the batch result is a list (synchronous result): set the GRAPHQL_RESOLVER_ROW_COUNT attribute to the number of returned items, end the span explicitly, and return a resolved Promise with the list.\n  - If the batch result is a Promise: attach fulfillment and rejection handlers. On fulfillment, set GRAPHQL_RESOLVER_ROW_COUNT to the number of returned items and end the span before returning the list. On rejection, end the span and re-raise the error to propagate failure. Ensure the function returns the Promise with these handlers attached.\n\nNotes and constraints:\n- Do not change DataLoader public API, generics, or the use of allow_writer_in_context.\n- Avoid altering other telemetry attributes or GraphQL tracing behavior.\n- The new attribute should be reported for every dataloader batch load regardless of success (end the span on both success and error).\n",
      "prompt": "Instrument GraphQL dataloaders so that each batch load is traced for the full duration, including asynchronous resolution, and expose an attribute with the number of items returned. Add the missing telemetry attribute for this row count. Ensure the span ends on both success and failure and that existing tracing attributes and behavior remain unchanged.",
      "supplementalFiles": [
        "saleor/graphql/core/tracing.py",
        "saleor/graphql/views.py",
        "saleor/core/telemetry/utils.py",
        "saleor/asgi/telemetry.py",
        "saleor/core/tracing.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/core/telemetry/saleor_attributes.py",
          "status": "modified",
          "diff": "Index: saleor/core/telemetry/saleor_attributes.py\n===================================================================\n--- saleor/core/telemetry/saleor_attributes.py\t9e1838c (parent)\n+++ saleor/core/telemetry/saleor_attributes.py\t8d0cb16 (commit)\n@@ -7,12 +7,13 @@\n OPERATION_NAME: Final = \"operation.name\"\n \n # GraphQL\n GRAPHQL_DOCUMENT_FINGERPRINT: Final = \"graphql.document_fingerprint\"\n-GRAPHQL_OPERATION_IDENTIFIER: Final = \"graphql.operation.identifier\"\n+GRAPHQL_FIELD_NAME: Final = \"graphql.field_name\"\n GRAPHQL_OPERATION_COST: Final = \"graphql.operation.cost\"\n+GRAPHQL_OPERATION_IDENTIFIER: Final = \"graphql.operation.identifier\"\n GRAPHQL_PARENT_TYPE: Final = \"graphql.parent_type\"\n-GRAPHQL_FIELD_NAME: Final = \"graphql.field_name\"\n+GRAPHQL_RESOLVER_ROW_COUNT: Final = \"graphql.resolver.row_count\"\n \n # Http\n SALEOR_SOURCE_SERVICE_NAME: Final = \"saleor.source.service.name\"\n \n"
        },
        {
          "path": "saleor/graphql/core/dataloaders.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/core/dataloaders.py\n===================================================================\n--- saleor/graphql/core/dataloaders.py\t9e1838c (parent)\n+++ saleor/graphql/core/dataloaders.py\t8d0cb16 (commit)\n@@ -41,20 +41,38 @@\n \n     def batch_load_fn(  # pylint: disable=method-hidden\n         self, keys: Iterable[K]\n     ) -> Promise[list[R]]:\n-        with tracer.start_as_current_span(self.__class__.__name__) as span:\n+        with tracer.start_as_current_span(\n+            self.__class__.__name__, end_on_exit=False\n+        ) as span:\n             span.set_attribute(\n                 saleor_attributes.OPERATION_NAME, \"dataloader.batch_load\"\n             )\n \n             with allow_writer_in_context(self.context):\n                 results = self.batch_load(keys)\n \n             if not isinstance(results, Promise):\n+                span.set_attribute(\n+                    saleor_attributes.GRAPHQL_RESOLVER_ROW_COUNT, len(results)\n+                )\n+                span.end()\n                 return Promise.resolve(results)\n-            return results\n \n+            def did_fulfill(results: list[R]) -> list[R]:\n+                span.set_attribute(\n+                    saleor_attributes.GRAPHQL_RESOLVER_ROW_COUNT, len(results)\n+                )\n+                span.end()\n+                return results\n+\n+            def did_reject(error: Exception) -> list[R]:\n+                span.end()\n+                raise error\n+\n+            return results.then(did_fulfill, did_reject)\n+\n     def batch_load(self, keys: Iterable[K]) -> Promise[list[R]] | list[R]:\n         raise NotImplementedError()\n \n \n"
        }
      ]
    },
    {
      "id": "transaction-amount-handling",
      "sha": "9a72f1265e4fd6e93f3b3495df22a7a3400892ff",
      "parentSha": "0696ec30d60663cce98725c3f8c7ae4709c62a42",
      "spec": "Implement a cohesive change to the Transaction API around the amount field in request, subscription, and sync webhook flows:\n\n1) GraphQL mutation input adjustments\n- In saleor/graphql/payment/mutations/transaction/transaction_request_action.py, update the TransactionRequestAction input field:\n  - Make amount required=False and update its description to: \"Transaction request amount. If empty, maximal possible amount will be used.\"\n  - For CANCEL actions, when creating the request:\n    - Default action_value to transaction.authorized_value if not provided.\n    - Clamp action_value to min(action_value, transaction.authorized_value).\n    - Create the request event with this action_value (not 0), and pass this value to the cancel flow.\n\n2) Gateway and data model propagation\n- In saleor/payment/gateway.py:\n  - In request_cancelation_action, if cancel_value is None, default it to transaction.authorized_value before creating TransactionActionData.\n  - Update _create_transaction_data signature and usage to require action_value: Decimal (non-optional).\n- In saleor/payment/interface.py:\n  - Update TransactionActionData dataclass so action_value is a required Decimal (remove Optional/None default).\n\n3) Subscription payload schema and resolver changes\n- In saleor/graphql/webhook/subscription_types.py:\n  - Update TransactionAction.amount to be required (PositiveDecimal!) and adjust description to \"Transaction request amount.\".\n  - Update resolve_amount to always return the quantized action_value (remove logic returning None).\n- In saleor/graphql/schema.graphql:\n  - Reflect the above: make TransactionAction.amount a non-null PositiveDecimal!, and update the mutation field description to match step 1.\n\n4) Webhook response parsing and defaults for missing amounts\n- In saleor/payment/utils.py:\n  - Remove legacy parse_transaction_event_amount helper and related strict requirements for presence of amount in responses.\n  - Change parse_transaction_action_data signature to accept request_event_amount: Decimal and event_is_optional flag.\n  - Validate webhook responses using the appropriate Transaction*RequestedSchema; when response_model.amount is missing or null, default to request_event_amount in the constructed TransactionRequestEventResponse. If result is missing and event_is_optional is False, return a validation error. Preserve available actions parsing.\n  - Update internal helpers and call sites to pass the request_event.amount_value:\n    - _get_parsed_transaction_action_data to take request_event_amount and pass it through to parse_transaction_action_data.\n    - create_transaction_event_from_request_and_webhook_response and create_transaction_event_for_transaction_session to pass request_event.amount_value so that when responses omit amount, the system uses the original requested amount.\n\n5) Webhook response schemas and validation context\n- In saleor/webhook/response_schemas/transaction.py:\n  - Make TransactionSchema.amount accept None in inputs (DefaultIfNone[Decimal], default None) and quantize only when provided; return None if missing.\n  - Make TransactionSchema.result optional in inputs (DefaultIfNone[str], default None) and lower-case only when provided.\n  - Add a model_validator that uses Pydantic ValidationInfo context (is_event_optional) to enforce that:\n    - If result is None and the event is not optional, raise a validation error.\n    - psp_reference is required unless the result belongs to OPTIONAL_PSP_REFERENCE_EVENTS.\n  - For the specific schemas TransactionChargeRequestedSchema, TransactionCancelRequestedSchema, TransactionRefundRequestedSchema, make result default None to support the optional flow.\n\n6) Behavior expectations and tests (update or add tests accordingly)\n- For CANCEL requests on both order and checkout:\n  - The created TransactionEvent for CANCEL_REQUEST must have amount_value equal to the authorized_value (not 0), and TransactionActionData.action_value must be set to that Decimal (not None).\n  - Subscription payload for TRANSACTION_CANCELATION_REQUESTED must include a non-null action.amount equal to the authorized amount.\n- For parse_transaction_action_data:\n  - When response lacks an amount, use request_event_amount.\n  - When both request_event_amount and response amount exist, prefer the response amount.\n  - When result is missing and the event is required (non-optional), return a validation error.\n- For transaction session responses (initialize/process):\n  - When response amount is null/missing, use the request_event.amount_value for updating events and transaction state.\n- Update test files in edited test modules to reflect these semantics, including new parameter passing of request_event_amount and assertions about amount presence and values.\n\n7) Documentation update\n- In CHANGELOG.md, under Webhooks, document that:\n  - TRANSACTION_CANCELATION_REQUESTED now provides a decimal value in action.amount instead of null.\n  - TransactionAction.amount in subscription payloads for TransactionRefundRequested, TransactionChargeRequested, TransactionCancelationRequested is now non-null.\n  - amount in responses for sync webhooks TRANSACTION_CHARGE_REQUESTED, TRANSACTION_REFUND_REQUESTED, TRANSACTION_CANCELATION_REQUESTED, TRANSACTION_INITIALIZE_SESSION, TRANSACTION_PROCESS_SESSION is now optional and defaults to the request payload's action.amount when omitted.\n\nScope alignment\n- Ensure all code paths expecting TransactionActionData.action_value handle it as required (Decimal) and no longer assume None.\n- Ensure the GraphQL schema SDL and Python resolvers remain consistent with these requirements.\n- Do not alter behavior of unrelated payment flows.",
      "prompt": "Update the Transaction API so that webhook amounts are handled consistently across mutations, subscriptions, and synchronous webhook responses.\n\n- Make the GraphQL transaction request mutation treat the input amount as optional. If omitted on cancel, default to the authorized amount (capped at the maximum allowed), and propagate this value when creating the request event and invoking the cancel action. The amount used must be reflected in the event and payloads.\n- For subscription payloads emitted to apps, require that the action’s amount is always present and non-null, and return the precise decimal amount for all transaction action types.\n- For synchronous webhook responses from apps, allow the amount field to be omitted. When it is missing or null, default to the amount from the original request event. Continue to honor an explicit amount if the app provides one.\n- Validate synchronous webhook responses with tolerant schemas: make result and amount optional in inputs and enforce requirements contextually (e.g., result must be present when the event is not optional; pspReference must be present when required by the event type). Use the request event’s amount when constructing events from responses that omit the amount.\n- Ensure all data structures and gateway logic treat the transaction action amount as required (not nullable) when creating and sending requests, and update any logic or tests that depended on a nullable action amount.\n- Update documentation to clearly describe these behaviors.",
      "supplementalFiles": [
        "saleor/webhook/transport/synchronous/transport.py",
        "saleor/webhook/payloads.py",
        "saleor/payment/models.py",
        "saleor/plugins/manager.py",
        "saleor/plugins/webhook/plugin.py",
        "saleor/webhook/response_schemas/annotations.py",
        "saleor/webhook/response_schemas/validators.py"
      ],
      "fileDiffs": [
        {
          "path": "CHANGELOG.md",
          "status": "modified",
          "diff": "Index: CHANGELOG.md\n===================================================================\n--- CHANGELOG.md\t0696ec3 (parent)\n+++ CHANGELOG.md\t9a72f12 (commit)\n@@ -72,8 +72,9 @@\n - Introduce total field in OrderDiscount to replace the amount field, with OrderDiscount.amount now deprecated - #17510 by @korycins\n - Introduce `useLegacyLineVoucherPropagation` flag to control legacy propagation behavior for specific voucher types - #17587 - by @korycins\n - Add filterable subscriptions for checkout events (`checkoutCreated`, `checkoutUpdated`, `checkoutFullyPaid`, `checkoutMetadataUpdated`) - #17647 by @korycins\n \n+\n ### Webhooks\n \n - Fixed webhookTrigger payload type for events related to ProductVariant - #16956 by @delemeator\n - Truncate lengthy responses in `EventDeliveryAttempt` objects - #17044 by @wcislo-saleor\n@@ -81,8 +82,11 @@\n - New feature: sync webhooks circuit breaker - #16658 by @tomaszszymanski129\n - Fixed webhook `PRODUCT_VARIANT_METADATA_UPDATED` not being sent when `productVariantUpdate` mutation was called. Now, when `metadata` or `privateMetadata` is included in `ProductVariantUpdateInput`, both `PRODUCT_VARIANT_METADATA_UPDATED` and `PRODUCT_VARIANT_UPDATED` will be emitted (if subscribed) - #17406 by @lkostrowski\n - Update Draft Order shipping via `orderUpdateShipping` will emit `DRAFT_ORDER_UPDATED` webhook. Previously it was `ORDER_UPDATED` - #17480 by @lkostrowski\n - Update editable Order shipping via `orderUpdateShipping` will emit `ORDER_UPDATED` webhook when `shippingMethod` will be cleared (by passing `null` to graphQL input). - #17480 by @lkostrowski\n+- Webhook `TRANSACTION_CANCELATION_REQUESTED` now provides a decimal value in the action.amount field instead of null - #17690 by @korycins\n+- `TransactionAction.amount` field in subscription payload for webhooks: `TransactionRefundRequested`, `TransactionChargeRequested`, `TransactionCancelationRequested`, is now a non-null field - #17690 by @korycins\n+- Field `amount` in the response for synchronous webhooks: `TRANSACTION_CHARGE_REQUESTED`, `TRANSACTION_REFUND_REQUESTED`, `TRANSACTION_CANCELATION_REQUESTED`, `TRANSACTION_INITIALIZE_SESSION`, `TRANSACTION_PROCESS_SESSION` is now optional field. If omitted, the system will default to using the `action.amount` specified in the payload. - #17690 by @korycins\n \n ### Other changes\n - Fixed outdated documentation links - #17675 by @krzysztofwolski\n - Added support for numeric and lower-case boolean environment variables - #16313 by @NyanKiyoshi\n"
        },
        {
          "path": "saleor/graphql/payment/mutations/transaction/transaction_request_action.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/mutations/transaction/transaction_request_action.py\n===================================================================\n--- saleor/graphql/payment/mutations/transaction/transaction_request_action.py\t0696ec3 (parent)\n+++ saleor/graphql/payment/mutations/transaction/transaction_request_action.py\t9a72f12 (commit)\n@@ -55,11 +55,12 @@\n             description=\"Determines the action type.\",\n         )\n         amount = PositiveDecimal(\n             description=(\n-                \"Transaction request amount. If empty for refund or capture, maximal \"\n-                \"possible amount will be used.\"\n-            )\n+                \"Transaction request amount. If empty, maximal possible \"\n+                \"amount will be used.\"\n+            ),\n+            required=False,\n         )\n \n     class Meta:\n         description = \"Request an action for payment transaction.\"\n@@ -77,14 +78,16 @@\n         app: App | None,\n     ):\n         if action == TransactionAction.CANCEL:\n             transaction = action_kwargs[\"transaction\"]\n+            action_value = action_value or transaction.authorized_value\n+            action_value = min(action_value, transaction.authorized_value)\n             request_event = cls.create_transaction_event_requested(\n-                transaction, 0, action, user=user, app=app\n+                transaction, action_value, action, user=user, app=app\n             )\n             request_cancelation_action(\n                 **action_kwargs,\n-                cancel_value=None,\n+                cancel_value=action_value,\n                 request_event=request_event,\n                 action=action,\n             )\n         elif action == TransactionAction.CHARGE:\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_request_action.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_request_action.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_request_action.py\t0696ec3 (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_request_action.py\t9a72f12 (commit)\n@@ -552,9 +552,9 @@\n     mocked_payment_action_request.assert_called_once_with(\n         TransactionActionData(\n             transaction=transaction,\n             action_type=TransactionAction.CANCEL,\n-            action_value=None,\n+            action_value=transaction.authorized_value,\n             event=request_event,\n             transaction_app_owner=transaction_request_webhook.app,\n         ),\n         order_with_lines.channel.slug,\n@@ -566,9 +566,9 @@\n \n     assert TransactionEvent.objects.get(\n         transaction=transaction,\n         type=TransactionEventType.CANCEL_REQUEST,\n-        amount_value=0,\n+        amount_value=transaction.authorized_value,\n     )\n \n \n @patch(\"saleor.plugins.manager.PluginsManager.is_event_active_for_any_plugin\")\n@@ -586,16 +586,16 @@\n \n     transaction_request_webhook.events.create(\n         event_type=WebhookEventSyncType.TRANSACTION_CANCELATION_REQUESTED\n     )\n-\n+    expected_amount = Decimal(\"10\")\n     transaction = TransactionItem.objects.create(\n         name=\"Credit card\",\n         psp_reference=\"PSP ref\",\n         available_actions=[\"charge\", \"cancel\"],\n         currency=\"USD\",\n         checkout_id=checkout.pk,\n-        authorized_value=Decimal(\"10\"),\n+        authorized_value=expected_amount,\n         app_identifier=transaction_request_webhook.app.identifier,\n         app=transaction_request_webhook.app,\n     )\n     variables = {\n@@ -622,9 +622,9 @@\n     mocked_payment_action_request.assert_called_once_with(\n         TransactionActionData(\n             transaction=transaction,\n             action_type=TransactionAction.CANCEL,\n-            action_value=None,\n+            action_value=expected_amount,\n             event=request_event,\n             transaction_app_owner=transaction_request_webhook.app,\n         ),\n         checkout.channel.slug,\n@@ -632,9 +632,9 @@\n \n     assert TransactionEvent.objects.get(\n         transaction=transaction,\n         type=TransactionEventType.CANCEL_REQUEST,\n-        amount_value=0,\n+        amount_value=expected_amount,\n     )\n \n \n @pytest.mark.parametrize(\n"
        },
        {
          "path": "saleor/graphql/schema.graphql",
          "status": "modified",
          "diff": "Index: saleor/graphql/schema.graphql\n===================================================================\n--- saleor/graphql/schema.graphql\t0696ec3 (parent)\n+++ saleor/graphql/schema.graphql\t9a72f12 (commit)\n@@ -15383,9 +15383,9 @@\n     \"\"\"Determines the action type.\"\"\"\n     actionType: TransactionActionEnum!\n \n     \"\"\"\n-    Transaction request amount. If empty for refund or capture, maximal possible amount will be used.\n+    Transaction request amount. If empty, maximal possible amount will be used.\n     \"\"\"\n     amount: PositiveDecimal\n \n     \"\"\"The ID of the transaction. One of field id or token is required.\"\"\"\n@@ -33028,10 +33028,10 @@\n type TransactionAction @doc(category: \"Payments\") {\n   \"\"\"Determines the action type.\"\"\"\n   actionType: TransactionActionEnum!\n \n-  \"\"\"Transaction request amount. Null when action type is VOID.\"\"\"\n-  amount: PositiveDecimal\n+  \"\"\"Transaction request amount.\"\"\"\n+  amount: PositiveDecimal!\n \n   \"\"\"Currency code.\"\"\"\n   currency: String!\n }\n"
        },
        {
          "path": "saleor/graphql/webhook/subscription_types.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/webhook/subscription_types.py\n===================================================================\n--- saleor/graphql/webhook/subscription_types.py\t0696ec3 (parent)\n+++ saleor/graphql/webhook/subscription_types.py\t9a72f12 (commit)\n@@ -1766,9 +1766,10 @@\n         required=True,\n         description=\"Determines the action type.\",\n     )\n     amount = PositiveDecimal(\n-        description=\"Transaction request amount. Null when action type is VOID.\",\n+        description=\"Transaction request amount.\",\n+        required=True,\n     )\n     currency = graphene.String(\n         description=\"Currency code.\",\n         required=True,\n@@ -1778,11 +1779,9 @@\n         doc_category = DOC_CATEGORY_PAYMENTS\n \n     @staticmethod\n     def resolve_amount(root: TransactionActionData, _info: ResolveInfo):\n-        if root.action_value is not None:\n-            return quantize_price(root.action_value, root.transaction.currency)\n-        return None\n+        return quantize_price(root.action_value, root.transaction.currency)\n \n     @staticmethod\n     def resolve_currency(root: TransactionActionData, _info: ResolveInfo):\n         return root.transaction.currency\n"
        },
        {
          "path": "saleor/payment/gateway.py",
          "status": "modified",
          "diff": "Index: saleor/payment/gateway.py\n===================================================================\n--- saleor/payment/gateway.py\t0696ec3 (parent)\n+++ saleor/payment/gateway.py\t9a72f12 (commit)\n@@ -167,8 +167,11 @@\n     user: User | None,\n     app: App | None,\n     action: str,\n ):\n+    if cancel_value is None:\n+        cancel_value = transaction.authorized_value\n+\n     transaction_action_data = _create_transaction_data(\n         transaction=transaction,\n         action_type=action,\n         action_value=cancel_value,\n@@ -194,9 +197,9 @@\n \n def _create_transaction_data(\n     transaction: TransactionItem,\n     action_type: str,\n-    action_value: Decimal | None,\n+    action_value: Decimal,\n     request_event: TransactionEvent,\n     granted_refund: OrderGrantedRefund | None = None,\n ):\n     app_owner = None\n"
        },
        {
          "path": "saleor/payment/interface.py",
          "status": "modified",
          "diff": "Index: saleor/payment/interface.py\n===================================================================\n--- saleor/payment/interface.py\t0696ec3 (parent)\n+++ saleor/payment/interface.py\t9a72f12 (commit)\n@@ -113,9 +113,9 @@\n     action_type: str\n     transaction: TransactionItem\n     event: \"TransactionEvent\"\n     transaction_app_owner: Optional[\"App\"]\n-    action_value: Decimal | None = None\n+    action_value: Decimal\n     granted_refund: Optional[\"OrderGrantedRefund\"] = None\n \n \n @dataclass\n"
        },
        {
          "path": "saleor/payment/tests/test_gateway.py",
          "status": "modified",
          "diff": "Index: saleor/payment/tests/test_gateway.py\n===================================================================\n--- saleor/payment/tests/test_gateway.py\t0696ec3 (parent)\n+++ saleor/payment/tests/test_gateway.py\t9a72f12 (commit)\n@@ -1216,9 +1216,9 @@\n     mocked_transaction_request.assert_called_once_with(\n         TransactionActionData(\n             transaction=transaction,\n             action_type=TransactionAction.CANCEL,\n-            action_value=None,\n+            action_value=transaction.authorized_value,\n             event=requested_event,\n             transaction_app_owner=app,\n         ),\n         order.channel.slug,\n@@ -1258,9 +1258,11 @@\n         authorized_value=Decimal(\"10\"),\n         app=webhook_app,\n     )\n     requested_event = transaction.events.create(\n-        currency=transaction.currency, type=TransactionEventType.CANCEL_REQUEST\n+        currency=transaction.currency,\n+        type=TransactionEventType.CANCEL_REQUEST,\n+        amount_value=transaction.authorized_value,\n     )\n     mocked_is_active.side_effect = [False, True]\n \n     # when\n@@ -1280,9 +1282,9 @@\n     mocked_transaction_request.assert_called_once_with(\n         TransactionActionData(\n             transaction=transaction,\n             action_type=TransactionAction.CANCEL,\n-            action_value=None,\n+            action_value=transaction.authorized_value,\n             event=requested_event,\n             transaction_app_owner=webhook_app,\n         ),\n         order.channel.slug,\n@@ -1325,8 +1327,9 @@\n     )\n     requested_event = transaction.events.create(\n         currency=transaction.currency,\n         type=TransactionEventType.CANCEL_REQUEST,\n+        amount_value=transaction.authorized_value,\n     )\n     mocked_is_active.side_effect = [False, True]\n \n     # when\n@@ -1346,9 +1349,9 @@\n     mocked_transaction_request.assert_called_once_with(\n         TransactionActionData(\n             transaction=transaction,\n             action_type=TransactionAction.CANCEL,\n-            action_value=None,\n+            action_value=transaction.authorized_value,\n             event=requested_event,\n             transaction_app_owner=app,\n         ),\n         checkout.channel.slug,\n"
        },
        {
          "path": "saleor/payment/tests/test_utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/tests/test_utils.py\n===================================================================\n--- saleor/payment/tests/test_utils.py\t0696ec3 (parent)\n+++ saleor/payment/tests/test_utils.py\t9a72f12 (commit)\n@@ -241,9 +241,9 @@\n     response_data = {\"pspReference\": expected_psp_reference}\n \n     # when\n     parsed_data, _ = parse_transaction_action_data(\n-        response_data, TransactionEventType.AUTHORIZATION_REQUEST\n+        response_data, TransactionEventType.CHARGE_REQUEST, Decimal(10.00)\n     )\n \n     # then\n     assert isinstance(parsed_data, TransactionRequestResponse)\n@@ -293,8 +293,9 @@\n def test_parse_transaction_action_data_with_provided_time(\n     event_time, expected_datetime\n ):\n     # given\n+    request_event_amount = Decimal(10.00)\n     expected_psp_reference = \"psp:122:222\"\n     event_amount = 12.00\n     event_type = TransactionEventType.CHARGE_SUCCESS\n     event_url = \"http://localhost:3000/event/ref123\"\n@@ -310,16 +311,18 @@\n     }\n \n     # when\n     parsed_data, error_msg = parse_transaction_action_data(\n-        response_data, TransactionEventType.CHARGE_REQUEST\n+        response_data, TransactionEventType.CHARGE_REQUEST, request_event_amount\n     )\n     # then\n     assert parsed_data.event.time == expected_datetime\n \n \n def test_parse_transaction_action_data_with_event_all_fields_provided():\n     # given\n+    request_event_amount = Decimal(10.00)\n+\n     expected_psp_reference = \"psp:122:222\"\n     event_amount = 12.00\n     event_type = TransactionEventType.CHARGE_SUCCESS\n     event_time = \"2022-11-18T13:25:58.169685+00:00\"\n@@ -336,9 +339,9 @@\n     }\n \n     # when\n     parsed_data, error_msg = parse_transaction_action_data(\n-        response_data, TransactionEventType.CHARGE_REQUEST\n+        response_data, TransactionEventType.CHARGE_REQUEST, request_event_amount\n     )\n     # then\n     assert isinstance(parsed_data, TransactionRequestResponse)\n     assert error_msg is None\n@@ -354,8 +357,9 @@\n \n \n def test_parse_transaction_action_data_with_incorrect_result():\n     # given\n+    request_event_amount = Decimal(10.00)\n     expected_psp_reference = \"psp:122:222\"\n     event_amount = 12.00\n     event_type = TransactionEventType.CHARGE_SUCCESS\n     event_time = \"2022-11-18T13:25:58.169685+00:00\"\n@@ -372,9 +376,9 @@\n     }\n \n     # when\n     parsed_data, error_msg = parse_transaction_action_data(\n-        response_data, TransactionEventType.REFUND_REQUEST\n+        response_data, TransactionEventType.REFUND_REQUEST, request_event_amount\n     )\n \n     # then\n     assert parsed_data is None\n@@ -388,14 +392,13 @@\n     expected_amount = Decimal(\"10.00\")\n     response_data = {\n         \"pspReference\": expected_psp_reference,\n         \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n-        \"amount\": expected_amount,\n     }\n \n     # when\n     parsed_data, _ = parse_transaction_action_data(\n-        response_data, TransactionEventType.CHARGE_REQUEST\n+        response_data, TransactionEventType.CHARGE_REQUEST, expected_amount\n     )\n \n     # then\n     assert isinstance(parsed_data, TransactionRequestResponse)\n@@ -409,30 +412,73 @@\n     assert parsed_data.event.external_url == \"\"\n     assert parsed_data.event.message == \"\"\n \n \n+def test_parse_transaction_action_data_use_provided_amount_when_event_amount_is_missing():\n+    # given\n+    request_event_amount = Decimal(10.00)\n+    response_data = {\n+        \"pspReference\": \"123\",\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+    }\n+\n+    # when\n+    parsed_data, _ = parse_transaction_action_data(\n+        response_data, TransactionEventType.CHARGE_REQUEST, request_event_amount\n+    )\n+\n+    # then\n+    assert isinstance(parsed_data, TransactionRequestResponse)\n+    assert parsed_data.event.amount == request_event_amount\n+\n+\n+def test_parse_transaction_action_data_skips_input_amount_when_event_has_amount():\n+    # given\n+    request_event_amount = Decimal(10.00)\n+    expected_amount = Decimal(12.00)\n+\n+    assert request_event_amount != expected_amount\n+    response_data = {\n+        \"pspReference\": \"123\",\n+        \"result\": TransactionEventType.CHARGE_SUCCESS.upper(),\n+        \"amount\": expected_amount,\n+    }\n+\n+    # when\n+    parsed_data, _ = parse_transaction_action_data(\n+        response_data, TransactionEventType.CHARGE_REQUEST, request_event_amount\n+    )\n+\n+    # then\n+    assert isinstance(parsed_data, TransactionRequestResponse)\n+    assert parsed_data.event.amount == expected_amount\n+\n+\n @freeze_time(\"2018-05-31 12:00:01\")\n def test_parse_transaction_action_data_with_missing_psp_reference():\n     # given\n     response_data = {}\n \n     # when\n     parsed_data, _ = parse_transaction_action_data(\n-        response_data, TransactionEventType.AUTHORIZATION_REQUEST\n+        response_data, TransactionEventType.AUTHORIZATION_REQUEST, Decimal(10.00)\n     )\n \n     # then\n     assert parsed_data is None\n \n \n def test_parse_transaction_action_data_with_missing_optional_psp_reference():\n     # given\n-    response_data = {}\n+    response_data = {\n+        \"result\": TransactionEventType.CHARGE_FAILURE.upper(),\n+    }\n \n     # when\n     parsed_data, _ = parse_transaction_action_data(\n         response_data,\n-        TransactionEventType.AUTHORIZATION_ACTION_REQUIRED,\n+        TransactionEventType.CHARGE_REQUEST,\n+        Decimal(\"10.00\"),\n     )\n \n     # then\n     assert parsed_data\n@@ -441,13 +487,18 @@\n def test_parse_transaction_action_data_with_missing_mandatory_event_fields():\n     # given\n     expected_psp_reference = \"psp:122:222\"\n \n-    response_data = {\"pspReference\": expected_psp_reference, \"amount\": Decimal(\"1\")}\n+    response_data = {\n+        \"pspReference\": expected_psp_reference,\n+    }\n \n     # when\n     parsed_data, _ = parse_transaction_action_data(\n-        response_data, TransactionEventType.AUTHORIZATION_REQUEST\n+        response_data,\n+        TransactionEventType.CHARGE_REQUEST,\n+        Decimal(\"10.00\"),\n+        event_is_optional=False,\n     )\n \n     # then\n     assert parsed_data is None\n@@ -612,8 +663,78 @@\n     assert caplog.records[0].levelno == logging.WARNING\n     assert error_msg in caplog.records[0].message\n \n \n+@pytest.mark.parametrize(\n+    (\"event_type\", \"result_event_type\"),\n+    [\n+        (\n+            TransactionEventType.REFUND_REQUEST,\n+            TransactionEventType.REFUND_SUCCESS,\n+        ),\n+        (\n+            TransactionEventType.CHARGE_REQUEST,\n+            TransactionEventType.CHARGE_SUCCESS,\n+        ),\n+        (\n+            TransactionEventType.CANCEL_REQUEST,\n+            TransactionEventType.CANCEL_SUCCESS,\n+        ),\n+        (\n+            TransactionEventType.REFUND_REQUEST,\n+            TransactionEventType.REFUND_FAILURE,\n+        ),\n+        (\n+            TransactionEventType.CHARGE_REQUEST,\n+            TransactionEventType.CHARGE_FAILURE,\n+        ),\n+        (\n+            TransactionEventType.CANCEL_REQUEST,\n+            TransactionEventType.CANCEL_FAILURE,\n+        ),\n+    ],\n+)\n+def test_create_transaction_event_from_request_and_webhook_response_with_no_amount_in_response(\n+    event_type,\n+    result_event_type,\n+    transaction_item_generator,\n+    app,\n+):\n+    # given\n+    expected_amount = Decimal(11.00)\n+    expected_psp_reference = \"psp:122:222\"\n+\n+    transaction = transaction_item_generator()\n+    request_event = TransactionEvent.objects.create(\n+        type=event_type,\n+        amount_value=expected_amount,\n+        currency=\"USD\",\n+        transaction_id=transaction.id,\n+    )\n+    event_count = transaction.events.count()\n+    response_data = {\n+        \"pspReference\": expected_psp_reference,\n+        \"result\": result_event_type.upper(),\n+    }\n+\n+    # when\n+    event = create_transaction_event_from_request_and_webhook_response(\n+        request_event, app, response_data\n+    )\n+\n+    # then\n+    request_event.refresh_from_db()\n+    transaction.refresh_from_db()\n+    assert request_event.psp_reference == expected_psp_reference\n+    assert request_event.include_in_calculations is True\n+    assert transaction.events.count() == event_count + 1\n+    assert event.psp_reference == expected_psp_reference\n+    assert event.transaction_id == transaction.id\n+    assert event.amount_value == expected_amount\n+    assert event.type == result_event_type\n+    assert not event.message\n+\n+\n @freeze_time(\"2018-05-31 12:00:01\")\n def test_create_transaction_event_from_request_and_webhook_response_part_event(\n     transaction_item_generator,\n     app,\n@@ -1360,9 +1481,9 @@\n \n \n @pytest.mark.parametrize(\n     \"event_amount\",\n-    [None, \"NaN\", \"-Inf\", \"Inf\", \"One\"],\n+    [\"NaN\", \"-Inf\", \"Inf\", \"One\"],\n )\n @freeze_time(\"2018-05-31 12:00:01\")\n def test_create_transaction_event_from_request_handle_incorrect_values(\n     transaction_item_generator,\n@@ -2142,8 +2263,54 @@\n         (TransactionEventType.CHARGE_REQUEST, \"charge_pending_value\"),\n         (TransactionEventType.CHARGE_SUCCESS, \"charged_value\"),\n     ],\n )\n+def test_create_transaction_event_for_transaction_session_success_response_with_no_amount(\n+    response_result,\n+    transaction_amount_field_name,\n+    transaction_item_generator,\n+    transaction_session_response,\n+    webhook_app,\n+    plugins_manager,\n+):\n+    # given\n+    request_event_amount = Decimal(\"12\")\n+    response = transaction_session_response.copy()\n+    response[\"result\"] = response_result.upper()\n+\n+    response[\"amount\"] = None\n+\n+    transaction = transaction_item_generator()\n+    request_event = TransactionEvent.objects.create(\n+        transaction=transaction,\n+        include_in_calculations=False,\n+        amount_value=request_event_amount,\n+        type=TransactionEventType.CHARGE_REQUEST,\n+    )\n+    # when\n+    response_event = create_transaction_event_for_transaction_session(\n+        request_event,\n+        webhook_app,\n+        manager=plugins_manager,\n+        transaction_webhook_response=response,\n+    )\n+\n+    # then\n+    assert response_event.include_in_calculations\n+    assert response_event.amount_value == request_event_amount\n+    transaction.refresh_from_db()\n+    assert getattr(transaction, transaction_amount_field_name) == request_event_amount\n+\n+\n+@pytest.mark.parametrize(\n+    (\"response_result\", \"transaction_amount_field_name\"),\n+    [\n+        (TransactionEventType.AUTHORIZATION_REQUEST, \"authorize_pending_value\"),\n+        (TransactionEventType.AUTHORIZATION_SUCCESS, \"authorized_value\"),\n+        (TransactionEventType.CHARGE_REQUEST, \"charge_pending_value\"),\n+        (TransactionEventType.CHARGE_SUCCESS, \"charged_value\"),\n+    ],\n+)\n def test_create_transaction_event_for_transaction_session_success_response_with_0(\n     response_result,\n     transaction_amount_field_name,\n     transaction_item_generator,\n@@ -2223,8 +2390,57 @@\n     assert transaction.charge_pending_value == Decimal(\"0\")\n \n \n @pytest.mark.parametrize(\n+    \"response_result\",\n+    [\n+        TransactionEventType.AUTHORIZATION_ACTION_REQUIRED,\n+        TransactionEventType.CHARGE_ACTION_REQUIRED,\n+        TransactionEventType.AUTHORIZATION_FAILURE,\n+        TransactionEventType.CHARGE_FAILURE,\n+        TransactionEventType.REFUND_FAILURE,\n+        TransactionEventType.REFUND_SUCCESS,\n+    ],\n+)\n+def test_create_transaction_event_for_transaction_session_not_success_events_with_no_amount(\n+    response_result,\n+    transaction_item_generator,\n+    transaction_session_response,\n+    webhook_app,\n+    plugins_manager,\n+):\n+    # given\n+    expected_amount = Decimal(\"15\")\n+    response = transaction_session_response.copy()\n+    response[\"result\"] = response_result.upper()\n+    response[\"amount\"] = None\n+\n+    transaction = transaction_item_generator()\n+    request_event = TransactionEvent.objects.create(\n+        transaction=transaction,\n+        include_in_calculations=False,\n+        amount_value=expected_amount,\n+        type=TransactionEventType.CHARGE_REQUEST,\n+    )\n+    # when\n+    response_event = create_transaction_event_for_transaction_session(\n+        request_event,\n+        webhook_app,\n+        manager=plugins_manager,\n+        transaction_webhook_response=response,\n+    )\n+\n+    # then\n+    assert response_event.amount_value == expected_amount\n+    assert response_event.type in [response_result, TransactionEventType.CHARGE_FAILURE]\n+    transaction.refresh_from_db()\n+    assert transaction.authorized_value == Decimal(\"0\")\n+    assert transaction.charged_value == Decimal(\"0\")\n+    assert transaction.authorize_pending_value == Decimal(\"0\")\n+    assert transaction.charge_pending_value == Decimal(\"0\")\n+\n+\n+@pytest.mark.parametrize(\n     (\"response_result\", \"message\"),\n     [\n         (\n             TransactionEventType.AUTHORIZATION_SUCCESS,\n"
        },
        {
          "path": "saleor/payment/utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/utils.py\n===================================================================\n--- saleor/payment/utils.py\t0696ec3 (parent)\n+++ saleor/payment/utils.py\t9a72f12 (commit)\n@@ -1,5 +1,4 @@\n-import decimal\n import json\n import logging\n from decimal import Decimal\n from typing import Any, Optional, cast, overload\n@@ -40,12 +39,12 @@\n from ..webhook.response_schemas.transaction import (\n     TransactionCancelRequestedSchema,\n     TransactionChargeRequestedSchema,\n     TransactionRefundRequestedSchema,\n+    TransactionSchema,\n     TransactionSessionSchema,\n )\n from . import (\n-    OPTIONAL_PSP_REFERENCE_EVENTS,\n     ChargeStatus,\n     GatewayError,\n     PaymentError,\n     StorePaymentMethod,\n@@ -820,73 +819,25 @@\n     }\n     return type_map.get(request_type, [])\n \n \n-def parse_transaction_event_amount(\n-    amount_data: str | int | float | None,\n-    parsed_event_data: dict,\n-    error_field_msg: list[str],\n-    invalid_msg: str,\n-    missing_msg: str,\n-):\n-    if amount_data is not None:\n-        amount_valid = True\n-        try:\n-            amount = decimal.Decimal(amount_data).quantize(\n-                decimal.Decimal(10) ** (-settings.DEFAULT_DECIMAL_PLACES)\n-            )\n-            parsed_event_data[\"amount\"] = amount\n-            if not amount.is_finite():\n-                amount_valid = False\n-        except decimal.DecimalException:\n-            amount_valid = False\n-\n-        if not amount_valid:\n-            logger.warning(invalid_msg, \"amount\", amount_data)\n-            error_field_msg.append(invalid_msg % (\"amount\", amount_data))\n-    else:\n-        logger.warning(missing_msg, \"amount\")\n-        error_field_msg.append(missing_msg % \"amount\")\n-\n-\n error_msg = str\n \n \n def parse_transaction_action_data(\n     response_data: Any,\n     request_type: str,\n+    request_event_amount: Decimal,\n     event_is_optional: bool = True,\n ) -> tuple[Optional[\"TransactionRequestResponse\"], error_msg | None]:\n     \"\"\"Parse response from transaction action webhook.\n \n     It takes the recieved response from sync webhook and\n     returns TransactionRequestResponse with all details.\n     If unable to parse, None will be returned.\n     \"\"\"\n-    skip_data_parsing = (\n-        event_is_optional\n-        and response_data.get(\"amount\") is None\n-        and not response_data.get(\"result\")\n-    )\n-    if skip_data_parsing:\n-        psp_reference = response_data.get(\"pspReference\")\n-        if not psp_reference and request_type not in OPTIONAL_PSP_REFERENCE_EVENTS:\n-            msg = f\"Providing `pspReference` is required for {request_type.upper()}.\"\n-            logger.warning(msg)\n-            return None, msg\n-        return (\n-            TransactionRequestResponse(\n-                psp_reference=psp_reference,\n-                available_actions=parse_available_actions(\n-                    response_data.get(\"actions\", None)\n-                ),\n-                event=None,\n-            ),\n-            None,\n-        )\n \n-    response_data_model = None\n-    request_type_to_schema_map = {\n+    request_type_to_schema_map: dict[str, type[TransactionSchema]] = {\n         TransactionEventType.CHARGE_REQUEST: TransactionChargeRequestedSchema,\n         TransactionEventType.REFUND_REQUEST: TransactionRefundRequestedSchema,\n         TransactionEventType.CANCEL_REQUEST: TransactionCancelRequestedSchema,\n         SESSION_REQUEST_EVENT_TYPE: TransactionSessionSchema,\n@@ -900,35 +851,34 @@\n             extra={\"request_type\": request_type},\n         )\n         return None, \"Request type not supported\"\n \n+    error_msg_response = None\n     try:\n-        response_data_model = (\n-            request_schema.model_validate(response_data)  # type: ignore[attr-defined]\n+        response_data_model = request_schema.model_validate(\n+            response_data, context={\"is_event_optional\": event_is_optional}\n         )\n-    except ValidationError as error:\n-        error_msg = str(error)\n-        logger.warning(error_msg)\n-        msg = truncate_transaction_event_message(error_msg)\n-        return None, msg\n-\n-    return (\n-        TransactionRequestResponse(\n+        event = TransactionRequestEventResponse(\n             psp_reference=response_data_model.psp_reference,\n-            available_actions=response_data_model.actions,\n-            event=(\n-                TransactionRequestEventResponse(\n-                    psp_reference=response_data_model.psp_reference,\n-                    type=response_data_model.result,\n-                    amount=response_data_model.amount,\n-                    time=response_data_model.time,\n-                    external_url=str(response_data_model.external_url),\n-                    message=response_data_model.message,\n-                )\n+            type=response_data_model.result,\n+            amount=response_data_model.amount or request_event_amount,\n+            time=response_data_model.time,\n+            external_url=str(response_data_model.external_url),\n+            message=response_data_model.message,\n+        )\n+        return (\n+            TransactionRequestResponse(\n+                psp_reference=response_data_model.psp_reference,\n+                available_actions=response_data_model.actions,\n+                event=event if response_data_model.result else None,\n             ),\n-        ),\n-        None,\n-    )\n+            None,\n+        )\n+    except ValidationError as error:\n+        error_msg_response = str(error)\n+        logger.warning(error_msg_response)\n+        error_msg_response = truncate_transaction_event_message(error_msg_response)\n+        return None, error_msg_response\n \n \n def parse_available_actions(available_actions):\n     if available_actions is not None:\n@@ -1120,16 +1070,18 @@\n \n def _get_parsed_transaction_action_data(\n     transaction_webhook_response: dict[str, Any] | None,\n     event_type: str,\n+    request_event_amount: Decimal,\n     event_is_optional: bool = True,\n ) -> tuple[Optional[\"TransactionRequestResponse\"], error_msg | None]:\n     if transaction_webhook_response is None:\n         return None, \"Failed to delivery request.\"\n \n     transaction_request_response, error_msg = parse_transaction_action_data(\n         transaction_webhook_response,\n         event_type,\n+        request_event_amount=request_event_amount,\n         event_is_optional=event_is_optional,\n     )\n     if not transaction_request_response:\n         return None, error_msg or \"\"\n@@ -1161,8 +1113,9 @@\n ):\n     transaction_request_response, error_msg = _get_parsed_transaction_action_data(\n         transaction_webhook_response=transaction_webhook_response,\n         event_type=SESSION_REQUEST_EVENT_TYPE,\n+        request_event_amount=request_event.amount_value,\n         event_is_optional=False,\n     )\n     if not transaction_request_response or not transaction_request_response.event:\n         return create_failed_transaction_event(request_event, cause=error_msg or \"\")\n@@ -1289,8 +1242,9 @@\n ):\n     transaction_request_response, error_msg = _get_parsed_transaction_action_data(\n         transaction_webhook_response=transaction_webhook_response,\n         event_type=request_event.type,\n+        request_event_amount=request_event.amount_value,\n     )\n     transaction_item = request_event.transaction\n     if not transaction_request_response:\n         recalculate_refundable_for_checkout(transaction_item, request_event)\n"
        },
        {
          "path": "saleor/webhook/response_schemas/transaction.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/response_schemas/transaction.py\n===================================================================\n--- saleor/webhook/response_schemas/transaction.py\t0696ec3 (parent)\n+++ saleor/webhook/response_schemas/transaction.py\t9a72f12 (commit)\n@@ -10,8 +10,9 @@\n     BaseModel,\n     Field,\n     HttpUrl,\n     JsonValue,\n+    ValidationInfo,\n     field_validator,\n     model_validator,\n )\n \n@@ -44,9 +45,13 @@\n             ),\n         ),\n     ]\n     amount: Annotated[\n-        Decimal, Field(description=\"Decimal amount of the processed action\")\n+        DefaultIfNone[Decimal],\n+        Field(\n+            description=\"Decimal amount of the processed action\",\n+            default=None,\n+        ),\n     ]\n     time: Annotated[\n         DefaultIfNone[DatetimeUTC],\n         Field(\n@@ -84,22 +89,35 @@\n         ]\n         | None\n     ) = None\n     result: Annotated[\n-        str,\n+        DefaultIfNone[str],\n         Field(description=\"Result of the action\"),\n     ]\n \n     @model_validator(mode=\"after\")\n-    def clean_psp_reference(self):\n-        if not self.psp_reference and self.result not in OPTIONAL_PSP_REFERENCE_EVENTS:\n+    def clean_event(self, info: ValidationInfo):\n+        is_event_optional = (\n+            info.context.get(\"is_event_optional\", False) if info.context else False\n+        )\n+\n+        if self.result is None:\n+            if not is_event_optional:\n+                raise ValueError(\"Providing `result` is required.\")\n+            if not self.psp_reference:\n+                raise ValueError(\"Providing `pspReference` is required.\")\n+        elif (\n+            not self.psp_reference and self.result not in OPTIONAL_PSP_REFERENCE_EVENTS\n+        ):\n             error_msg = f\"Providing `pspReference` is required for {self.result.upper()} action result.\"\n             raise ValueError(error_msg)\n         return self\n \n     @field_validator(\"amount\", mode=\"after\")\n     @classmethod\n-    def clean_amount(cls, amount: Decimal) -> Decimal:\n+    def clean_amount(cls, amount: Decimal | None) -> Decimal | None:\n+        if amount is None:\n+            return None\n         amount = amount.quantize(Decimal(10) ** (-settings.DEFAULT_DECIMAL_PLACES))\n         return amount\n \n     @field_validator(\"time\", mode=\"before\")\n@@ -149,9 +167,11 @@\n         return [action.lower() for action in actions] if actions else actions\n \n     @field_validator(\"result\", mode=\"after\")\n     @classmethod\n-    def clean_result(cls, result: str) -> str:\n+    def clean_result(cls, result: str | None) -> str | None:\n+        if result is None:\n+            return None\n         return result.lower()\n \n \n TransactionEventTypeEnum = Enum(  # type: ignore[misc]\n@@ -165,9 +185,9 @@\n         Literal[\n             TransactionEventTypeEnum.CHARGE_SUCCESS.name,\n             TransactionEventTypeEnum.CHARGE_FAILURE.name,\n         ],\n-        Field(description=\"Result of the action\"),\n+        Field(description=\"Result of the action\", default=None),\n     ]\n \n \n class TransactionCancelRequestedSchema(TransactionSchema):\n@@ -175,9 +195,9 @@\n         Literal[\n             TransactionEventTypeEnum.CANCEL_SUCCESS.name,\n             TransactionEventTypeEnum.CANCEL_FAILURE.name,\n         ],\n-        Field(description=\"Result of the action\"),\n+        Field(description=\"Result of the action\", default=None),\n     ]\n \n \n class TransactionRefundRequestedSchema(TransactionSchema):\n@@ -185,9 +205,9 @@\n         Literal[\n             TransactionEventTypeEnum.REFUND_SUCCESS.name,\n             TransactionEventTypeEnum.REFUND_FAILURE.name,\n         ],\n-        Field(description=\"Result of the action\"),\n+        Field(description=\"Result of the action\", default=None),\n     ]\n \n \n class TransactionSessionSchema(TransactionSchema):\n"
        },
        {
          "path": "saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_transaction_cancelation_requested.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_transaction_cancelation_requested.py\n===================================================================\n--- saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_transaction_cancelation_requested.py\t0696ec3 (parent)\n+++ saleor/webhook/tests/subscription_webhooks/test_create_deliveries_for_transaction_cancelation_requested.py\t9a72f12 (commit)\n@@ -71,8 +71,9 @@\n         transaction=transaction,\n         action_type=TransactionAction.CANCEL,\n         event=request_event,\n         transaction_app_owner=None,\n+        action_value=authorized_value,\n     )\n     # when\n     deliveries = create_deliveries_for_subscriptions(\n         event_type, transaction_data, [webhook]\n@@ -99,9 +100,13 @@\n                 \"id\": graphene.Node.to_global_id(\"Order\", order.id),\n             },\n             \"checkout\": None,\n         },\n-        \"action\": {\"actionType\": \"CANCEL\", \"amount\": None, \"currency\": order.currency},\n+        \"action\": {\n+            \"actionType\": \"CANCEL\",\n+            \"amount\": quantize_price(authorized_value, \"USD\"),\n+            \"currency\": order.currency,\n+        },\n     }\n \n \n @freeze_time(\"2020-03-18 12:00:00\")\n@@ -142,8 +147,9 @@\n         transaction=transaction,\n         action_type=TransactionAction.CANCEL,\n         event=request_event,\n         transaction_app_owner=None,\n+        action_value=authorized_value,\n     )\n     # when\n     deliveries = create_deliveries_for_subscriptions(\n         event_type, transaction_data, [webhook]\n@@ -181,6 +187,10 @@\n                     }\n                 },\n             },\n         },\n-        \"action\": {\"actionType\": \"CANCEL\", \"amount\": None, \"currency\": \"USD\"},\n+        \"action\": {\n+            \"actionType\": \"CANCEL\",\n+            \"amount\": quantize_price(authorized_value, \"USD\"),\n+            \"currency\": \"USD\",\n+        },\n     }\n"
        },
        {
          "path": "saleor/webhook/tests/test_tasks.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/test_tasks.py\n===================================================================\n--- saleor/webhook/tests/test_tasks.py\t0696ec3 (parent)\n+++ saleor/webhook/tests/test_tasks.py\t9a72f12 (commit)\n@@ -641,14 +641,17 @@\n     mocked_webhook_response,\n     app,\n ):\n     # given\n-    expected_psp_reference = \"psp:123:111\"\n     mocked_webhook_response.text = json.dumps(\n-        {\"pspReference\": expected_psp_reference, \"amount\": 12.00}\n+        {\n+            \"result\": TransactionEventType.REFUND_REQUEST.upper(),\n+        }\n     )\n     mocked_webhook_response.content = json.dumps(\n-        {\"pspReference\": expected_psp_reference, \"amount\": 12.00}\n+        {\n+            \"result\": TransactionEventType.REFUND_REQUEST.upper(),\n+        }\n     )\n     mocked_post_request.return_value = mocked_webhook_response\n \n     target_url = \"http://localhost:3000/\"\n"
        }
      ]
    },
    {
      "id": "type-shipping-webhooks",
      "sha": "4163d8e330aad10ebf6009a6698ea9dc06d8de74",
      "parentSha": "81e51c794766e77e97e2e4cefce8a5a93e207eac",
      "spec": "Implement Pydantic-validated response handling for shipping sync webhooks and refactor shared helpers.\n\nScope and required changes:\n\n1) Dependencies and typing configuration\n- Add Pydantic v2 as a runtime dependency and pydantic-core in pyproject.toml under main dependencies. Configure mypy to use pydantic.mypy and add a [tool.pydantic-mypy] section with init_forbid_extra=true, init_typed=true, warn_required_dynamic_aliases=true.\n\n2) New reusable metadata validator\n- In saleor/core/utils/metadata_manager.py add a new function metadata_is_valid(metadata: Any) -> bool with the following behavior:\n  - Return False if metadata is not a dict.\n  - Ensure all keys and values are strings and keys are non-empty when stripped; otherwise return False.\n  - Return True when valid. If metadata is an empty dict or contains empty string values, it is still considered valid.\n- Add unit tests in saleor/core/utils/tests/test_metadata_manager.py covering true and false cases as shown in the diff.\n\n3) Introduce Pydantic response schemas for shipping\n- Create package saleor/webhook/response_schemas/ with:\n  - __init__.py (empty).\n  - annotations.py providing two Annotated helpers:\n    - Metadata: dict[str, str] using a BeforeValidator that skips invalid metadata by raising PydanticUseDefault() when metadata_is_valid returns False, otherwise returns the value.\n    - DefaultIfNone[T]: Annotated wrapper that raises PydanticUseDefault() when the input is None.\n  - shipping.py defining:\n    - logger = logging.getLogger(__name__).\n    - ShippingMethodSchema (Pydantic BaseModel):\n      - id: str (coerce_numbers_to_str=True)\n      - name: str (max_length is pulled from ShippingMethod._meta.get_field(\"name\").max_length)\n      - amount: Decimal (ge=0)\n      - currency: str\n      - maximum_delivery_days: int | None (ge=0)\n      - minimum_delivery_days: int | None (ge=0)\n      - description: str | None\n      - metadata: DefaultIfNone[Metadata] defaulting to {}\n      - A property price that returns prices.Money(amount, currency).\n    - ListShippingMethodsSchema (RootModel): root: DefaultIfNone[list[OnErrorSkipShippingMethod[ShippingMethodSchema]]] defaulting to []. Invalid list entries should be skipped using WrapValidator with PydanticOmit; each skip must log a warning via logger.warning(\"Skipping invalid shipping method: %s\", err).\n    - ExcludedShippingMethodSchema (BaseModel):\n      - id: str\n      - reason: DefaultIfNone[str] defaulting to \"\"\n      - A field_validator(\"id\", mode=\"after\") that:\n        - Decodes global IDs via from_global_id_or_error.\n        - Logs a warning and raises ValueError when decoding fails or when the decoded type is neither APP_ID_PREFIX nor \"ShippingMethod\".\n        - Returns only the decoded method id (not the global id) for valid inputs.\n    - FilterShippingMethodsSchema (BaseModel):\n      - excluded_methods: DefaultIfNone[list[OnErrorSkipShippingMethod[ExcludedShippingMethodSchema]]] defaulting to [].\n\n4) Refactor helper functions into dedicated module\n- Create new module saleor/webhook/transport/shipping_helpers.py and move the following functions from saleor/webhook/transport/shipping.py:\n  - to_shipping_app_id(app: App, shipping_method_id: str) -> str that base64-encodes strings in the format f\"{APP_ID_PREFIX}:{app.identifier or app.id}:{shipping_method_id}\".\n  - convert_to_app_id_with_identifier(shipping_app_id: str) -> str | None that translates legacy app:<app-pk>:<method_id> IDs into app:<app-identifier>:<method_id> IDs, returning None when parsing fails or the app is missing.\n\n5) Update shipping transport to use Pydantic schemas\n- In saleor/webhook/transport/shipping.py:\n  - Replace manual validation and data parsing in parse_list_shipping_methods_response with Pydantic:\n    - Try to validate using ListShippingMethodsSchema.model_validate(response_data). On ValidationError, log a warning: \"Skipping invalid shipping method response: %s\" with the raw response and return an empty list.\n    - For each validated shipping method, build a ShippingMethodData with fields:\n      - id: to_shipping_app_id(app, str(shipping_method.id))\n      - name, price (using the schema.price property), maximum_delivery_days, minimum_delivery_days, description, metadata from the schema.\n  - Update get_excluded_shipping_methods_from_response to accept an additional parameter webhook: Webhook and to use FilterShippingMethodsSchema.model_validate(response_data). On ValidationError, log a warning: \"Skipping invalid response from app %s: %s\" using webhook.app.identifier and the raw response, then return an empty list. Return the list of ExcludedShippingMethodSchema from the model.\n  - Update get_excluded_shipping_methods_or_fetch to accumulate a typed list[list of ExcludedShippingMethodSchema] and pass the webhook object into get_excluded_shipping_methods_from_response.\n  - Update parse_excluded_shipping_methods to accept list[ExcludedShippingMethodSchema] and produce dict[str, list[ExcludedShippingMethod]] by mapping schema.id and schema.reason (default empty string) to the ExcludedShippingMethod dataclass.\n  - Import and use to_shipping_app_id from saleor/webhook/transport/shipping_helpers.\n  - Import Webhook model and Pydantic ValidationError as needed; remove unused imports left over from the manual validation flow since these are now encapsulated in schemas.\n\n6) Update imports at call sites\n- In saleor/checkout/fetch.py change the top-level import to: from ..webhook.transport.shipping_helpers import convert_to_app_id_with_identifier. Remove any function-local import of convert_to_app_id_with_identifier from the old shipping module. Ensure all use sites in this file rely on the module-level import.\n- In tests and other references, switch imports of to_shipping_app_id from saleor/webhook/transport/shipping to saleor/webhook/transport/shipping_helpers.\n\n7) Update tests to reflect new behavior\n- saleor/plugins/webhook/tests/test_shipping_webhook.py:\n  - Import to_shipping_app_id from saleor/webhook/transport/shipping_helpers.\n  - Update get_excluded_shipping_methods_from_response usage to pass the webhook object.\n  - Where excluded methods were dicts, update assertions to use object attributes (e.g., excluded_methods[0].id) and adjust reason handling to default to empty string.\n  - Mock the response_schemas.shipping.logger.warning and assert call counts according to the number of invalid list entries and invalid fields.\n  - Ensure tests expecting invalid list formats for list-shipping-methods log once per invalid element and return an empty result.\n- saleor/graphql/checkout/tests/benchmark/test_homepage.py: update import of to_shipping_app_id to saleor/webhook/transport/shipping_helpers.\n- Add new tests:\n  - saleor/webhook/tests/response_schemas/test_shipping.py to comprehensively validate ShippingMethodSchema, ListShippingMethodsSchema, ExcludedShippingMethodSchema, and FilterShippingMethodsSchema behaviors including coercions, skipping invalid entries, and logging warnings.\n  - saleor/webhook/transport/tests/test_shipping_helpers.py to validate convert_to_app_id_with_identifier across valid, missing/invalid parts, and missing app cases.\n\nBehavioral expectations after changes:\n- External shipping methods parsing uses Pydantic to validate and coerce fields; invalid entries are skipped and log warnings; id is coerced to str; metadata defaults to {} if absent or invalid.\n- Excluded shipping methods parsing validates global IDs, returns stripped method ids, and logs a warning when invalid.\n- Legacy shipping app IDs are translated to identifier-based form when possible.\n- mypy uses Pydantic plugin settings for stricter typing.",
      "prompt": "Add robust, typed validation for shipping-related webhook responses and refactor shared helpers. Replace manual dict-based parsing for external shipping methods and excluded shipping methods with schema-based validation, ensuring invalid entries are skipped with warnings and valid entries are coerced to the correct types. Extract helper functions that build and normalize shipping app IDs into a dedicated module and update all imports accordingly. Introduce a reusable metadata validator to ensure only string-to-string maps with non-empty keys are accepted, defaulting to empty metadata when invalid or None. Update unit tests to reflect the new object-based structures and logging behavior, and configure mypy to work with Pydantic models.",
      "supplementalFiles": [
        "saleor/shipping/interface.py",
        "saleor/plugins/base_plugin.py",
        "saleor/webhook/const.py"
      ],
      "fileDiffs": [
        {
          "path": "poetry.lock",
          "status": "modified",
          "diff": "Index: poetry.lock\n===================================================================\n--- poetry.lock\t81e51c7 (parent)\n+++ poetry.lock\t4163d8e (commit)\n@@ -41,8 +41,21 @@\n     {file = \"aniso8601-7.0.0.tar.gz\", hash = \"sha256:513d2b6637b7853806ae79ffaca6f3e8754bdd547048f5ccc1420aec4b714f1e\"},\n ]\n \n [[package]]\n+name = \"annotated-types\"\n+version = \"0.7.0\"\n+description = \"Reusable constraint types to use with typing.Annotated\"\n+optional = false\n+python-versions = \">=3.8\"\n+groups = [\"main\"]\n+markers = \"platform_python_implementation == \\\"PyPy\\\"\"\n+files = [\n+    {file = \"annotated_types-0.7.0-py3-none-any.whl\", hash = \"sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53\"},\n+    {file = \"annotated_types-0.7.0.tar.gz\", hash = \"sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89\"},\n+]\n+\n+[[package]]\n name = \"anyio\"\n version = \"4.8.0\"\n description = \"High level compatibility layer for multiple asynchronous event loop implementations\"\n optional = false\n@@ -3917,8 +3930,144 @@\n     {file = \"pycurl-7.45.4.tar.gz\", hash = \"sha256:32c8e237069273f4260b6ae13d1e0f99daae938977016021565dc6e11050e803\"},\n ]\n \n [[package]]\n+name = \"pydantic\"\n+version = \"2.11.1\"\n+description = \"Data validation using Python type hints\"\n+optional = false\n+python-versions = \">=3.9\"\n+groups = [\"main\"]\n+markers = \"platform_python_implementation == \\\"PyPy\\\"\"\n+files = [\n+    {file = \"pydantic-2.11.1-py3-none-any.whl\", hash = \"sha256:5b6c415eee9f8123a14d859be0c84363fec6b1feb6b688d6435801230b56e0b8\"},\n+    {file = \"pydantic-2.11.1.tar.gz\", hash = \"sha256:442557d2910e75c991c39f4b4ab18963d57b9b55122c8b2a9cd176d8c29ce968\"},\n+]\n+\n+[package.dependencies]\n+annotated-types = \">=0.6.0\"\n+pydantic-core = \"2.33.0\"\n+typing-extensions = \">=4.12.2\"\n+typing-inspection = \">=0.4.0\"\n+\n+[package.extras]\n+email = [\"email-validator (>=2.0.0)\"]\n+timezone = [\"tzdata ; python_version >= \\\"3.9\\\" and platform_system == \\\"Windows\\\"\"]\n+\n+[[package]]\n+name = \"pydantic-core\"\n+version = \"2.33.0\"\n+description = \"Core functionality for Pydantic validation and serialization\"\n+optional = false\n+python-versions = \">=3.9\"\n+groups = [\"main\"]\n+markers = \"platform_python_implementation == \\\"PyPy\\\"\"\n+files = [\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-macosx_10_12_x86_64.whl\", hash = \"sha256:71dffba8fe9ddff628c68f3abd845e91b028361d43c5f8e7b3f8b91d7d85413e\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-macosx_11_0_arm64.whl\", hash = \"sha256:abaeec1be6ed535a5d7ffc2e6c390083c425832b20efd621562fbb5bff6dc518\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:759871f00e26ad3709efc773ac37b4d571de065f9dfb1778012908bcc36b3a73\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:dcfebee69cd5e1c0b76a17e17e347c84b00acebb8dd8edb22d4a03e88e82a207\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:1b1262b912435a501fa04cd213720609e2cefa723a07c92017d18693e69bf00b\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:4726f1f3f42d6a25678c67da3f0b10f148f5655813c5aca54b0d1742ba821b8f\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:e790954b5093dff1e3a9a2523fddc4e79722d6f07993b4cd5547825c3cbf97b5\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:34e7fb3abe375b5c4e64fab75733d605dda0f59827752debc99c17cb2d5f3276\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-musllinux_1_1_aarch64.whl\", hash = \"sha256:ecb158fb9b9091b515213bed3061eb7deb1d3b4e02327c27a0ea714ff46b0760\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-musllinux_1_1_armv7l.whl\", hash = \"sha256:4d9149e7528af8bbd76cc055967e6e04617dcb2a2afdaa3dea899406c5521faa\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-musllinux_1_1_x86_64.whl\", hash = \"sha256:e81a295adccf73477220e15ff79235ca9dcbcee4be459eb9d4ce9a2763b8386c\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-win32.whl\", hash = \"sha256:f22dab23cdbce2005f26a8f0c71698457861f97fc6318c75814a50c75e87d025\"},\n+    {file = \"pydantic_core-2.33.0-cp310-cp310-win_amd64.whl\", hash = \"sha256:9cb2390355ba084c1ad49485d18449b4242da344dea3e0fe10babd1f0db7dcfc\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-macosx_10_12_x86_64.whl\", hash = \"sha256:a608a75846804271cf9c83e40bbb4dab2ac614d33c6fd5b0c6187f53f5c593ef\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-macosx_11_0_arm64.whl\", hash = \"sha256:e1c69aa459f5609dec2fa0652d495353accf3eda5bdb18782bc5a2ae45c9273a\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:b9ec80eb5a5f45a2211793f1c4aeddff0c3761d1c70d684965c1807e923a588b\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:e925819a98318d17251776bd3d6aa9f3ff77b965762155bdad15d1a9265c4cfd\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:5bf68bb859799e9cec3d9dd8323c40c00a254aabb56fe08f907e437005932f2b\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:1b2ea72dea0825949a045fa4071f6d5b3d7620d2a208335207793cf29c5a182d\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:1583539533160186ac546b49f5cde9ffc928062c96920f58bd95de32ffd7bffd\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:23c3e77bf8a7317612e5c26a3b084c7edeb9552d645742a54a5867635b4f2453\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-musllinux_1_1_aarch64.whl\", hash = \"sha256:a7a7f2a3f628d2f7ef11cb6188bcf0b9e1558151d511b974dfea10a49afe192b\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-musllinux_1_1_armv7l.whl\", hash = \"sha256:f1fb026c575e16f673c61c7b86144517705865173f3d0907040ac30c4f9f5915\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-musllinux_1_1_x86_64.whl\", hash = \"sha256:635702b2fed997e0ac256b2cfbdb4dd0bf7c56b5d8fba8ef03489c03b3eb40e2\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-win32.whl\", hash = \"sha256:07b4ced28fccae3f00626eaa0c4001aa9ec140a29501770a88dbbb0966019a86\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-win_amd64.whl\", hash = \"sha256:4927564be53239a87770a5f86bdc272b8d1fbb87ab7783ad70255b4ab01aa25b\"},\n+    {file = \"pydantic_core-2.33.0-cp311-cp311-win_arm64.whl\", hash = \"sha256:69297418ad644d521ea3e1aa2e14a2a422726167e9ad22b89e8f1130d68e1e9a\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-macosx_10_12_x86_64.whl\", hash = \"sha256:6c32a40712e3662bebe524abe8abb757f2fa2000028d64cc5a1006016c06af43\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-macosx_11_0_arm64.whl\", hash = \"sha256:8ec86b5baa36f0a0bfb37db86c7d52652f8e8aa076ab745ef7725784183c3fdd\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:4deac83a8cc1d09e40683be0bc6d1fa4cde8df0a9bf0cda5693f9b0569ac01b6\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:175ab598fb457a9aee63206a1993874badf3ed9a456e0654273e56f00747bbd6\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:5f36afd0d56a6c42cf4e8465b6441cf546ed69d3a4ec92724cc9c8c61bd6ecf4\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:0a98257451164666afafc7cbf5fb00d613e33f7e7ebb322fbcd99345695a9a61\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:ecc6d02d69b54a2eb83ebcc6f29df04957f734bcf309d346b4f83354d8376862\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:1a69b7596c6603afd049ce7f3835bcf57dd3892fc7279f0ddf987bebed8caa5a\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-musllinux_1_1_aarch64.whl\", hash = \"sha256:ea30239c148b6ef41364c6f51d103c2988965b643d62e10b233b5efdca8c0099\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-musllinux_1_1_armv7l.whl\", hash = \"sha256:abfa44cf2f7f7d7a199be6c6ec141c9024063205545aa09304349781b9a125e6\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-musllinux_1_1_x86_64.whl\", hash = \"sha256:20d4275f3c4659d92048c70797e5fdc396c6e4446caf517ba5cad2db60cd39d3\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-win32.whl\", hash = \"sha256:918f2013d7eadea1d88d1a35fd4a1e16aaf90343eb446f91cb091ce7f9b431a2\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-win_amd64.whl\", hash = \"sha256:aec79acc183865bad120b0190afac467c20b15289050648b876b07777e67ea48\"},\n+    {file = \"pydantic_core-2.33.0-cp312-cp312-win_arm64.whl\", hash = \"sha256:5461934e895968655225dfa8b3be79e7e927e95d4bd6c2d40edd2fa7052e71b6\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-macosx_10_12_x86_64.whl\", hash = \"sha256:f00e8b59e1fc8f09d05594aa7d2b726f1b277ca6155fc84c0396db1b373c4555\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-macosx_11_0_arm64.whl\", hash = \"sha256:1a73be93ecef45786d7d95b0c5e9b294faf35629d03d5b145b09b81258c7cd6d\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:ff48a55be9da6930254565ff5238d71d5e9cd8c5487a191cb85df3bdb8c77365\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:26a4ea04195638dcd8c53dadb545d70badba51735b1594810e9768c2c0b4a5da\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:41d698dcbe12b60661f0632b543dbb119e6ba088103b364ff65e951610cb7ce0\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:ae62032ef513fe6281ef0009e30838a01057b832dc265da32c10469622613885\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:f225f3a3995dbbc26affc191d0443c6c4aa71b83358fd4c2b7d63e2f6f0336f9\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:5bdd36b362f419c78d09630cbaebc64913f66f62bda6d42d5fbb08da8cc4f181\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-musllinux_1_1_aarch64.whl\", hash = \"sha256:2a0147c0bef783fd9abc9f016d66edb6cac466dc54a17ec5f5ada08ff65caf5d\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-musllinux_1_1_armv7l.whl\", hash = \"sha256:c860773a0f205926172c6644c394e02c25421dc9a456deff16f64c0e299487d3\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-musllinux_1_1_x86_64.whl\", hash = \"sha256:138d31e3f90087f42aa6286fb640f3c7a8eb7bdae829418265e7e7474bd2574b\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-win32.whl\", hash = \"sha256:d20cbb9d3e95114325780f3cfe990f3ecae24de7a2d75f978783878cce2ad585\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-win_amd64.whl\", hash = \"sha256:ca1103d70306489e3d006b0f79db8ca5dd3c977f6f13b2c59ff745249431a606\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313-win_arm64.whl\", hash = \"sha256:6291797cad239285275558e0a27872da735b05c75d5237bbade8736f80e4c225\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313t-macosx_11_0_arm64.whl\", hash = \"sha256:7b79af799630af263eca9ec87db519426d8c9b3be35016eddad1832bac812d87\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:eabf946a4739b5237f4f56d77fa6668263bc466d06a8036c055587c130a46f7b\"},\n+    {file = \"pydantic_core-2.33.0-cp313-cp313t-win_amd64.whl\", hash = \"sha256:8a1d581e8cdbb857b0e0e81df98603376c1a5c34dc5e54039dcc00f043df81e7\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-macosx_10_12_x86_64.whl\", hash = \"sha256:7c9c84749f5787781c1c45bb99f433402e484e515b40675a5d121ea14711cf61\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-macosx_11_0_arm64.whl\", hash = \"sha256:64672fa888595a959cfeff957a654e947e65bbe1d7d82f550417cbd6898a1d6b\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:26bc7367c0961dec292244ef2549afa396e72e28cc24706210bd44d947582c59\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl\", hash = \"sha256:ce72d46eb201ca43994303025bd54d8a35a3fc2a3495fac653d6eb7205ce04f4\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl\", hash = \"sha256:14229c1504287533dbf6b1fc56f752ce2b4e9694022ae7509631ce346158de11\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl\", hash = \"sha256:085d8985b1c1e48ef271e98a658f562f29d89bda98bf120502283efbc87313eb\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:31860fbda80d8f6828e84b4a4d129fd9c4535996b8249cfb8c720dc2a1a00bb8\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:f200b2f20856b5a6c3a35f0d4e344019f805e363416e609e9b47c552d35fd5ea\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-musllinux_1_1_aarch64.whl\", hash = \"sha256:5f72914cfd1d0176e58ddc05c7a47674ef4222c8253bf70322923e73e14a4ac3\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-musllinux_1_1_armv7l.whl\", hash = \"sha256:91301a0980a1d4530d4ba7e6a739ca1a6b31341252cb709948e0aca0860ce0ae\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-musllinux_1_1_x86_64.whl\", hash = \"sha256:7419241e17c7fbe5074ba79143d5523270e04f86f1b3a0dff8df490f84c8273a\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-win32.whl\", hash = \"sha256:7a25493320203005d2a4dac76d1b7d953cb49bce6d459d9ae38e30dd9f29bc9c\"},\n+    {file = \"pydantic_core-2.33.0-cp39-cp39-win_amd64.whl\", hash = \"sha256:82a4eba92b7ca8af1b7d5ef5f3d9647eee94d1f74d21ca7c21e3a2b92e008358\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-macosx_10_12_x86_64.whl\", hash = \"sha256:e2762c568596332fdab56b07060c8ab8362c56cf2a339ee54e491cd503612c50\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-macosx_11_0_arm64.whl\", hash = \"sha256:5bf637300ff35d4f59c006fff201c510b2b5e745b07125458a5389af3c0dff8c\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:62c151ce3d59ed56ebd7ce9ce5986a409a85db697d25fc232f8e81f195aa39a1\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:9ee65f0cc652261744fd07f2c6e6901c914aa6c5ff4dcfaf1136bc394d0dd26b\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:024d136ae44d233e6322027bbf356712b3940bee816e6c948ce4b90f18471b3d\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-musllinux_1_1_aarch64.whl\", hash = \"sha256:e37f10f6d4bc67c58fbd727108ae1d8b92b397355e68519f1e4a7babb1473442\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-musllinux_1_1_armv7l.whl\", hash = \"sha256:502ed542e0d958bd12e7c3e9a015bce57deaf50eaa8c2e1c439b512cb9db1e3a\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-musllinux_1_1_x86_64.whl\", hash = \"sha256:715c62af74c236bf386825c0fdfa08d092ab0f191eb5b4580d11c3189af9d330\"},\n+    {file = \"pydantic_core-2.33.0-pp310-pypy310_pp73-win_amd64.whl\", hash = \"sha256:bccc06fa0372151f37f6b69834181aa9eb57cf8665ed36405fb45fbf6cac3bae\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-macosx_10_12_x86_64.whl\", hash = \"sha256:5d8dc9f63a26f7259b57f46a7aab5af86b2ad6fbe48487500bb1f4b27e051e4c\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-macosx_11_0_arm64.whl\", hash = \"sha256:30369e54d6d0113d2aa5aee7a90d17f225c13d87902ace8fcd7bbf99b19124db\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:f3eb479354c62067afa62f53bb387827bee2f75c9c79ef25eef6ab84d4b1ae3b\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:0310524c833d91403c960b8a3cf9f46c282eadd6afd276c8c5edc617bd705dc9\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:eddb18a00bbb855325db27b4c2a89a4ba491cd6a0bd6d852b225172a1f54b36c\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-musllinux_1_1_aarch64.whl\", hash = \"sha256:ade5dbcf8d9ef8f4b28e682d0b29f3008df9842bb5ac48ac2c17bc55771cc976\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-musllinux_1_1_armv7l.whl\", hash = \"sha256:2c0afd34f928383e3fd25740f2050dbac9d077e7ba5adbaa2227f4d4f3c8da5c\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-musllinux_1_1_x86_64.whl\", hash = \"sha256:7da333f21cd9df51d5731513a6d39319892947604924ddf2e24a4612975fb936\"},\n+    {file = \"pydantic_core-2.33.0-pp311-pypy311_pp73-win_amd64.whl\", hash = \"sha256:4b6d77c75a57f041c5ee915ff0b0bb58eabb78728b69ed967bc5b780e8f701b8\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-macosx_10_12_x86_64.whl\", hash = \"sha256:ba95691cf25f63df53c1d342413b41bd7762d9acb425df8858d7efa616c0870e\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-macosx_11_0_arm64.whl\", hash = \"sha256:4f1ab031feb8676f6bd7c85abec86e2935850bf19b84432c64e3e239bffeb1ec\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl\", hash = \"sha256:58c1151827eef98b83d49b6ca6065575876a02d2211f259fb1a6b7757bd24dd8\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\", hash = \"sha256:a66d931ea2c1464b738ace44b7334ab32a2fd50be023d863935eb00f42be1778\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.whl\", hash = \"sha256:0bcf0bab28995d483f6c8d7db25e0d05c3efa5cebfd7f56474359e7137f39856\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-musllinux_1_1_aarch64.whl\", hash = \"sha256:89670d7a0045acb52be0566df5bc8b114ac967c662c06cf5e0c606e4aadc964b\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-musllinux_1_1_armv7l.whl\", hash = \"sha256:b716294e721d8060908dbebe32639b01bfe61b15f9f57bcc18ca9a0e00d9520b\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-musllinux_1_1_x86_64.whl\", hash = \"sha256:fc53e05c16697ff0c1c7c2b98e45e131d4bfb78068fffff92a82d169cbb4c7b7\"},\n+    {file = \"pydantic_core-2.33.0-pp39-pypy39_pp73-win_amd64.whl\", hash = \"sha256:68504959253303d3ae9406b634997a2123a0b0c1da86459abbd0ffc921695eac\"},\n+    {file = \"pydantic_core-2.33.0.tar.gz\", hash = \"sha256:40eb8af662ba409c3cbf4a8150ad32ae73514cd7cb1f1a2113af39763dd616b3\"},\n+]\n+\n+[package.dependencies]\n+typing-extensions = \">=4.6.0,<4.7.0 || >4.7.0\"\n+\n+[[package]]\n name = \"pygments\"\n version = \"2.19.1\"\n description = \"Pygments is a syntax highlighting package written in Python.\"\n optional = false\n@@ -5472,8 +5621,24 @@\n     {file = \"typing_extensions-4.12.2.tar.gz\", hash = \"sha256:1a7ead55c7e559dd4dee8856e3a88b41225abfe1ce8df57b7c13915fe121ffb8\"},\n ]\n \n [[package]]\n+name = \"typing-inspection\"\n+version = \"0.4.0\"\n+description = \"Runtime typing introspection tools\"\n+optional = false\n+python-versions = \">=3.9\"\n+groups = [\"main\"]\n+markers = \"platform_python_implementation == \\\"PyPy\\\"\"\n+files = [\n+    {file = \"typing_inspection-0.4.0-py3-none-any.whl\", hash = \"sha256:50e72559fcd2a6367a19f7a7e610e6afcb9fac940c650290eed893d61386832f\"},\n+    {file = \"typing_inspection-0.4.0.tar.gz\", hash = \"sha256:9765c87de36671694a67904bf2c96e395be9c6439bb6c87b5142569dcdd65122\"},\n+]\n+\n+[package.dependencies]\n+typing-extensions = \">=4.12.0\"\n+\n+[[package]]\n name = \"tzdata\"\n version = \"2024.2\"\n description = \"Provider of IANA time zone data\"\n optional = false\n@@ -6050,5 +6215,5 @@\n \n [metadata]\n lock-version = \"2.1\"\n python-versions = \"~3.12\"\n-content-hash = \"ed08f72eba1fa28a9002de21546df3bc8b19cc877019bfdb85263caa568cae28\"\n+content-hash = \"eb0d014135f96bc0dcdbfd7c02b90056cc11be2543b004673dd8f1aed334a3d1\"\n"
        },
        {
          "path": "pyproject.toml",
          "status": "modified",
          "diff": "Index: pyproject.toml\n===================================================================\n--- pyproject.toml\t81e51c7 (parent)\n+++ pyproject.toml\t4163d8e (commit)\n@@ -123,8 +123,10 @@\n   urllib3 = \"^1.26.19\"\n   uvicorn = {extras = [\"standard\"], version = \"^0.32.0\"}\n   setuptools = \"^76.0.0\"\n   psycopg = {version = \"^3.1.8\", extras = [\"binary\"]}\n+  pydantic = \"^2.10.6\"\n+  pydantic-core = \"^2.33.0\"\n \n     [tool.poetry.dependencies.celery]\n     version = \">=4.4.5,<6.0.0\"\n     extras = [ \"redis\", \"sqs\" ]\n@@ -205,9 +207,10 @@\n warn_redundant_casts = true\n warn_unused_ignores = true\n \n plugins = [\n-  \"mypy_django_plugin.main\"\n+  \"mypy_django_plugin.main\",\n+  \"pydantic.mypy\"\n ]\n \n exclude = [\n   \"tests/\"\n@@ -216,8 +219,12 @@\n   [[tool.mypy.overrides]]\n   module = [\"saleor.*.migrations.*\"]\n   ignore_errors = true\n \n+[tool.pydantic-mypy]\n+init_forbid_extra = true\n+init_typed = true\n+warn_required_dynamic_aliases = true\n \n [tool.ruff]\n target-version = \"py312\"\n \n"
        },
        {
          "path": "saleor/checkout/fetch.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/fetch.py\n===================================================================\n--- saleor/checkout/fetch.py\t81e51c7 (parent)\n+++ saleor/checkout/fetch.py\t4163d8e (commit)\n@@ -26,8 +26,9 @@\n     initialize_shipping_method_active_status,\n )\n from ..warehouse import WarehouseClickAndCollectOption\n from ..warehouse.models import Warehouse\n+from ..webhook.transport.shipping_helpers import convert_to_app_id_with_identifier\n \n if TYPE_CHECKING:\n     from ..account.models import Address, User\n     from ..channel.models import Channel\n@@ -218,9 +219,8 @@\n             with allow_writer():\n                 checkout.save(update_fields=fields_to_update)\n \n     def get_delivery_method_info(self) -> \"DeliveryMethodBase\":\n-        from ..webhook.transport.shipping import convert_to_app_id_with_identifier\n         from .utils import get_external_shipping_id\n \n         delivery_method: ShippingMethodData | Warehouse | None = None\n \n"
        },
        {
          "path": "saleor/core/utils/metadata_manager.py",
          "status": "modified",
          "diff": "Index: saleor/core/utils/metadata_manager.py\n===================================================================\n--- saleor/core/utils/metadata_manager.py\t81e51c7 (parent)\n+++ saleor/core/utils/metadata_manager.py\t4163d8e (commit)\n@@ -1,6 +1,7 @@\n from dataclasses import dataclass\n from enum import Enum\n+from typing import Any\n \n from ...graphql.meta.inputs import MetadataInput\n from ..models import ModelWithMetadata\n \n@@ -72,4 +73,13 @@\n \n     return MetadataItemCollection(\n         [MetadataItem(item.key, item.value) for item in items]\n     )\n+\n+\n+def metadata_is_valid(metadata: Any) -> bool:\n+    if not isinstance(metadata, dict):\n+        return False\n+    for key, value in metadata.items():\n+        if not isinstance(key, str) or not isinstance(value, str) or not key.strip():\n+            return False\n+    return True\n"
        },
        {
          "path": "saleor/core/utils/tests/test_metadata_manager.py",
          "status": "added",
          "diff": "Index: saleor/core/utils/tests/test_metadata_manager.py\n===================================================================\n--- saleor/core/utils/tests/test_metadata_manager.py\t81e51c7 (parent)\n+++ saleor/core/utils/tests/test_metadata_manager.py\t4163d8e (commit)\n@@ -0,0 +1,38 @@\n+import pytest\n+\n+from ..metadata_manager import metadata_is_valid\n+\n+\n+@pytest.mark.parametrize(\n+    \"metadata\",\n+    [\n+        {\"key1\": \"value1\", \"key2\": \"value2\"},\n+        {},\n+        {\"key1\": \"\"},\n+    ],\n+)\n+def test_metadata_is_valid_true(metadata):\n+    # when\n+    is_metadata_valid = metadata_is_valid(metadata)\n+\n+    # then\n+    assert is_metadata_valid is True\n+\n+\n+@pytest.mark.parametrize(\n+    \"metadata\",\n+    [\n+        None,\n+        \"not_a_dict\",\n+        {\"key1\": 123},\n+        {123: \"value1\"},\n+        {\"\": \"value1\"},\n+        {\"   \": \"value1\"},\n+    ],\n+)\n+def test_metadata_is_valid_false(metadata):\n+    # when\n+    is_metadata_valid = metadata_is_valid(metadata)\n+\n+    # then\n+    assert is_metadata_valid is False\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/benchmark/test_homepage.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/benchmark/test_homepage.py\n===================================================================\n--- saleor/graphql/checkout/tests/benchmark/test_homepage.py\t81e51c7 (parent)\n+++ saleor/graphql/checkout/tests/benchmark/test_homepage.py\t4163d8e (commit)\n@@ -6,9 +6,9 @@\n from prices import Money\n \n from .....checkout.utils import assign_external_shipping_to_checkout\n from .....shipping.interface import ShippingMethodData\n-from .....webhook.transport.shipping import to_shipping_app_id\n+from .....webhook.transport.shipping_helpers import to_shipping_app_id\n from ....tests.utils import get_graphql_content\n \n \n @pytest.mark.django_db\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/test_shipping_webhook.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/tests/test_shipping_webhook.py\n===================================================================\n--- saleor/plugins/webhook/tests/test_shipping_webhook.py\t81e51c7 (parent)\n+++ saleor/plugins/webhook/tests/test_shipping_webhook.py\t4163d8e (commit)\n@@ -16,14 +16,15 @@\n from ....webhook.payloads import (\n     generate_excluded_shipping_methods_for_checkout_payload,\n     generate_excluded_shipping_methods_for_order_payload,\n )\n+from ....webhook.response_schemas.shipping import logger as schema_logger\n from ....webhook.transport.shipping import (\n     get_excluded_shipping_methods_from_response,\n     get_excluded_shipping_methods_or_fetch,\n     parse_list_shipping_methods_response,\n-    to_shipping_app_id,\n )\n+from ....webhook.transport.shipping_helpers import to_shipping_app_id\n from ....webhook.transport.synchronous.transport import trigger_webhook_sync\n from ....webhook.transport.utils import generate_cache_key_for_webhook\n from ...base_plugin import ExcludedShippingMethod\n \n@@ -393,9 +394,10 @@\n         ]\n     )\n \n \n-def test_parse_excluded_shipping_methods_response(app):\n+@mock.patch.object(schema_logger, \"warning\")\n+def test_parse_excluded_shipping_methods_response(mocked_schema_logger, app):\n     # given\n     external_id = to_shipping_app_id(app, \"test-1234\")\n     response = {\n         \"excluded_methods\": [\n@@ -415,16 +417,23 @@\n                 \"id\": external_id,\n             },\n         ]\n     }\n+    webhook = Webhook.objects.create(\n+        name=\"shipping-webhook-1\",\n+        app=app,\n+        target_url=\"https://shipping-gateway.com/apiv2/\",\n+    )\n \n     # when\n-    excluded_methods = get_excluded_shipping_methods_from_response(response)\n+    excluded_methods = get_excluded_shipping_methods_from_response(response, webhook)\n \n     # then\n     assert len(excluded_methods) == 2\n-    assert excluded_methods[0][\"id\"] == \"2\"\n-    assert excluded_methods[1][\"id\"] == external_id\n+    assert excluded_methods[0].id == \"2\"\n+    assert excluded_methods[1].id == external_id\n+    # 2 warning for each invalid data\n+    assert mocked_schema_logger.call_count == 6\n \n \n @mock.patch(\n     \"saleor.plugins.webhook.plugin.WebhookPlugin.excluded_shipping_methods_for_order\"\n@@ -1242,17 +1251,22 @@\n     mocked_get_excluded.asssert_not_called()\n     mocked_parse.assert_called_once_with([])\n \n \n-def test_parse_list_shipping_methods_response_response_incorrect_format(app):\n+@mock.patch.object(schema_logger, \"warning\")\n+def test_parse_list_shipping_methods_response_response_incorrect_format(\n+    mocked_logger, app\n+):\n     # given\n     response_data_with_incorrect_format = [[1], 2, \"3\"]\n     # when\n     result = parse_list_shipping_methods_response(\n         response_data_with_incorrect_format, app\n     )\n     # then\n     assert result == []\n+    # Ensure the warning about invalit method data wa logged\n+    assert mocked_logger.call_count == len(response_data_with_incorrect_format)\n \n \n def test_parse_list_shipping_methods_with_metadata(app):\n     # given\n@@ -1309,17 +1323,18 @@\n         }\n     ]\n     # when\n     response = parse_list_shipping_methods_response(response_data_with_meta, app)\n+\n     # then\n     assert response[0].metadata == {}\n \n \n def test_parse_list_shipping_methods_metadata_is_none(app):\n     # given\n     response_data_with_meta = [\n         {\n-            \"id\": 123,\n+            \"id\": \"123\",\n             \"amount\": 10,\n             \"currency\": \"USD\",\n             \"name\": \"shipping\",\n             \"description\": \"Description\",\n"
        },
        {
          "path": "saleor/webhook/response_schemas/__init__.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/__init__.py\n===================================================================\n--- saleor/webhook/response_schemas/__init__.py\t81e51c7 (parent)\n+++ saleor/webhook/response_schemas/__init__.py\t4163d8e (commit)\n"
        },
        {
          "path": "saleor/webhook/response_schemas/annotations.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/annotations.py\n===================================================================\n--- saleor/webhook/response_schemas/annotations.py\t81e51c7 (parent)\n+++ saleor/webhook/response_schemas/annotations.py\t4163d8e (commit)\n@@ -0,0 +1,27 @@\n+from typing import Annotated, Any, TypeVar\n+\n+from pydantic import (\n+    BeforeValidator,\n+)\n+from pydantic_core import PydanticUseDefault\n+\n+from ...core.utils.metadata_manager import metadata_is_valid\n+\n+\n+def skip_invalid_metadata(value: Any) -> Any:\n+    if not metadata_is_valid(value):\n+        raise PydanticUseDefault()\n+    return value\n+\n+\n+Metadata = Annotated[dict[str, str], BeforeValidator(skip_invalid_metadata)]\n+\n+\n+def default_if_none(value: Any) -> Any:\n+    if value is None:\n+        raise PydanticUseDefault()\n+    return value\n+\n+\n+T = TypeVar(\"T\")\n+DefaultIfNone = Annotated[T, BeforeValidator(default_if_none)]\n"
        },
        {
          "path": "saleor/webhook/response_schemas/shipping.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/shipping.py\n===================================================================\n--- saleor/webhook/response_schemas/shipping.py\t81e51c7 (parent)\n+++ saleor/webhook/response_schemas/shipping.py\t4163d8e (commit)\n@@ -0,0 +1,86 @@\n+import logging\n+from decimal import Decimal\n+from typing import Annotated, Any, TypeVar\n+\n+from graphql.error import GraphQLError\n+from prices import Money\n+from pydantic import (\n+    BaseModel,\n+    Field,\n+    RootModel,\n+    ValidationError,\n+    ValidatorFunctionWrapHandler,\n+    WrapValidator,\n+    field_validator,\n+)\n+from pydantic_core import PydanticOmit\n+\n+from ...graphql.core.utils import from_global_id_or_error\n+from ...shipping.models import ShippingMethod\n+from ..const import APP_ID_PREFIX\n+from .annotations import DefaultIfNone, Metadata\n+\n+logger = logging.getLogger(__name__)\n+\n+name_max_length = ShippingMethod._meta.get_field(\"name\").max_length\n+\n+T = TypeVar(\"T\")\n+\n+\n+def skip_invalid_shipping_method(\n+    value: Any, handler: ValidatorFunctionWrapHandler\n+) -> Any:\n+    try:\n+        return handler(value)\n+    except ValidationError as err:\n+        logger.warning(\"Skipping invalid shipping method: %s\", err)\n+        raise PydanticOmit() from err\n+\n+\n+OnErrorSkipShippingMethod = Annotated[T, WrapValidator(skip_invalid_shipping_method)]\n+\n+\n+class ShippingMethodSchema(BaseModel):\n+    id: str = Field(coerce_numbers_to_str=True)\n+    name: str = Field(max_length=name_max_length)\n+    amount: Decimal = Field(ge=0)\n+    currency: str\n+    maximum_delivery_days: Annotated[int, Field(ge=0)] | None = None\n+    minimum_delivery_days: Annotated[int, Field(ge=0)] | None = None\n+    description: str | None = None\n+    metadata: DefaultIfNone[Metadata] = {}\n+\n+    @property\n+    def price(self) -> Money:\n+        return Money(self.amount, self.currency)\n+\n+\n+class ListShippingMethodsSchema(RootModel):\n+    root: DefaultIfNone[list[OnErrorSkipShippingMethod[ShippingMethodSchema]]] = []\n+\n+\n+class ExcludedShippingMethodSchema(BaseModel):\n+    id: str\n+    reason: DefaultIfNone[str] = \"\"\n+\n+    @field_validator(\"id\", mode=\"after\")\n+    @classmethod\n+    def clean_id(cls, value: str) -> str:\n+        try:\n+            type_name, method_id = from_global_id_or_error(value)\n+        except (KeyError, ValueError, TypeError, GraphQLError) as e:\n+            error_msg = \"Malformed ShippingMethod id was provided: %s\"\n+            logger.warning(error_msg, value)\n+            raise ValueError(error_msg, e) from e\n+\n+        if type_name not in (APP_ID_PREFIX, \"ShippingMethod\"):\n+            error_msg = \"Invalid type received. Expected ShippingMethod, got %s\"\n+            logger.warning(error_msg, type_name)\n+            raise ValueError(error_msg, type_name)\n+        return method_id\n+\n+\n+class FilterShippingMethodsSchema(BaseModel):\n+    excluded_methods: DefaultIfNone[\n+        list[OnErrorSkipShippingMethod[ExcludedShippingMethodSchema]]\n+    ] = []\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/__init__.py",
          "status": "added",
          "diff": "Index: saleor/webhook/tests/response_schemas/__init__.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/__init__.py\t81e51c7 (parent)\n+++ saleor/webhook/tests/response_schemas/__init__.py\t4163d8e (commit)\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_shipping.py",
          "status": "added",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_shipping.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_shipping.py\t81e51c7 (parent)\n+++ saleor/webhook/tests/response_schemas/test_shipping.py\t4163d8e (commit)\n@@ -0,0 +1,352 @@\n+import base64\n+from decimal import Decimal\n+from unittest.mock import patch\n+\n+import graphene\n+import pytest\n+from pydantic import ValidationError\n+\n+from ...response_schemas.shipping import (\n+    ExcludedShippingMethodSchema,\n+    FilterShippingMethodsSchema,\n+    ListShippingMethodsSchema,\n+    ShippingMethodSchema,\n+    logger,\n+)\n+\n+\n+def decode_id(id):\n+    return base64.b64decode(id).decode()\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # All fields provided\n+        {\n+            \"id\": \"1\",\n+            \"name\": \"Standard Shipping\",\n+            \"amount\": Decimal(\"10.00\"),\n+            \"currency\": \"USD\",\n+            \"maximum_delivery_days\": 5,\n+            \"minimum_delivery_days\": 2,\n+            \"description\": \"Fast delivery\",\n+            \"metadata\": {\"key1\": \"value1\", \"key2\": \"value2\"},\n+        },\n+        # Optional fields not provided\n+        {\n+            \"id\": 2,  # Integer ID\n+            \"name\": \"Express Shipping\",\n+            \"amount\": Decimal(\"20.00\"),\n+            \"currency\": \"EUR\",\n+        },\n+        # Metadata is empty, delivery days, and description as None\n+        {\n+            \"id\": \"3\",\n+            \"name\": \"Overnight Shipping\",\n+            \"amount\": Decimal(\"50.00\"),\n+            \"currency\": \"GBP\",\n+            \"maximum_delivery_days\": None,\n+            \"minimum_delivery_days\": None,\n+            \"description\": None,\n+            \"metadata\": {},  # Empty metadata\n+        },\n+        # No description or metadata\n+        {\n+            \"id\": \"4\",\n+            \"name\": \"Free Shipping\",\n+            \"amount\": Decimal(\"0.00\"),\n+            \"currency\": \"USD\",\n+            \"maximum_delivery_days\": 7,\n+            \"minimum_delivery_days\": 5,\n+        },\n+        # Metadata is None\n+        {\n+            \"id\": 5,\n+            \"name\": \"International Shipping\",\n+            \"amount\": Decimal(\"30.00\"),\n+            \"currency\": \"USD\",\n+            \"description\": None,\n+            \"metadata\": None,\n+        },\n+    ],\n+)\n+def test_shipping_method_schema_valid(data):\n+    # when\n+    shipping_method_model = ShippingMethodSchema.model_validate(data)\n+\n+    # then\n+    assert shipping_method_model.id == str(data[\"id\"])\n+    assert shipping_method_model.name == data[\"name\"]\n+    assert shipping_method_model.amount == data[\"amount\"]\n+    assert shipping_method_model.currency == data[\"currency\"]\n+    assert shipping_method_model.maximum_delivery_days == data.get(\n+        \"maximum_delivery_days\"\n+    )\n+    assert shipping_method_model.minimum_delivery_days == data.get(\n+        \"minimum_delivery_days\"\n+    )\n+    assert shipping_method_model.description == data.get(\"description\")\n+    assert shipping_method_model.metadata == (data.get(\"metadata\") or {})\n+\n+\n+@pytest.mark.parametrize(\n+    \"metadata\", [12345, \"not_a_dict\", {123: 123}, {\"123\": 123}, {123: \"123\"}]\n+)\n+def test_shipping_method_schema_invalid_metadata_skipped(metadata):\n+    # given\n+    data = {\n+        \"id\": \"4\",\n+        \"name\": \"Free Shipping\",\n+        \"amount\": Decimal(\"0.00\"),\n+        \"currency\": \"USD\",\n+        \"metadata\": metadata,\n+    }\n+\n+    # when\n+    shipping_method_model = ShippingMethodSchema.model_validate(data)\n+\n+    # then\n+    assert shipping_method_model.id == data[\"id\"]\n+    assert shipping_method_model.name == data[\"name\"]\n+    assert shipping_method_model.amount == data[\"amount\"]\n+    assert shipping_method_model.currency == data[\"currency\"]\n+    assert shipping_method_model.maximum_delivery_days is None\n+    assert shipping_method_model.minimum_delivery_days is None\n+    assert shipping_method_model.description is None\n+    assert shipping_method_model.metadata == {}\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # Missing required fields - missing id\n+        {\n+            \"name\": \"Standard Shipping\",\n+            \"amount\": Decimal(\"10.00\"),\n+            \"currency\": \"USD\",\n+        },\n+        # Missing required fields - missing name\n+        {\n+            \"id\": 0,\n+            \"amount\": Decimal(\"10.00\"),\n+            \"currency\": \"USD\",\n+        },\n+        # Missing required fields - missing amount\n+        {\n+            \"id\": 0,\n+            \"name\": \"Standard Shipping\",\n+            \"currency\": \"USD\",\n+        },\n+        # Invalid type for \"id\"\n+        {\n+            \"id\": {\"invalid\": \"dict\"},\n+            \"name\": \"Standard Shipping\",\n+            \"amount\": Decimal(\"10.00\"),\n+            \"currency\": \"USD\",\n+        },\n+        # Invalid type for \"amount\"\n+        {\n+            \"id\": \"1\",\n+            \"name\": \"Standard Shipping\",\n+            \"amount\": \"invalid_amount\",\n+            \"currency\": \"USD\",\n+        },\n+        # Negative value for \"amount\"\n+        {\n+            \"id\": \"2\",\n+            \"name\": \"Express Shipping\",\n+            \"amount\": Decimal(\"-10.00\"),\n+            \"currency\": \"USD\",\n+        },\n+        # Invalid type for \"maximum_delivery_days\"\n+        {\n+            \"id\": \"5\",\n+            \"name\": \"International Shipping\",\n+            \"amount\": Decimal(\"30.00\"),\n+            \"currency\": \"USD\",\n+            \"maximum_delivery_days\": \"invalid_days\",\n+        },\n+        # Invalid type for \"minimum_delivery_days\"\n+        {\n+            \"id\": \"5\",\n+            \"name\": \"International Shipping\",\n+            \"amount\": Decimal(\"30.00\"),\n+            \"currency\": \"USD\",\n+            \"minimum_delivery_days\": \"invalid_days\",\n+        },\n+        # Negative value for \"maximum_delivery_days\"\n+        {\n+            \"id\": 6,\n+            \"name\": \"Economy Shipping\",\n+            \"amount\": Decimal(\"5.00\"),\n+            \"currency\": \"USD\",\n+            \"maximum_delivery_days\": -1,\n+        },\n+        # Negative value for \"minimum_delivery_days\"\n+        {\n+            \"id\": 6,\n+            \"name\": \"Economy Shipping\",\n+            \"amount\": Decimal(\"5.00\"),\n+            \"currency\": \"USD\",\n+            \"minimum_delivery_days\": -1,\n+        },\n+        # Name exceeds max length\n+        {\n+            \"id\": 7,\n+            \"name\": \"A\" * 300,\n+            \"amount\": Decimal(\"15.00\"),\n+            \"currency\": \"USD\",\n+        },\n+    ],\n+)\n+def test_shipping_method_schema_invalid(data):\n+    with pytest.raises(ValidationError):\n+        ShippingMethodSchema.model_validate(data)\n+\n+\n+@pytest.mark.parametrize(\"data\", [None, []])\n+def test_list_shipping_methods_schema_skipped_values(data):\n+    # when\n+    list_methods = ListShippingMethodsSchema.model_validate(data)\n+\n+    # Then the root should be an empty list\n+    assert list_methods.root == []\n+\n+\n+@patch.object(logger, \"warning\")\n+def test_list_shipping_methods_schema_invalid_element_skipped(mocked_logger):\n+    \"\"\"Test when the provided input has 2 elements, one valid and one invalid.\"\"\"\n+    # given a list with one valid and one invalid shipping method\n+    data = [\n+        {\n+            \"id\": \"1\",\n+            \"name\": \"Standard Shipping\",\n+            \"amount\": Decimal(\"10.00\"),\n+            \"currency\": \"USD\",\n+            \"maximum_delivery_days\": 5,\n+            \"minimum_delivery_days\": 2,\n+            \"description\": \"Fast delivery\",\n+            \"metadata\": {\"key1\": \"value1\", \"key2\": \"value2\"},\n+        },\n+        {\n+            \"id\": \"2\",\n+            \"name\": \"Express Shipping\",\n+            \"amount\": \"invalid_amount\",  # Invalid amount\n+            \"currency\": \"EUR\",\n+        },\n+    ]\n+\n+    # when\n+    schema = ListShippingMethodsSchema.model_validate(data)\n+\n+    # then only the valid shipping method should be included\n+    assert len(schema.root) == 1\n+    assert schema.root[0].id == data[0][\"id\"]\n+    assert schema.root[0].name == data[0][\"name\"]\n+    assert mocked_logger.call_count == 1\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        {\"id\": graphene.Node.to_global_id(\"app\", \"123\"), \"reason\": \"Some reason\"},\n+        {\"id\": graphene.Node.to_global_id(\"app\", \"456\"), \"reason\": None},\n+        {\"id\": graphene.Node.to_global_id(\"app\", \"789\"), \"reason\": \"\"},\n+    ],\n+)\n+def test_excluded_shipping_method_schema_valid_external_method(data):\n+    # when\n+    excluded_method_data = ExcludedShippingMethodSchema.model_validate(data)\n+\n+    # then\n+    assert excluded_method_data.id == data[\"id\"]\n+    assert excluded_method_data.reason == (data[\"reason\"] or \"\")\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        {\n+            \"id\": graphene.Node.to_global_id(\"ShippingMethod\", \"123\"),\n+            \"reason\": \"Some reason\",\n+        },\n+        {\"id\": graphene.Node.to_global_id(\"ShippingMethod\", \"456\"), \"reason\": None},\n+        {\"id\": graphene.Node.to_global_id(\"ShippingMethod\", \"789\"), \"reason\": \"\"},\n+    ],\n+)\n+def test_excluded_shipping_method_schema_valid_shipping_method(data):\n+    # when\n+    excluded_method_data = ExcludedShippingMethodSchema.model_validate(data)\n+\n+    # then\n+    assert excluded_method_data.id == graphene.Node.from_global_id(data[\"id\"])[1]\n+    assert excluded_method_data.reason == (data[\"reason\"] or \"\")\n+\n+\n+@pytest.mark.parametrize(\n+    \"id\",\n+    [\n+        \"invalid_id\",\n+        \"123\",\n+        graphene.Node.to_global_id(\"ABC\", \"123\"),\n+    ],\n+)\n+@patch.object(logger, \"warning\")\n+def test_excluded_shipping_method_schema_invalid_id(mocked_logger, id):\n+    # given\n+    data = {\"id\": id, \"reason\": \"Some reason\"}\n+\n+    # when\n+    with pytest.raises(ValidationError):\n+        ExcludedShippingMethodSchema.model_validate(data)\n+\n+    # then\n+    assert mocked_logger.call_count == 1\n+\n+\n+@pytest.mark.parametrize(\"data\", [None, []])\n+def test_filter_shipping_methods_schema_skipped_values(data):\n+    # given\n+    input_data = {\"excluded_methods\": data}\n+\n+    # when\n+    list_methods = FilterShippingMethodsSchema.model_validate(input_data)\n+\n+    # Then the root should be an empty list\n+    assert list_methods.excluded_methods == []\n+\n+\n+@patch.object(logger, \"warning\")\n+def test_filter_shipping_methods_schema_invalid_element_skipped(mocked_logger):\n+    \"\"\"Test when the provided input has 2 elements, one valid and one invalid.\"\"\"\n+    # given a list with one valid and one invalid shipping method\n+    data = {\n+        \"excluded_methods\": [\n+            {\n+                \"id\": graphene.Node.to_global_id(\"app\", \"123\"),\n+                \"reason\": \"Some reason\",\n+            },\n+            {\n+                \"id\": \"INVALID\",\n+                \"reason\": None,\n+            },\n+            {\n+                \"id\": graphene.Node.to_global_id(\"ShippingMethod\", \"456\"),\n+                \"reason\": None,\n+            },\n+        ]\n+    }\n+\n+    # when\n+    schema = FilterShippingMethodsSchema.model_validate(data)\n+\n+    # then only the valid shipping method should be included\n+    assert len(schema.excluded_methods) == 2\n+    assert schema.excluded_methods[0].id == data[\"excluded_methods\"][0][\"id\"]\n+    assert schema.excluded_methods[0].reason == data[\"excluded_methods\"][0][\"reason\"]\n+    assert (\n+        schema.excluded_methods[1].id\n+        == graphene.Node.from_global_id(data[\"excluded_methods\"][2][\"id\"])[1]\n+    )\n+    assert schema.excluded_methods[1].reason == \"\"\n"
        },
        {
          "path": "saleor/webhook/transport/shipping.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/shipping.py\n===================================================================\n--- saleor/webhook/transport/shipping.py\t81e51c7 (parent)\n+++ saleor/webhook/transport/shipping.py\t4163d8e (commit)\n@@ -1,109 +1,58 @@\n-import base64\n import json\n import logging\n from collections import defaultdict\n from collections.abc import Callable\n from typing import Any, Union\n \n from django.db.models import QuerySet\n-from graphql import GraphQLError\n-from prices import Money\n+from pydantic import ValidationError\n \n from ...app.models import App\n from ...checkout.models import Checkout\n-from ...graphql.core.utils import from_global_id_or_error\n-from ...graphql.shipping.types import ShippingMethod\n from ...graphql.webhook.utils import get_pregenerated_subscription_payload\n from ...order.models import Order\n from ...plugins.base_plugin import ExcludedShippingMethod, RequestorOrLazyObject\n from ...settings import WEBHOOK_SYNC_TIMEOUT\n from ...shipping.interface import ShippingMethodData\n from ...webhook.utils import get_webhooks_for_event\n-from ..const import APP_ID_PREFIX, CACHE_EXCLUDED_SHIPPING_TIME\n+from ..const import CACHE_EXCLUDED_SHIPPING_TIME\n+from ..models import Webhook\n+from ..response_schemas.shipping import (\n+    ExcludedShippingMethodSchema,\n+    FilterShippingMethodsSchema,\n+    ListShippingMethodsSchema,\n+)\n+from .shipping_helpers import to_shipping_app_id\n from .synchronous.transport import trigger_webhook_sync_if_not_cached\n \n logger = logging.getLogger(__name__)\n \n \n-def to_shipping_app_id(app: App, shipping_method_id: str) -> str:\n-    app_identifier = app.identifier or app.id\n-    return base64.b64encode(\n-        str.encode(f\"{APP_ID_PREFIX}:{app_identifier}:{shipping_method_id}\")\n-    ).decode(\"utf-8\")\n-\n-\n-def convert_to_app_id_with_identifier(shipping_app_id: str) -> None | str:\n-    \"\"\"Prepare the shipping_app_id in format `app:<app-identifier>/method_id>`.\n-\n-    The format of shipping_app_id has been changes so we need to support both of them.\n-    This method is preparing the new shipping_app_id format based on assumptions\n-    that right now the old one is used which is `app:<app-pk>:method_id>`\n-    \"\"\"\n-    decoded_id = base64.b64decode(shipping_app_id).decode()\n-    splitted_id = decoded_id.split(\":\")\n-    if len(splitted_id) != 3:\n-        return None\n-    try:\n-        app_id = int(splitted_id[1])\n-    except (TypeError, ValueError):\n-        return None\n-    app = App.objects.filter(id=app_id).first()\n-    if app is None:\n-        return None\n-    return to_shipping_app_id(app, splitted_id[2])\n-\n-\n-def method_metadata_is_valid(metadata) -> bool:\n-    if not isinstance(metadata, dict):\n-        return False\n-    for key, value in metadata.items():\n-        if not isinstance(key, str) or not isinstance(value, str) or not key.strip():\n-            return False\n-    return True\n-\n-\n def parse_list_shipping_methods_response(\n     response_data: Any, app: \"App\"\n ) -> list[\"ShippingMethodData\"]:\n-    shipping_methods = []\n-    for shipping_method_data in response_data:\n-        if not validate_shipping_method_data(shipping_method_data):\n-            continue\n-        method_id = shipping_method_data.get(\"id\")\n-        method_name = shipping_method_data.get(\"name\")\n-        method_amount = shipping_method_data.get(\"amount\")\n-        method_currency = shipping_method_data.get(\"currency\")\n-        method_maximum_delivery_days = shipping_method_data.get(\"maximum_delivery_days\")\n-        method_minimum_delivery_days = shipping_method_data.get(\"minimum_delivery_days\")\n-        method_description = shipping_method_data.get(\"description\")\n-        method_metadata = shipping_method_data.get(\"metadata\") or {}\n-        if method_metadata:\n-            method_metadata = (\n-                method_metadata if method_metadata_is_valid(method_metadata) else {}\n-            )\n-\n-        shipping_methods.append(\n-            ShippingMethodData(\n-                id=to_shipping_app_id(app, method_id),\n-                name=method_name,\n-                price=Money(method_amount, method_currency),\n-                maximum_delivery_days=method_maximum_delivery_days,\n-                minimum_delivery_days=method_minimum_delivery_days,\n-                description=method_description,\n-                metadata=method_metadata,\n-            )\n+    try:\n+        list_shipping_method_model = ListShippingMethodsSchema.model_validate(\n+            response_data\n         )\n-    return shipping_methods\n+    except ValidationError:\n+        logger.warning(\"Skipping invalid shipping method response: %s\", response_data)\n+        return []\n+    return [\n+        ShippingMethodData(\n+            id=to_shipping_app_id(app, str(shipping_method.id)),\n+            name=shipping_method.name,\n+            price=shipping_method.price,\n+            maximum_delivery_days=shipping_method.maximum_delivery_days,\n+            minimum_delivery_days=shipping_method.minimum_delivery_days,\n+            description=shipping_method.description,\n+            metadata=shipping_method.metadata,\n+        )\n+        for shipping_method in list_shipping_method_model.root\n+    ]\n \n \n-def validate_shipping_method_data(shipping_method_data):\n-    if not isinstance(shipping_method_data, dict):\n-        return False\n-    keys = [\"id\", \"name\", \"amount\", \"currency\"]\n-    return all(key in shipping_method_data for key in keys)\n-\n-\n def get_cache_data_for_exclude_shipping_methods(payload: str) -> dict:\n     payload_dict = json.loads(payload)\n     source_object = payload_dict.get(\"checkout\", payload_dict.get(\"order\", {}))\n \n@@ -130,9 +79,9 @@\n     \"\"\"\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n     cache_data = get_cache_data_for_exclude_shipping_methods(payload)\n-    excluded_methods = []\n+    excluded_methods: list[ExcludedShippingMethodSchema] = []\n     # Gather responses from webhooks\n     for webhook in webhooks:\n         pregenerated_subscription_payload = get_pregenerated_subscription_payload(\n             webhook, pregenerated_subscription_payloads\n@@ -150,9 +99,9 @@\n             pregenerated_subscription_payload=pregenerated_subscription_payload,\n         )\n         if response_data and isinstance(response_data, dict):\n             excluded_methods.extend(\n-                get_excluded_shipping_methods_from_response(response_data)\n+                get_excluded_shipping_methods_from_response(response_data, webhook)\n             )\n     return parse_excluded_shipping_methods(excluded_methods)\n \n \n@@ -208,38 +157,35 @@\n \n \n def get_excluded_shipping_methods_from_response(\n     response_data: dict,\n-) -> list[dict]:\n+    webhook: \"Webhook\",\n+) -> list[ExcludedShippingMethodSchema]:\n     excluded_methods = []\n-    for method_data in response_data.get(\"excluded_methods\", []):\n-        try:\n-            type_name, method_id = from_global_id_or_error(method_data[\"id\"])\n-            if type_name not in (APP_ID_PREFIX, str(ShippingMethod)):\n-                logger.warning(\n-                    \"Invalid type received. Expected ShippingMethod, got %s\", type_name\n-                )\n-                continue\n-\n-        except (KeyError, ValueError, TypeError, GraphQLError) as e:\n-            logger.warning(\"Malformed ShippingMethod id was provided: %s\", e)\n-            continue\n-        excluded_methods.append(\n-            {\"id\": method_id, \"reason\": method_data.get(\"reason\", \"\")}\n+    try:\n+        filter_methods_schema = FilterShippingMethodsSchema.model_validate(\n+            response_data\n         )\n+        excluded_methods.extend(filter_methods_schema.excluded_methods)\n+    except ValidationError:\n+        logger.warning(\n+            \"Skipping invalid response from app %s: %s\",\n+            str(webhook.app.identifier),\n+            response_data,\n+        )\n     return excluded_methods\n \n \n def parse_excluded_shipping_methods(\n-    excluded_methods: list[dict],\n+    excluded_methods: list[ExcludedShippingMethodSchema],\n ) -> dict[str, list[ExcludedShippingMethod]]:\n+    \"\"\"Prepare method_id to excluded methods map.\"\"\"\n     excluded_methods_map = defaultdict(list)\n     for excluded_method in excluded_methods:\n-        method_id = excluded_method[\"id\"]\n+        method_id = excluded_method.id\n+        reason = excluded_method.reason or \"\"\n         excluded_methods_map[method_id].append(\n-            ExcludedShippingMethod(\n-                id=method_id, reason=excluded_method.get(\"reason\", \"\")\n-            )\n+            ExcludedShippingMethod(id=method_id, reason=reason)\n         )\n     return excluded_methods_map\n \n \n"
        },
        {
          "path": "saleor/webhook/transport/shipping_helpers.py",
          "status": "added",
          "diff": "Index: saleor/webhook/transport/shipping_helpers.py\n===================================================================\n--- saleor/webhook/transport/shipping_helpers.py\t81e51c7 (parent)\n+++ saleor/webhook/transport/shipping_helpers.py\t4163d8e (commit)\n@@ -0,0 +1,32 @@\n+import base64\n+\n+from ...app.models import App\n+from ..const import APP_ID_PREFIX\n+\n+\n+def to_shipping_app_id(app: App, shipping_method_id: str) -> str:\n+    app_identifier = app.identifier or app.id\n+    return base64.b64encode(\n+        str.encode(f\"{APP_ID_PREFIX}:{app_identifier}:{shipping_method_id}\")\n+    ).decode(\"utf-8\")\n+\n+\n+def convert_to_app_id_with_identifier(shipping_app_id: str) -> None | str:\n+    \"\"\"Prepare the shipping_app_id in format `app:<app-identifier>:method_id>`.\n+\n+    The format of shipping_app_id has been changes so we need to support both of them.\n+    This method is preparing the new shipping_app_id format based on assumptions\n+    that right now the old one is used which is `app:<app-pk>:<method_id>`\n+    \"\"\"\n+    decoded_id = base64.b64decode(shipping_app_id).decode()\n+    splitted_id = decoded_id.split(\":\")\n+    if len(splitted_id) != 3:\n+        return None\n+    try:\n+        app_id = int(splitted_id[1])\n+    except (TypeError, ValueError):\n+        return None\n+    app = App.objects.filter(id=app_id).first()\n+    if app is None:\n+        return None\n+    return to_shipping_app_id(app, splitted_id[2])\n"
        },
        {
          "path": "saleor/webhook/transport/tests/test_shipping_helpers.py",
          "status": "added",
          "diff": "Index: saleor/webhook/transport/tests/test_shipping_helpers.py\n===================================================================\n--- saleor/webhook/transport/tests/test_shipping_helpers.py\t81e51c7 (parent)\n+++ saleor/webhook/transport/tests/test_shipping_helpers.py\t4163d8e (commit)\n@@ -0,0 +1,62 @@\n+import base64\n+\n+from ..shipping_helpers import convert_to_app_id_with_identifier\n+\n+\n+def test_convert_to_app_id_with_identifier_valid(app):\n+    # given\n+    method_id = \"123\"\n+    shipping_app_id = base64.b64encode(str.encode(f\"app:{app.pk}:{method_id}\")).decode(\n+        \"utf-8\"\n+    )\n+\n+    # when\n+    app_id_with_identifier = convert_to_app_id_with_identifier(shipping_app_id)\n+\n+    # then\n+    assert app_id_with_identifier\n+    assert (\n+        base64.b64decode(app_id_with_identifier).decode()\n+        == f\"app:{app.identifier}:{method_id}\"\n+    )\n+\n+\n+def test_convert_to_app_id_with_identifier_missing_shipping_id(app):\n+    # given\n+    shipping_app_id = base64.b64encode(str.encode(f\"app:{app.pk}\")).decode(\"utf-8\")\n+\n+    # when\n+    app_id_with_identifier = convert_to_app_id_with_identifier(shipping_app_id)\n+\n+    # then\n+    assert app_id_with_identifier is None\n+\n+\n+def test_convert_to_app_id_with_identifier_missing_app_for_given_id():\n+    # given\n+    method_id = \"123\"\n+    app_id = 321\n+    shipping_app_id = base64.b64encode(str.encode(f\"app:{app_id}:{method_id}\")).decode(\n+        \"utf-8\"\n+    )\n+\n+    # when\n+    app_id_with_identifier = convert_to_app_id_with_identifier(shipping_app_id)\n+\n+    # then\n+    assert app_id_with_identifier is None\n+\n+\n+def test_convert_to_app_id_with_identifier_invalid_app_id():\n+    # given\n+    method_id = \"123\"\n+    app_id = \"xyz\"\n+    shipping_app_id = base64.b64encode(str.encode(f\"app:{app_id}:{method_id}\")).decode(\n+        \"utf-8\"\n+    )\n+\n+    # when\n+    app_id_with_identifier = convert_to_app_id_with_identifier(shipping_app_id)\n+\n+    # then\n+    assert app_id_with_identifier is None\n"
        }
      ]
    },
    {
      "id": "type-stored-payments",
      "sha": "1ef1f7413cc4daf0dfeb882a5071b09c7a0654df",
      "parentSha": "40f4e903cf11f09fd52737106a52d1136aa27f09",
      "spec": "Implement static response schemas and reusable validation/logging for webhook responses and integrate them into transports, plus align typings:\n\n1) Add reusable validators and logging helpers for response schemas\n- File: saleor/webhook/response_schemas/annotations.py\n  - Introduce two WrapValidator-based helpers that centralize error handling:\n    - OnErrorSkip[T]: wraps a field/item; upon ValidationError, log at WARNING level using the module logger with a message taken from context[\"custom_message\"] (default: \"Skipping invalid value\"), include the offending value and error string, and include extra={\"app\": app.id if provided in context}. Then omit the item (PydanticOmit).\n    - OnErrorDefault[T]: wraps a field; upon ValidationError, log at WARNING level with message \"Skipping invalid value: {value} error: {err}\", include extra={\"app\": app.id if provided, \"field_name\": info.field_name}, and use the field’s default (PydanticUseDefault).\n  - Ensure the validator functions accept (value, handler, info: ValidationInfo), read info.context for custom_message and app, and call handler(value) on success.\n  - Keep DefaultIfNone for optional fields and DatetimeUTC as is.\n\n2) Add shared value-normalization validator utilities\n- File: saleor/webhook/response_schemas/validators.py\n  - Provide lower_values(values) that lowercases a string or every element of a list of strings; leave None/other types unchanged.\n\n3) Define payment response schemas for LIST_STORED_PAYMENT_METHODS\n- File: saleor/webhook/response_schemas/payment.py (new)\n  - Create TokenizedPaymentFlowEnum that mirrors saleor.payment.TokenizedPaymentFlow.CHOICES using graphql.core.utils.str_to_enum for enum member names.\n  - CreditCardInfoSchema:\n    - Required: brand (str), lastDigits (alias-> last_digits), expYear (alias-> exp_year, int coercible from numeric strings), expMonth (alias-> exp_month, int coercible similarly).\n    - Optional: firstDigits (alias-> first_digits) with default None.\n    - Coerce last_digits and first_digits to string when provided; preserve None.\n  - StoredPaymentMethodSchema:\n    - Required: id (str), type (str).\n    - Optional: supportedPaymentFlows (alias-> supported_payment_flows) as list of allowed tokenized flow literals; default empty list; normalize to lowercase via lower_values.\n    - Optional: name (str|None), data (pydantic JsonValue|None).\n    - Optional: creditCardInfo (alias-> credit_card_info) using OnErrorDefault[CreditCardInfoSchema] with default None, so invalid nested card info is dropped and logged.\n  - ListStoredPaymentMethodsSchema:\n    - paymentMethods (alias-> payment_methods): DefaultIfNone[list[OnErrorSkip[StoredPaymentMethodSchema]]] defaulting to [] so invalid list elements are skipped with logging.\n\n4) Refactor shipping response schemas to use shared OnErrorSkip\n- File: saleor/webhook/response_schemas/shipping.py\n  - Remove bespoke skip/omit validator and its imports (Any, ValidationError, ValidatorFunctionWrapHandler, WrapValidator, PydanticOmit).\n  - Import and use OnErrorSkip from annotations in both ListShippingMethodsSchema and FilterShippingMethodsSchema for their list element types.\n  - Keep other existing field definitions and Metadata/DefaultIfNone behavior.\n\n5) Update transports to pass context and use schemas\n- File: saleor/webhook/transport/list_stored_payment_methods.py\n  - Replace ad-hoc parsing helpers (get_credit_card_info, get_payment_method_from_response) with validation via ListStoredPaymentMethodsSchema.model_validate(response_data, context={\"custom_message\": \"Skipping invalid stored payment method\", \"app\": app}).\n  - On top-level ValidationError, log once with logger.warning(\"Skipping stored payment methods from app %s. Error: %s\", app.id, err, extra={\"app\": app.id}) and return [].\n  - Otherwise map each validated item to PaymentMethodData:\n    - id = to_payment_app_id(app, payment_method.id)\n    - external_id = payment_method.id\n    - supported_payment_flows = normalized list from schema\n    - type, name, data copied from schema\n    - credit_card_info: construct PaymentMethodCreditCardInfo from validated nested model if present; else None\n    - gateway = PaymentGateway(id=app.identifier, name=app.name, currencies=[currency], config=[])\n\n- File: saleor/webhook/transport/shipping.py\n  - For parse_list_shipping_methods_response, call ListShippingMethodsSchema.model_validate(response_data, context={\"app\": app, \"custom_message\": \"Skipping invalid shipping method (ListShippingMethodsSchema)\"}); on ValidationError, keep existing fallback logging and behavior.\n  - For get_excluded_shipping_methods_from_response, call FilterShippingMethodsSchema.model_validate(response_data, context={\"custom_message\": \"Skipping invalid shipping method (FilterShippingMethodsSchema)\"}), then extend excluded_methods with the validated list; on ValidationError keep existing fallback logging.\n\n6) Align typing for PaymentMethodData JSON payloads\n- File: saleor/payment/interface.py\n  - Change PaymentMethodData.data type from JSONType | None to JSONValue | None to accept any JSON scalar/object/array value consistent with Pydantic JsonValue used in the schema.\n\n7) Tests: add/adjust tests to verify behavior (names reflect intent; contents should match assertions in the diff)\n- Payment schemas (new module tests): validate both valid and invalid inputs; ensure required field enforcement, coercion of digit fields, OnErrorDefault drops invalid credit card info and logs one warning with extra[\"app\"] and field_name; ListStoredPaymentMethodsSchema skips invalid entries and logs appropriately.\n- Shipping schema tests: patch annotations logger for list/filtered schemas, assert skipped invalid element behavior and that custom messages are used when provided in context.\n- Webhook utils tests: update list stored payment methods parsing tests to build expected PaymentMethodData objects from minimal and full inputs; assert that an invalid element is skipped and that annotations logger warning uses the \"Skipping invalid stored payment method\" message and includes extra[\"app\"]; also assert that completely invalid top-level response yields [] with a single module logger warning mentioning the app.\n- Plugin shipping webhook tests: update to patch the annotations logger where skip/default occurs and adjust expected warning counts and messages accordingly (e.g., differentiate malformed id warnings vs. skip warnings).\n\nAcceptance criteria\n- list_stored_payment_methods parsing uses Pydantic schema; bad items are skipped with annotations logger; invalid nested creditCardInfo is defaulted to None with annotations logger, including field_name; fatal schema errors return [] with a module-level warning.\n- Shipping response parsing uses shared OnErrorSkip and logs via annotations logger with the provided custom_message strings; tests expect these exact messages and warning counts.\n- PaymentMethodData.data type accepts any JSON value, consistent with JsonValue in schema.\n- All updated and new tests pass.",
      "prompt": "Implement structured, schema-validated parsing for webhook responses and unify error handling:\n\n- Add Pydantic response schemas for listing stored payment methods, including a card details model, and use them to parse webhook responses. Normalize and validate supported flows, default invalid nested fields, and skip invalid list items with clear warnings.\n- Introduce reusable validators that log and either skip the invalid value or use a default. Use a context-aware custom message and include the app identifier in log metadata.\n- Refactor shipping response schemas to reuse these validators and update shipping transport code to pass context so logs show clear messages for skipped items.\n- Adjust the list-stored-payment-methods transport to parse with the new schemas and return domain objects, logging and returning an empty list when the overall payload is invalid.\n- Update typing on payment method structures so arbitrary JSON values are accepted for arbitrary data fields.\n- Update and add tests to cover valid/invalid cases, logging messages and counts, and proper mapping to domain objects.\n\nDo not paste the exact code; implement the functionality and structure so that tests depending on this behavior will pass.",
      "supplementalFiles": [
        "saleor/webhook/transport/utils.py",
        "saleor/webhook/transport/shipping_helpers.py",
        "saleor/webhook/event_types.py",
        "saleor/payment/__init__.py",
        "saleor/webhook/const.py",
        "saleor/webhook/response_schemas/transaction.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/payment/interface.py",
          "status": "modified",
          "diff": "Index: saleor/payment/interface.py\n===================================================================\n--- saleor/payment/interface.py\t40f4e90 (parent)\n+++ saleor/payment/interface.py\t1ef1f74 (commit)\n@@ -104,9 +104,9 @@\n     gateway: PaymentGateway\n     supported_payment_flows: list[str] = field(default_factory=list)\n     credit_card_info: PaymentMethodCreditCardInfo | None = None\n     name: str | None = None\n-    data: JSONType | None = None\n+    data: JSONValue | None = None\n \n \n @dataclass\n class TransactionActionData:\n"
        },
        {
          "path": "saleor/plugins/webhook/tests/test_shipping_webhook.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/tests/test_shipping_webhook.py\n===================================================================\n--- saleor/plugins/webhook/tests/test_shipping_webhook.py\t40f4e90 (parent)\n+++ saleor/plugins/webhook/tests/test_shipping_webhook.py\t1ef1f74 (commit)\n@@ -16,8 +16,9 @@\n from ....webhook.payloads import (\n     generate_excluded_shipping_methods_for_checkout_payload,\n     generate_excluded_shipping_methods_for_order_payload,\n )\n+from ....webhook.response_schemas.annotations import logger as annotations_logger\n from ....webhook.response_schemas.shipping import logger as schema_logger\n from ....webhook.transport.shipping import (\n     get_excluded_shipping_methods_from_response,\n     get_excluded_shipping_methods_or_fetch,\n@@ -394,10 +395,13 @@\n         ]\n     )\n \n \n+@mock.patch.object(annotations_logger, \"warning\")\n @mock.patch.object(schema_logger, \"warning\")\n-def test_parse_excluded_shipping_methods_response(mocked_schema_logger, app):\n+def test_parse_excluded_shipping_methods_response(\n+    mocked_schema_logger, mocked_annotations_logger, app\n+):\n     # given\n     external_id = to_shipping_app_id(app, \"test-1234\")\n     response = {\n         \"excluded_methods\": [\n@@ -431,11 +435,48 @@\n     assert len(excluded_methods) == 2\n     assert excluded_methods[0].id == \"2\"\n     assert excluded_methods[1].id == external_id\n     # 2 warning for each invalid data\n-    assert mocked_schema_logger.call_count == 6\n+    # warning for malformed id\n+    assert mocked_schema_logger.call_count == 3\n+    # warning for skipping shipping method\n+    assert mocked_annotations_logger.call_count == 3\n \n \n+@mock.patch.object(annotations_logger, \"warning\")\n+@mock.patch.object(schema_logger, \"warning\")\n+def test_parse_excluded_shipping_methods_response_invalid(\n+    mocked_schema_logger, mocked_annotations_logger, app\n+):\n+    # given\n+    response = {\n+        \"excluded_methods\": [\n+            {\n+                \"id\": \"not-an-id\",\n+            },\n+        ]\n+    }\n+    webhook = Webhook.objects.create(\n+        name=\"shipping-webhook-1\",\n+        app=app,\n+        target_url=\"https://shipping-gateway.com/apiv2/\",\n+    )\n+\n+    # when\n+    excluded_methods = get_excluded_shipping_methods_from_response(response, webhook)\n+\n+    # then\n+    assert not excluded_methods\n+    assert mocked_schema_logger.call_count == 1\n+    assert (\n+        \"Malformed ShippingMethod id was provided:\"\n+        in mocked_schema_logger.call_args[0][0]\n+    )\n+    assert mocked_annotations_logger.call_count == 1\n+    error_msg = mocked_annotations_logger.call_args[0][1]\n+    assert \"Skipping invalid shipping method (FilterShippingMethodsSchema)\" in error_msg\n+\n+\n @mock.patch(\n     \"saleor.plugins.webhook.plugin.WebhookPlugin.excluded_shipping_methods_for_order\"\n )\n def test_order_shipping_methods(\n@@ -1251,9 +1292,9 @@\n     mocked_get_excluded.asssert_not_called()\n     mocked_parse.assert_called_once_with([])\n \n \n-@mock.patch.object(schema_logger, \"warning\")\n+@mock.patch.object(annotations_logger, \"warning\")\n def test_parse_list_shipping_methods_response_response_incorrect_format(\n     mocked_logger, app\n ):\n     # given\n@@ -1265,8 +1306,10 @@\n     # then\n     assert result == []\n     # Ensure the warning about invalit method data wa logged\n     assert mocked_logger.call_count == len(response_data_with_incorrect_format)\n+    error_msg = mocked_logger.call_args[0][1]\n+    assert error_msg == \"Skipping invalid shipping method (ListShippingMethodsSchema)\"\n \n \n def test_parse_list_shipping_methods_with_metadata(app):\n     # given\n"
        },
        {
          "path": "saleor/webhook/response_schemas/annotations.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/response_schemas/annotations.py\n===================================================================\n--- saleor/webhook/response_schemas/annotations.py\t40f4e90 (parent)\n+++ saleor/webhook/response_schemas/annotations.py\t1ef1f74 (commit)\n@@ -5,8 +5,9 @@\n from pydantic import (\n     AfterValidator,\n     BeforeValidator,\n     ValidationError,\n+    ValidationInfo,\n     ValidatorFunctionWrapHandler,\n     WrapValidator,\n )\n from pydantic_core import PydanticOmit, PydanticUseDefault\n@@ -15,9 +16,11 @@\n \n M = TypeVar(\"M\")\n logger = logging.getLogger(__name__)\n \n+logger = logging.getLogger(__name__)\n \n+\n def skip_invalid_metadata(value: M) -> M:\n     if not metadata_is_valid(value):\n         raise PydanticUseDefault()\n     return value\n@@ -34,8 +37,55 @@\n \n T = TypeVar(\"T\")\n DefaultIfNone = Annotated[T, BeforeValidator(default_if_none)]\n \n+\n+def skip_invalid(\n+    value: Any, handler: ValidatorFunctionWrapHandler, info: ValidationInfo\n+) -> Any:\n+    try:\n+        return handler(value)\n+    except ValidationError as err:\n+        context = info.context or {}\n+        custom_message = context.get(\"custom_message\", \"Skipping invalid value\")\n+        app = context.get(\"app\")\n+        logger.warning(\n+            \"%s Value: %s Error: %s\",\n+            custom_message,\n+            value,\n+            str(err),\n+            extra={\n+                \"app\": app.id if app else None,\n+            },\n+        )\n+        raise PydanticOmit() from err\n+\n+\n+OnErrorSkip = Annotated[T, WrapValidator(skip_invalid)]\n+\n+\n+def default_if_invalid(\n+    value: Any, handler: ValidatorFunctionWrapHandler, info: ValidationInfo\n+) -> Any:\n+    try:\n+        return handler(value)\n+    except ValidationError as err:\n+        context = info.context or {}\n+        app = context.get(\"app\")\n+        logger.warning(\n+            \"Skipping invalid value: %s error: %s\",\n+            value,\n+            str(err),\n+            extra={\n+                \"app\": app.id if app else None,\n+                \"field_name\": info.field_name,\n+            },\n+        )\n+        raise PydanticUseDefault() from err\n+\n+\n+OnErrorDefault = Annotated[T, WrapValidator(default_if_invalid)]\n+\n DatetimeUTC = Annotated[datetime, AfterValidator(lambda v: v.replace(tzinfo=UTC))]\n \n \n def skip_invalid_literal(value: T, handler: ValidatorFunctionWrapHandler) -> T:\n"
        },
        {
          "path": "saleor/webhook/response_schemas/payment.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/payment.py\n===================================================================\n--- saleor/webhook/response_schemas/payment.py\t40f4e90 (parent)\n+++ saleor/webhook/response_schemas/payment.py\t1ef1f74 (commit)\n@@ -0,0 +1,101 @@\n+from enum import Enum\n+from typing import Annotated, Any, Literal\n+\n+from pydantic import AfterValidator, BaseModel, Field, JsonValue, field_validator\n+\n+from ...graphql.core.utils import str_to_enum\n+from ...payment import TokenizedPaymentFlow\n+from .annotations import DefaultIfNone, OnErrorDefault, OnErrorSkip\n+from .validators import lower_values\n+\n+TokenizedPaymentFlowEnum = Enum(  # type: ignore[misc]\n+    \"TokenizedPaymentFlowEnum\",\n+    [(str_to_enum(value), value) for value, _ in TokenizedPaymentFlow.CHOICES],\n+)\n+\n+\n+class CreditCardInfoSchema(BaseModel):\n+    brand: Annotated[str, Field(description=\"Brand of the credit card.\")]\n+    last_digits: Annotated[\n+        str,\n+        Field(\n+            validation_alias=\"lastDigits\", description=\"Last digits of the credit card.\"\n+        ),\n+    ]\n+    exp_year: Annotated[\n+        int,\n+        Field(\n+            validation_alias=\"expYear\",\n+            description=\"Expiration year of the credit card.\",\n+        ),\n+    ]\n+    exp_month: Annotated[\n+        int,\n+        Field(\n+            validation_alias=\"expMonth\",\n+            description=\"Expiration month of the credit card.\",\n+        ),\n+    ]\n+    first_digits: Annotated[\n+        DefaultIfNone[str],\n+        Field(\n+            validation_alias=\"firstDigits\",\n+            description=\"First digits of the credit card.\",\n+            default=None,\n+        ),\n+    ]\n+\n+    @field_validator(\"last_digits\", \"first_digits\", mode=\"before\")\n+    @classmethod\n+    def clean_digits(cls, value: Any) -> str | None:\n+        return str(value) if value is not None else None\n+\n+\n+class StoredPaymentMethodSchema(BaseModel):\n+    id: Annotated[str, Field(description=\"ID of stored payment method.\")]\n+    supported_payment_flows: Annotated[  # type: ignore[name-defined]\n+        DefaultIfNone[list[Literal[TokenizedPaymentFlowEnum.INTERACTIVE.name,]]],\n+        Field(\n+            validation_alias=\"supportedPaymentFlows\",\n+            description=\"Supported flows that can be performed with this payment method.\",\n+            default_factory=list,\n+        ),\n+        AfterValidator(lower_values),\n+    ]\n+    type: Annotated[\n+        str,\n+        Field(description=\"Type of stored payment method. For example: Credit Card.\"),\n+    ]\n+    name: Annotated[\n+        DefaultIfNone[str],\n+        Field(\n+            description=\"Name of the payment method. For example: last 4 digits of credit card, obfuscated email.\",\n+            default=None,\n+        ),\n+    ]\n+    data: Annotated[\n+        DefaultIfNone[JsonValue],\n+        Field(\n+            description=\"JSON data that will be returned to client.\",\n+            default=None,\n+        ),\n+    ]\n+    credit_card_info: Annotated[\n+        OnErrorDefault[CreditCardInfoSchema],\n+        Field(\n+            validation_alias=\"creditCardInfo\",\n+            description=\"Credit card information.\",\n+            default=None,\n+        ),\n+    ]\n+\n+\n+class ListStoredPaymentMethodsSchema(BaseModel):\n+    payment_methods: Annotated[\n+        DefaultIfNone[list[OnErrorSkip[StoredPaymentMethodSchema]]],\n+        Field(\n+            validation_alias=\"paymentMethods\",\n+            default_factory=list,\n+            description=\"List of stored payment methods.\",\n+        ),\n+    ]\n"
        },
        {
          "path": "saleor/webhook/response_schemas/shipping.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/response_schemas/shipping.py\n===================================================================\n--- saleor/webhook/response_schemas/shipping.py\t40f4e90 (parent)\n+++ saleor/webhook/response_schemas/shipping.py\t1ef1f74 (commit)\n@@ -1,49 +1,32 @@\n import logging\n from decimal import Decimal\n-from typing import Annotated, Any, TypeVar\n+from typing import Annotated, TypeVar\n \n from graphql.error import GraphQLError\n from prices import Money\n from pydantic import (\n     BaseModel,\n     Field,\n     RootModel,\n-    ValidationError,\n     ValidationInfo,\n-    ValidatorFunctionWrapHandler,\n-    WrapValidator,\n     field_validator,\n )\n-from pydantic_core import PydanticOmit\n \n from ...app.models import App\n from ...graphql.core.utils import from_global_id_or_error\n from ...shipping.models import ShippingMethod\n from ..const import APP_ID_PREFIX\n from ..transport.shipping_helpers import to_shipping_app_id\n-from .annotations import DefaultIfNone, Metadata\n+from .annotations import DefaultIfNone, Metadata, OnErrorSkip\n \n logger = logging.getLogger(__name__)\n \n name_max_length = ShippingMethod._meta.get_field(\"name\").max_length\n \n T = TypeVar(\"T\")\n \n \n-def skip_invalid_shipping_method(\n-    value: Any, handler: ValidatorFunctionWrapHandler\n-) -> Any:\n-    try:\n-        return handler(value)\n-    except ValidationError as err:\n-        logger.warning(\"Skipping invalid shipping method: %s\", err)\n-        raise PydanticOmit() from err\n-\n-\n-OnErrorSkipShippingMethod = Annotated[T, WrapValidator(skip_invalid_shipping_method)]\n-\n-\n class ShippingMethodSchema(BaseModel):\n     id: Annotated[str, Field(coerce_numbers_to_str=True)]\n     name: Annotated[str, Field(max_length=name_max_length)]\n     amount: Annotated[Decimal, Field(ge=0)]\n@@ -66,9 +49,9 @@\n         return to_shipping_app_id(app, shipping_method_id)\n \n \n class ListShippingMethodsSchema(RootModel):\n-    root: DefaultIfNone[list[OnErrorSkipShippingMethod[ShippingMethodSchema]]] = []\n+    root: DefaultIfNone[list[OnErrorSkip[ShippingMethodSchema]]] = []\n \n \n class ExcludedShippingMethodSchema(BaseModel):\n     id: str\n@@ -92,6 +75,6 @@\n \n \n class FilterShippingMethodsSchema(BaseModel):\n     excluded_methods: DefaultIfNone[\n-        list[OnErrorSkipShippingMethod[ExcludedShippingMethodSchema]]\n+        list[OnErrorSkip[ExcludedShippingMethodSchema]]\n     ] = []\n"
        },
        {
          "path": "saleor/webhook/response_schemas/validators.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/validators.py\n===================================================================\n--- saleor/webhook/response_schemas/validators.py\t40f4e90 (parent)\n+++ saleor/webhook/response_schemas/validators.py\t1ef1f74 (commit)\n@@ -0,0 +1,11 @@\n+def lower_values(\n+    values: str | list[str] | None,\n+) -> str | list[str] | None:\n+    \"\"\"Lowercase all values in a string or a list.\"\"\"\n+    match values:\n+        case str():\n+            return values.lower()\n+        case list():\n+            return [value.lower() for value in values]\n+        case _:\n+            return values\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_payment.py",
          "status": "added",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_payment.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_payment.py\t40f4e90 (parent)\n+++ saleor/webhook/tests/response_schemas/test_payment.py\t1ef1f74 (commit)\n@@ -0,0 +1,472 @@\n+from unittest.mock import patch\n+\n+import pytest\n+from pydantic import ValidationError\n+\n+from ...response_schemas.annotations import logger as annotations_logger\n+from ...response_schemas.payment import (\n+    CreditCardInfoSchema,\n+    ListStoredPaymentMethodsSchema,\n+    StoredPaymentMethodSchema,\n+)\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # All fields\n+        {\n+            \"brand\": \"visa\",\n+            \"lastDigits\": \"1234\",\n+            \"expYear\": 2023,\n+            \"expMonth\": 12,\n+            \"firstDigits\": \"123456\",\n+        },\n+        # Only required fields\n+        {\n+            \"brand\": \"mastercard\",\n+            \"lastDigits\": \"5678\",\n+            \"expYear\": 2025,\n+            \"expMonth\": 6,\n+        },\n+        # All int fields as strings\n+        {\n+            \"brand\": \"visa\",\n+            \"lastDigits\": \"1234\",\n+            \"expYear\": \"2023\",\n+            \"expMonth\": \"12\",\n+            \"firstDigits\": \"123456\",\n+        },\n+        # All digit fields as int\n+        {\n+            \"brand\": \"visa\",\n+            \"lastDigits\": 1234,\n+            \"expYear\": 2023,\n+            \"expMonth\": 12,\n+            \"firstDigits\": 123456,\n+        },\n+    ],\n+)\n+def test_credit_card_info_schema_valid(data):\n+    # when\n+    schema = CreditCardInfoSchema.model_validate(data)\n+\n+    # then\n+    assert schema.brand == data[\"brand\"]\n+    assert schema.last_digits == str(data[\"lastDigits\"])\n+    assert schema.exp_year == int(data[\"expYear\"])\n+    assert schema.exp_month == int(data[\"expMonth\"])\n+    first_digits = data.get(\"firstDigits\")\n+    assert schema.first_digits == (str(first_digits) if first_digits else None)\n+\n+\n+class NonParsableObject:\n+    def __str__(self):\n+        raise ValueError(\"Cannot convert to string\")\n+\n+\n+@pytest.mark.parametrize(\n+    (\"data\", \"invalid_field\"),\n+    [\n+        # Missing `brand` field\n+        (\n+            {\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"brand\",\n+        ),\n+        # Missing `lastDigits` field\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"lastDigits\",\n+        ),\n+        # Missing `expYear` field\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"expMonth\": 12,\n+                \"lastDigits\": \"1234\",\n+            },\n+            \"expYear\",\n+        ),\n+        # Missing `expMonth` field\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"expYear\": 2023,\n+                \"lastDigits\": \"1234\",\n+            },\n+            \"expMonth\",\n+        ),\n+        # Not parsable `expYear`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": \"ABC\",\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"expYear\",\n+        ),\n+        # Not parsable `expMonth`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": 2023,\n+                \"expMonth\": \"ABC\",\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"expMonth\",\n+        ),\n+        # Empty string as `expYear`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": \"\",\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"expYear\",\n+        ),\n+        # Empty string as `expMonth`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": 2023,\n+                \"expMonth\": \"\",\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"expMonth\",\n+        ),\n+        # None as `lastDigits`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": None,\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"lastDigits\",\n+        ),\n+        # Not parsable as `lastDigits`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": NonParsableObject(),\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+            \"lastDigits\",\n+        ),\n+        # Not parsable as `firstDigits`\n+        (\n+            {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": NonParsableObject(),\n+            },\n+            \"firstDigits\",\n+        ),\n+    ],\n+)\n+def test_credit_card_info_schema_invalid(data, invalid_field):\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        CreditCardInfoSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"][0] == invalid_field\n+\n+\n+@pytest.mark.parametrize(\n+    \"field\",\n+    [\n+        \"brand\",\n+        \"lastDigits\",\n+        \"expYear\",\n+        \"expMonth\",\n+    ],\n+)\n+def test_credit_card_info_schema_required_field_is_none(field):\n+    # given\n+    data = {\n+        \"brand\": \"visa\",\n+        \"lastDigits\": \"1234\",\n+        \"expYear\": 2023,\n+        \"expMonth\": 12,\n+        \"firstDigits\": \"123456\",\n+    }\n+    data[field] = None\n+\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        CreditCardInfoSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"][0] == field\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # All fields\n+        {\n+            \"id\": \"method-1\",\n+            \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+            \"type\": \"Credit Card\",\n+            \"name\": \"Visa ***1234\",\n+            \"data\": {\"key\": \"value\"},\n+            \"creditCardInfo\": {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": \"1234\",\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+        },\n+        # Only required fields\n+        {\n+            \"id\": \"method-2\",\n+            \"type\": \"Credit Card\",\n+        },\n+        # Empty not required fields\n+        {\n+            \"id\": \"method-3\",\n+            \"supportedPaymentFlows\": None,\n+            \"type\": \"Credit Card\",\n+            \"name\": None,\n+            \"data\": None,\n+            \"creditCardInfo\": None,\n+        },\n+        # Empty list as supportedPaymentFlows\n+        {\n+            \"id\": \"method-4\",\n+            \"supportedPaymentFlows\": [],\n+            \"type\": \"Credit Card\",\n+        },\n+    ],\n+)\n+def test_stored_payment_method_schema_valid(data):\n+    # when\n+    schema = StoredPaymentMethodSchema.model_validate(data)\n+\n+    # then\n+    assert schema.id == data[\"id\"]\n+    assert schema.supported_payment_flows == [\n+        flow.lower() for flow in data.get(\"supportedPaymentFlows\") or []\n+    ]\n+    assert schema.type == data[\"type\"]\n+    assert schema.name == data.get(\"name\")\n+    assert schema.data == data.get(\"data\")\n+    if \"creditCardInfo\" in data and data[\"creditCardInfo\"]:\n+        assert schema.credit_card_info.brand == data[\"creditCardInfo\"][\"brand\"]\n+        assert (\n+            schema.credit_card_info.last_digits == data[\"creditCardInfo\"][\"lastDigits\"]\n+        )\n+        assert schema.credit_card_info.exp_year == data[\"creditCardInfo\"][\"expYear\"]\n+        assert schema.credit_card_info.exp_month == data[\"creditCardInfo\"][\"expMonth\"]\n+        assert (\n+            schema.credit_card_info.first_digits\n+            == data[\"creditCardInfo\"][\"firstDigits\"]\n+        )\n+    else:\n+        assert schema.credit_card_info is None\n+\n+\n+@pytest.mark.parametrize(\n+    (\"data\", \"invalid_field\"),\n+    [\n+        # Missing `id` field\n+        (\n+            {\n+                \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+                \"type\": \"Credit Card\",\n+            },\n+            \"id\",\n+        ),\n+        # Invalid `supportedPaymentFlows`\n+        (\n+            {\n+                \"id\": \"method-1\",\n+                \"supportedPaymentFlows\": [\"INVALID_FLOW\"],\n+                \"type\": \"Credit Card\",\n+            },\n+            \"supportedPaymentFlows\",\n+        ),\n+        # Missing `type` field\n+        (\n+            {\n+                \"id\": \"method-1\",\n+                \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+            },\n+            \"type\",\n+        ),\n+        # Not parable `data` field\n+        (\n+            {\n+                \"id\": \"method-1\",\n+                \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+                \"type\": \"Credit Card\",\n+                \"data\": object(),\n+            },\n+            \"data\",\n+        ),\n+    ],\n+)\n+def test_stored_payment_method_schema_invalid(data, invalid_field):\n+    # when\n+    with pytest.raises(ValidationError) as exc_info:\n+        StoredPaymentMethodSchema.model_validate(data)\n+\n+    # then\n+    assert len(exc_info.value.errors()) == 1\n+    assert exc_info.value.errors()[0][\"loc\"][0] == invalid_field\n+\n+\n+@patch.object(annotations_logger, \"warning\")\n+def test_stored_payment_method_schema_invalid_credit_card_info_skipped(\n+    mocked_logger, app\n+):\n+    # given\n+    id = \"method-1\"\n+    type = \"Credit Card\"\n+\n+    # when\n+    schema = StoredPaymentMethodSchema.model_validate(\n+        {\n+            \"id\": id,\n+            \"type\": type,\n+            \"creditCardInfo\": {\n+                \"brand\": \"visa\",\n+                \"lastDigits\": NonParsableObject(),\n+                \"expYear\": 2023,\n+                \"expMonth\": 12,\n+                \"firstDigits\": \"123456\",\n+            },\n+        },\n+        context={\n+            \"app\": app,\n+        },\n+    )\n+\n+    # then\n+    assert schema.credit_card_info is None\n+    assert schema.id == id\n+    assert schema.type == type\n+    assert mocked_logger.call_count == 1\n+    error_msg = mocked_logger.call_args[0][0]\n+    assert \"Skipping invalid value\" in error_msg\n+    assert mocked_logger.call_args[1][\"extra\"][\"app\"] == app.id\n+    assert mocked_logger.call_args[1][\"extra\"][\"field_name\"] == \"credit_card_info\"\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # All fields\n+        {\n+            \"paymentMethods\": [\n+                {\n+                    \"id\": \"method-1\",\n+                    \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+                    \"type\": \"Credit Card\",\n+                    \"name\": \"Visa ***1234\",\n+                    \"data\": {\"key\": \"value\"},\n+                    \"creditCardInfo\": {\n+                        \"brand\": \"visa\",\n+                        \"lastDigits\": \"1234\",\n+                        \"expYear\": 2023,\n+                        \"expMonth\": 12,\n+                        \"firstDigits\": \"123456\",\n+                    },\n+                },\n+                {\n+                    \"id\": \"method-2\",\n+                    \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+                    \"type\": \"Debit Card\",\n+                },\n+            ]\n+        },\n+        # Empty list ad paymentMethods\n+        {\"paymentMethods\": []},\n+        # None as paymentMethods\n+        {\"paymentMethods\": None},\n+        # Only required fields\n+        {\n+            \"paymentMethods\": [\n+                {\n+                    \"id\": \"method-3\",\n+                    \"type\": \"Credit Card\",\n+                }\n+            ]\n+        },\n+    ],\n+)\n+def test_list_stored_payment_methods_schema_valid(data):\n+    # when\n+    schema = ListStoredPaymentMethodsSchema.model_validate(data)\n+\n+    # then\n+    assert len(schema.payment_methods) == (\n+        len(data[\"paymentMethods\"]) if data[\"paymentMethods\"] else 0\n+    )\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [{}, {\"test\": \"invalid\"}],\n+)\n+def test_list_stored_payment_methods_schema_invalid(data):\n+    # when\n+    schema = ListStoredPaymentMethodsSchema.model_validate(data)\n+\n+    # then\n+    assert schema.payment_methods == []\n+\n+\n+@patch.object(annotations_logger, \"warning\")\n+def test_list_stored_payment_methods_schema_invalid_element_skipped(mocked_logger):\n+    \"\"\"Test when the input has one valid and one invalid stored payment method.\"\"\"\n+    # given a list with one valid and one invalid payment method\n+    data = {\n+        \"paymentMethods\": [\n+            {\n+                \"id\": \"method-1\",\n+                \"supportedPaymentFlows\": [\"INTERACTIVE\"],\n+                \"type\": \"Credit Card\",\n+                \"name\": \"Visa ***1234\",\n+            },\n+            # missing type\n+            {\n+                \"id\": \"method-2\",\n+                \"name\": \"Visa ***4321\",\n+            },\n+        ]\n+    }\n+\n+    # when\n+    schema = ListStoredPaymentMethodsSchema.model_validate(data)\n+\n+    # then only the valid payment method should be included\n+    assert len(schema.payment_methods) == 1\n+    assert schema.payment_methods[0].id == data[\"paymentMethods\"][0][\"id\"]\n+    assert schema.payment_methods[0].name == data[\"paymentMethods\"][0][\"name\"]\n+    assert mocked_logger.call_count == 1\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_shipping.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_shipping.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_shipping.py\t40f4e90 (parent)\n+++ saleor/webhook/tests/response_schemas/test_shipping.py\t1ef1f74 (commit)\n@@ -5,8 +5,9 @@\n import graphene\n import pytest\n from pydantic import ValidationError\n \n+from ...response_schemas.annotations import logger as annotations_logger\n from ...response_schemas.shipping import (\n     ExcludedShippingMethodSchema,\n     FilterShippingMethodsSchema,\n     ListShippingMethodsSchema,\n@@ -241,9 +242,9 @@\n     # Then the root should be an empty list\n     assert list_methods.root == []\n \n \n-@patch.object(logger, \"warning\")\n+@patch.object(annotations_logger, \"warning\")\n def test_list_shipping_methods_schema_invalid_element_skipped(mocked_logger, app):\n     \"\"\"Test when the provided input has 2 elements, one valid and one invalid.\"\"\"\n     # given a list with one valid and one invalid shipping method\n     data = [\n@@ -366,9 +367,14 @@\n         ]\n     }\n \n     # when\n-    schema = FilterShippingMethodsSchema.model_validate(data)\n+    schema = FilterShippingMethodsSchema.model_validate(\n+        data,\n+        context={\n+            \"custom_message\": \"Custom error while validating stored payment methods\"\n+        },\n+    )\n \n     # then only the valid shipping method should be included\n     assert len(schema.excluded_methods) == 2\n     assert schema.excluded_methods[0].id == data[\"excluded_methods\"][0][\"id\"]\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_validators.py",
          "status": "added",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_validators.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_validators.py\t40f4e90 (parent)\n+++ saleor/webhook/tests/response_schemas/test_validators.py\t1ef1f74 (commit)\n@@ -0,0 +1,19 @@\n+import pytest\n+\n+from saleor.webhook.response_schemas.validators import lower_values\n+\n+\n+@pytest.mark.parametrize(\n+    (\"input_value\", \"expected_output\"),\n+    [\n+        (\"HELLO\", \"hello\"),\n+        (\"world\", \"world\"),\n+        ([\"HELLO\", \"WORLD\"], [\"hello\", \"world\"]),\n+        ([\"Python\", \"TEST\"], [\"python\", \"test\"]),\n+        ([], []),\n+        (None, None),\n+        ([\"MiXeD\", \"CaSe\"], [\"mixed\", \"case\"]),\n+    ],\n+)\n+def test_lower_values(input_value, expected_output):\n+    assert lower_values(input_value) == expected_output\n"
        },
        {
          "path": "saleor/webhook/tests/test_utils.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/test_utils.py\n===================================================================\n--- saleor/webhook/tests/test_utils.py\t40f4e90 (parent)\n+++ saleor/webhook/tests/test_utils.py\t1ef1f74 (commit)\n@@ -1,22 +1,27 @@\n import copy\n+from unittest.mock import patch\n \n import pytest\n \n from ...app.models import App\n-from ...payment.interface import PaymentGateway\n+from ...payment.interface import (\n+    PaymentGateway,\n+    PaymentMethodCreditCardInfo,\n+    PaymentMethodData,\n+)\n from ..event_types import WebhookEventAsyncType, WebhookEventSyncType\n from ..models import Webhook\n from ..observability.exceptions import (\n     ApiCallTruncationError,\n     EventDeliveryAttemptTruncationError,\n     TruncationError,\n )\n from ..observability.payload_schema import ObservabilityEventTypes\n+from ..response_schemas.annotations import logger as annotations_logger\n from ..transport.list_stored_payment_methods import (\n-    get_credit_card_info,\n     get_list_stored_payment_methods_from_response,\n-    get_payment_method_from_response,\n+    logger,\n )\n from ..transport.utils import (\n     generate_cache_key_for_webhook,\n     to_payment_app_id,\n@@ -335,279 +340,108 @@\n     # then\n     assert cache_key_1 != cache_key_2\n \n \n-def test_get_credit_card_info(app):\n+@patch.object(annotations_logger, \"warning\")\n+def test_get_list_stored_payment_methods_from_response(\n+    mocked_logger, payment_method_response, app\n+):\n     # given\n-    brand = \"VISA\"\n-    last_digits = \"1234\"\n-    exp_year = \"2023\"\n-    exp_month = 1\n-    first_digits = \"4321\"\n+    # invalid second payment method due to to missing id\n+    second_payment_method = copy.deepcopy(payment_method_response)\n+    del second_payment_method[\"id\"]\n \n-    credit_card_info = {\n-        \"brand\": brand,\n-        \"lastDigits\": last_digits,\n-        \"expYear\": exp_year,\n-        \"expMonth\": exp_month,\n-        \"firstDigits\": first_digits,\n+    list_stored_payment_methods_response = {\n+        \"paymentMethods\": [payment_method_response, second_payment_method]\n     }\n+    currency = \"usd\"\n \n     # when\n-    response = get_credit_card_info(app, credit_card_info)\n-\n-    # then\n-    assert response.brand == brand\n-    assert response.last_digits == last_digits\n-    assert response.exp_year == int(exp_year)\n-    assert response.exp_month == exp_month\n-    assert response.first_digits == first_digits\n-\n-\n-def test_get_credit_card_info_without_first_digits_field(app):\n-    # given\n-    brand = \"VISA\"\n-    last_digits = \"1234\"\n-    exp_year = 2023\n-    exp_month = 1\n-\n-    credit_card_info = {\n-        \"brand\": brand,\n-        \"lastDigits\": last_digits,\n-        \"expYear\": exp_year,\n-        \"expMonth\": exp_month,\n-    }\n-\n-    # when\n-    response = get_credit_card_info(app, credit_card_info)\n-\n-    # then\n-    assert response.brand == brand\n-    assert response.last_digits == last_digits\n-    assert response.exp_year == exp_year\n-    assert response.exp_month == exp_month\n-    assert response.first_digits is None\n-\n-\n-@pytest.mark.parametrize(\n-    \"field\",\n-    [\n-        \"brand\",\n-        \"lastDigits\",\n-        \"expYear\",\n-        \"expMonth\",\n-    ],\n-)\n-def test_get_credit_card_info_missing_required_field(field, app):\n-    # given\n-    brand = \"VISA\"\n-    last_digits = \"1234\"\n-    exp_year = 2023\n-    exp_month = 1\n-    first_digits = \"4321\"\n-\n-    credit_card_info = {\n-        \"brand\": brand,\n-        \"lastDigits\": last_digits,\n-        \"expYear\": exp_year,\n-        \"expMonth\": exp_month,\n-        \"firstDigits\": first_digits,\n-    }\n-    del credit_card_info[field]\n-\n-    # when\n-    response = get_credit_card_info(app, credit_card_info)\n-\n-    # then\n-    assert response is None\n-\n-\n-@pytest.mark.parametrize(\n-    \"field\",\n-    [\n-        \"brand\",\n-        \"lastDigits\",\n-        \"expYear\",\n-        \"expMonth\",\n-    ],\n-)\n-def test_get_credit_card_info_required_field_is_none(field, app):\n-    # given\n-    brand = \"VISA\"\n-    last_digits = \"1234\"\n-    exp_year = 2023\n-    exp_month = 1\n-    first_digits = \"4321\"\n-\n-    credit_card_info = {\n-        \"brand\": brand,\n-        \"lastDigits\": last_digits,\n-        \"expYear\": exp_year,\n-        \"expMonth\": exp_month,\n-        \"firstDigits\": first_digits,\n-    }\n-    credit_card_info[field] = None\n-\n-    # when\n-    response = get_credit_card_info(app, credit_card_info)\n-\n-    # then\n-    assert response is None\n-\n-\n-@pytest.mark.parametrize(\"exp_year\", [None, \"\", \"str\"])\n-def test_get_credit_card_info_incorrect_exp_year(exp_year, app):\n-    # given\n-    brand = \"VISA\"\n-    last_digits = \"1234\"\n-    exp_month = 1\n-    first_digits = \"4321\"\n-\n-    credit_card_info = {\n-        \"brand\": brand,\n-        \"lastDigits\": last_digits,\n-        \"expYear\": exp_year,\n-        \"expMonth\": exp_month,\n-        \"firstDigits\": first_digits,\n-    }\n-\n-    # when\n-    response = get_credit_card_info(app, credit_card_info)\n-\n-    # then\n-    assert response is None\n-\n-\n-@pytest.mark.parametrize(\"exp_month\", [None, \"\", \"str\"])\n-def test_get_credit_card_info_incorrect_exp_month(exp_month, app):\n-    # given\n-    brand = \"VISA\"\n-    last_digits = \"1234\"\n-    exp_year = 2023\n-    first_digits = \"4321\"\n-\n-    credit_card_info = {\n-        \"brand\": brand,\n-        \"lastDigits\": last_digits,\n-        \"expYear\": exp_year,\n-        \"expMonth\": exp_month,\n-        \"firstDigits\": first_digits,\n-    }\n-\n-    # when\n-    response = get_credit_card_info(app, credit_card_info)\n-\n-    # then\n-    assert response is None\n-\n-\n-def test_get_payment_method_from_response(payment_method_response, app):\n-    # when\n-    payment_method = get_payment_method_from_response(\n-        app, payment_method_response, \"usd\"\n+    response = get_list_stored_payment_methods_from_response(\n+        app, list_stored_payment_methods_response, currency\n     )\n \n     # then\n-    assert payment_method.id == to_payment_app_id(app, payment_method_response[\"id\"])\n-    assert payment_method.external_id == payment_method_response[\"id\"]\n-    assert payment_method.type == payment_method_response[\"type\"]\n-    assert payment_method.gateway == PaymentGateway(\n-        id=app.identifier, name=app.name, currencies=[\"usd\"], config=[]\n+    assert len(response) == 1\n+    assert response[0] == PaymentMethodData(\n+        id=to_payment_app_id(app, payment_method_response[\"id\"]),\n+        external_id=payment_method_response[\"id\"],\n+        supported_payment_flows=[\n+            flow.lower()\n+            for flow in payment_method_response.get(\"supportedPaymentFlows\", [])\n+        ],\n+        type=payment_method_response[\"type\"],\n+        credit_card_info=PaymentMethodCreditCardInfo(\n+            brand=payment_method_response[\"creditCardInfo\"][\"brand\"],\n+            last_digits=payment_method_response[\"creditCardInfo\"][\"lastDigits\"],\n+            exp_year=payment_method_response[\"creditCardInfo\"][\"expYear\"],\n+            exp_month=payment_method_response[\"creditCardInfo\"][\"expMonth\"],\n+            first_digits=payment_method_response[\"creditCardInfo\"].get(\"firstDigits\"),\n+        )\n+        if payment_method_response.get(\"creditCardInfo\")\n+        else None,\n+        name=payment_method_response[\"name\"],\n+        data=payment_method_response[\"data\"],\n+        gateway=PaymentGateway(\n+            id=app.identifier,\n+            name=app.name,\n+            currencies=[currency],\n+            config=[],\n+        ),\n     )\n-    assert payment_method.supported_payment_flows == [\n-        flow.lower() for flow in payment_method_response[\"supportedPaymentFlows\"]\n-    ]\n-    assert payment_method.credit_card_info == get_credit_card_info(\n-        app, payment_method_response[\"creditCardInfo\"]\n-    )\n-    assert payment_method.name == payment_method_response[\"name\"]\n-    assert payment_method.data == payment_method_response[\"data\"]\n+    assert mocked_logger.call_count == 1\n+    error_msg = mocked_logger.call_args[0][1]\n+    assert error_msg == \"Skipping invalid stored payment method\"\n+    assert mocked_logger.call_args[1][\"extra\"][\"app\"] == app.id\n \n \n-@pytest.mark.parametrize(\"field\", [\"id\", \"type\", \"supportedPaymentFlows\"])\n-def test_get_payment_method_from_response_missing_required_field(\n-    field, payment_method_response, app\n-):\n+def test_get_list_stored_payment_methods_from_response_only_required_fields(app):\n     # given\n-    del payment_method_response[field]\n+    payment_method_response = {\n+        \"id\": \"method-1\",\n+        \"type\": \"Credit Card\",\n+    }\n \n-    # when\n-    payment_method = get_payment_method_from_response(\n-        app, payment_method_response, \"usd\"\n-    )\n+    list_stored_payment_methods_response = {\"paymentMethods\": [payment_method_response]}\n+    currency = \"usd\"\n \n-    # then\n-    assert payment_method is None\n-\n-\n-@pytest.mark.parametrize(\"field\", [\"creditCardInfo\", \"name\", \"data\"])\n-def test_get_payment_method_from_response_optional_field(\n-    field, payment_method_response, app\n-):\n-    del payment_method_response[field]\n-\n     # when\n-    payment_method = get_payment_method_from_response(\n-        app, payment_method_response, \"usd\"\n+    response = get_list_stored_payment_methods_from_response(\n+        app, list_stored_payment_methods_response, currency\n     )\n \n     # then\n-    assert payment_method.id == to_payment_app_id(app, payment_method_response[\"id\"])\n-    assert payment_method.external_id == payment_method_response[\"id\"]\n-    assert payment_method.type == payment_method_response[\"type\"]\n-    assert payment_method.gateway == PaymentGateway(\n-        id=app.identifier, name=app.name, currencies=[\"usd\"], config=[]\n+    assert len(response) == 1\n+    assert response[0] == PaymentMethodData(\n+        id=to_payment_app_id(app, payment_method_response[\"id\"]),\n+        external_id=payment_method_response[\"id\"],\n+        supported_payment_flows=[],\n+        type=payment_method_response[\"type\"],\n+        credit_card_info=None,\n+        gateway=PaymentGateway(\n+            id=app.identifier,\n+            name=app.name,\n+            currencies=[currency],\n+            config=[],\n+        ),\n     )\n-    assert payment_method.supported_payment_flows == [\n-        flow.lower() for flow in payment_method_response[\"supportedPaymentFlows\"]\n-    ]\n \n \n-@pytest.mark.parametrize(\"field\", [\"id\", \"type\", \"supportedPaymentFlows\"])\n-def test_get_payment_method_from_response_required_field_is_none(\n-    field, payment_method_response, app\n+@patch.object(logger, \"warning\")\n+def test_get_list_stored_payment_methods_from_response_invalid_input_data(\n+    mocked_logger, app\n ):\n     # given\n-    payment_method_response[field] = None\n+    list_stored_payment_methods_response = None\n+    currency = \"usd\"\n \n     # when\n-    payment_method = get_payment_method_from_response(\n-        app, payment_method_response, \"usd\"\n-    )\n-\n-    # then\n-    assert payment_method is None\n-\n-\n-def test_get_payment_method_from_response_incorrect_payment_flow_choices(\n-    payment_method_response, app\n-):\n-    # given\n-    payment_method_response[\"supportedPaymentFlows\"] = [\"incorrect\", \"INTERACTIVE\"]\n-\n-    # when\n-    payment_method = get_payment_method_from_response(\n-        app, payment_method_response, \"usd\"\n-    )\n-\n-    # then\n-    assert payment_method is None\n-\n-\n-def test_get_list_stored_payment_methods_from_response(payment_method_response, app):\n-    # given\n-    second_payment_method = copy.deepcopy(payment_method_response)\n-    del second_payment_method[\"id\"]\n-    list_stored_payment_methods_response = {\n-        \"paymentMethods\": [payment_method_response, second_payment_method]\n-    }\n-\n-    # when\n     response = get_list_stored_payment_methods_from_response(\n-        app, list_stored_payment_methods_response, \"usd\"\n+        app, list_stored_payment_methods_response, currency\n     )\n \n     # then\n-    assert len(response) == 1\n-    assert response == [\n-        get_payment_method_from_response(app, payment_method_response, \"usd\")\n-    ]\n+    assert response == []\n+    assert mocked_logger.call_count == 1\n+    error_msg = mocked_logger.call_args[0][0]\n+    assert \"Skipping stored payment methods from app\" in error_msg\n+    assert mocked_logger.call_args[1][\"extra\"][\"app\"] == app.id\n"
        },
        {
          "path": "saleor/webhook/transport/list_stored_payment_methods.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/list_stored_payment_methods.py\n===================================================================\n--- saleor/webhook/transport/list_stored_payment_methods.py\t40f4e90 (parent)\n+++ saleor/webhook/transport/list_stored_payment_methods.py\t1ef1f74 (commit)\n@@ -1,11 +1,11 @@\n import logging\n \n import graphene\n from django.core.cache import cache\n+from pydantic import ValidationError\n \n from ...app.models import App\n-from ...payment import TokenizedPaymentFlow\n from ...payment.interface import (\n     PaymentGateway,\n     PaymentGatewayInitializeTokenizationResponseData,\n     PaymentGatewayInitializeTokenizationResult,\n@@ -17,139 +17,56 @@\n     StoredPaymentMethodRequestDeleteResult,\n )\n from ...webhook.event_types import WebhookEventSyncType\n from ...webhook.utils import get_webhooks_for_event\n+from ..response_schemas.payment import ListStoredPaymentMethodsSchema\n from .utils import generate_cache_key_for_webhook, to_payment_app_id\n \n logger = logging.getLogger(__name__)\n \n \n-def get_credit_card_info(\n-    app: App, credit_card_info: dict\n-) -> PaymentMethodCreditCardInfo | None:\n-    required_fields = [\n-        \"brand\",\n-        \"lastDigits\",\n-        \"expYear\",\n-        \"expMonth\",\n-    ]\n-    brand = credit_card_info.get(\"brand\")\n-    last_digits = credit_card_info.get(\"lastDigits\")\n-    exp_year = credit_card_info.get(\"expYear\")\n-    exp_month = credit_card_info.get(\"expMonth\")\n-    first_digits = credit_card_info.get(\"firstDigits\")\n-    if not all(field in credit_card_info for field in required_fields):\n+def get_list_stored_payment_methods_from_response(\n+    app: \"App\", response_data: dict, currency: str\n+) -> list[\"PaymentMethodData\"]:\n+    try:\n+        stored_payment_methods_model = ListStoredPaymentMethodsSchema.model_validate(\n+            response_data,\n+            context={\n+                \"custom_message\": \"Skipping invalid stored payment method\",\n+                \"app\": app,\n+            },\n+        )\n+    except ValidationError as e:\n         logger.warning(\n-            \"Skipping stored payment method. Missing required fields for credit card \"\n-            \"info. Required fields: %s, received fields: %s from app %s.\",\n-            required_fields,\n-            credit_card_info.keys(),\n+            \"Skipping stored payment methods from app %s. Error: %s\",\n             app.id,\n+            str(e),\n+            extra={\"app\": app.id},\n         )\n-        return None\n-    if not all([brand, last_digits, exp_year, exp_month]):\n-        logger.warning(\"Skipping stored credit card info without required fields\")\n-        return None\n-    if not isinstance(exp_year, int):\n-        if isinstance(exp_year, str) and exp_year.isdigit():\n-            exp_year = int(exp_year)\n-        else:\n-            logger.warning(\n-                \"Skipping stored payment method with invalid expYear, \"\n-                \"received from app %s\",\n-                app.id,\n-            )\n-            return None\n+        return []\n \n-    if not isinstance(exp_month, int):\n-        if isinstance(exp_month, str) and exp_month.isdigit():\n-            exp_month = int(exp_month)\n-        else:\n-            logger.warning(\n-                \"Skipping stored payment method with invalid expMonth, \"\n-                \"received from app %s\",\n-                app.id,\n+    app_identifier = app.identifier\n+    return [\n+        PaymentMethodData(\n+            id=to_payment_app_id(app, payment_method.id),\n+            external_id=payment_method.id,\n+            supported_payment_flows=payment_method.supported_payment_flows,\n+            type=payment_method.type,\n+            credit_card_info=PaymentMethodCreditCardInfo(\n+                **dict(payment_method.credit_card_info),\n             )\n-            return None\n-\n-    return PaymentMethodCreditCardInfo(\n-        brand=str(brand),\n-        last_digits=str(last_digits),\n-        exp_year=exp_year,\n-        exp_month=exp_month,\n-        first_digits=str(first_digits) if first_digits else None,\n-    )\n-\n-\n-def get_payment_method_from_response(\n-    app: \"App\", payment_method: dict, currency: str\n-) -> PaymentMethodData | None:\n-    payment_method_external_id = payment_method.get(\"id\")\n-    if not payment_method_external_id:\n-        logger.warning(\n-            \"Skipping stored payment method without id, received from app %s\", app.id\n+            if payment_method.credit_card_info\n+            else None,\n+            name=payment_method.name,\n+            data=payment_method.data,\n+            gateway=PaymentGateway(\n+                id=app_identifier, name=app.name, currencies=[currency], config=[]\n+            ),\n         )\n-        return None\n-    payment_method_type = payment_method.get(\"type\")\n-    if not payment_method_type:\n-        logger.warning(\n-            \"Skipping stored payment method without type, received from app %s\",\n-            app.id,\n-        )\n-        return None\n+        for payment_method in stored_payment_methods_model.payment_methods\n+    ]\n \n-    supported_payment_flows = payment_method.get(\"supportedPaymentFlows\")\n-    if not supported_payment_flows or not isinstance(supported_payment_flows, list):\n-        logger.warning(\n-            \"Skipping stored payment method with incorrect `supportedPaymentFlows`, \"\n-            \"received from app %s\",\n-            app.id,\n-        )\n-        return None\n-    payment_flow_choices = {\n-        flow[0].upper(): flow[0] for flow in TokenizedPaymentFlow.CHOICES\n-    }\n-    if set(supported_payment_flows).difference(payment_flow_choices.keys()):\n-        logger.warning(\n-            \"Skipping stored payment method with unsupported payment flows, \"\n-            \"received from app %s\",\n-            app.id,\n-        )\n-        return None\n-    app_identifier = app.identifier\n-    credit_card_info = payment_method.get(\"creditCardInfo\")\n-    name = payment_method.get(\"name\")\n-    return PaymentMethodData(\n-        id=to_payment_app_id(app, payment_method_external_id),\n-        external_id=payment_method_external_id,\n-        supported_payment_flows=[\n-            payment_flow_choices[flow] for flow in supported_payment_flows\n-        ],\n-        type=payment_method_type,\n-        credit_card_info=get_credit_card_info(app, credit_card_info)\n-        if credit_card_info\n-        else None,\n-        name=name if name else None,\n-        data=payment_method.get(\"data\"),\n-        gateway=PaymentGateway(\n-            id=app_identifier, name=app.name, currencies=[currency], config=[]\n-        ),\n-    )\n \n-\n-def get_list_stored_payment_methods_from_response(\n-    app: \"App\", response_data: dict, currency: str\n-) -> list[\"PaymentMethodData\"]:\n-    payment_methods_response = response_data.get(\"paymentMethods\", [])\n-    payment_methods = []\n-    for payment_method in payment_methods_response:\n-        if parsed_payment_method := get_payment_method_from_response(\n-            app, payment_method, currency\n-        ):\n-            payment_methods.append(parsed_payment_method)\n-    return payment_methods\n-\n-\n def get_response_for_stored_payment_method_request_delete(\n     response_data: dict | None,\n ) -> \"StoredPaymentMethodRequestDeleteResponseData\":\n     if response_data is None:\n"
        },
        {
          "path": "saleor/webhook/transport/shipping.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/shipping.py\n===================================================================\n--- saleor/webhook/transport/shipping.py\t40f4e90 (parent)\n+++ saleor/webhook/transport/shipping.py\t1ef1f74 (commit)\n@@ -31,9 +31,13 @@\n     response_data: Any, app: \"App\"\n ) -> list[\"ShippingMethodData\"]:\n     try:\n         list_shipping_method_model = ListShippingMethodsSchema.model_validate(\n-            response_data, context={\"app\": app}\n+            response_data,\n+            context={\n+                \"app\": app,\n+                \"custom_message\": \"Skipping invalid shipping method (ListShippingMethodsSchema)\",\n+            },\n         )\n     except ValidationError:\n         logger.warning(\"Skipping invalid shipping method response: %s\", response_data)\n         return []\n@@ -161,9 +165,12 @@\n ) -> list[ExcludedShippingMethodSchema]:\n     excluded_methods = []\n     try:\n         filter_methods_schema = FilterShippingMethodsSchema.model_validate(\n-            response_data\n+            response_data,\n+            context={\n+                \"custom_message\": \"Skipping invalid shipping method (FilterShippingMethodsSchema)\"\n+            },\n         )\n         excluded_methods.extend(filter_methods_schema.excluded_methods)\n     except ValidationError:\n         logger.warning(\n"
        }
      ]
    },
    {
      "id": "update-denorm-discounts",
      "sha": "d7b03a3eeec016efdcc6119ae4cd77726df9b282",
      "parentSha": "ffc07d1c48d62b60bb9c74760241232b13db3f77",
      "spec": "Implement unified, object-driven handling of order line denormalized discount fields across promotions, vouchers, and manual discounts by introducing a DiscountInfo dataclass and refactoring functions to use it and discount objects directly.\n\n1) Add DiscountInfo dataclass\n- File: saleor/discount/interface.py\n- Add: from decimal import Decimal; from . import DiscountType, DiscountValueType; from .models import PromotionRule, Voucher\n- Define dataclass DiscountInfo with fields:\n  - currency: str (required)\n  - type: str = DiscountType.MANUAL\n  - value_type: str = DiscountValueType.FIXED\n  - value: Decimal = Decimal(\"0.0\")\n  - amount_value: Decimal = Decimal(\"0.0\")\n  - name: str | None = None\n  - translated_name: str | None = None\n  - reason: str | None = None\n  - promotion_rule: PromotionRule | None = None\n  - voucher: Voucher | None = None\n  - voucher_code: str | None = None\n\n2) Refactor order discount utilities to operate on model instances and update denormalized fields\n- File: saleor/discount/utils/order.py\n- create_order_line_discount_objects: change signature to accept discount_data where the first element is list[OrderLineDiscount] (not list[dict]). Bulk create the provided OrderLineDiscount instances directly.\n- Add helper _create_order_line_discount_for_catalogue_promotion(line, rule_info, channel) -> OrderLineDiscount that returns a fully constructed model object including: type=DiscountType.PROMOTION, value_type=rule.reward_value_type, value=rule.reward_value, amount_value computed by _get_rule_discount_amount, currency=line.currency, name, translated_name, reason via helpers, promotion_rule=rule, unique_type=DiscountType.PROMOTION.\n- create_order_line_discount_objects_for_catalogue_promotions: build a list[OrderLineDiscount] via the helper and bulk_create them; return list[OrderLineDiscount].\n- prepare_order_line_discount_objects_for_catalogue_promotions: return a tuple where the first element is list[OrderLineDiscount] to create (built via helper) instead of list[dict]; when updating, recompute rule_discount_amount and pass to update_promotion_discount; unchanged updated_fields handling.\n- Replace update_unit_discount_data_on_order_line(lines_info) with two functions:\n  - update_unit_discount_data_on_order_line(line: OrderLine, discounts: list[OrderLineDiscount]):\n    - unit_discount_reason: join non-empty reasons with \"; \", or None\n    - unit_discount_amount: quantize_price(sum(discount.amount_value) / line.quantity, line.currency) or Decimal(\"0.0\") if no discounts\n    - If multiple discounts: unit_discount_type = DiscountValueType.FIXED and unit_discount_value = unit_discount_amount; else if single discount: unit_discount_type = discount.value_type and unit_discount_value = discount.value; if none: type=None, value=Decimal(\"0.0\")\n    - Set the four unit_discount_... fields on line\n  - update_unit_discount_data_on_order_lines_info(lines_info): iterate all and call the per-line function using line_info.discounts\n\n3) Refactor promotion utilities to use DiscountInfo and set gift line denormalized fields\n- File: saleor/discount/utils/promotion.py\n- Imports: from dataclasses import asdict; cast; import DiscountInfo from discount.interface\n- create_discount_objects_for_order_promotions: instead of dict defaults, create a DiscountInfo with type=DiscountType.ORDER_PROMOTION, promotion_rule, value_type (or RewardValueType.FIXED for gifts), value (reward or amount_value), amount_value, currency, name, translated_name, and reason.\n- _handle_order_promotion: use asdict(line_discount_data) in get_or_create defaults; discount_amount = line_discount_data.amount_value; when updating with update_promotion_discount, pass the promotion_rule cast from line_discount_data; save fields_to_update if any.\n- _handle_gift_reward: pass line_discount_data to create_gift_line and use asdict(line_discount_data) in get_or_create defaults; when updating, use promotion_rule cast from line_discount and line_discount_data.amount_value.\n- create_gift_line signature: add line_discount_data: DiscountInfo. _get_defaults_for_gift_line should set unit_discount_amount, unit_discount_value, unit_discount_reason, unit_discount_type using line_discount_data on gift line defaults in addition to existing defaults.\n\n4) Refactor voucher utilities to use DiscountInfo and update denormalized line fields\n- File: saleor/discount/utils/voucher.py\n- Imports: from dataclasses import asdict; import DiscountInfo and VoucherInfo from discount.interface\n- create_or_update_voucher_discount_objects_for_order: after updating line discounts, bulk_update order lines with [\"base_unit_price_amount\", \"unit_discount_amount\", \"unit_discount_reason\", \"unit_discount_type\", \"unit_discount_value\"].\n- create_or_update_discount_object_from_order_level_voucher: build DiscountInfo with voucher, value_type, value, amount_value, currency, reason, name, type=DiscountType.VOUCHER, voucher_code, translated_name=\"\"; get_or_create discount on order.discounts with defaults=asdict(discount_data). For updates, keep existing update_discount logic.\n- prepare_line_discount_objects_for_voucher: first tuple element should be list[OrderLineDiscount] instances constructed directly (not dicts) with the appropriate fields (line, type=DiscountType.VOUCHER, value_type, value, amount_value (Money.amount), currency, name, translated_name=None, reason, voucher, unique_type=DiscountType.VOUCHER, voucher_code).\n- create_or_update_line_discount_objects_from_voucher: replace calls to update_unit_discount_data_on_order_line with update_unit_discount_data_on_order_lines_info; if modified lines exist, reduce base unit price, then update denormalized discount fields for those lines.\n\n5) Adjust GraphQL checkout gift reward creation to use DiscountInfo\n- File: saleor/graphql/checkout/mutations/utils.py\n- Imports: from dataclasses import asdict; from ....discount.interface import DiscountInfo\n- apply_gift_reward_if_applicable_on_checkout_creation: build a DiscountInfo with type=ORDER_PROMOTION, amount_value=best_discount_amount, value_type=DiscountValueType.FIXED, value=best_discount_amount, promotion_rule, currency; pass to create_gift_line; create CheckoutLineDiscount with asdict(line_discount_data) and line=line.\n\n6) Centralize when denormalized unit discount fields are persisted during calculations\n- File: saleor/order/calculations.py\n- Update import to use update_unit_discount_data_on_order_lines_info.\n- In fetch_order_prices_if_expired, remove the call that updated denormalized unit discount fields before price calculation. Do not include unit_discount fields (amount, reason, type, value) in this function's lines bulk_update list. Persist unit discount field updates in flows that specifically update discounts (e.g., refresh_order_base_prices_and_discounts and voucher/promotion handlers) where the unit_discount fields are explicitly bulk-updated.\n- In refresh_order_base_prices_and_discounts, replace update_unit_discount_data_on_order_line with update_unit_discount_data_on_order_lines_info; retain bulk_update for unit_discount fields (already present there): [\"unit_discount_amount\", \"unit_discount_reason\", \"unit_discount_type\", \"unit_discount_value\", ...].\n\n7) Update order line creation and manual discount update logic to rely on discount objects\n- File: saleor/order/utils.py\n- create_order_line: when unit_discount exists and rules_info provided, create catalogue discounts, set sale_id, then set denormalized discount fields by calling update_unit_discount_data_on_order_line(line, line_discounts). Save line with update_fields including \"unit_discount_amount\", \"unit_discount_value\", \"unit_discount_reason\", \"unit_discount_type\", \"sale_id\". Remove previous direct computation of unit_discount based on tax config when no discount objects are created.\n- update_discount_for_order_line: rework to operate on OrderLineDiscount objects instead of writing denormalized fields first.\n  - Load existing discounts, remove all except at most one MANUAL type using helper _remove_invalid_discounts_for_adding_manual.\n  - Ensure a MANUAL OrderLineDiscount exists (create if needed with type=MANUAL, currency=order.currency, unique_type=MANUAL) and determine value/value_type defaults.\n  - Update the manual discount object using helper _update_order_line_discount_object(value, value_type, reason, quantity, base_unit_price=order_line.undiscounted_base_unit_price), which recalculates amount_value based on the delta between undiscounted and discounted base unit prices.\n  - Recompute line.base_unit_price from apply_discount_to_value; update denormalized unit discount fields via update_unit_discount_data_on_order_line(order_line, line_discounts). Save only [\"unit_discount_value\", \"unit_discount_amount\", \"unit_discount_type\", \"unit_discount_reason\", \"base_unit_price_amount\"].\n  - Add helpers: _remove_invalid_discounts_for_adding_manual(order_line_discounts), _get_manual_order_line_discount(order_line_discounts) -> OrderLineDiscount | None, and _update_order_line_discount_object(...) to set value/value_type/reason, recalc amount_value across quantity, and save updated fields.\n- remove_discount_from_order_line: delete all line.discounts, reset denormalized fields using update_unit_discount_data_on_order_line(order_line, []), set base_unit_price to undiscounted, and save with update_fields including unit discount fields, base_unit_price_amount, total/unit price fields remain managed by recalculation flows.\n\n8) Quantization and unit discount expectations in tests\n- Ensure all places that set unit_discount_amount (especially for vouchers and gift lines) quantize the per-unit value with quantize_price(value, currency). In cases of single-discount vs multi-discount, set denormalized type and value according to rule above. This is enforced by tests that now assert quantized unit_discount amounts and updated behavior for gifts and vouchers.\n\nNote: Rename calls in code that previously used update_unit_discount_data_on_order_line(list_of_lines_info) to update_unit_discount_data_on_order_lines_info where applicable.\n",
      "prompt": "Unify and fix how line-level discount data is denormalized and persisted across the system. Introduce a common discount info structure that can be used across promotions, vouchers, and checkout/order flows. Ensure denormalized order line fields (unit_discount_amount, unit_discount_reason, unit_discount_type, unit_discount_value) are derived from the actual discount objects, properly quantized per currency, and updated at the right points in the flows (catalogue promotions, voucher application, and manual line discount updates). Update gift line creation to set these denormalized fields at creation based on the discount info. Replace ad-hoc dict-based discount creation with model instances and use the new structure consistently, including in checkout gift reward handling. Adjust calculations so denormalized discount fields aren’t redundantly updated during generic price recalculations, but are persisted when discount objects are actually created or updated.",
      "supplementalFiles": [
        "saleor/discount/models.py",
        "saleor/discount/utils/manual_discount.py",
        "saleor/discount/utils/shared.py",
        "saleor/order/models.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/discount/interface.py",
          "status": "modified",
          "diff": "Index: saleor/discount/interface.py\n===================================================================\n--- saleor/discount/interface.py\tffc07d1 (parent)\n+++ saleor/discount/interface.py\td7b03a3 (commit)\n@@ -1,8 +1,10 @@\n from dataclasses import dataclass\n+from decimal import Decimal\n from typing import TYPE_CHECKING, NamedTuple, Optional\n \n-from .models import Voucher\n+from . import DiscountType, DiscountValueType\n+from .models import PromotionRule, Voucher\n \n if TYPE_CHECKING:\n     from ..product.models import (\n         ProductVariantChannelListing,\n@@ -16,8 +18,28 @@\n     )\n \n \n @dataclass\n+class DiscountInfo:\n+    \"\"\"It stores the discount details.\n+\n+    The dataclass used to represent the discount before storing it on database side.\n+    \"\"\"\n+\n+    currency: str\n+    type: str = DiscountType.MANUAL\n+    value_type: str = DiscountValueType.FIXED\n+    value: Decimal = Decimal(\"0.0\")\n+    amount_value: Decimal = Decimal(\"0.0\")\n+    name: str | None = None\n+    translated_name: str | None = None\n+    reason: str | None = None\n+    promotion_rule: PromotionRule | None = None\n+    voucher: Voucher | None = None\n+    voucher_code: str | None = None\n+\n+\n+@dataclass\n class VoucherInfo:\n     \"\"\"It contains the voucher's details and PKs of all applicable objects.\"\"\"\n \n     voucher: Voucher\n"
        },
        {
          "path": "saleor/discount/tests/test_utils/test_copy_unit_discount_data_to_order_line.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tests/test_utils/test_copy_unit_discount_data_to_order_line.py\n===================================================================\n--- saleor/discount/tests/test_utils/test_copy_unit_discount_data_to_order_line.py\tffc07d1 (parent)\n+++ saleor/discount/tests/test_utils/test_copy_unit_discount_data_to_order_line.py\td7b03a3 (commit)\n@@ -4,9 +4,9 @@\n \n from ....order.fetch import fetch_draft_order_lines_info\n from ... import DiscountType, DiscountValueType\n from ...models import PromotionRule\n-from ...utils.order import update_unit_discount_data_on_order_line\n+from ...utils.order import update_unit_discount_data_on_order_lines_info\n \n \n def test_copy_unit_discount_data_to_order_line_multiple_discounts(\n     order_with_lines_and_catalogue_promotion,\n@@ -37,9 +37,9 @@\n     assert line.discounts.count() == 2\n     lines_info = fetch_draft_order_lines_info(order)\n \n     # when\n-    update_unit_discount_data_on_order_line(lines_info)\n+    update_unit_discount_data_on_order_lines_info(lines_info)\n \n     # then\n     line = lines_info[0].line\n     assert line.unit_discount_amount == rule_reward_value + manual_reward_value\n@@ -67,9 +67,9 @@\n     assert line.discounts.count() == 1\n     lines_info = fetch_draft_order_lines_info(order)\n \n     # when\n-    update_unit_discount_data_on_order_line(lines_info)\n+    update_unit_discount_data_on_order_lines_info(lines_info)\n \n     # then\n     line = lines_info[0].line\n     assert line.unit_discount_amount == rule_reward_value\n@@ -85,9 +85,9 @@\n     assert not line.discounts.exists()\n     lines_info = fetch_draft_order_lines_info(order)\n \n     # when\n-    update_unit_discount_data_on_order_line(lines_info)\n+    update_unit_discount_data_on_order_lines_info(lines_info)\n \n     # then\n     line = lines_info[0].line\n     assert line.unit_discount_amount == Decimal(0)\n"
        },
        {
          "path": "saleor/discount/tests/test_utils/test_create_or_update_discount_objects_from_promotion_for_order.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tests/test_utils/test_create_or_update_discount_objects_from_promotion_for_order.py\n===================================================================\n--- saleor/discount/tests/test_utils/test_create_or_update_discount_objects_from_promotion_for_order.py\tffc07d1 (parent)\n+++ saleor/discount/tests/test_utils/test_create_or_update_discount_objects_from_promotion_for_order.py\td7b03a3 (commit)\n@@ -7,9 +7,9 @@\n     ProductVariantChannelListing,\n     VariantChannelListingPromotionRule,\n )\n from ....warehouse.models import Stock\n-from ... import DiscountType, RewardType, RewardValueType\n+from ... import DiscountType, DiscountValueType, RewardType, RewardValueType\n from ...interface import VariantPromotionRuleInfo, fetch_variant_rules_info\n from ...models import OrderDiscount, OrderLineDiscount\n from ...utils.order import (\n     create_order_discount_objects_for_order_promotions,\n@@ -268,11 +268,11 @@\n     assert gift_line.undiscounted_total_price_net_amount == Decimal(0)\n     assert gift_line.unit_price_gross_amount == Decimal(0)\n     assert gift_line.unit_price_net_amount == Decimal(0)\n     assert gift_line.base_unit_price_amount == Decimal(0)\n-    assert gift_line.unit_discount_amount == Decimal(0)\n-    assert gift_line.unit_discount_type is None\n-    assert gift_line.unit_discount_value == Decimal(0)\n+    assert gift_line.unit_discount_amount == listing.price_amount\n+    assert gift_line.unit_discount_type == DiscountValueType.FIXED\n+    assert gift_line.unit_discount_value == listing.price_amount\n     assert gift_line.product_name == product.name\n     assert gift_line.product_sku == variant.sku\n \n \n"
        },
        {
          "path": "saleor/discount/tests/test_utils/test_create_voucher_discount_object_for_order.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tests/test_utils/test_create_voucher_discount_object_for_order.py\n===================================================================\n--- saleor/discount/tests/test_utils/test_create_voucher_discount_object_for_order.py\tffc07d1 (parent)\n+++ saleor/discount/tests/test_utils/test_create_voucher_discount_object_for_order.py\td7b03a3 (commit)\n@@ -6,16 +6,10 @@\n from ....core.taxes import zero_money\n from ....order import OrderStatus\n from ....order.calculations import fetch_order_prices_if_expired\n from ... import DiscountType, DiscountValueType, VoucherType\n-from ...models import (\n-    OrderDiscount,\n-    OrderLineDiscount,\n-    PromotionRule,\n-)\n-from ...utils.voucher import (\n-    create_or_update_voucher_discount_objects_for_order,\n-)\n+from ...models import OrderDiscount, OrderLineDiscount, PromotionRule\n+from ...utils.voucher import create_or_update_voucher_discount_objects_for_order\n \n \n def test_create_discount_for_voucher_specific_product_fixed(\n     order_with_lines,\n@@ -299,9 +293,11 @@\n         == discounted_line.undiscounted_base_unit_price_amount\n         * discounted_line.quantity\n         * tax_rate\n     )\n-    assert discounted_line.unit_discount_amount == unit_discount_amount\n+    assert discounted_line.unit_discount_amount == quantize_price(\n+        unit_discount_amount, currency\n+    )\n     assert discounted_line.unit_discount_type == DiscountValueType.PERCENTAGE\n     assert discounted_line.unit_discount_reason == f\"Voucher code: {order.voucher_code}\"\n \n     assert line_1.base_unit_price_amount == line_1.undiscounted_base_unit_price_amount\n@@ -405,9 +401,11 @@\n         == discounted_line.undiscounted_base_unit_price_amount\n         * discounted_line.quantity\n         * tax_rate\n     )\n-    assert discounted_line.unit_discount_amount == unit_discount_amount\n+    assert discounted_line.unit_discount_amount == quantize_price(\n+        unit_discount_amount, currency\n+    )\n     assert discounted_line.unit_discount_type == DiscountValueType.FIXED\n     assert discounted_line.unit_discount_reason == f\"Voucher code: {order.voucher_code}\"\n \n     assert line_1.base_unit_price_amount == line_1.undiscounted_base_unit_price_amount\n"
        },
        {
          "path": "saleor/discount/tests/test_utils/test_update_voucher_discount_object_for_order.py",
          "status": "modified",
          "diff": "Index: saleor/discount/tests/test_utils/test_update_voucher_discount_object_for_order.py\n===================================================================\n--- saleor/discount/tests/test_utils/test_update_voucher_discount_object_for_order.py\tffc07d1 (parent)\n+++ saleor/discount/tests/test_utils/test_update_voucher_discount_object_for_order.py\td7b03a3 (commit)\n@@ -223,9 +223,11 @@\n     assert discount_2.type == DiscountType.VOUCHER\n     assert discount_2.reason == f\"Voucher code: {order.voucher_code}\"\n     assert discount_2.value == voucher_2_discount_amount\n \n-    unit_discount_amount_2 = discount_amount_2 / cheapest_line.quantity\n+    unit_discount_amount_2 = quantize_price(\n+        discount_amount_2 / cheapest_line.quantity, currency\n+    )\n     assert quantize_price(\n         cheapest_line.base_unit_price_amount, currency\n     ) == quantize_price(\n         cheapest_line.undiscounted_base_unit_price_amount - unit_discount_amount_2,\n"
        },
        {
          "path": "saleor/discount/utils/order.py",
          "status": "modified",
          "diff": "Index: saleor/discount/utils/order.py\n===================================================================\n--- saleor/discount/utils/order.py\tffc07d1 (parent)\n+++ saleor/discount/utils/order.py\td7b03a3 (commit)\n@@ -15,12 +15,9 @@\n from ...order.base_calculations import base_order_subtotal\n from ...order.models import Order, OrderLine\n from .. import DiscountType\n from ..interface import VariantPromotionRuleInfo\n-from ..models import (\n-    DiscountValueType,\n-    OrderLineDiscount,\n-)\n+from ..models import DiscountValueType, OrderLineDiscount\n from .manual_discount import apply_discount_to_value\n from .promotion import (\n     _get_rule_discount_amount,\n     create_discount_objects_for_order_promotions,\n@@ -39,11 +36,11 @@\n \n def create_order_line_discount_objects(\n     lines_info: list[\"EditableOrderLineInfo\"],\n     discount_data: tuple[\n-        list[dict],\n         list[OrderLineDiscount],\n         list[OrderLineDiscount],\n+        list[OrderLineDiscount],\n         list[str],\n     ],\n ) -> None | list[\"EditableOrderLineInfo\"]:\n     from ...order.utils import order_qs_select_for_update\n@@ -51,15 +48,14 @@\n     if not discount_data or not lines_info:\n         return None\n \n     (\n-        discounts_to_create_inputs,\n+        discounts_to_create,\n         discounts_to_update,\n         discount_to_remove,\n         updated_fields,\n     ) = discount_data\n \n-    new_line_discounts: list[OrderLineDiscount] = []\n     affected_line_ids: list[UUID] = []\n     with allow_writer():\n         with transaction.atomic():\n             # Protect against potential thread race. OrderLine object can have only\n@@ -76,27 +72,24 @@\n                     if discount.line_id is not None\n                 )\n                 OrderLineDiscount.objects.filter(id__in=discount_ids_to_remove).delete()\n \n-            if discounts_to_create_inputs:\n-                new_line_discounts = [\n-                    OrderLineDiscount(**input) for input in discounts_to_create_inputs\n-                ]\n+            if discounts_to_create:\n                 OrderLineDiscount.objects.bulk_create(\n-                    new_line_discounts, ignore_conflicts=True\n+                    discounts_to_create, ignore_conflicts=True\n                 )\n \n             if discounts_to_update and updated_fields:\n                 OrderLineDiscount.objects.bulk_update(\n                     discounts_to_update, updated_fields\n                 )\n \n     update_line_info_cached_discounts(\n-        lines_info, new_line_discounts, discounts_to_update, discount_ids_to_remove\n+        lines_info, discounts_to_create, discounts_to_update, discount_ids_to_remove\n     )\n     affected_line_ids.extend(\n         discount_line.line_id\n-        for discount_line in (new_line_discounts + discounts_to_update)\n+        for discount_line in (discounts_to_create + discounts_to_update)\n         if discount_line.line_id is not None\n     )\n \n     modified_lines_info = [\n@@ -129,38 +122,49 @@\n     discount_to_update.save(update_fields=[\"amount_value\"])\n \n \n def update_unit_discount_data_on_order_line(\n+    line: OrderLine, discounts: list[OrderLineDiscount]\n+):\n+    unit_discount_reason = (\n+        \"; \".join([discount.reason for discount in discounts if discount.reason])\n+        or None\n+    )\n+\n+    unit_discount_amount = Decimal(\"0.0\")\n+    unit_discount_type = None\n+    unit_discount_value = Decimal(\"0.0\")\n+    if discounts:\n+        discount_amount = sum(\n+            [discount.amount_value for discount in discounts], Decimal(\"0.0\")\n+        )\n+        unit_discount_amount = quantize_price(\n+            discount_amount / line.quantity, line.currency\n+        )\n+\n+        more_than_one_discount = len(discounts) > 1\n+        if more_than_one_discount:\n+            unit_discount_type = DiscountValueType.FIXED\n+            unit_discount_value = unit_discount_amount\n+        else:\n+            discount = discounts[0]\n+            unit_discount_type = discount.value_type\n+            unit_discount_value = discount.value\n+\n+    line.unit_discount_amount = unit_discount_amount\n+    line.unit_discount_reason = unit_discount_reason\n+    line.unit_discount_type = unit_discount_type\n+    line.unit_discount_value = unit_discount_value\n+\n+\n+def update_unit_discount_data_on_order_lines_info(\n     lines_info: list[\"EditableOrderLineInfo\"],\n ):\n     for line_info in lines_info:\n         line = line_info.line\n-        if discounts := line_info.discounts:\n-            discount_amount = sum([discount.amount_value for discount in discounts])\n-            unit_discount_amount = discount_amount / line.quantity\n-            discount_reason = \"; \".join(\n-                [discount.reason for discount in discounts if discount.reason]\n-            )\n-            discount_type = (\n-                discounts[0].value_type\n-                if len(discounts) == 1\n-                else DiscountValueType.FIXED\n-            )\n-            discount_value = (\n-                discounts[0].value if len(discounts) == 1 else unit_discount_amount\n-            )\n+        update_unit_discount_data_on_order_line(line, line_info.discounts)\n \n-            line.unit_discount_amount = unit_discount_amount\n-            line.unit_discount_reason = discount_reason\n-            line.unit_discount_type = discount_type\n-            line.unit_discount_value = discount_value\n-        else:\n-            line.unit_discount_amount = Decimal(\"0.0\")\n-            line.unit_discount_reason = None\n-            line.unit_discount_type = None\n-            line.unit_discount_value = Decimal(\"0.0\")\n \n-\n def handle_order_promotion(\n     order: \"Order\",\n     lines_info,\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n@@ -245,50 +249,52 @@\n         delete_gift_line(order_or_checkout, lines_info)\n         order_or_checkout.discounts.filter(type=DiscountType.ORDER_PROMOTION).delete()\n \n \n+def _create_order_line_discount_for_catalogue_promotion(\n+    line: OrderLine, rule_info: VariantPromotionRuleInfo, channel: Channel\n+):\n+    rule = rule_info.rule\n+    rule_discount_amount = _get_rule_discount_amount(line, rule_info, channel)\n+    discount_name = get_discount_name(rule, rule_info.promotion)\n+    translated_name = get_discount_translated_name(rule_info)\n+    reason = prepare_promotion_discount_reason(rule_info.promotion)\n+    return OrderLineDiscount(\n+        line=line,\n+        type=DiscountType.PROMOTION,\n+        value_type=rule.reward_value_type,\n+        value=rule.reward_value,\n+        amount_value=rule_discount_amount,\n+        currency=line.currency,\n+        name=discount_name,\n+        translated_name=translated_name,\n+        reason=reason,\n+        promotion_rule=rule,\n+        unique_type=DiscountType.PROMOTION,\n+    )\n+\n+\n def create_order_line_discount_objects_for_catalogue_promotions(\n     line: \"OrderLine\",\n     rules_info: Iterable[VariantPromotionRuleInfo],\n     channel: Channel,\n-) -> Iterable[\"OrderLineDiscount\"]:\n+) -> list[\"OrderLineDiscount\"]:\n     from ...order.utils import order_qs_select_for_update\n \n-    line_discounts_to_create_inputs: list[dict] = []\n+    line_discounts_to_create: list[OrderLineDiscount] = []\n     for rule_info in rules_info:\n-        rule = rule_info.rule\n-        rule_discount_amount = _get_rule_discount_amount(line, rule_info, channel)\n-        discount_name = get_discount_name(rule, rule_info.promotion)\n-        translated_name = get_discount_translated_name(rule_info)\n-        reason = prepare_promotion_discount_reason(rule_info.promotion)\n+        line_discount = _create_order_line_discount_for_catalogue_promotion(\n+            line, rule_info, channel\n+        )\n+        line_discounts_to_create.append(line_discount)\n \n-        line_discount_input = {\n-            \"line\": line,\n-            \"type\": DiscountType.PROMOTION,\n-            \"value_type\": rule.reward_value_type,\n-            \"value\": rule.reward_value,\n-            \"amount_value\": rule_discount_amount,\n-            \"currency\": line.currency,\n-            \"name\": discount_name,\n-            \"translated_name\": translated_name,\n-            \"reason\": reason,\n-            \"promotion_rule\": rule,\n-            \"unique_type\": DiscountType.PROMOTION,\n-        }\n-        line_discounts_to_create_inputs.append(line_discount_input)\n-\n-    if line_discounts_to_create_inputs:\n+    if line_discounts_to_create:\n         with allow_writer():\n             with transaction.atomic():\n                 order_id = line.order_id\n                 _order_lock = list(order_qs_select_for_update().filter(id=order_id))\n-                new_line_discounts = [\n-                    OrderLineDiscount(**input)\n-                    for input in line_discounts_to_create_inputs\n-                ]\n-\n                 return OrderLineDiscount.objects.bulk_create(\n-                    new_line_discounts, ignore_conflicts=True\n+                    line_discounts_to_create, ignore_conflicts=True\n                 )\n     return []\n \n \n@@ -302,9 +308,9 @@\n     _update_base_unit_price_amount_for_catalogue_promotion(lines_info)\n \n \n def prepare_order_line_discount_objects_for_catalogue_promotions(lines_info):\n-    line_discounts_to_create_inputs: list[dict] = []\n+    line_discounts_to_create: list[OrderLineDiscount] = []\n     line_discounts_to_update: list[OrderLineDiscount] = []\n     line_discounts_to_remove: list[OrderLineDiscount] = []\n     updated_fields: list[str] = []\n \n@@ -343,30 +349,17 @@\n \n         if line_info.rules_info:\n             rule_info = line_info.rules_info[0]\n             rule = rule_info.rule\n-            rule_discount_amount = _get_rule_discount_amount(\n-                line, rule_info, line_info.channel\n-            )\n-            discount_name = get_discount_name(rule, rule_info.promotion)\n-            translated_name = get_discount_translated_name(rule_info)\n-            reason = prepare_promotion_discount_reason(rule_info.promotion)\n             if not discount_to_update:\n-                line_discount_input = {\n-                    \"line\": line,\n-                    \"type\": DiscountType.PROMOTION,\n-                    \"value_type\": rule.reward_value_type,\n-                    \"value\": rule.reward_value,\n-                    \"amount_value\": rule_discount_amount,\n-                    \"currency\": line.currency,\n-                    \"name\": discount_name,\n-                    \"translated_name\": translated_name,\n-                    \"reason\": reason,\n-                    \"promotion_rule\": rule,\n-                    \"unique_type\": DiscountType.PROMOTION,\n-                }\n-                line_discounts_to_create_inputs.append(line_discount_input)\n+                line_discount = _create_order_line_discount_for_catalogue_promotion(\n+                    line, rule_info, line_info.channel\n+                )\n+                line_discounts_to_create.append(line_discount)\n             else:\n+                rule_discount_amount = _get_rule_discount_amount(\n+                    line, rule_info, line_info.channel\n+                )\n                 update_promotion_discount(\n                     rule,\n                     rule_info,\n                     rule_discount_amount,\n@@ -378,9 +371,9 @@\n             # Fallback for unlike mismatch between discount_amount and rules_info\n             line_discounts_to_remove.extend(discounts_to_update)\n \n     return (\n-        line_discounts_to_create_inputs,\n+        line_discounts_to_create,\n         line_discounts_to_update,\n         line_discounts_to_remove,\n         updated_fields,\n     )\n"
        },
        {
          "path": "saleor/discount/utils/promotion.py",
          "status": "modified",
          "diff": "Index: saleor/discount/utils/promotion.py\n===================================================================\n--- saleor/discount/utils/promotion.py\tffc07d1 (parent)\n+++ saleor/discount/utils/promotion.py\td7b03a3 (commit)\n@@ -1,10 +1,11 @@\n import datetime\n from collections import defaultdict\n from collections.abc import Callable, Iterable, Iterator\n+from dataclasses import asdict\n from decimal import Decimal\n from itertools import chain\n-from typing import TYPE_CHECKING, NamedTuple, Union\n+from typing import TYPE_CHECKING, NamedTuple, Union, cast\n from uuid import UUID\n \n import graphene\n from django.conf import settings\n@@ -33,9 +34,9 @@\n     PromotionType,\n     RewardType,\n     RewardValueType,\n )\n-from ..interface import VariantPromotionRuleInfo, get_rule_translations\n+from ..interface import DiscountInfo, VariantPromotionRuleInfo, get_rule_translations\n from ..models import (\n     CheckoutDiscount,\n     CheckoutLineDiscount,\n     NotApplicable,\n@@ -431,10 +432,13 @@\n \n def create_gift_line(\n     order_or_checkout: Checkout | Order,\n     gift_listing: \"ProductVariantChannelListing\",\n+    line_discount_data: DiscountInfo,\n ):\n-    defaults = _get_defaults_for_gift_line(order_or_checkout, gift_listing)\n+    defaults = _get_defaults_for_gift_line(\n+        order_or_checkout, gift_listing, line_discount_data\n+    )\n     line, created = order_or_checkout.lines.get_or_create(\n         is_gift=True, defaults=defaults\n     )\n     if not created:\n@@ -451,8 +455,9 @@\n \n def _get_defaults_for_gift_line(\n     order_or_checkout: Checkout | Order,\n     gift_listing: \"ProductVariantChannelListing\",\n+    line_discount_data: DiscountInfo,\n ):\n     variant_id = gift_listing.variant_id\n     if isinstance(order_or_checkout, Checkout):\n         return {\n@@ -478,8 +483,12 @@\n         \"total_price_net_amount\": Decimal(0),\n         \"total_price_gross_amount\": Decimal(0),\n         \"is_shipping_required\": True,\n         \"is_gift_card\": False,\n+        \"unit_discount_amount\": line_discount_data.amount_value,\n+        \"unit_discount_value\": line_discount_data.value,\n+        \"unit_discount_reason\": line_discount_data.reason,\n+        \"unit_discount_type\": line_discount_data.value_type,\n     }\n \n \n def get_variants_to_promotion_rules_map(\n@@ -727,33 +736,35 @@\n     # gift rule has empty reward_value and reward_value_type\n     value_type = best_rule.reward_value_type or RewardValueType.FIXED\n     amount_value = gift_listing.price_amount if gift_listing else best_discount_amount\n     value = best_rule.reward_value or amount_value\n-    discount_object_defaults = {\n-        \"promotion_rule\": best_rule,\n-        \"value_type\": value_type,\n-        \"value\": value,\n-        \"amount_value\": amount_value,\n-        \"currency\": currency,\n-        \"name\": get_discount_name(best_rule, promotion),\n-        \"translated_name\": get_discount_translated_name(rule_info),\n-        \"reason\": prepare_promotion_discount_reason(rule_info.promotion),\n-    }\n+    line_discount = DiscountInfo(\n+        type=DiscountType.ORDER_PROMOTION,\n+        promotion_rule=best_rule,\n+        value_type=value_type,\n+        value=value,\n+        amount_value=amount_value,\n+        currency=currency,\n+        name=get_discount_name(best_rule, promotion),\n+        translated_name=get_discount_translated_name(rule_info),\n+        reason=prepare_promotion_discount_reason(rule_info.promotion),\n+    )\n+\n     if gift_listing:\n         _handle_gift_reward(\n             order_or_checkout,\n             lines_info,\n             gift_listing,\n             channel,\n-            discount_object_defaults,\n+            line_discount,\n             rule_info,\n         )\n         gift_promotion_applied = True\n     else:\n         discount_object = _handle_order_promotion(\n             order_or_checkout,\n             lines_info,\n-            discount_object_defaults,\n+            line_discount,\n             rule_info,\n         )\n     return gift_promotion_applied, discount_object\n \n@@ -761,21 +772,21 @@\n @allow_writer()\n def _handle_order_promotion(\n     order_or_checkout: Order | Checkout,\n     lines_info: list[\"EditableOrderLineInfo\"] | list[\"CheckoutLineInfo\"],\n-    discount_object_defaults: dict,\n+    line_discount_data: DiscountInfo,\n     rule_info: VariantPromotionRuleInfo,\n ):\n     discount_object, created = order_or_checkout.discounts.get_or_create(\n         type=DiscountType.ORDER_PROMOTION,\n-        defaults=discount_object_defaults,\n+        defaults=asdict(line_discount_data),\n     )\n-    discount_amount = discount_object_defaults[\"amount_value\"]\n-\n+    discount_amount = line_discount_data.amount_value\n+    promotion_rule = cast(PromotionRule, line_discount_data.promotion_rule)\n     if not created:\n         fields_to_update: list[str] = []\n         update_promotion_discount(\n-            discount_object_defaults[\"promotion_rule\"],\n+            promotion_rule,\n             rule_info,\n             discount_amount,\n             discount_object,\n             fields_to_update,\n@@ -792,36 +803,39 @@\n     order_or_checkout: Order | Checkout,\n     lines_info: list[EditableOrderLineInfo] | list[CheckoutLineInfo],\n     gift_listing: ProductVariantChannelListing,\n     channel: \"Channel\",\n-    discount_object_defaults: dict,\n+    line_discount_data: DiscountInfo,\n     rule_info: VariantPromotionRuleInfo,\n ):\n     discount_model = (\n         CheckoutLineDiscount\n         if isinstance(order_or_checkout, Checkout)\n         else OrderLineDiscount\n     )\n     with transaction.atomic():\n-        line, line_created = create_gift_line(order_or_checkout, gift_listing)\n+        line, line_created = create_gift_line(\n+            order_or_checkout, gift_listing, line_discount_data\n+        )\n         (\n             line_discount,\n             discount_created,\n         ) = discount_model.objects.get_or_create(  # type: ignore[attr-defined]\n             type=DiscountType.ORDER_PROMOTION,\n             line=line,\n-            defaults=discount_object_defaults,\n+            defaults=asdict(line_discount_data),\n         )\n \n     if not discount_created:\n         fields_to_update = []\n         if line_discount.line_id != line.id:\n             line_discount.line = line\n             fields_to_update.append(\"line_id\")\n+        promotion_rule = cast(PromotionRule, line_discount.promotion_rule)\n         update_promotion_discount(\n-            discount_object_defaults[\"promotion_rule\"],\n+            promotion_rule,\n             rule_info,\n-            discount_object_defaults[\"amount_value\"],\n+            line_discount_data.amount_value,\n             line_discount,\n             fields_to_update,\n         )\n         if fields_to_update:\n"
        },
        {
          "path": "saleor/discount/utils/voucher.py",
          "status": "modified",
          "diff": "Index: saleor/discount/utils/voucher.py\n===================================================================\n--- saleor/discount/utils/voucher.py\tffc07d1 (parent)\n+++ saleor/discount/utils/voucher.py\td7b03a3 (commit)\n@@ -1,6 +1,6 @@\n from collections.abc import Iterable, Sequence\n-from dataclasses import dataclass\n+from dataclasses import asdict, dataclass\n from decimal import Decimal\n from typing import TYPE_CHECKING, Optional, cast\n from uuid import UUID\n \n@@ -14,8 +14,9 @@\n from ...core.taxes import zero_money\n from ...core.utils.promo_code import InvalidPromoCode\n from ...order.models import Order\n from .. import DiscountType, VoucherType\n+from ..interface import DiscountInfo, VoucherInfo\n from ..models import (\n     DiscountValueType,\n     NotApplicable,\n     OrderLineDiscount,\n@@ -32,9 +33,8 @@\n     from ...core.pricing.interface import LineInfo\n     from ...order.fetch import EditableOrderLineInfo\n     from ...order.models import OrderLine\n     from ...plugins.manager import PluginsManager\n-    from ..interface import VoucherInfo\n     from ..models import Voucher\n \n \n @dataclass\n@@ -345,9 +345,18 @@\n     create_or_update_line_discount_objects_from_voucher(\n         lines_info, use_denormalized_data\n     )\n     lines = [line_info.line for line_info in lines_info]\n-    OrderLine.objects.bulk_update(lines, [\"base_unit_price_amount\"])\n+    OrderLine.objects.bulk_update(\n+        lines,\n+        [\n+            \"base_unit_price_amount\",\n+            \"unit_discount_amount\",\n+            \"unit_discount_reason\",\n+            \"unit_discount_type\",\n+            \"unit_discount_value\",\n+        ],\n+    )\n \n \n def create_or_update_discount_object_from_order_level_voucher(\n     order,\n@@ -405,26 +414,26 @@\n \n     discount_reason = f\"Voucher code: {order.voucher_code}\"\n     discount_name = voucher.name or \"\"\n \n-    discount_object_defaults = {\n-        \"voucher\": voucher,\n-        \"value_type\": voucher.discount_value_type,\n-        \"value\": voucher_channel_listing.discount_value,\n-        \"amount_value\": discount_amount.amount,\n-        \"currency\": order.currency,\n-        \"reason\": discount_reason,\n-        \"name\": discount_name,\n-        \"type\": DiscountType.VOUCHER,\n-        \"voucher_code\": order.voucher_code,\n+    discount_data = DiscountInfo(\n+        voucher=voucher,\n+        value_type=voucher.discount_value_type,\n+        value=voucher_channel_listing.discount_value,\n+        amount_value=discount_amount.amount,\n+        currency=order.currency,\n+        reason=discount_reason,\n+        name=discount_name,\n+        type=DiscountType.VOUCHER,\n+        voucher_code=order.voucher_code,\n         # TODO (SHOPX-914): set translated voucher name\n-        \"translated_name\": \"\",\n-    }\n+        translated_name=\"\",\n+    )\n \n     with allow_writer():\n         discount_object, created = order.discounts.get_or_create(\n             type=DiscountType.VOUCHER,\n-            defaults=discount_object_defaults,\n+            defaults=asdict(discount_data),\n         )\n         if not created:\n             updated_fields: list[str] = []\n             update_discount(\n@@ -460,18 +469,18 @@\n     \"\"\"\n     # FIXME: temporary - create_order_line_discount_objects should be moved to shared\n     from .order import (\n         create_order_line_discount_objects,\n-        update_unit_discount_data_on_order_line,\n+        update_unit_discount_data_on_order_lines_info,\n     )\n \n     discount_data = prepare_line_discount_objects_for_voucher(\n         lines_info, use_denormalized_data\n     )\n     modified_lines_info = create_order_line_discount_objects(lines_info, discount_data)\n     if modified_lines_info:\n         _reduce_base_unit_price_for_voucher_discount(modified_lines_info)\n-        update_unit_discount_data_on_order_line(modified_lines_info)\n+        update_unit_discount_data_on_order_lines_info(modified_lines_info)\n \n \n # TODO (SHOPX-912): share the method with checkout\n def prepare_line_discount_objects_for_voucher(\n@@ -483,9 +492,9 @@\n     `use_denormalized_data=True` indicates, that the discount should be calculated based on the\n     conditions from the moment of the voucher application. Otherwise, the latest\n     voucher values will be retrieved from the database.\n     \"\"\"\n-    line_discounts_to_create_inputs: list[dict] = []\n+    line_discounts_to_create: list[OrderLineDiscount] = []\n     line_discounts_to_update: list[OrderLineDiscount] = []\n     line_discounts_to_remove: list[OrderLineDiscount] = []\n     updated_fields: list[str] = []\n \n@@ -559,26 +568,26 @@\n                 voucher_code=code,\n             )\n             line_discounts_to_update.append(discount_to_update)\n         else:\n-            line_discount_input = {\n-                \"line\": line,\n-                \"type\": DiscountType.VOUCHER,\n-                \"value_type\": discount_value_type,\n-                \"value\": discount_value,\n-                \"amount_value\": discount_amount,\n-                \"currency\": line.currency,\n-                \"name\": discount_name,\n-                \"translated_name\": None,\n-                \"reason\": discount_reason,\n-                \"voucher\": voucher,\n-                \"unique_type\": DiscountType.VOUCHER,\n-                \"voucher_code\": code,\n-            }\n-            line_discounts_to_create_inputs.append(line_discount_input)\n+            line_discount_to_create = OrderLineDiscount(\n+                line=line,\n+                type=DiscountType.VOUCHER,\n+                value_type=discount_value_type,\n+                value=discount_value,\n+                amount_value=discount_amount,\n+                currency=line.currency,\n+                name=discount_name,\n+                translated_name=None,\n+                reason=discount_reason,\n+                voucher=voucher,\n+                unique_type=DiscountType.VOUCHER,\n+                voucher_code=code,\n+            )\n+            line_discounts_to_create.append(line_discount_to_create)\n \n     return (\n-        line_discounts_to_create_inputs,\n+        line_discounts_to_create,\n         line_discounts_to_update,\n         line_discounts_to_remove,\n         updated_fields,\n     )\n"
        },
        {
          "path": "saleor/graphql/checkout/mutations/utils.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/mutations/utils.py\n===================================================================\n--- saleor/graphql/checkout/mutations/utils.py\tffc07d1 (parent)\n+++ saleor/graphql/checkout/mutations/utils.py\td7b03a3 (commit)\n@@ -1,9 +1,9 @@\n import datetime\n import uuid\n from collections import defaultdict\n from collections.abc import Iterable\n-from dataclasses import dataclass, field\n+from dataclasses import asdict, dataclass, field\n from decimal import Decimal\n from typing import TYPE_CHECKING, Any, cast\n \n import graphene\n@@ -30,8 +30,9 @@\n     remove_external_shipping_from_checkout,\n )\n from ....core.exceptions import InsufficientStock, PermissionDenied\n from ....discount import DiscountType, DiscountValueType\n+from ....discount.interface import DiscountInfo\n from ....discount.models import CheckoutLineDiscount, PromotionRule\n from ....discount.utils.promotion import (\n     create_gift_line,\n     fetch_promotion_rules_for_checkout_or_order,\n@@ -567,19 +568,21 @@\n     best_rule, best_discount_amount, gift_listing = best_rule_data\n     if not gift_listing:\n         return\n \n+    line_discount_data = DiscountInfo(\n+        type=DiscountType.ORDER_PROMOTION,\n+        amount_value=best_discount_amount,\n+        value_type=DiscountValueType.FIXED,\n+        value=best_discount_amount,\n+        promotion_rule=best_rule,\n+        currency=checkout.currency,\n+    )\n     with transaction.atomic():\n-        line, _line_created = create_gift_line(checkout, gift_listing)\n-        CheckoutLineDiscount.objects.create(\n-            type=DiscountType.ORDER_PROMOTION,\n-            line=line,\n-            amount_value=best_discount_amount,\n-            value_type=DiscountValueType.FIXED,\n-            value=best_discount_amount,\n-            promotion_rule=best_rule,\n-            currency=checkout.currency,\n+        line, _line_created = create_gift_line(\n+            checkout, gift_listing, line_discount_data\n         )\n+        CheckoutLineDiscount.objects.create(line=line, **asdict(line_discount_data))\n \n \n def _set_checkout_base_subtotal_and_total_on_checkout_creation(\n     checkout: \"models.Checkout\",\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\n===================================================================\n--- saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\tffc07d1 (parent)\n+++ saleor/graphql/checkout/tests/benchmark/test_checkout_mutations.py\td7b03a3 (commit)\n@@ -1323,9 +1323,9 @@\n     }\n \n     # when\n     user_api_client.ensure_access_token()\n-    with django_assert_num_queries(123):\n+    with django_assert_num_queries(124):\n         response = user_api_client.post_graphql(MUTATION_CHECKOUT_LINES_ADD, variables)\n \n     # then\n     assert checkout.lines.count() == 2\n"
        },
        {
          "path": "saleor/graphql/order/tests/deprecated/test_order.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/deprecated/test_order.py\n===================================================================\n--- saleor/graphql/order/tests/deprecated/test_order.py\tffc07d1 (parent)\n+++ saleor/graphql/order/tests/deprecated/test_order.py\td7b03a3 (commit)\n@@ -663,16 +663,23 @@\n     discount_data = line_data.get(\"discount\")\n \n     assert discount_data[\"value\"] == str(value)\n     assert discount_data[\"value_type\"] == DiscountValueTypeEnum.FIXED.value\n-    assert discount_data[\"amount_value\"] == str(unit_discount.amount)\n+    assert discount_data[\"amount_value\"] == str(\n+        quantize_price(unit_discount.amount, order.currency)\n+    )\n \n \n ORDER_LINE_DISCOUNT_REMOVE = \"\"\"\n mutation OrderLineDiscountRemove($orderLineId: ID!){\n   orderLineDiscountRemove(orderLineId: $orderLineId){\n     orderLine{\n       id\n+      unitPrice{\n+        net{\n+          amount\n+        }\n+      }\n     }\n     errors{\n       field\n       message\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_draft_order_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_draft_order_complete.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_draft_order_complete.py\tffc07d1 (parent)\n+++ saleor/graphql/order/tests/mutations/test_draft_order_complete.py\td7b03a3 (commit)\n@@ -1403,12 +1403,8 @@\n     expected_discount_reason = f\"Promotion: {catalogue_promotion_id}\"\n     expected_unit_discount_amount = rule_catalogue_value\n \n     assert line_2[\"totalPrice\"][\"net\"][\"amount\"] == float(line_2_total)\n-    assert line_2[\"unitDiscount\"][\"amount\"] == expected_unit_discount_amount\n-    assert line_2[\"unitDiscountReason\"] == expected_discount_reason\n-    assert line_2[\"unitDiscountType\"] == DiscountValueType.FIXED.upper()\n-    assert line_2[\"unitDiscountValue\"] == rule_catalogue_value\n \n     assigned_discount_objects = line_2[\"discounts\"]\n     assert len(assigned_discount_objects) == 1\n     assigned_discount = assigned_discount_objects[0]\n@@ -1494,12 +1490,8 @@\n     expected_line_2_discount_reason = f\"Promotion: {catalogue_promotion_id}\"\n     expected_line_2_unit_discount_amount = rule_catalogue_value\n \n     assert line_2[\"totalPrice\"][\"net\"][\"amount\"] == line_2_total\n-    assert line_2[\"unitDiscount\"][\"amount\"] == rule_catalogue_value\n-    assert line_2[\"unitDiscountReason\"] == expected_line_2_discount_reason\n-    assert line_2[\"unitDiscountType\"] == DiscountValueType.FIXED.upper()\n-    assert line_2[\"unitDiscountValue\"] == rule_catalogue_value\n \n     assigned_discount_objects = line_2[\"discounts\"]\n     assert len(assigned_discount_objects) == 1\n     assigned_discount = assigned_discount_objects[0]\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_discount.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_discount.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_discount.py\tffc07d1 (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_discount.py\td7b03a3 (commit)\n@@ -15,8 +15,9 @@\n from .....order import OrderEvents, OrderStatus\n from .....order.calculations import fetch_order_prices_if_expired\n from .....order.error_codes import OrderErrorCode\n from .....order.interface import OrderTaxedPricesData\n+from .....order.utils import invalidate_order_prices\n from ....discount.enums import DiscountValueTypeEnum\n from ....tests.utils import assert_no_permission, get_graphql_content\n \n ORDER_DISCOUNT_ADD = \"\"\"\n@@ -1170,10 +1171,15 @@\n }\n \"\"\"\n \n \n+@patch(\n+    \"saleor.graphql.order.mutations.order_line_discount_update.invalidate_order_prices\",\n+    wraps=invalidate_order_prices,\n+)\n @pytest.mark.parametrize(\"status\", [OrderStatus.DRAFT, OrderStatus.UNCONFIRMED])\n def test_update_order_line_discount(\n+    mocked_invalidate_order_prices,\n     status,\n     draft_order_with_fixed_discount_order,\n     staff_api_client,\n     permission_group_manage_orders,\n@@ -1278,18 +1284,22 @@\n     discount_data = line_data.get(\"discount\")\n \n     assert discount_data[\"value\"] == str(value)\n     assert discount_data[\"value_type\"] == value_type.value\n-    assert discount_data[\"amount_value\"] == str(unit_discount.amount)\n+    assert discount_data[\"amount_value\"] == str(\n+        quantize_price(unit_discount.amount, currency=order.currency)\n+    )\n \n     line_discount = line_to_discount.discounts.get()\n     assert line_discount.type == DiscountType.MANUAL\n     assert line_discount.value == value\n     assert line_discount.value_type == value_type.value\n     assert line_discount.reason == reason\n     assert line_discount.amount_value == value * line_to_discount.quantity\n \n+    mocked_invalidate_order_prices.assert_called_once_with(order, save=True)\n \n+\n def test_update_order_line_discount_by_user_no_channel_access(\n     draft_order_with_fixed_discount_order,\n     staff_api_client,\n     permission_group_all_perms_channel_USD_only,\n@@ -1320,9 +1330,14 @@\n     # then\n     assert_no_permission(response)\n \n \n+@patch(\n+    \"saleor.graphql.order.mutations.order_line_discount_update.invalidate_order_prices\",\n+    wraps=invalidate_order_prices,\n+)\n def test_update_order_line_discount_by_app(\n+    mocked_invalidate_order_prices,\n     draft_order_with_fixed_discount_order,\n     app_api_client,\n     permission_manage_orders,\n     channel_PLN,\n@@ -1373,18 +1388,22 @@\n     discount_data = line_data.get(\"discount\")\n \n     assert discount_data[\"value\"] == str(value)\n     assert discount_data[\"value_type\"] == value_type.value\n-    assert discount_data[\"amount_value\"] == str(unit_discount.amount)\n+    assert discount_data[\"amount_value\"] == str(\n+        quantize_price(unit_discount.amount, unit_discount.currency)\n+    )\n \n     line_discount = line_to_discount.discounts.get()\n     assert line_discount.type == DiscountType.MANUAL\n     assert line_discount.value == value\n     assert line_discount.value_type == value_type.value\n     assert line_discount.reason == reason\n     assert line_discount.amount_value == value * line_to_discount.quantity\n \n+    mocked_invalidate_order_prices.assert_called_once_with(order, save=True)\n \n+\n @pytest.mark.parametrize(\"status\", [OrderStatus.DRAFT, OrderStatus.UNCONFIRMED])\n def test_update_order_line_discount_line_with_discount(\n     status,\n     draft_order_with_fixed_discount_order,\n@@ -1474,9 +1493,11 @@\n     discount_data = line_data.get(\"discount\")\n \n     assert discount_data[\"value\"] == str(value)\n     assert discount_data[\"value_type\"] == value_type.value\n-    assert discount_data[\"amount_value\"] == str(unit_discount.amount)\n+    assert discount_data[\"amount_value\"] == str(\n+        quantize_price(unit_discount.amount, unit_discount.currency)\n+    )\n \n     assert discount_data[\"old_value\"] == str(line_discount_value_before_update)\n     assert discount_data[\"old_value_type\"] == DiscountValueTypeEnum.FIXED.value\n     assert discount_data[\"old_amount_value\"] == str(line_discount_amount_before_update)\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_order_line_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_order_line_update.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_order_line_update.py\tffc07d1 (parent)\n+++ saleor/graphql/order/tests/mutations/test_order_line_update.py\td7b03a3 (commit)\n@@ -792,9 +792,15 @@\n     discount.refresh_from_db()\n     assert discount.amount_value != initial_discount_amount\n     assert discount.amount_value == unit_discount * new_quantity\n \n+    assert line_data[\"unitDiscountType\"] == discount.value_type.upper()\n+    assert line_data[\"unitDiscountValue\"] == discount.value\n+    assert Decimal(line_data[\"unitDiscount\"][\"amount\"]) == quantize_price(\n+        unit_discount, currency\n+    )\n \n+\n def test_order_line_update_apply_once_per_order_voucher_discount(\n     order_with_lines,\n     permission_group_manage_orders,\n     staff_api_client,\n"
        },
        {
          "path": "saleor/order/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/order/calculations.py\n===================================================================\n--- saleor/order/calculations.py\tffc07d1 (parent)\n+++ saleor/order/calculations.py\td7b03a3 (commit)\n@@ -20,9 +20,9 @@\n from ..discount.utils.order import (\n     handle_order_promotion,\n     refresh_manual_line_discount_object,\n     refresh_order_line_discount_objects_for_catalogue_promotions,\n-    update_unit_discount_data_on_order_line,\n+    update_unit_discount_data_on_order_lines_info,\n )\n from ..discount.utils.voucher import (\n     create_or_update_line_discount_objects_from_voucher,\n     get_the_cheapest_line,\n@@ -94,11 +94,8 @@\n     # order promotion is qualified based on the most actual prices, therefor need to be assessed\n     # on the every recalculation\n     handle_order_promotion(order, lines_info, database_connection_name)\n \n-    # update `OrderLine.unit_discount_...` fields\n-    update_unit_discount_data_on_order_line(lines_info)\n-\n     lines = [line_info.line for line_info in lines_info]\n     calculate_prices(\n         order,\n         lines,\n@@ -143,13 +140,8 @@\n                     \"total_price_gross_amount\",\n                     \"undiscounted_total_price_net_amount\",\n                     \"undiscounted_total_price_gross_amount\",\n                     \"tax_rate\",\n-                    \"unit_discount_amount\",\n-                    \"unit_discount_reason\",\n-                    \"unit_discount_type\",\n-                    \"unit_discount_value\",\n-                    \"base_unit_price_amount\",\n                 ],\n             )\n \n         return order, lines\n@@ -593,9 +585,9 @@\n     else:\n         create_or_update_line_discount_objects_from_voucher(lines_info_to_update)\n \n     # update unit discount fields based on updated discounts\n-    update_unit_discount_data_on_order_line(lines_info)\n+    update_unit_discount_data_on_order_lines_info(lines_info)\n \n     # set price expiration time\n     expiration_time = calculate_draft_order_line_price_expiration_date(\n         order.channel, order.status\n"
        },
        {
          "path": "saleor/order/tests/fixtures/order.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/fixtures/order.py\n===================================================================\n--- saleor/order/tests/fixtures/order.py\tffc07d1 (parent)\n+++ saleor/order/tests/fixtures/order.py\td7b03a3 (commit)\n@@ -13,8 +13,9 @@\n from ....core.prices import quantize_price\n from ....core.taxes import zero_money\n from ....discount import DiscountType, RewardType, RewardValueType, VoucherType\n from ....discount.models import NotApplicable, Voucher\n+from ....discount.utils.order import update_unit_discount_data_on_order_line\n from ....discount.utils.voucher import (\n     get_products_voucher_discount,\n     validate_voucher_in_order,\n )\n@@ -543,9 +544,9 @@\n         discount_amount=reward_value,\n         currency=currency,\n     )\n \n-    line.discounts.create(\n+    discount = line.discounts.create(\n         type=DiscountType.PROMOTION,\n         value_type=RewardValueType.FIXED,\n         value=reward_value,\n         amount_value=reward_value * line.quantity,\n@@ -559,13 +560,18 @@\n     )\n     total = quantize_price(line.base_unit_price_amount * line.quantity, currency)\n     line.total_price_net_amount = total\n     line.total_price_gross_amount = quantize_price(total * Decimal(\"1.23\"), currency)\n+    update_unit_discount_data_on_order_line(line, [discount])\n     line.save(\n         update_fields=[\n             \"base_unit_price_amount\",\n             \"total_price_net_amount\",\n             \"total_price_gross_amount\",\n+            \"unit_discount_amount\",\n+            \"unit_discount_reason\",\n+            \"unit_discount_type\",\n+            \"unit_discount_value\",\n         ]\n     )\n     return order\n \n"
        },
        {
          "path": "saleor/order/tests/test_fetch_order_prices.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_fetch_order_prices.py\n===================================================================\n--- saleor/order/tests/test_fetch_order_prices.py\tffc07d1 (parent)\n+++ saleor/order/tests/test_fetch_order_prices.py\td7b03a3 (commit)\n@@ -5,13 +5,9 @@\n \n from ...core.prices import quantize_price\n from ...core.taxes import zero_money\n from ...discount import DiscountType, DiscountValueType, VoucherType\n-from ...discount.models import (\n-    OrderDiscount,\n-    OrderLineDiscount,\n-    PromotionRule,\n-)\n+from ...discount.models import OrderDiscount, OrderLineDiscount, PromotionRule\n from ...discount.utils.voucher import (\n     create_or_update_voucher_discount_objects_for_order,\n )\n from ...product.models import Product\n@@ -133,14 +129,9 @@\n     assert order.total_gross_amount == order.total_net_amount * tax_rate\n     assert order.subtotal_net_amount == order.total_net_amount - shipping_net_price\n     assert order.subtotal_gross_amount == order.subtotal_net_amount * tax_rate\n \n-    assert line_1.unit_discount_amount == reward_value\n-    assert line_1.unit_discount_reason == f\"Promotion: {promotion_id}\"\n-    assert line_1.unit_discount_type == DiscountValueType.FIXED\n-    assert line_1.unit_discount_value == reward_value\n \n-\n @pytest.mark.parametrize(\"create_new_discounts\", [True, False])\n def test_fetch_order_prices_order_discount_flat_rates(\n     order_with_lines_and_order_promotion,\n     plugins_manager,\n@@ -1212,12 +1203,8 @@\n     )\n     assert line_1.unit_price_gross_amount == round_up(\n         line_1.unit_price_net_amount * tax_rate\n     )\n-    assert line_1.unit_discount_amount == rule_catalogue_reward\n-    assert line_1.unit_discount_reason == f\"Promotion: {promotion_id}\"\n-    assert line_1.unit_discount_value == rule_catalogue_reward\n-    assert line_1.unit_discount_type == DiscountValueType.FIXED\n \n     variant_2 = line_2.variant\n     variant_2_listing = variant_2.channel_listings.get(channel=order.channel)\n     variant_2_undiscounted_unit_price = variant_2_listing.price_amount\n@@ -1949,14 +1936,9 @@\n         order.subtotal_gross_amount == order.total_gross_amount - shipping_gross_price\n     )\n     assert order.subtotal_gross_amount == order.subtotal_net_amount\n \n-    assert line_1.unit_discount_amount == reward_value\n-    assert line_1.unit_discount_reason == f\"Promotion: {promotion_id}\"\n-    assert line_1.unit_discount_type == DiscountValueType.FIXED\n-    assert line_1.unit_discount_value == reward_value\n \n-\n def test_fetch_order_prices_removing_catalogue_promotion_doesnt_remove_discount(\n     order_with_lines_and_catalogue_promotion,\n     plugins_manager,\n     tax_configuration_flat_rates,\n"
        },
        {
          "path": "saleor/order/tests/test_fetch_order_prices_line_price_expiration.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_fetch_order_prices_line_price_expiration.py\n===================================================================\n--- saleor/order/tests/test_fetch_order_prices_line_price_expiration.py\tffc07d1 (parent)\n+++ saleor/order/tests/test_fetch_order_prices_line_price_expiration.py\td7b03a3 (commit)\n@@ -7,13 +7,9 @@\n \n from ...core.prices import quantize_price\n from ...core.taxes import zero_money\n from ...discount import DiscountType, DiscountValueType, RewardValueType, VoucherType\n-from ...discount.models import (\n-    OrderLineDiscount,\n-    Promotion,\n-    PromotionRule,\n-)\n+from ...discount.models import OrderLineDiscount, Promotion, PromotionRule\n from ...discount.utils.voucher import (\n     create_or_update_voucher_discount_objects_for_order,\n )\n from ...product.models import Product\n@@ -1579,9 +1575,11 @@\n     assert line_2.total_price_net_amount == expected_unit_price_2 * line_2.quantity\n     assert line_2.total_price_gross_amount == quantize_price(\n         line_2.total_price_net_amount * tax_rate, currency\n     )\n-    assert line_2.unit_discount_amount == expected_unit_discount_2\n+    assert line_2.unit_discount_amount == quantize_price(\n+        expected_unit_discount_2, currency\n+    )\n     assert line_2.unit_discount_reason == f\"Voucher code: {order.voucher_code}\"\n \n     discount_2 = line_2.discounts.get()\n     assert discount_2.amount.amount == expected_discount_amount_2\n"
        },
        {
          "path": "saleor/order/tests/test_fetch_order_prices_tax_app.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_fetch_order_prices_tax_app.py\n===================================================================\n--- saleor/order/tests/test_fetch_order_prices_tax_app.py\tffc07d1 (parent)\n+++ saleor/order/tests/test_fetch_order_prices_tax_app.py\td7b03a3 (commit)\n@@ -239,11 +239,8 @@\n     assert line_1.total_price_gross_amount == line_1_total_price_gross\n     assert line_1.unit_price_net_amount == line_1_unit_price_net\n     assert line_1.unit_price_gross_amount == line_1_unit_price_gross\n \n-    assert line_1.unit_discount_reason == f\"Promotion: {promotion_id}\"\n-    assert line_1.unit_discount_amount == reward_value\n-\n     assert line_2.undiscounted_total_price_net_amount == line_2_total_price_net\n     assert line_2.undiscounted_total_price_gross_amount == line_2_total_price_gross\n     assert line_2.undiscounted_unit_price_net_amount == line_2_unit_price_net\n     assert line_2.undiscounted_unit_price_gross_amount == line_2_unit_price_gross\n@@ -253,12 +250,9 @@\n     assert line_2.total_price_gross_amount == line_2_total_price_gross\n     assert line_2.unit_price_net_amount == line_2_unit_price_net\n     assert line_2.unit_price_gross_amount == line_2_unit_price_gross\n \n-    assert line_2.unit_discount_reason is None\n-    assert line_2.unit_discount_amount == Decimal(0)\n \n-\n def test_fetch_order_prices_order_discount_tax_app(\n     order_with_lines_and_order_promotion,\n     tax_configuration_tax_app,\n ):\n"
        },
        {
          "path": "saleor/order/tests/test_refresh_order_base_prices_and_discounts.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_refresh_order_base_prices_and_discounts.py\n===================================================================\n--- saleor/order/tests/test_refresh_order_base_prices_and_discounts.py\tffc07d1 (parent)\n+++ saleor/order/tests/test_refresh_order_base_prices_and_discounts.py\td7b03a3 (commit)\n@@ -480,16 +480,20 @@\n     assert line_1.unit_discount_amount == expected_unit_discount_1\n \n     assert line_2.undiscounted_base_unit_price_amount == new_variant_2_price\n     assert line_2.base_unit_price_amount == expected_unit_price_2\n-    assert line_2.unit_discount_amount == expected_unit_discount_2\n+    assert line_2.unit_discount_amount == quantize_price(\n+        expected_unit_discount_2, currency\n+    )\n \n     with pytest.raises(OrderLineDiscount.DoesNotExist):\n         discount_1.refresh_from_db()\n     assert not line_1.discounts.exists()\n \n     discount_2 = line_2.discounts.get()\n-    assert discount_2.amount.amount == expected_discount_amount_2\n+    assert discount_2.amount.amount == quantize_price(\n+        expected_discount_amount_2, currency\n+    )\n     assert discount_2.value == new_voucher_unit_discount\n     assert discount_2.value_type == DiscountValueType.PERCENTAGE\n \n \n"
        },
        {
          "path": "saleor/order/utils.py",
          "status": "modified",
          "diff": "Index: saleor/order/utils.py\n===================================================================\n--- saleor/order/utils.py\tffc07d1 (parent)\n+++ saleor/order/utils.py\td7b03a3 (commit)\n@@ -27,14 +27,11 @@\n from ..discount.utils.manual_discount import apply_discount_to_value\n from ..discount.utils.order import (\n     create_order_line_discount_objects_for_catalogue_promotions,\n     update_catalogue_promotion_discount_amount_for_order,\n+    update_unit_discount_data_on_order_line,\n )\n-from ..discount.utils.promotion import (\n-    delete_gift_lines_qs,\n-    get_sale_id,\n-    prepare_promotion_discount_reason,\n-)\n+from ..discount.utils.promotion import delete_gift_lines_qs, get_sale_id\n from ..discount.utils.voucher import (\n     create_or_update_discount_object_from_order_level_voucher,\n     create_or_update_line_discount_objects_from_voucher,\n     create_or_update_voucher_discount_objects_for_order,\n@@ -324,34 +321,16 @@\n         **get_tax_class_kwargs_for_order_line(tax_class),\n     )\n \n     unit_discount = line.undiscounted_unit_price - line.unit_price\n-    if unit_discount.gross:\n-        if rules_info:\n-            line_discounts = (\n-                create_order_line_discount_objects_for_catalogue_promotions(\n-                    line, rules_info, channel\n-                )\n-            )\n-            promotion = rules_info[0].promotion\n-            line.sale_id = get_sale_id(promotion)\n-            line.unit_discount_reason = (\n-                prepare_promotion_discount_reason(rules_info[0].promotion)\n-                if line_discounts\n-                else None\n-            )\n+    if unit_discount.gross and rules_info:\n+        line_discounts = create_order_line_discount_objects_for_catalogue_promotions(\n+            line, rules_info, channel\n+        )\n+        promotion = rules_info[0].promotion\n+        line.sale_id = get_sale_id(promotion)\n+        update_unit_discount_data_on_order_line(line, line_discounts)\n \n-        tax_configuration = channel.tax_configuration\n-        prices_entered_with_tax = tax_configuration.prices_entered_with_tax\n-\n-        if prices_entered_with_tax:\n-            discount_amount = unit_discount.gross\n-        else:\n-            discount_amount = unit_discount.net\n-        line.unit_discount = discount_amount\n-        line.unit_discount_type = DiscountValueType.FIXED\n-        line.unit_discount_value = discount_amount.amount\n-\n         line.save(\n             update_fields=[\n                 \"unit_discount_amount\",\n                 \"unit_discount_value\",\n@@ -908,125 +887,126 @@\n     value_type: str | None,\n     value: Decimal | None,\n ):\n     \"\"\"Update discount fields for order line. Apply discount to the price.\"\"\"\n-    current_value = order_line.unit_discount_value\n-    current_value_type = order_line.unit_discount_type\n-    value = value or current_value\n-    value_type = value_type or current_value_type\n-    fields_to_update = []\n-    if reason is not None:\n-        order_line.unit_discount_reason = reason\n-        fields_to_update.append(\"unit_discount_reason\")\n+    line_discounts = list(order_line.discounts.all())\n+    _remove_invalid_discounts_for_adding_manual(line_discounts)\n+    manual_line_discount = _get_manual_order_line_discount(line_discounts)\n+    if not manual_line_discount:\n+        current_value = None\n+        current_value_type = None\n+        manual_line_discount = OrderLineDiscount.objects.create(\n+            line=order_line,\n+            type=DiscountType.MANUAL,\n+            currency=order.currency,\n+            unique_type=DiscountType.MANUAL,\n+        )\n+        line_discounts.append(manual_line_discount)\n+    else:\n+        current_value = manual_line_discount.value\n+        current_value_type = manual_line_discount.value_type\n \n+    value = value or current_value or Decimal(0)\n+    value_type = value_type or current_value_type or DiscountValueType.FIXED\n+\n+    undiscounted_base_unit_price = order_line.undiscounted_base_unit_price\n+    currency = undiscounted_base_unit_price.currency\n+\n+    _update_order_line_discount_object(\n+        value,\n+        value_type,\n+        reason,\n+        order_line.quantity,\n+        undiscounted_base_unit_price,\n+        manual_line_discount,\n+    )\n+\n     if current_value != value or current_value_type != value_type:\n-        undiscounted_base_unit_price = order_line.undiscounted_base_unit_price\n-        currency = undiscounted_base_unit_price.currency\n         base_unit_price = apply_discount_to_value(\n             value, value_type, currency, undiscounted_base_unit_price\n         )\n-\n-        order_line.unit_discount = undiscounted_base_unit_price - base_unit_price\n-\n-        order_line.unit_price = TaxedMoney(base_unit_price, base_unit_price)\n         order_line.base_unit_price = base_unit_price\n \n-        order_line.unit_discount_type = value_type\n-        order_line.unit_discount_value = value\n-        # TODO: should we save those values?\n-        order_line.total_price = order_line.unit_price * order_line.quantity\n-        order_line.undiscounted_unit_price = (\n-            order_line.unit_price + order_line.unit_discount\n-        )\n-        order_line.undiscounted_total_price = (\n-            order_line.quantity * order_line.undiscounted_unit_price\n-        )\n-        fields_to_update.extend(\n-            [\n-                \"tax_rate\",\n-                \"unit_discount_value\",\n-                \"unit_discount_amount\",\n-                \"unit_discount_type\",\n-                \"unit_discount_reason\",\n-                \"unit_price_gross_amount\",\n-                \"unit_price_net_amount\",\n-                \"total_price_net_amount\",\n-                \"total_price_gross_amount\",\n-                \"base_unit_price_amount\",\n-                \"undiscounted_unit_price_gross_amount\",\n-                \"undiscounted_unit_price_net_amount\",\n-                \"undiscounted_total_price_gross_amount\",\n-                \"undiscounted_total_price_net_amount\",\n-            ]\n-        )\n+        update_unit_discount_data_on_order_line(order_line, line_discounts)\n+        fields_to_update = [\n+            \"unit_discount_value\",\n+            \"unit_discount_amount\",\n+            \"unit_discount_type\",\n+            \"unit_discount_reason\",\n+            \"base_unit_price_amount\",\n+        ]\n+        order_line.save(update_fields=fields_to_update)\n \n-    # Save lines before calculating the taxes as some plugin can fetch all order data\n-    # from db\n-    order_line.save(update_fields=fields_to_update)\n \n-    _update_manual_order_line_discount_object(\n-        value, value_type, reason, order_line, order.currency\n-    )\n+def _remove_invalid_discounts_for_adding_manual(\n+    order_line_discounts: list[OrderLineDiscount],\n+):\n+    \"\"\"Remove all line discounts except the single manual line discount.\"\"\"\n+    discount_to_delete = []\n+    current_manual_discount = None\n+    for discount in order_line_discounts:\n+        if discount.type == DiscountType.MANUAL and not current_manual_discount:\n+            current_manual_discount = discount\n+        else:\n+            discount_to_delete.append(discount)\n \n+    if discount_to_delete:\n+        for discount in discount_to_delete:\n+            order_line_discounts.remove(discount)\n+        OrderLineDiscount.objects.filter(\n+            id__in=[discount.id for discount in discount_to_delete]\n+        ).delete()\n \n-def _update_manual_order_line_discount_object(\n-    value, value_type, reason, order_line, currency\n-):\n+\n+def _get_manual_order_line_discount(\n+    order_line_discounts: list[OrderLineDiscount],\n+) -> OrderLineDiscount | None:\n     discount_to_update = None\n-    discount_to_delete_ids = []\n-    discounts = order_line.discounts.all()\n-    for discount in discounts:\n-        if discount.type == DiscountType.MANUAL and not discount_to_update:\n+    for discount in order_line_discounts:\n+        if discount.type == DiscountType.MANUAL:\n             discount_to_update = discount\n-        else:\n-            discount_to_delete_ids.append(discount.pk)\n+            break\n+    return discount_to_update\n \n-    if discount_to_delete_ids:\n-        OrderLineDiscount.objects.filter(id__in=discount_to_delete_ids).delete()\n \n-    amount_value = quantize_price(\n-        order_line.unit_discount.amount * order_line.quantity, currency\n-    )\n-    if not discount_to_update:\n-        order_line.discounts.create(\n-            type=DiscountType.MANUAL,\n-            value_type=value_type,\n-            value=value,\n-            amount_value=amount_value,\n-            currency=currency,\n-            reason=reason,\n-            unique_type=DiscountType.MANUAL,\n+def _update_order_line_discount_object(\n+    value: Decimal,\n+    value_type: str,\n+    reason: str | None,\n+    quantity: int,\n+    base_unit_price: Money,\n+    line_discount: OrderLineDiscount,\n+):\n+    update_fields = []\n+    if line_discount.value_type != value_type:\n+        line_discount.value_type = value_type\n+        update_fields.append(\"value_type\")\n+    if line_discount.value != value:\n+        line_discount.value = value\n+        update_fields.append(\"value\")\n+    if reason is not None and line_discount.reason != reason:\n+        line_discount.reason = reason\n+        update_fields.append(\"reason\")\n+\n+    if {\"value\", \"value_type\"}.intersection(update_fields):\n+        discounted_base_unit = apply_discount_to_value(\n+            line_discount.value,\n+            line_discount.value_type,\n+            base_unit_price.currency,\n+            base_unit_price,\n         )\n-    else:\n-        update_fields = []\n-        if discount_to_update.value_type != value_type:\n-            discount_to_update.value_type = value_type\n-            update_fields.append(\"value_type\")\n-        if discount_to_update.value != value:\n-            discount_to_update.value = value\n-            discount_to_update.amount_value = amount_value\n-            update_fields.extend([\"value\", \"amount_value\"])\n-        if discount_to_update.reason != reason:\n-            discount_to_update.reason = reason\n-            update_fields.append(\"reason\")\n-        discount_to_update.save(update_fields=update_fields)\n+        line_base_total = base_unit_price * quantity\n+        discounted_base_total = discounted_base_unit * quantity\n+        line_discount.amount = line_base_total - discounted_base_total\n+        update_fields.append(\"amount_value\")\n+    line_discount.save(update_fields=update_fields)\n \n \n def remove_discount_from_order_line(order_line: OrderLine, order: \"Order\"):\n     \"\"\"Drop discount applied to order line. Restore undiscounted price.\"\"\"\n-    order_line.unit_price = TaxedMoney(\n-        net=order_line.undiscounted_base_unit_price,\n-        gross=order_line.undiscounted_base_unit_price,\n-    )\n+    order_line.discounts.all().delete()\n+    update_unit_discount_data_on_order_line(order_line, [])\n     order_line.base_unit_price = order_line.undiscounted_base_unit_price\n-    order_line.undiscounted_unit_price = TaxedMoney(\n-        net=order_line.undiscounted_base_unit_price,\n-        gross=order_line.undiscounted_base_unit_price,\n-    )\n-    order_line.unit_discount_amount = Decimal(0)\n-    order_line.unit_discount_value = Decimal(0)\n-    order_line.unit_discount_reason = \"\"\n-    order_line.total_price = order_line.unit_price * order_line.quantity\n     order_line.save(\n         update_fields=[\n             \"unit_discount_value\",\n             \"unit_discount_amount\",\n@@ -1038,9 +1018,8 @@\n             \"total_price_gross_amount\",\n             \"tax_rate\",\n         ]\n     )\n-    order_line.discounts.all().delete()\n \n     # Manual discounts take precedence over vouchers, overriding them when applied.\n     # However, this does not entirely dissociate the voucher from the order.\n     # If the manual discount is removed, the voucher is reevaluated.\n"
        }
      ]
    },
    {
      "id": "validate-tax-webhooks",
      "sha": "1337f67b001927aac5c30854debdd1de8e6ccfcf",
      "parentSha": "f1b632ef74f6784ed84d8c54ef82647a9ea9725d",
      "spec": "Implement static validation and structured error handling for tax sync webhook responses and propagate them through checkout/order calculations and plugin/transport layers.\n\nScope and required changes:\n\n1) Core error constants and exceptions\n- In saleor/core/taxes.py, add a constant TAX_ERROR_FIELD_LENGTH = 255.\n- Extend TaxDataError to accept an optional errors: list in the constructor, store on self.errors.\n\n2) Model field lengths for tax errors\n- In saleor/checkout/models.py and saleor/order/models.py, set the tax_error CharField max_length to TAX_ERROR_FIELD_LENGTH (import from core.taxes) instead of a numeric literal.\n\n3) Replace ad-hoc tax data validation with Pydantic schemas\n- Create saleor/webhook/response_schemas/taxes.py with two Pydantic models:\n  - LineCalculateTaxesSchema: fields tax_rate (Decimal, 0–100), total_gross_amount (Decimal, 0–MAXIMUM_PRICE), total_net_amount (Decimal, 0–MAXIMUM_PRICE).\n  - CalculateTaxesSchema: fields shipping_tax_rate (0–100), shipping_price_gross_amount (0–MAXIMUM_PRICE), shipping_price_net_amount (0–MAXIMUM_PRICE), lines: list[LineCalculateTaxesSchema] with a field validator enforcing that len(lines) equals an expected_line_count taken from context.\n- In saleor/webhook/response_schemas/shipping.py, update typing to use Annotated for id/name/amount and coerce amount to Decimal; tests should assert amount is Decimal and only one validation error is raised per invalid input.\n- In saleor/webhook/response_schemas/annotations.py, add a TypeVar and type the skip_invalid_metadata helper to return the same type.\n\n4) Webhook transport utils parsing\n- In saleor/webhook/transport/utils.py, change parse_tax_data signature to parse_tax_data(response_data, lines_count) -> TaxData and implement validation using CalculateTaxesSchema.model_validate(..., context={\"expected_line_count\": lines_count}). Remove the old _unsafe_parse_tax_data; construct a core.taxes.TaxData from the validated model.\n\n5) Synchronous transport orchestration for tax webhooks\n- In saleor/webhook/transport/synchronous/transport.py, replace trigger_all_webhooks_sync with a dedicated trigger_taxes_all_webhooks_sync(event_type, generate_payload, expected_lines_count, subscribable_object=None, requestor=None, pregenerated_subscription_payloads=None) -> TaxData | None that:\n  - Iterates eligible webhooks for the event, constructs and sends deliveries, and for each response calls parse_tax_data(response, expected_lines_count).\n  - Catches pydantic.ValidationError, logs a warning with the error and an extra payload containing the list of errors, and continues to the next webhook.\n  - Returns the first successfully parsed TaxData or None if none succeed.\n- Update saleor/webhook/transport/synchronous/__init__.py to export trigger_taxes_all_webhooks_sync instead of trigger_all_webhooks_sync.\n\n6) Webhook plugin responsibilities for tax calculation\n- In saleor/plugins/webhook/plugin.py:\n  - Import ValidationError from pydantic and truncatechars from django.template.defaultfilters, and TAX_ERROR_FIELD_LENGTH and TaxDataError from core.taxes.\n  - Update the internal tax webhook runner to accept expected_lines_count and return TaxData. If the configured tax app is missing, log a warning and raise TaxDataError(\"Configured tax app doesn't exist.\"); if the app's tax webhook is missing, log and raise TaxDataError(\"Configured tax app's webhook for taxes calculation doesn't exists.\").\n  - Parse and validate tax responses using parse_tax_data(response, expected_lines_count). If validation fails, log a warning with extra={\"errors\": errors}, and raise TaxDataError with the message truncated to TAX_ERROR_FIELD_LENGTH via truncatechars and include errors on the exception.\n  - For the deprecated flow (when no app identifier is supplied), call trigger_taxes_all_webhooks_sync(...) rather than trigger_all_webhooks_sync.\n\n7) Plugin manager: iterate tax plugins until success\n- In saleor/plugins/manager.py, add __run_tax_method_until_first_success(method_name, *args, channel_slug, **kwargs) that loops active plugins and:\n  - For each plugin, call the tax method; if it raises TaxDataError, remember the exception and continue; if it returns non-None TaxData, return it.\n  - After the loop, if an error occurred and no plugin returned data, re-raise the last TaxDataError; otherwise return None.\n- Update get_taxes_for_checkout(...) and get_taxes_for_order(...) to delegate to __run_tax_method_until_first_success instead of the generic runner.\n\n8) Checkout and order calculations: centralize tax fetching and structured logging\n- In saleor/checkout/calculations.py, implement a helper _get_taxes_for_checkout(checkout_info, lines, tax_app_identifier, manager, pregenerated_subscription_payloads=None, allowed_empty_tax_data=False) that:\n  - Calls manager.get_taxes_for_checkout(...), logs address details if the return is None.\n  - If no tax_data and allowed_empty_tax_data is False, raise TaxDataError(TaxDataErrorMessage.EMPTY).\n  - Return the tax_data (possibly None if allowed).\n- Update _calculate_and_add_tax and _call_plugin_or_tax_app to call _get_taxes_for_checkout and remove validate_tax_data usage entirely. When catching TaxDataError during price fetching, include errors in the logger extra if present and set checkout.tax_error to the error message; set base prices where applicable.\n- In saleor/order/calculations.py, mirror the above with _get_taxes_for_order(order, tax_app_identifier, manager, allowed_empty_tax_data=False), similarly removing validate_tax_data, and include errors in logger extra when logging TaxDataError.\n\n9) Remove legacy tax validation in tax/utils\n- In saleor/tax/utils.py, remove validate_tax_data and its helpers (negative value, line count, overflow checks) and any references. Update tests accordingly.\n\n10) Message truncation and tests\n- In saleor/payment/utils.py, change truncate_transaction_event_message to use Django’s truncatechars filter with TRANSACTION_EVENT_MSG_MAX_LENGTH. Update tests to expect a 511-character truncation with a single Unicode ellipsis character (…).\n\n11) Tests and expectations alignment\n- Update tests where previously parse_tax_data returned None on invalid input to instead expect ValidationError to be raised by parse_tax_data or TaxDataError from plugin layers.\n- Update tests to pass the expected lines count into parse_tax_data and trigger_taxes_all_webhooks_sync, and to validate that logger.warning is called with extra={\"errors\": [...]} where applicable.\n- Adjust GraphQL and order/checkout tests to expect the new error message \"Configured tax app doesn't exist.\" in scenarios where the configured app is missing, and to accept empty tax_data only when explicitly allowed (e.g., allowed_empty_tax_data=True flows).\n\n12) Logging behavior\n- Wherever TaxDataError is caught in checkout/order calculations, build logger extra via existing *_info_for_logs helpers and, if the exception has e.errors, include errors in extra before logging.\n\nAcceptance criteria:\n- All tax webhook responses are validated via the new Pydantic schemas and respect MAXIMUM_PRICE and tax rate bounds, and lines count matches expected_line_count.\n- Transport and plugin methods either return a valid TaxData or raise a TaxDataError with truncated user-facing message; structured error details are logged in the extra payload.\n- Manager returns the first successful plugin response or raises the last TaxDataError if all fail.\n- validate_tax_data and old unsafe tax parsers are fully removed.\n- Checkout/order tax calculation flows use the new helpers and no longer call validate_tax_data.\n- Tests updated to the new signatures and expectations (including Unicode ellipsis and 511 char truncation) pass.",
      "prompt": "Introduce strict validation and structured error propagation for tax calculation webhooks.\n\nHigh-level requirements:\n- Add schema-based validation for tax webhook responses and ensure invalid responses are rejected early.\n- Update the synchronous transport and webhook plugin layers to validate responses, propagate meaningful errors, and include structured errors in logs.\n- Adjust checkout and order tax calculation flows to rely on a common tax-fetching helper that either returns a valid tax payload or raises a consistent error, and remove legacy validation code.\n- Ensure plugin manager iterates through active plugins, returning the first valid tax data or surfacing the last error if none succeed.\n- Unify error message lengths with a shared constant and switch to a standard truncation helper; update tests to reflect the new messages and truncation behavior.\n\nDeliverables:\n- New validation schemas for tax response payloads and updates across transport, plugin, manager, and calculation layers to use them.\n- Logging updates to include structured error details when available.\n- Removal of the legacy tax data validators and their tests.\n- Updated tests and fixtures to reflect the strict validation, new function signatures, and message truncation behavior.",
      "supplementalFiles": [
        "saleor/webhook/event_types.py",
        "saleor/core/prices.py",
        "saleor/graphql/webhook/utils.py",
        "saleor/checkout/utils.py",
        "saleor/order/utils.py",
        "saleor/core/utils/metadata_manager.py",
        "saleor/plugins/tests/sample_plugins.py"
      ],
      "fileDiffs": [
        {
          "path": "saleor/checkout/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/calculations.py\n===================================================================\n--- saleor/checkout/calculations.py\tf1b632e (parent)\n+++ saleor/checkout/calculations.py\t1337f67 (commit)\n@@ -29,9 +29,8 @@\n     get_charge_taxes_for_checkout,\n     get_tax_app_identifier_for_checkout,\n     get_tax_calculation_strategy_for_checkout,\n     normalize_tax_rate_for_db,\n-    validate_tax_data,\n )\n from .fetch import find_checkout_line_info\n from .models import Checkout\n from .payment_utils import update_checkout_payment_statuses\n@@ -405,11 +404,12 @@\n                 pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n             )\n         except TaxDataError as e:\n             if str(e) != TaxDataErrorMessage.EMPTY:\n-                logger.warning(\n-                    str(e), extra=checkout_info_for_logs(checkout_info, lines)\n-                )\n+                extra = checkout_info_for_logs(checkout_info, lines)\n+                if e.errors:\n+                    extra[\"errors\"] = e.errors\n+                logger.warning(str(e), extra=extra)\n             _set_checkout_base_prices(checkout, checkout_info, lines)\n             checkout.tax_error = str(e)\n \n         if not should_charge_tax:\n@@ -436,11 +436,12 @@\n                     pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n                 )\n             except TaxDataError as e:\n                 if str(e) != TaxDataErrorMessage.EMPTY:\n-                    logger.warning(\n-                        str(e), extra=checkout_info_for_logs(checkout_info, lines)\n-                    )\n+                    extra = checkout_info_for_logs(checkout_info, lines)\n+                    if e.errors:\n+                        extra[\"errors\"] = e.errors\n+                    logger.warning(str(e), extra=extra)\n                 _set_checkout_base_prices(checkout, checkout_info, lines)\n                 checkout.tax_error = str(e)\n         else:\n             # Calculate net prices without taxes.\n@@ -499,10 +500,8 @@\n     address: Optional[\"Address\"] = None,\n     database_connection_name: str = settings.DATABASE_CONNECTION_DEFAULT_NAME,\n     pregenerated_subscription_payloads: dict | None = None,\n ):\n-    from .utils import log_address_if_validation_skipped_for_checkout\n-\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n     if tax_calculation_strategy == TaxCalculationStrategy.TAX_APP:\n         # If taxAppId is not configured run all active plugins and tax apps.\n@@ -513,17 +512,18 @@\n             _apply_tax_data_from_plugins(\n                 checkout, manager, checkout_info, lines, address\n             )\n             # Get the taxes calculated with apps and apply to checkout.\n-            tax_data = manager.get_taxes_for_checkout(\n+            # We should allow empty tax_data in case any tax webhook has not been\n+            # configured - handled by `allowed_empty_tax_data`\n+            tax_data = _get_taxes_for_checkout(\n                 checkout_info,\n                 lines,\n                 tax_app_identifier,\n+                manager,\n                 pregenerated_subscription_payloads,\n+                allowed_empty_tax_data=True,\n             )\n-            if not tax_data:\n-                log_address_if_validation_skipped_for_checkout(checkout_info, logger)\n-            validate_tax_data(tax_data, lines, allow_empty_tax_data=True)\n             _apply_tax_data(checkout, lines, tax_data)\n         else:\n             _call_plugin_or_tax_app(\n                 tax_app_identifier,\n@@ -554,10 +554,8 @@\n     lines: list[\"CheckoutLineInfo\"],\n     address: Optional[\"Address\"] = None,\n     pregenerated_subscription_payloads: dict | None = None,\n ):\n-    from .utils import log_address_if_validation_skipped_for_checkout\n-\n     if pregenerated_subscription_payloads is None:\n         pregenerated_subscription_payloads = {}\n \n     if tax_app_identifier.startswith(PLUGIN_IDENTIFIER_PREFIX):\n@@ -579,20 +577,54 @@\n         )\n         if checkout.tax_error:\n             raise TaxDataError(checkout.tax_error)\n     else:\n+        tax_data = _get_taxes_for_checkout(\n+            checkout_info,\n+            lines,\n+            tax_app_identifier,\n+            manager,\n+            pregenerated_subscription_payloads,\n+        )\n+        _apply_tax_data(checkout, lines, tax_data)\n+\n+\n+def _get_taxes_for_checkout(\n+    checkout_info: \"CheckoutInfo\",\n+    lines: list[\"CheckoutLineInfo\"],\n+    tax_app_identifier: str | None,\n+    manager: \"PluginsManager\",\n+    pregenerated_subscription_payloads: dict | None = None,\n+    allowed_empty_tax_data: bool = False,\n+):\n+    \"\"\"Get taxes for checkout from tax apps.\n+\n+    The `allowed_empty_tax_data` flag prevents an error from being raised when tax data\n+    is missing due to the absence of a configured tax app.\n+    \"\"\"\n+    from .utils import log_address_if_validation_skipped_for_checkout\n+\n+    tax_data = None\n+    try:\n         tax_data = manager.get_taxes_for_checkout(\n             checkout_info,\n             lines,\n             tax_app_identifier,\n             pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         )\n+    except TaxDataError as e:\n+        raise e from e\n+    finally:\n+        # log in case the tax_data is missing\n         if tax_data is None:\n             log_address_if_validation_skipped_for_checkout(checkout_info, logger)\n-        validate_tax_data(tax_data, lines)\n-        _apply_tax_data(checkout, lines, tax_data)\n \n+    if not tax_data and not allowed_empty_tax_data:\n+        raise TaxDataError(TaxDataErrorMessage.EMPTY)\n \n+    return tax_data\n+\n+\n def _remove_tax(checkout, lines_info):\n     checkout.total_gross_amount = checkout.total_net_amount\n     checkout.subtotal_gross_amount = checkout.subtotal_net_amount\n     checkout.shipping_price_gross_amount = checkout.shipping_price_net_amount\n"
        },
        {
          "path": "saleor/checkout/models.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/models.py\n===================================================================\n--- saleor/checkout/models.py\tf1b632e (parent)\n+++ saleor/checkout/models.py\t1337f67 (commit)\n@@ -16,9 +16,9 @@\n \n from ..channel.models import Channel\n from ..core.db.fields import MoneyField, TaxedMoneyField\n from ..core.models import ModelWithMetadata\n-from ..core.taxes import zero_money\n+from ..core.taxes import TAX_ERROR_FIELD_LENGTH, zero_money\n from ..giftcard.models import GiftCard\n from ..permission.enums import CheckoutPermissions\n from ..shipping.models import ShippingMethod\n from . import CheckoutAuthorizeStatus, CheckoutChargeStatus\n@@ -219,9 +219,11 @@\n         max_length=35, choices=settings.LANGUAGES, default=settings.LANGUAGE_CODE\n     )\n \n     tax_exemption = models.BooleanField(default=False)\n-    tax_error = models.CharField(max_length=255, blank=True, null=True)\n+    tax_error = models.CharField(\n+        max_length=TAX_ERROR_FIELD_LENGTH, blank=True, null=True\n+    )\n \n     class Meta:\n         ordering = (\"-last_change\", \"pk\")\n         permissions = (\n"
        },
        {
          "path": "saleor/checkout/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_calculations.py\n===================================================================\n--- saleor/checkout/tests/test_calculations.py\tf1b632e (parent)\n+++ saleor/checkout/tests/test_calculations.py\t1337f67 (commit)\n@@ -13,9 +13,15 @@\n     add_promo_code_to_checkout,\n     assign_external_shipping_to_checkout,\n )\n from ...core.prices import quantize_price\n-from ...core.taxes import TaxData, TaxDataErrorMessage, TaxLineData, zero_taxed_money\n+from ...core.taxes import (\n+    TaxData,\n+    TaxDataError,\n+    TaxDataErrorMessage,\n+    TaxLineData,\n+    zero_taxed_money,\n+)\n from ...graphql.core.utils import to_global_id_or_none\n from ...plugins import PLUGIN_IDENTIFIER_PREFIX\n from ...plugins.avatax.plugin import AvataxPlugin\n from ...plugins.avatax.tests.conftest import plugin_configuration  # noqa: F401\n@@ -33,8 +39,9 @@\n     _apply_tax_data,\n     _calculate_and_add_tax,\n     _set_checkout_base_prices,\n     fetch_checkout_data,\n+    logger,\n )\n from ..fetch import CheckoutLineInfo, fetch_checkout_info, fetch_checkout_lines\n \n \n@@ -638,27 +645,27 @@\n     mock_get_taxes.assert_not_called()\n \n \n @freeze_time()\n-@patch(\"saleor.checkout.calculations.validate_tax_data\")\n @patch(\"saleor.plugins.manager.PluginsManager.calculate_checkout_total\")\n @patch(\"saleor.plugins.manager.PluginsManager.get_taxes_for_checkout\")\n @patch(\"saleor.checkout.calculations._apply_tax_data\")\n @override_settings(PLUGINS=[\"saleor.plugins.tests.sample_plugins.PluginSample\"])\n def test_fetch_checkout_data_calls_tax_app(\n     mock_apply_tax_data,\n     mock_get_taxes,\n     mock_calculate_checkout_total,\n-    mock_validate_tax_data,\n     checkout_with_items,\n+    tax_data_response,\n ):\n     # given\n-    mock_validate_tax_data.return_value = False\n \n     checkout = checkout_with_items\n     checkout.price_expiration = timezone.now()\n     checkout.save()\n \n+    mock_get_taxes.return_value = tax_data_response\n+\n     checkout.channel.tax_configuration.tax_app_id = \"test.app\"\n     checkout.channel.tax_configuration.save()\n \n     manager = get_plugins_manager(allow_replica=False)\n@@ -681,22 +688,19 @@\n     mock_calculate_checkout_total.assert_not_called()\n \n \n @freeze_time()\n-@patch(\"saleor.checkout.calculations.validate_tax_data\")\n @patch(\"saleor.plugins.manager.PluginsManager.calculate_checkout_total\")\n @patch(\"saleor.plugins.manager.PluginsManager.get_taxes_for_checkout\")\n @patch(\"saleor.checkout.calculations._apply_tax_data\")\n @override_settings(PLUGINS=[\"saleor.plugins.tests.sample_plugins.PluginSample\"])\n def test_fetch_checkout_data_calls_tax_app_when_allow_sync_webhooks_set_to_false(\n     mock_apply_tax_data,\n     mock_get_taxes,\n     mock_calculate_checkout_total,\n-    mock_validate_tax_data,\n     checkout_with_items,\n ):\n     # given\n-    mock_validate_tax_data.return_value = False\n \n     checkout = checkout_with_items\n     checkout.price_expiration = timezone.now()\n     checkout.save()\n@@ -736,9 +740,8 @@\n \n     mock_apply_tax_data.assert_not_called()\n     mock_get_taxes.assert_not_called()\n     mock_calculate_checkout_total.assert_not_called()\n-    mock_validate_tax_data.assert_not_called()\n \n \n @freeze_time()\n def test_fetch_checkout_data_calls_inactive_plugin(\n@@ -901,15 +904,16 @@\n @pytest.mark.parametrize(\n     (\"prices_entered_with_tax\", \"tax_app_id\"),\n     [(True, None), (True, \"test.app\"), (False, None), (False, \"test.app\")],\n )\n+@patch.object(logger, \"warning\")\n @patch(\"saleor.checkout.calculations._set_checkout_base_prices\")\n-def test_fetch_checkout_data_tax_data_with_negative_values(\n+def test_fetch_checkout_data_tax_data_with_tax_data_error(\n     mock_set_base_prices,\n+    mocked_logger,\n     prices_entered_with_tax,\n     tax_app_id,\n     checkout_with_single_item,\n-    caplog,\n ):\n     # given\n     checkout = checkout_with_single_item\n \n@@ -917,30 +921,20 @@\n     channel.tax_configuration.tax_app_id = tax_app_id\n     channel.tax_configuration.prices_entered_with_tax = prices_entered_with_tax\n     channel.tax_configuration.save()\n \n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"-3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n+    error_msg = \"Invalid tax data\"\n+    errors = [{\"error1\": \"Negative tax data\"}, {\"error2\": \"Invalid tax data\"}]\n+    returned_tax_error = TaxDataError(message=error_msg, errors=errors)\n     zero_money = zero_taxed_money(checkout.currency)\n     manager_methods = {\n         \"calculate_checkout_total\": Mock(return_value=zero_money),\n         \"calculate_checkout_subtotal\": Mock(return_value=zero_money),\n         \"calculate_checkout_line_total\": Mock(return_value=zero_money),\n         \"calculate_checkout_shipping\": Mock(return_value=zero_money),\n         \"get_checkout_shipping_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n         \"get_checkout_line_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_taxes_for_checkout\": Mock(return_value=tax_data),\n+        \"get_taxes_for_checkout\": Mock(side_effect=returned_tax_error),\n     }\n     manager = Mock(**manager_methods)\n \n     checkout_lines_info, _ = fetch_checkout_lines(checkout)\n@@ -949,60 +943,45 @@\n     # when\n     fetch_checkout_data(checkout_info, manager, checkout_lines_info, force_update=True)\n \n     # then\n-    assert checkout_info.checkout.tax_error == TaxDataErrorMessage.NEGATIVE_VALUE\n-    assert TaxDataErrorMessage.NEGATIVE_VALUE in caplog.text\n-    assert caplog.records[0].checkout_id == to_global_id_or_none(checkout)\n+    assert checkout_info.checkout.tax_error == error_msg\n+    assert mocked_logger.call_count == 1\n+    assert len(mocked_logger.call_args) == 2\n+    assert mocked_logger.call_args[0][0] == error_msg\n+    assert mocked_logger.call_args[1][\"extra\"][\"errors\"] == errors\n+    mock_set_base_prices.assert_called_once()\n \n \n @pytest.mark.parametrize(\n-    (\"prices_entered_with_tax\", \"tax_app_id\"),\n-    [(True, None), (True, \"test.app\"), (False, None), (False, \"test.app\")],\n+    \"prices_entered_with_tax\",\n+    [True, False],\n )\n+@patch.object(logger, \"warning\")\n @patch(\"saleor.checkout.calculations._set_checkout_base_prices\")\n-def test_fetch_checkout_data_tax_data_with_wrong_number_of_lines(\n+def test_fetch_checkout_data_tax_data_missing_tax_id_empty_tax_data(\n     mock_set_base_prices,\n+    mocked_logger,\n     prices_entered_with_tax,\n-    tax_app_id,\n     checkout_with_single_item,\n-    caplog,\n ):\n     # given\n     checkout = checkout_with_single_item\n \n     channel = checkout.channel\n-    channel.tax_configuration.tax_app_id = tax_app_id\n+    channel.tax_configuration.tax_app_id = None\n     channel.tax_configuration.prices_entered_with_tax = prices_entered_with_tax\n     channel.tax_configuration.save()\n \n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-            TaxLineData(\n-                total_net_amount=Decimal(\"4\"),\n-                total_gross_amount=Decimal(\"6\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n     zero_money = zero_taxed_money(checkout.currency)\n     manager_methods = {\n         \"calculate_checkout_total\": Mock(return_value=zero_money),\n         \"calculate_checkout_subtotal\": Mock(return_value=zero_money),\n         \"calculate_checkout_line_total\": Mock(return_value=zero_money),\n         \"calculate_checkout_shipping\": Mock(return_value=zero_money),\n         \"get_checkout_shipping_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n         \"get_checkout_line_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_taxes_for_checkout\": Mock(return_value=tax_data),\n+        \"get_taxes_for_checkout\": Mock(return_value=None),\n     }\n     manager = Mock(**manager_methods)\n \n     checkout_lines_info, _ = fetch_checkout_lines(checkout)\n@@ -1011,70 +990,14 @@\n     # when\n     fetch_checkout_data(checkout_info, manager, checkout_lines_info, force_update=True)\n \n     # then\n-    assert checkout_info.checkout.tax_error == TaxDataErrorMessage.LINE_NUMBER\n-    assert TaxDataErrorMessage.LINE_NUMBER in caplog.text\n-    assert caplog.records[0].checkout_id == to_global_id_or_none(checkout)\n+    # In case the app identifier is not set, in case of error in tax data, it's skipped.\n+    assert not checkout_info.checkout.tax_error\n+    assert mocked_logger.call_count == 0\n+    mock_set_base_prices.assert_not_called()\n \n \n-@pytest.mark.parametrize(\n-    (\"prices_entered_with_tax\", \"tax_app_id\"),\n-    [(True, None), (True, \"test.app\"), (False, None), (False, \"test.app\")],\n-)\n-@patch(\"saleor.checkout.calculations._set_checkout_base_prices\")\n-def test_fetch_checkout_data_tax_data_with_price_overflow(\n-    mock_set_base_prices,\n-    prices_entered_with_tax,\n-    tax_app_id,\n-    checkout_with_single_item,\n-    caplog,\n-):\n-    # given\n-    checkout = checkout_with_single_item\n-\n-    channel = checkout.channel\n-    channel.tax_configuration.tax_app_id = tax_app_id\n-    channel.tax_configuration.prices_entered_with_tax = prices_entered_with_tax\n-    channel.tax_configuration.save()\n-\n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"120\"),\n-            ),\n-        ],\n-    )\n-\n-    zero_money = zero_taxed_money(checkout.currency)\n-    manager_methods = {\n-        \"calculate_checkout_total\": Mock(return_value=zero_money),\n-        \"calculate_checkout_subtotal\": Mock(return_value=zero_money),\n-        \"calculate_checkout_line_total\": Mock(return_value=zero_money),\n-        \"calculate_checkout_shipping\": Mock(return_value=zero_money),\n-        \"get_checkout_shipping_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_checkout_line_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_taxes_for_checkout\": Mock(return_value=tax_data),\n-    }\n-    manager = Mock(**manager_methods)\n-\n-    checkout_lines_info, _ = fetch_checkout_lines(checkout)\n-    checkout_info = fetch_checkout_info(checkout, checkout_lines_info, manager)\n-\n-    # when\n-    fetch_checkout_data(checkout_info, manager, checkout_lines_info, force_update=True)\n-\n-    # then\n-    assert checkout_info.checkout.tax_error == TaxDataErrorMessage.OVERFLOW\n-    assert TaxDataErrorMessage.OVERFLOW in caplog.text\n-    assert caplog.records[0].checkout_id == to_global_id_or_none(checkout)\n-\n-\n @patch(\"saleor.plugins.avatax.plugin.get_checkout_tax_data\")\n @override_settings(PLUGINS=[\"saleor.plugins.avatax.plugin.AvataxPlugin\"])\n def test_fetch_order_data_plugin_tax_data_with_negative_values(\n     mock_get_tax_data,\n"
        },
        {
          "path": "saleor/checkout/tests/test_order_from_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/checkout/tests/test_order_from_checkout.py\n===================================================================\n--- saleor/checkout/tests/test_order_from_checkout.py\tf1b632e (parent)\n+++ saleor/checkout/tests/test_order_from_checkout.py\t1337f67 (commit)\n@@ -1044,22 +1044,21 @@\n         discount.amount_value == (order.undiscounted_total - order.total).gross.amount\n     )\n \n \n-@patch(\"saleor.checkout.calculations.validate_tax_data\")\n+@patch(\"saleor.checkout.calculations._calculate_and_add_tax\")\n def test_create_order_from_checkout_update_tax_error(\n-    mock_validate_tax_data,\n+    _calculate_and_add_tax_mock,\n     checkout_with_items_and_shipping,\n     customer_user,\n     app,\n     tax_configuration_tax_app,\n     caplog,\n ):\n     # given\n-    mock_validate_tax_data.side_effect = TaxDataError(TaxDataErrorMessage.EMPTY)\n-\n     checkout = checkout_with_items_and_shipping\n     lines, _ = fetch_checkout_lines(checkout)\n+    _calculate_and_add_tax_mock.side_effect = TaxDataError(TaxDataErrorMessage.EMPTY)\n \n     manager = get_plugins_manager(allow_replica=False)\n     checkout_info = fetch_checkout_info(checkout, lines, manager, [])\n \n@@ -1070,7 +1069,8 @@\n             manager=manager,\n             user=None,\n             app=app,\n         )\n+\n     assert not Order.objects.exists()\n     assert \"Tax app error for checkout\" in caplog.text\n     assert caplog.records[0].checkout_id == to_global_id_or_none(checkout)\n"
        },
        {
          "path": "saleor/core/taxes.py",
          "status": "modified",
          "diff": "Index: saleor/core/taxes.py\n===================================================================\n--- saleor/core/taxes.py\tf1b632e (parent)\n+++ saleor/core/taxes.py\t1337f67 (commit)\n@@ -2,17 +2,23 @@\n from decimal import Decimal\n \n from prices import Money, TaxedMoney\n \n+TAX_ERROR_FIELD_LENGTH = 255\n \n+\n class TaxError(Exception):\n     \"\"\"Default tax error.\"\"\"\n \n \n class TaxDataError(Exception):\n     \"\"\"Error in tax data received from tax app or plugin.\"\"\"\n \n+    def __init__(self, message: str, errors: list | None = None):\n+        super().__init__(message)\n+        self.errors = errors or []\n \n+\n def zero_money(currency: str) -> Money:\n     \"\"\"Return a money object set to zero.\n \n     This is a function used as a model's default.\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_checkout_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\tf1b632e (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_checkout_complete.py\t1337f67 (commit)\n@@ -434,30 +434,30 @@\n     assert not EventDelivery.objects.exists()\n \n     checkout.refresh_from_db()\n     assert checkout.price_expiration == timezone.now() + settings.CHECKOUT_PRICES_TTL\n-    assert checkout.tax_error == \"Empty tax data.\"\n+    assert checkout.tax_error == \"Configured tax app doesn't exist.\"\n \n \n @freeze_time()\n @override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n-@mock.patch(\"saleor.checkout.calculations.validate_tax_data\")\n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_checkout_complete_calls_correct_tax_app(\n     mock_request,\n-    mock_validate_tax_data,\n     user_api_client,\n     checkout_without_shipping_required,\n     channel_USD,\n     address,\n     tax_app,\n-    tax_data_response,  # noqa: F811\n+    tax_data_response_factory,  # noqa: F811\n     settings,\n ):\n     # given\n-    mock_request.return_value = tax_data_response\n-    mock_validate_tax_data.return_value = False\n     checkout = checkout_without_shipping_required\n+    mock_request.return_value = tax_data_response_factory(\n+        lines_length=checkout.lines.count()\n+    )\n+\n     checkout.billing_address = address\n     checkout.price_expiration = timezone.now()\n     checkout.metadata_storage.store_value_in_metadata(items={\"accepted\": \"true\"})\n     checkout.metadata_storage.store_value_in_private_metadata(\n@@ -552,26 +552,27 @@\n \n \n @freeze_time()\n @override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n-@mock.patch(\"saleor.checkout.calculations.validate_tax_data\")\n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_checkout_complete_calls_correct_force_tax_calculation_when_tax_error_was_saved(\n     mock_request,\n-    mock_validate_tax_data,\n     user_api_client,\n     checkout_without_shipping_required,\n     channel_USD,\n     address,\n     tax_app,\n-    tax_data_response,  # noqa: F811\n+    tax_data_response_factory,  # noqa: F811\n     settings,\n ):\n     # given\n-    mock_request.return_value = tax_data_response\n-    mock_validate_tax_data.return_value = False\n \n     checkout = checkout_without_shipping_required\n+\n+    mock_request.return_value = tax_data_response_factory(\n+        lines_length=checkout.lines.count()\n+    )\n+\n     checkout.billing_address = address\n     checkout.price_expiration = (\n         timezone.now() + settings.CHECKOUT_PRICES_TTL + timezone.timedelta(hours=1)\n     )\n"
        },
        {
          "path": "saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py\n===================================================================\n--- saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py\tf1b632e (parent)\n+++ saleor/graphql/checkout/tests/mutations/test_order_create_from_checkout.py\t1337f67 (commit)\n@@ -16,9 +16,8 @@\n from .....checkout.models import Checkout, CheckoutLine\n from .....checkout.payment_utils import update_checkout_payment_statuses\n from .....core.taxes import (\n     TaxDataError,\n-    TaxDataErrorMessage,\n     TaxError,\n     zero_money,\n     zero_taxed_money,\n )\n@@ -2665,18 +2664,20 @@\n         \"Checkout should have been deleted\"\n     )\n \n \n-@patch(\"saleor.checkout.calculations.validate_tax_data\")\n+@patch(\n+    \"saleor.checkout.calculations._get_taxes_for_checkout\",\n+    side_effect=TaxDataError(\"Invalid data\"),\n+)\n def test_order_from_checkout_tax_error(\n-    mock_validate_tax_data,\n+    mocked_get_taxes_for_order,\n     app_api_client,\n     permission_handle_checkouts,\n     checkout_with_items_and_shipping,\n     caplog,\n ):\n     # given\n-    mock_validate_tax_data.side_effect = TaxDataError(TaxDataErrorMessage.EMPTY)\n     checkout = checkout_with_items_and_shipping\n     variables = {\"id\": graphene.Node.to_global_id(\"Checkout\", checkout.pk)}\n \n     # when\n"
        },
        {
          "path": "saleor/graphql/order/tests/mutations/test_draft_order_complete.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/order/tests/mutations/test_draft_order_complete.py\n===================================================================\n--- saleor/graphql/order/tests/mutations/test_draft_order_complete.py\tf1b632e (parent)\n+++ saleor/graphql/order/tests/mutations/test_draft_order_complete.py\t1337f67 (commit)\n@@ -1088,12 +1088,14 @@\n     permission_group_manage_orders,\n     draft_order,\n     channel_USD,\n     tax_app,\n-    tax_data_response,  # noqa: F811\n+    tax_data_response_factory,\n ):\n     # given\n-    mock_request.return_value = tax_data_response\n+    mock_request.return_value = tax_data_response_factory(\n+        lines_length=draft_order.lines.count()\n+    )\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n \n     order = draft_order\n     order.should_refresh_prices = True\n@@ -1119,28 +1121,27 @@\n     assert not EventDelivery.objects.exists()\n \n     order.refresh_from_db()\n     assert not order.should_refresh_prices\n-    assert order.tax_error == \"Empty tax data.\"\n+    assert order.tax_error == \"Configured tax app doesn't exist.\"\n \n \n @freeze_time()\n @override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n-@patch(\"saleor.order.calculations.validate_tax_data\")\n @patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_draft_order_complete_force_tax_calculation_when_tax_error_was_saved(\n     mock_request,\n-    mock_validate_tax_data,\n     staff_api_client,\n     permission_group_manage_orders,\n     draft_order,\n     channel_USD,\n     tax_app,\n-    tax_data_response,  # noqa: F811\n+    tax_data_response_factory,  # noqa: F811\n ):\n     # given\n-    mock_request.return_value = tax_data_response\n-    mock_validate_tax_data.return_value = False\n+    mock_request.return_value = tax_data_response_factory(\n+        lines_length=draft_order.lines.count()\n+    )\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n \n     order = draft_order\n     order.should_refresh_prices = False\n@@ -1172,23 +1173,22 @@\n \n \n @freeze_time()\n @override_settings(PLUGINS=[\"saleor.plugins.webhook.plugin.WebhookPlugin\"])\n-@patch(\"saleor.order.calculations.validate_tax_data\")\n @patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_draft_order_complete_calls_correct_tax_app(\n     mock_request,\n-    mock_validate_tax_data,\n     staff_api_client,\n     permission_group_manage_orders,\n     draft_order,\n     channel_USD,\n     tax_app,\n-    tax_data_response,  # noqa: F811\n+    tax_data_response_factory,  # noqa: F811\n ):\n     # given\n-    mock_request.return_value = tax_data_response\n-    mock_validate_tax_data.return_value = False\n+    mock_request.return_value = tax_data_response_factory(\n+        lines_length=draft_order.lines.count()\n+    )\n     permission_group_manage_orders.user_set.add(staff_api_client.user)\n \n     order = draft_order\n     order.should_refresh_prices = True\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_create.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_create.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_create.py\tf1b632e (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_create.py\t1337f67 (commit)\n@@ -2412,9 +2412,9 @@\n     }\n \n     transaction = order_with_lines.payment_transactions.first()\n     event = transaction.events.last()\n-    assert event.message == transaction_msg[:509] + \"...\"\n+    assert event.message == transaction_msg[:511] + \"…\"\n     assert event.psp_reference == transaction_reference\n \n \n def test_transaction_create_create_event_message_is_empty(\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_event_report.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\tf1b632e (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_event_report.py\t1337f67 (commit)\n@@ -3222,9 +3222,9 @@\n     assert event.transaction == transaction\n     assert event.app_identifier == app_api_client.app.identifier\n     assert event.app == app_api_client.app\n     assert event.user is None\n-    assert event.message == message[:509] + \"...\"\n+    assert event.message == message[:511] + \"…\"\n \n \n def test_transaction_event_report_empty_message(\n     transaction_item_generator,\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_initialize.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_initialize.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_initialize.py\tf1b632e (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_initialize.py\t1337f67 (commit)\n@@ -2720,9 +2720,9 @@\n         app_identifier=webhook_app.identifier,\n         mocked_initialize=mocked_initialize,\n         charged_value=expected_amount,\n         returned_data=expected_response[\"data\"],\n-        expected_message=expected_response[\"message\"][:509] + \"...\",\n+        expected_message=expected_response[\"message\"][:511] + \"…\",\n     )\n     assert checkout.charge_status == CheckoutChargeStatus.PARTIAL\n     assert checkout.authorize_status == CheckoutAuthorizeStatus.PARTIAL\n     assert (\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_process.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_process.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_process.py\tf1b632e (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_process.py\t1337f67 (commit)\n@@ -2300,9 +2300,9 @@\n         app_identifier=webhook_app.identifier,\n         mocked_process=mocked_process,\n         charged_value=expected_amount,\n         returned_data=None,\n-        expected_message=expected_response[\"message\"][:509] + \"...\",\n+        expected_message=expected_response[\"message\"][:511] + \"…\",\n     )\n     assert (\n         \"Value for field: message in response of transaction action webhook \"\n         \"exceeds the character field limit. Message has been truncated.\"\n"
        },
        {
          "path": "saleor/graphql/payment/tests/mutations/test_transaction_update.py",
          "status": "modified",
          "diff": "Index: saleor/graphql/payment/tests/mutations/test_transaction_update.py\n===================================================================\n--- saleor/graphql/payment/tests/mutations/test_transaction_update.py\tf1b632e (parent)\n+++ saleor/graphql/payment/tests/mutations/test_transaction_update.py\t1337f67 (commit)\n@@ -3424,9 +3424,9 @@\n     }\n \n     transaction = order_with_lines.payment_transactions.first()\n     event = transaction.events.last()\n-    assert event.message == transaction_msg[:509] + \"...\"\n+    assert event.message == transaction_msg[:511] + \"…\"\n     assert event.psp_reference == transaction_reference\n \n \n def test_transaction_uodate_transaction_event_empty_message(\n"
        },
        {
          "path": "saleor/order/calculations.py",
          "status": "modified",
          "diff": "Index: saleor/order/calculations.py\n===================================================================\n--- saleor/order/calculations.py\tf1b632e (parent)\n+++ saleor/order/calculations.py\t1337f67 (commit)\n@@ -37,9 +37,8 @@\n     get_charge_taxes_for_order,\n     get_tax_app_identifier_for_order,\n     get_tax_calculation_strategy_for_order,\n     normalize_tax_rate_for_db,\n-    validate_tax_data,\n )\n from . import ORDER_EDITABLE_STATUS, OrderStatus\n from .base_calculations import base_order_line_total, calculate_prices\n from .fetch import (\n@@ -198,9 +197,12 @@\n                 database_connection_name=database_connection_name,\n             )\n         except TaxDataError as e:\n             if str(e) != TaxDataErrorMessage.EMPTY:\n-                logger.warning(str(e), extra=order_info_for_logs(order, lines))\n+                extra = order_info_for_logs(order, lines)\n+                if e.errors:\n+                    extra[\"errors\"] = e.errors\n+                logger.warning(str(e), extra=extra)\n             order.tax_error = str(e)\n \n         if not should_charge_tax:\n             # If charge_taxes is disabled or order is exempt from taxes, remove the\n@@ -223,9 +225,12 @@\n                     database_connection_name=database_connection_name,\n                 )\n             except TaxDataError as e:\n                 if str(e) != TaxDataErrorMessage.EMPTY:\n-                    logger.warning(str(e), extra=order_info_for_logs(order, lines))\n+                    extra = order_info_for_logs(order, lines)\n+                    if e.errors:\n+                        extra[\"errors\"] = e.errors\n+                    logger.warning(str(e), extra=extra)\n                 order.tax_error = str(e)\n         else:\n             remove_tax(order, lines, prices_entered_with_tax)\n \n@@ -247,12 +252,14 @@\n             # This is deprecated flow, kept to maintain backward compatibility.\n             # In Saleor 4.0 `tax_app_identifier` should be required and the flow should\n             # be dropped.\n             _recalculate_with_plugins(manager, order, lines, prices_entered_with_tax)\n-            tax_data = manager.get_taxes_for_order(order, tax_app_identifier)\n-            if not tax_data:\n-                log_address_if_validation_skipped_for_order(order, logger)\n-            validate_tax_data(tax_data, lines, allow_empty_tax_data=True)\n+            # Get the taxes calculated with apps and apply to order.\n+            # We should allow empty tax_data in case any tax webhook has not been\n+            # configured - handled by `allowed_empty_tax_data`\n+            tax_data = _get_taxes_for_order(\n+                order, tax_app_identifier, manager, allowed_empty_tax_data=True\n+            )\n             _apply_tax_data(order, lines, tax_data, prices_entered_with_tax)\n         else:\n             _call_plugin_or_tax_app(\n                 tax_app_identifier,\n@@ -294,15 +301,39 @@\n         )\n         if order.tax_error:\n             raise TaxDataError(order.tax_error)\n     else:\n+        tax_data = _get_taxes_for_order(order, tax_app_identifier, manager)\n+        _apply_tax_data(order, lines, tax_data, prices_entered_with_tax)\n+\n+\n+def _get_taxes_for_order(\n+    order: \"Order\",\n+    tax_app_identifier: str | None,\n+    manager: \"PluginsManager\",\n+    allowed_empty_tax_data: bool = False,\n+):\n+    \"\"\"Get taxes for order from tax apps.\n+\n+    The `allowed_empty_tax_data` flag prevents an error from being raised when tax data\n+    is missing due to the absence of a configured tax app.\n+    \"\"\"\n+    tax_data = None\n+    try:\n         tax_data = manager.get_taxes_for_order(order, tax_app_identifier)\n+    except TaxDataError as e:\n+        raise e from e\n+    finally:\n+        # log in case the tax_data is missing\n         if tax_data is None:\n             log_address_if_validation_skipped_for_order(order, logger)\n-        validate_tax_data(tax_data, lines)\n-        _apply_tax_data(order, lines, tax_data, prices_entered_with_tax)\n \n+    if not tax_data and not allowed_empty_tax_data:\n+        raise TaxDataError(TaxDataErrorMessage.EMPTY)\n \n+    return tax_data\n+\n+\n def _recalculate_with_plugins(\n     manager: PluginsManager,\n     order: Order,\n     lines: Iterable[OrderLine],\n"
        },
        {
          "path": "saleor/order/models.py",
          "status": "modified",
          "diff": "Index: saleor/order/models.py\n===================================================================\n--- saleor/order/models.py\tf1b632e (parent)\n+++ saleor/order/models.py\t1337f67 (commit)\n@@ -20,8 +20,9 @@\n from ..app.models import App\n from ..channel.models import Channel\n from ..core.db.fields import MoneyField, TaxedMoneyField\n from ..core.models import ModelWithExternalReference, ModelWithMetadata\n+from ..core.taxes import TAX_ERROR_FIELD_LENGTH\n from ..core.units import WeightUnits\n from ..core.utils.json_serializer import CustomJsonEncoder\n from ..core.weight import zero_weight\n from ..discount import DiscountValueType\n@@ -356,9 +357,11 @@\n     search_vector = SearchVectorField(blank=True, null=True)\n     # this field is used only for draft/unconfirmed orders\n     should_refresh_prices = models.BooleanField(default=True)\n     tax_exemption = models.BooleanField(default=False)\n-    tax_error = models.CharField(max_length=255, null=True, blank=True)\n+    tax_error = models.CharField(\n+        max_length=TAX_ERROR_FIELD_LENGTH, null=True, blank=True\n+    )\n \n     objects = OrderManager()\n \n     class Meta:\n"
        },
        {
          "path": "saleor/order/tests/test_calculations.py",
          "status": "modified",
          "diff": "Index: saleor/order/tests/test_calculations.py\n===================================================================\n--- saleor/order/tests/test_calculations.py\tf1b632e (parent)\n+++ saleor/order/tests/test_calculations.py\t1337f67 (commit)\n@@ -8,8 +8,9 @@\n \n from ...core.prices import quantize_price\n from ...core.taxes import (\n     TaxData,\n+    TaxDataError,\n     TaxDataErrorMessage,\n     TaxError,\n     TaxLineData,\n     zero_taxed_money,\n@@ -24,8 +25,9 @@\n from ...tax import TaxCalculationStrategy\n from ...tax.calculations.order import update_order_prices_with_flat_rates\n from ...tax.utils import get_tax_calculation_strategy_for_order\n from .. import OrderStatus, calculations\n+from ..calculations import logger\n from ..interface import OrderTaxedPricesData\n \n \n @pytest.fixture\n@@ -1507,28 +1509,27 @@\n     assert mock_calculate_order_line_total.call_count == 2\n     mock_get_taxes.assert_not_called()\n \n \n-@patch(\"saleor.order.calculations.validate_tax_data\")\n @patch(\"saleor.plugins.manager.PluginsManager.calculate_order_total\")\n @patch(\"saleor.plugins.manager.PluginsManager.get_taxes_for_order\")\n @patch(\"saleor.order.calculations._apply_tax_data\")\n @override_settings(PLUGINS=[\"saleor.plugins.tests.sample_plugins.PluginSample\"])\n def test_fetch_order_data_calls_tax_app(\n     mock_apply_tax_data,\n     mock_get_taxes,\n     mock_calculate_order_total,\n-    mock_validate_tax_data,\n     order_with_lines,\n     order_lines,\n+    tax_data_response,\n ):\n     # given\n-    mock_validate_tax_data.return_value = False\n-\n     order = order_with_lines\n     order.channel.tax_configuration.tax_app_id = \"test.app\"\n     order.channel.tax_configuration.save()\n \n+    mock_get_taxes.return_value = tax_data_response\n+\n     fetch_kwargs = {\n         \"order\": order,\n         \"manager\": get_plugins_manager(allow_replica=False),\n         \"lines\": order_lines,\n@@ -1614,13 +1615,14 @@\n @pytest.mark.parametrize(\n     (\"prices_entered_with_tax\", \"tax_app_id\"),\n     [(True, None), (True, \"test.app\"), (False, None), (False, \"test.app\")],\n )\n-def test_fetch_order_data_tax_data_with_negative_values(\n+@patch.object(logger, \"warning\")\n+def test_fetch_order_data_tax_data_with_tax_data_error(\n+    mocked_logger,\n     prices_entered_with_tax,\n     tax_app_id,\n     order_with_lines,\n-    caplog,\n ):\n     # given\n     order = order_with_lines\n \n@@ -1628,26 +1630,11 @@\n     channel.tax_configuration.tax_app_id = tax_app_id\n     channel.tax_configuration.prices_entered_with_tax = prices_entered_with_tax\n     channel.tax_configuration.save()\n \n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"-1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-            TaxLineData(\n-                total_net_amount=Decimal(\"4\"),\n-                total_gross_amount=Decimal(\"6\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n+    error_msg = \"Invalid tax data\"\n+    errors = [{\"error1\": \"Negative tax data\"}, {\"error2\": \"Invalid tax data\"}]\n+    returned_tax_error = TaxDataError(message=error_msg, errors=errors)\n     zero_money = zero_taxed_money(order.currency)\n     zero_prices = OrderTaxedPricesData(\n         undiscounted_price=zero_money,\n         price_with_discounts=zero_money,\n@@ -1658,111 +1645,41 @@\n         \"calculate_order_total\": Mock(return_value=zero_money),\n         \"calculate_order_shipping\": Mock(return_value=zero_money),\n         \"get_order_shipping_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n         \"get_order_line_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_taxes_for_order\": Mock(return_value=tax_data),\n+        \"get_taxes_for_order\": Mock(side_effect=returned_tax_error),\n     }\n     manager = Mock(**manager_methods)\n \n     # when\n     calculations.fetch_order_prices_if_expired(order, manager, None, True)\n \n     # then\n-    assert order.tax_error == TaxDataErrorMessage.NEGATIVE_VALUE\n-    assert TaxDataErrorMessage.NEGATIVE_VALUE in caplog.text\n-    assert caplog.records[0].order_id == to_global_id_or_none(order)\n+    assert order.tax_error == error_msg\n+    assert mocked_logger.call_count == 1\n+    assert len(mocked_logger.call_args) == 2\n+    assert mocked_logger.call_args[0][0] == error_msg\n+    assert mocked_logger.call_args[1][\"extra\"][\"errors\"] == errors\n \n \n @pytest.mark.parametrize(\n-    (\"prices_entered_with_tax\", \"tax_app_id\"),\n-    [(True, None), (True, \"test.app\"), (False, None), (False, \"test.app\")],\n+    \"prices_entered_with_tax\",\n+    [True, False],\n )\n-def test_fetch_order_data_tax_data_with_wrong_number_of_lines(\n+@patch.object(logger, \"warning\")\n+def test_fetch_order_data_tax_data_missing_tax_id_empty_tax_data(\n+    mocked_logger,\n     prices_entered_with_tax,\n-    tax_app_id,\n     order_with_lines,\n-    caplog,\n ):\n     # given\n     order = order_with_lines\n-    channel = order.channel\n-    channel.tax_configuration.tax_app_id = tax_app_id\n-    channel.tax_configuration.prices_entered_with_tax = prices_entered_with_tax\n-    channel.tax_configuration.save()\n \n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n-    zero_money = zero_taxed_money(order.currency)\n-    zero_prices = OrderTaxedPricesData(\n-        undiscounted_price=zero_money,\n-        price_with_discounts=zero_money,\n-    )\n-    manager_methods = {\n-        \"calculate_order_line_unit\": Mock(return_value=zero_prices),\n-        \"calculate_order_line_total\": Mock(return_value=zero_prices),\n-        \"calculate_order_total\": Mock(return_value=zero_money),\n-        \"calculate_order_shipping\": Mock(return_value=zero_money),\n-        \"get_order_shipping_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_order_line_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_taxes_for_order\": Mock(return_value=tax_data),\n-    }\n-    manager = Mock(**manager_methods)\n-\n-    # when\n-    calculations.fetch_order_prices_if_expired(order, manager, None, True)\n-\n-    # then\n-    assert order.tax_error == TaxDataErrorMessage.LINE_NUMBER\n-    assert TaxDataErrorMessage.LINE_NUMBER in caplog.text\n-    assert caplog.records[0].order_id == to_global_id_or_none(order)\n-\n-\n-@pytest.mark.parametrize(\n-    (\"prices_entered_with_tax\", \"tax_app_id\"),\n-    [(True, None), (True, \"test.app\"), (False, None), (False, \"test.app\")],\n-)\n-def test_fetch_order_data_tax_data_with_price_overflow(\n-    prices_entered_with_tax,\n-    tax_app_id,\n-    order_with_lines,\n-    caplog,\n-):\n-    # given\n-    order = order_with_lines\n     channel = order.channel\n-    channel.tax_configuration.tax_app_id = tax_app_id\n+    channel.tax_configuration.tax_app_id = None\n     channel.tax_configuration.prices_entered_with_tax = prices_entered_with_tax\n     channel.tax_configuration.save()\n \n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"99999999999\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-            TaxLineData(\n-                total_net_amount=Decimal(\"4\"),\n-                total_gross_amount=Decimal(\"6\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n     zero_money = zero_taxed_money(order.currency)\n     zero_prices = OrderTaxedPricesData(\n         undiscounted_price=zero_money,\n         price_with_discounts=zero_money,\n@@ -1773,19 +1690,18 @@\n         \"calculate_order_total\": Mock(return_value=zero_money),\n         \"calculate_order_shipping\": Mock(return_value=zero_money),\n         \"get_order_shipping_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n         \"get_order_line_tax_rate\": Mock(return_value=Decimal(\"0.00\")),\n-        \"get_taxes_for_order\": Mock(return_value=tax_data),\n+        \"get_taxes_for_order\": Mock(return_value=None),\n     }\n     manager = Mock(**manager_methods)\n \n     # when\n     calculations.fetch_order_prices_if_expired(order, manager, None, True)\n \n     # then\n-    assert order.tax_error == TaxDataErrorMessage.OVERFLOW\n-    assert TaxDataErrorMessage.OVERFLOW in caplog.text\n-    assert caplog.records[0].order_id == to_global_id_or_none(order)\n+    assert not order.tax_error\n+    assert mocked_logger.call_count == 0\n \n \n @patch(\"saleor.plugins.avatax.plugin.get_order_tax_data\")\n @override_settings(PLUGINS=[\"saleor.plugins.avatax.plugin.AvataxPlugin\"])\n"
        },
        {
          "path": "saleor/payment/tests/test_utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/tests/test_utils.py\n===================================================================\n--- saleor/payment/tests/test_utils.py\tf1b632e (parent)\n+++ saleor/payment/tests/test_utils.py\t1337f67 (commit)\n@@ -1808,9 +1808,9 @@\n     assert event.psp_reference == expected_psp_reference\n     assert event.amount_value == event_amount\n     assert event.created_at == datetime.datetime.fromisoformat(event_time)\n     assert event.external_url == event_url\n-    assert event.message == event_message[:509] + \"...\"\n+    assert event.message == event_message[:511] + \"…\"\n     assert event.type == event_type\n     assert len(caplog.records) == 1\n     assert caplog.records[0].message == (\n         \"Value for field: message in response of transaction action webhook \"\n@@ -2718,9 +2718,9 @@\n     # then\n     transaction.refresh_from_db()\n     assert transaction.events.count() == 2\n     event = transaction.events.last()\n-    assert event.message == message[:509] + \"...\"\n+    assert event.message == message[:511] + \"…\"\n     assert len(caplog.records) == 1\n     assert caplog.records[0].message == (\n         \"Value for field: message in response of transaction action webhook \"\n         \"exceeds the character field limit. Message has been truncated.\"\n"
        },
        {
          "path": "saleor/payment/utils.py",
          "status": "modified",
          "diff": "Index: saleor/payment/utils.py\n===================================================================\n--- saleor/payment/utils.py\tf1b632e (parent)\n+++ saleor/payment/utils.py\t1337f67 (commit)\n@@ -10,8 +10,9 @@\n from django.conf import settings\n from django.core.serializers.json import DjangoJSONEncoder\n from django.db import IntegrityError, transaction\n from django.db.models import Q\n+from django.template.defaultfilters import truncatechars\n from django.utils import timezone\n \n from ..account.models import User\n from ..app.models import App\n@@ -1001,13 +1002,9 @@\n     )\n \n \n def truncate_transaction_event_message(message: str):\n-    return (\n-        message[: TRANSACTION_EVENT_MSG_MAX_LENGTH - 3] + \"...\"\n-        if len(message) > TRANSACTION_EVENT_MSG_MAX_LENGTH\n-        else message\n-    )\n+    return truncatechars(message, TRANSACTION_EVENT_MSG_MAX_LENGTH)\n \n \n def get_failed_transaction_event_type_for_request_event(\n     request_event: TransactionEvent,\n"
        },
        {
          "path": "saleor/plugins/manager.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/manager.py\n===================================================================\n--- saleor/plugins/manager.py\tf1b632e (parent)\n+++ saleor/plugins/manager.py\t1337f67 (commit)\n@@ -14,9 +14,9 @@\n from ..core.db.connection import allow_writer\n from ..core.models import EventDelivery\n from ..core.payments import PaymentInterface\n from ..core.prices import quantize_price\n-from ..core.taxes import TaxData, TaxType, zero_money, zero_taxed_money\n+from ..core.taxes import TaxData, TaxDataError, TaxType, zero_money, zero_taxed_money\n from ..graphql.core import SaleorContext\n from ..order import base_calculations as base_order_calculations\n from ..order.base_calculations import (\n     base_order_line_total,\n@@ -638,9 +638,9 @@\n         pregenerated_subscription_payloads: dict | None = None,\n     ) -> TaxData | None:\n         if pregenerated_subscription_payloads is None:\n             pregenerated_subscription_payloads = {}\n-        return self.__run_plugin_method_until_first_success(\n+        return self.__run_tax_method_until_first_success(\n             \"get_taxes_for_checkout\",\n             checkout_info,\n             lines,\n             app_identifier,\n@@ -650,15 +650,42 @@\n \n     # Note: this method is deprecated and will be removed in a future release.\n     # Webhook-related functionality will be moved from plugin to core modules.\n     def get_taxes_for_order(self, order: \"Order\", app_identifier) -> TaxData | None:\n-        return self.__run_plugin_method_until_first_success(\n+        return self.__run_tax_method_until_first_success(\n             \"get_taxes_for_order\",\n             order,\n             app_identifier,\n             channel_slug=order.channel.slug,\n         )\n \n+    def __run_tax_method_until_first_success(\n+        self,\n+        method_name: str,\n+        *args,\n+        channel_slug: str | None,\n+        **kwargs,\n+    ) -> TaxData | None:\n+        plugins = self.get_plugins(channel_slug=channel_slug, active_only=True)\n+        default_value = None\n+        error = None\n+        if plugins:\n+            # try to get the proper response from the plugins; in case any plugin\n+            # return proper response, raise an error from last plugin\n+            for plugin in plugins:\n+                try:\n+                    tax_data = self.__run_method_on_single_plugin(\n+                        plugin, method_name, default_value, *args, **kwargs\n+                    )\n+                except TaxDataError as e:\n+                    error = e\n+                    continue\n+                if tax_data is not None:\n+                    return tax_data\n+        if error:\n+            raise error\n+        return default_value\n+\n     def preprocess_order_creation(\n         self,\n         checkout_info: \"CheckoutInfo\",\n         lines: list[\"CheckoutLineInfo\"] | None = None,\n"
        },
        {
          "path": "saleor/plugins/tests/test_manager.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/tests/test_manager.py\n===================================================================\n--- saleor/plugins/tests/test_manager.py\tf1b632e (parent)\n+++ saleor/plugins/tests/test_manager.py\t1337f67 (commit)\n@@ -46,9 +46,8 @@\n     ChannelPluginSample,\n     InactivePaymentGateway,\n     PluginInactive,\n     PluginSample,\n-    sample_tax_data,\n )\n \n \n def test_get_plugins_manager(settings):\n@@ -536,51 +535,8 @@\n def test_manager_uses_get_tax_rate_choices(plugins, tax_rate_list):\n     assert tax_rate_list == PluginsManager(plugins=plugins).get_tax_rate_type_choices()\n \n \n-def sample_none_data(obj):\n-    return None\n-\n-\n-@pytest.mark.parametrize(\n-    (\"plugins\", \"expected_tax_data\"),\n-    [\n-        ([], sample_none_data),\n-        ([\"saleor.plugins.tests.sample_plugins.PluginSample\"], sample_tax_data),\n-    ],\n-)\n-def test_manager_get_taxes_for_checkout(\n-    checkout,\n-    plugins,\n-    expected_tax_data,\n-):\n-    lines, _ = fetch_checkout_lines(checkout)\n-    manager = get_plugins_manager(allow_replica=False)\n-    checkout_info = fetch_checkout_info(checkout, lines, manager)\n-    app_identifier = None\n-    assert PluginsManager(plugins=plugins).get_taxes_for_checkout(\n-        checkout_info, lines, app_identifier\n-    ) == expected_tax_data(checkout)\n-\n-\n-@pytest.mark.parametrize(\n-    (\"plugins\", \"expected_tax_data\"),\n-    [\n-        ([], sample_none_data),\n-        ([\"saleor.plugins.tests.sample_plugins.PluginSample\"], sample_tax_data),\n-    ],\n-)\n-def test_manager_get_taxes_for_order(\n-    order,\n-    plugins,\n-    expected_tax_data,\n-):\n-    app_identifier = None\n-    assert PluginsManager(plugins=plugins).get_taxes_for_order(\n-        order, app_identifier\n-    ) == expected_tax_data(order)\n-\n-\n def test_manager_sale_created(promotion_converted_from_sale):\n     plugins = [\"saleor.plugins.tests.sample_plugins.PluginSample\"]\n \n     promotion = promotion_converted_from_sale\n"
        },
        {
          "path": "saleor/plugins/tests/test_manager_get_taxes.py",
          "status": "added",
          "diff": "Index: saleor/plugins/tests/test_manager_get_taxes.py\n===================================================================\n--- saleor/plugins/tests/test_manager_get_taxes.py\tf1b632e (parent)\n+++ saleor/plugins/tests/test_manager_get_taxes.py\t1337f67 (commit)\n@@ -0,0 +1,210 @@\n+from unittest.mock import patch\n+\n+import pytest\n+\n+from ...checkout.fetch import fetch_checkout_info, fetch_checkout_lines\n+from ...core.taxes import TaxDataError\n+from ..manager import PluginsManager, get_plugins_manager\n+from ..tests.sample_plugins import sample_tax_data\n+\n+\n+def sample_none_data(obj):\n+    return None\n+\n+\n+@pytest.mark.parametrize(\n+    (\"plugins\", \"expected_tax_data\"),\n+    [\n+        ([], sample_none_data),\n+        ([\"saleor.plugins.tests.sample_plugins.PluginSample\"], sample_tax_data),\n+    ],\n+)\n+def test_manager_get_taxes_for_checkout(\n+    checkout,\n+    plugins,\n+    expected_tax_data,\n+):\n+    # given\n+    lines, _ = fetch_checkout_lines(checkout)\n+    manager = get_plugins_manager(allow_replica=False)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    app_identifier = None\n+\n+    # when\n+    tax_data = PluginsManager(plugins=plugins).get_taxes_for_checkout(\n+        checkout_info, lines, app_identifier\n+    )\n+\n+    # then\n+    assert tax_data == expected_tax_data(checkout)\n+\n+\n+@patch(\n+    \"saleor.plugins.webhook.plugin.WebhookPlugin.get_taxes_for_checkout\",\n+    side_effect=TaxDataError(\"test error\"),\n+)\n+def test_manager_get_taxes_for_checkout_raises_error(\n+    mocked_get_taxes_for_checkout,\n+    checkout,\n+):\n+    # given\n+    lines, _ = fetch_checkout_lines(checkout)\n+    manager = get_plugins_manager(allow_replica=False)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    app_identifier = None\n+    plugins = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+\n+    # when & then\n+    with pytest.raises(TaxDataError):\n+        PluginsManager(plugins=plugins).get_taxes_for_checkout(\n+            checkout_info, lines, app_identifier\n+        )\n+\n+    mocked_get_taxes_for_checkout.assert_called_once()\n+\n+\n+def test_manager_get_taxes_for_checkout_raises_no_active_plugin(\n+    checkout,\n+):\n+    # given\n+    lines, _ = fetch_checkout_lines(checkout)\n+    manager = get_plugins_manager(allow_replica=False)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    app_identifier = None\n+\n+    # when\n+    tax_data = PluginsManager(plugins=[]).get_taxes_for_checkout(\n+        checkout_info, lines, app_identifier\n+    )\n+\n+    # then\n+    assert tax_data is None\n+\n+\n+@pytest.mark.parametrize(\n+    \"plugins\",\n+    [\n+        # first plugin that raises an error\n+        [\n+            \"saleor.plugins.webhook.plugin.WebhookPlugin\",\n+            \"saleor.plugins.tests.sample_plugins.PluginSample\",\n+        ],\n+        # as a second plugin that raises an error\n+        [\n+            \"saleor.plugins.tests.sample_plugins.PluginSample\",\n+            \"saleor.plugins.webhook.plugin.WebhookPlugin\",\n+        ],\n+    ],\n+)\n+@patch(\n+    \"saleor.plugins.webhook.plugin.WebhookPlugin.get_taxes_for_checkout\",\n+    side_effect=TaxDataError(\"test error\"),\n+)\n+def test_manager_get_taxes_for_checkout_multiple_plugins(\n+    mocked_get_taxes_for_checkout,\n+    plugins,\n+    checkout,\n+):\n+    # given\n+    lines, _ = fetch_checkout_lines(checkout)\n+    manager = get_plugins_manager(allow_replica=False)\n+    checkout_info = fetch_checkout_info(checkout, lines, manager)\n+    app_identifier = None\n+\n+    # when\n+    tax_data = PluginsManager(plugins).get_taxes_for_checkout(\n+        checkout_info, lines, app_identifier\n+    )\n+\n+    # then\n+    assert tax_data == sample_tax_data(checkout)\n+\n+\n+@pytest.mark.parametrize(\n+    (\"plugins\", \"expected_tax_data\"),\n+    [\n+        ([], sample_none_data),\n+        ([\"saleor.plugins.tests.sample_plugins.PluginSample\"], sample_tax_data),\n+    ],\n+)\n+def test_manager_get_taxes_for_order(\n+    order,\n+    plugins,\n+    expected_tax_data,\n+):\n+    # given\n+    app_identifier = None\n+\n+    # when\n+    tax_data = PluginsManager(plugins=plugins).get_taxes_for_order(\n+        order, app_identifier\n+    )\n+\n+    # then\n+    assert tax_data == expected_tax_data(order)\n+\n+\n+@patch(\n+    \"saleor.plugins.webhook.plugin.WebhookPlugin.get_taxes_for_order\",\n+    side_effect=TaxDataError(\"test error\"),\n+)\n+def test_manager_get_taxes_for_order_raises_error(\n+    mocked_get_taxes_for_order,\n+    order,\n+):\n+    # given\n+    app_identifier = None\n+    plugins = [\"saleor.plugins.webhook.plugin.WebhookPlugin\"]\n+\n+    # when & then\n+    with pytest.raises(TaxDataError):\n+        PluginsManager(plugins=plugins).get_taxes_for_order(order, app_identifier)\n+\n+    mocked_get_taxes_for_order.assert_called_once()\n+\n+\n+def test_manager_get_taxes_for_order_raises_no_active_plugin(\n+    order,\n+):\n+    # given\n+    app_identifier = None\n+\n+    # when\n+    tax_data = PluginsManager(plugins=[]).get_taxes_for_order(order, app_identifier)\n+\n+    # then\n+    assert tax_data is None\n+\n+\n+@pytest.mark.parametrize(\n+    \"plugins\",\n+    [\n+        # first plugin that raises an error\n+        [\n+            \"saleor.plugins.webhook.plugin.WebhookPlugin\",\n+            \"saleor.plugins.tests.sample_plugins.PluginSample\",\n+        ],\n+        # as a second plugin that raises an error\n+        [\n+            \"saleor.plugins.tests.sample_plugins.PluginSample\",\n+            \"saleor.plugins.webhook.plugin.WebhookPlugin\",\n+        ],\n+    ],\n+)\n+@patch(\n+    \"saleor.plugins.webhook.plugin.WebhookPlugin.get_taxes_for_order\",\n+    side_effect=TaxDataError(\"test error\"),\n+)\n+def test_manager_get_taxes_for_order_multiple_plugins(\n+    mocked_get_taxes_for_order,\n+    plugins,\n+    order,\n+):\n+    # given\n+    app_identifier = None\n+\n+    # when\n+    tax_data = PluginsManager(plugins).get_taxes_for_order(order, app_identifier)\n+\n+    # then\n+    assert tax_data == sample_tax_data(order)\n"
        },
        {
          "path": "saleor/plugins/webhook/plugin.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/plugin.py\n===================================================================\n--- saleor/plugins/webhook/plugin.py\tf1b632e (parent)\n+++ saleor/plugins/webhook/plugin.py\t1337f67 (commit)\n@@ -7,17 +7,19 @@\n from typing import TYPE_CHECKING, Any, Final, Optional, Union\n \n import graphene\n from django.conf import settings\n+from django.template.defaultfilters import truncatechars\n+from pydantic import ValidationError\n \n from ...app.models import App\n from ...channel.models import Channel\n from ...checkout.fetch import CheckoutInfo, CheckoutLineInfo\n from ...checkout.models import Checkout\n from ...core import EventDeliveryStatus\n from ...core.models import EventDelivery\n from ...core.notify import NotifyEventType\n-from ...core.taxes import TaxData, TaxType\n+from ...core.taxes import TAX_ERROR_FIELD_LENGTH, TaxData, TaxDataError, TaxType\n from ...core.utils import build_absolute_uri\n from ...core.utils.json_serializer import CustomJsonEncoder\n from ...csv.notifications import get_default_export_payload\n from ...graphql.core.context import SaleorContext\n@@ -28,8 +30,9 @@\n from ...graphql.webhook.utils import (\n     get_pregenerated_subscription_payload,\n     get_subscription_query_hash,\n )\n+from ...order.models import Order\n from ...payment import PaymentError, TransactionKind\n from ...payment.interface import (\n     GatewayResponse,\n     ListStoredPaymentMethodsRequestData,\n@@ -106,9 +109,9 @@\n     get_excluded_shipping_data,\n     parse_list_shipping_methods_response,\n )\n from ...webhook.transport.synchronous.transport import (\n-    trigger_all_webhooks_sync,\n+    trigger_taxes_all_webhooks_sync,\n     trigger_transaction_request,\n     trigger_webhook_sync,\n     trigger_webhook_sync_if_not_cached,\n )\n@@ -158,9 +161,8 @@\n # time labels were valid for when checking documentation for the carriers\n # (FedEx, UPS, TNT, DHL).\n CACHE_TIME_SHIPPING_LIST_METHODS_FOR_CHECKOUT: Final[int] = 3600 * 12\n \n-\n logger = logging.getLogger(__name__)\n \n \n class WebhookPlugin(BasePlugin):\n@@ -3386,11 +3388,12 @@\n         self,\n         event_type: str,\n         app_identifier: str,\n         payload_gen: Callable,\n+        expected_lines_count: int,\n         subscriptable_object=None,\n         pregenerated_subscription_payloads: dict | None = None,\n-    ):\n+    ) -> TaxData:\n         if pregenerated_subscription_payloads is None:\n             pregenerated_subscription_payloads = {}\n         app = (\n             App.objects.using(settings.DATABASE_CONNECTION_REPLICA_NAME)\n@@ -3401,16 +3404,16 @@\n             .order_by(\"-created_at\")\n             .first()\n         )\n         if app is None:\n-            logger.warning(\"Configured tax app doesn't exists.\")\n-            return None\n+            msg = \"Configured tax app doesn't exist.\"\n+            logger.warning(msg)\n+            raise TaxDataError(msg)\n         webhook = get_webhooks_for_event(event_type, apps_ids=[app.id]).first()\n         if webhook is None:\n-            logger.warning(\n-                \"Configured tax app's webhook for checkout taxes doesn't exists.\"\n-            )\n-            return None\n+            msg = \"Configured tax app's webhook for taxes calculation doesn't exists.\"\n+            logger.warning(msg)\n+            raise TaxDataError(msg)\n \n         request_context = initialize_request(\n             self.requestor,\n             event_type in WebhookEventSyncType.ALL,\n@@ -3430,58 +3433,80 @@\n             request=request_context,\n             requestor=self.requestor,\n             pregenerated_subscription_payload=pregenerated_subscription_payload,\n         )\n-        return parse_tax_data(response)\n+        try:\n+            tax_data = parse_tax_data(response, expected_lines_count)\n+        except ValidationError as e:\n+            errors = e.errors()\n+            logger.warning(\n+                \"Webhook response for event %s is invalid: %s\",\n+                event_type,\n+                str(e),\n+                extra={\"errors\": errors},\n+            )\n+            error_msg = truncatechars(str(e), TAX_ERROR_FIELD_LENGTH)\n+            raise TaxDataError(error_msg, errors=errors) from e\n+        return tax_data\n \n     def get_taxes_for_checkout(\n         self,\n         checkout_info,\n         lines,\n         app_identifier,\n         previous_value,\n         pregenerated_subscription_payloads: dict | None = None,\n-    ) -> Optional[\"TaxData\"]:\n+    ) -> TaxData | None:\n         if pregenerated_subscription_payloads is None:\n             pregenerated_subscription_payloads = {}\n         event_type = WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n+        lines_count = len(lines)\n         if app_identifier:\n             return self.__run_tax_webhook(\n                 event_type,\n                 app_identifier,\n                 lambda: generate_checkout_payload_for_tax_calculation(\n                     checkout_info, lines\n                 ),\n+                lines_count,\n                 checkout_info.checkout,\n                 pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n             )\n-        return trigger_all_webhooks_sync(\n+        # This is deprecated flow, kept to maintain backward compatibility.\n+        # In Saleor 4.0 `tax_app_identifier` should be required and the flow should\n+        # be dropped.\n+        return trigger_taxes_all_webhooks_sync(\n             event_type,\n             lambda: generate_checkout_payload_for_tax_calculation(\n                 checkout_info,\n                 lines,\n             ),\n-            parse_tax_data,\n+            lines_count,\n             checkout_info.checkout,\n             self.requestor,\n             pregenerated_subscription_payloads=pregenerated_subscription_payloads,\n         )\n \n     def get_taxes_for_order(\n         self, order: \"Order\", app_identifier, previous_value\n-    ) -> Optional[\"TaxData\"]:\n+    ) -> TaxData | None:\n         event_type = WebhookEventSyncType.ORDER_CALCULATE_TAXES\n+        lines_count = order.lines.count()\n         if app_identifier:\n             return self.__run_tax_webhook(\n                 event_type,\n                 app_identifier,\n                 lambda: generate_order_payload_for_tax_calculation(order),\n+                lines_count,\n                 order,\n             )\n-        return trigger_all_webhooks_sync(\n+        # This is deprecated flow, kept to maintain backward compatibility.\n+        # In Saleor 4.0 `tax_app_identifier` should be required and the flow should\n+        # be dropped.\n+        return trigger_taxes_all_webhooks_sync(\n             WebhookEventSyncType.ORDER_CALCULATE_TAXES,\n             lambda: generate_order_payload_for_tax_calculation(order),\n-            parse_tax_data,\n+            lines_count,\n             order,\n             self.requestor,\n         )\n \n"
        },
        {
          "path": "saleor/plugins/webhook/tests/test_tax_webhook.py",
          "status": "modified",
          "diff": "Index: saleor/plugins/webhook/tests/test_tax_webhook.py\n===================================================================\n--- saleor/plugins/webhook/tests/test_tax_webhook.py\tf1b632e (parent)\n+++ saleor/plugins/webhook/tests/test_tax_webhook.py\t1337f67 (commit)\n@@ -7,9 +7,9 @@\n \n from ....checkout.fetch import fetch_checkout_info, fetch_checkout_lines\n from ....core import EventDeliveryStatus\n from ....core.models import EventDelivery\n-from ....core.taxes import TaxType\n+from ....core.taxes import TaxDataError, TaxType\n from ....graphql.webhook.utils import get_subscription_query_hash\n from ....webhook.event_types import WebhookEventSyncType\n from ....webhook.payloads import generate_order_payload_for_tax_calculation\n from ....webhook.transport.utils import (\n@@ -76,9 +76,9 @@\n     assert delivery.status == EventDeliveryStatus.PENDING\n     assert delivery.event_type == WebhookEventSyncType.ORDER_CALCULATE_TAXES\n     assert delivery.webhook == webhook\n     mock_fetch.assert_not_called()\n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, order.lines.count())\n \n \n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_get_taxes_for_order_no_permission(\n@@ -194,9 +194,9 @@\n     assert delivery.status == EventDeliveryStatus.PENDING\n     assert delivery.event_type == WebhookEventSyncType.ORDER_CALCULATE_TAXES\n     assert delivery.webhook == webhook\n     mock_fetch.assert_not_called()\n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, order.lines.count())\n \n \n @freeze_time()\n @mock.patch(\"saleor.checkout.calculations.fetch_checkout_data\")\n@@ -246,9 +246,9 @@\n     assert delivery.status == EventDeliveryStatus.PENDING\n     assert delivery.event_type == WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n     assert delivery.webhook == webhook\n     mock_fetch.assert_not_called()\n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, checkout.lines.count())\n \n \n @freeze_time()\n @mock.patch(\"saleor.checkout.calculations.fetch_checkout_data\")\n@@ -301,5 +301,290 @@\n     assert delivery.status == EventDeliveryStatus.PENDING\n     assert delivery.event_type == WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n     assert delivery.webhook == webhook\n     mock_fetch.assert_not_called()\n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, checkout.lines.count())\n+\n+\n+def test_get_taxes_for_checkout_with_app_identifier_app_missing(\n+    checkout_info, webhook_plugin\n+):\n+    # given\n+    app_identifier = \"missing_app\"\n+    plugin = webhook_plugin()\n+\n+    # when & then\n+    with pytest.raises(TaxDataError, match=\"Configured tax app doesn't exist.\"):\n+        plugin.get_taxes_for_checkout(\n+            checkout_info, checkout_info.lines, app_identifier, None\n+        )\n+\n+\n+def test_get_taxes_for_checkout_with_app_identifier_webhook_is_missing(\n+    checkout_info, webhook_plugin, app\n+):\n+    # given\n+    plugin = webhook_plugin()\n+\n+    # when & then\n+    with pytest.raises(\n+        TaxDataError,\n+        match=\"Configured tax app's webhook for taxes calculation doesn't exists.\",\n+    ):\n+        plugin.get_taxes_for_checkout(\n+            checkout_info, checkout_info.lines, app.identifier, None\n+        )\n+\n+\n+@mock.patch(\"saleor.checkout.calculations.fetch_checkout_data\")\n+@mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@mock.patch(\n+    \"saleor.webhook.transport.synchronous.transport.generate_payload_from_subscription\"\n+)\n+def test_get_taxes_for_checkout_with_app_identifier_invalid_response(\n+    mock_generate_payload,\n+    mock_request,\n+    mock_fetch,\n+    webhook_plugin,\n+    tax_data_response_factory,\n+    checkout,\n+    tax_app,\n+):\n+    # given\n+    subscription_query = \"subscription{event{... on CalculateTaxes{taxBase{currency}}}}\"\n+    expected_payload = {\"taxBase\": {\"currency\": \"USD\"}}\n+    checkout_info = fetch_checkout_info(\n+        checkout, [], get_plugins_manager(allow_replica=False)\n+    )\n+    # mock returning invalid data - tax_rate above 100\n+    mock_request.return_value = tax_data_response_factory(shipping_tax_rate=120)\n+    mock_generate_payload.return_value = expected_payload\n+    plugin = webhook_plugin()\n+    webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n+    webhook.subscription_query = subscription_query\n+    webhook.save(update_fields=[\"subscription_query\"])\n+    app_identifier = tax_app.identifier\n+\n+    # when\n+    with pytest.raises(TaxDataError):\n+        plugin.get_taxes_for_checkout(checkout_info, [], app_identifier, None)\n+\n+\n+@freeze_time()\n+@mock.patch(\"saleor.checkout.calculations.fetch_checkout_data\")\n+@mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@mock.patch(\n+    \"saleor.webhook.transport.synchronous.transport.generate_payload_from_subscription\"\n+)\n+def test_get_taxes_for_checkout_with_app_identifier(\n+    mock_generate_payload,\n+    mock_request,\n+    mock_fetch,\n+    webhook_plugin,\n+    tax_data_response,\n+    checkout,\n+    tax_app,\n+):\n+    # given\n+    subscription_query = \"subscription{event{... on CalculateTaxes{taxBase{currency}}}}\"\n+    expected_payload = {\"taxBase\": {\"currency\": \"USD\"}}\n+    checkout_info = fetch_checkout_info(\n+        checkout, [], get_plugins_manager(allow_replica=False)\n+    )\n+    mock_request.return_value = tax_data_response\n+    mock_generate_payload.return_value = expected_payload\n+    plugin = webhook_plugin()\n+    webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n+    webhook.subscription_query = subscription_query\n+    webhook.save(update_fields=[\"subscription_query\"])\n+    app_identifier = tax_app.identifier\n+\n+    # when\n+    tax_data = plugin.get_taxes_for_checkout(checkout_info, [], app_identifier, None)\n+\n+    # then\n+    mock_generate_payload.assert_called_once_with(\n+        event_type=WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES,\n+        subscribable_object=checkout,\n+        subscription_query=subscription_query,\n+        request=ANY,  # SaleorContext,\n+        app=tax_app,\n+    )\n+    mock_request.assert_called_once()\n+    assert not EventDelivery.objects.exists()\n+\n+    delivery = mock_request.mock_calls[0].args[0]\n+    assert delivery.payload.get_payload() == json.dumps(expected_payload)\n+    assert delivery.status == EventDeliveryStatus.PENDING\n+    assert delivery.event_type == WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n+    assert delivery.webhook == webhook\n+    mock_fetch.assert_not_called()\n+    assert tax_data == parse_tax_data(tax_data_response, checkout.lines.count())\n+\n+\n+def test_get_taxes_for_order_with_app_identifier_app_missing(order, webhook_plugin):\n+    # given\n+    app_identifier = \"missing_app\"\n+    plugin = webhook_plugin()\n+\n+    # when & then\n+    with pytest.raises(TaxDataError, match=\"Configured tax app doesn't exist.\"):\n+        plugin.get_taxes_for_order(order, app_identifier, None)\n+\n+\n+def test_get_taxes_for_order_with_app_identifier_webhook_is_missing(\n+    order, webhook_plugin, app\n+):\n+    # given\n+    plugin = webhook_plugin()\n+\n+    # when & then\n+    with pytest.raises(\n+        TaxDataError,\n+        match=\"Configured tax app's webhook for taxes calculation doesn't exists.\",\n+    ):\n+        plugin.get_taxes_for_order(order, app.identifier, None)\n+\n+\n+@mock.patch(\"saleor.order.calculations.fetch_order_prices_if_expired\")\n+@mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@mock.patch(\n+    \"saleor.webhook.transport.synchronous.transport.generate_payload_from_subscription\"\n+)\n+def test_get_taxes_for_order_with_app_identifier_invalid_response(\n+    mock_generate_payload,\n+    mock_request,\n+    mock_fetch,\n+    webhook_plugin,\n+    tax_data_response_factory,\n+    order,\n+    tax_app,\n+):\n+    # given\n+    subscription_query = \"subscription{event{... on CalculateTaxes{taxBase{currency}}}}\"\n+    expected_payload = {\"taxBase\": {\"currency\": \"USD\"}}\n+    # mock returning invalid data - tax_rate above 100\n+    mock_request.return_value = tax_data_response_factory(shipping_tax_rate=120)\n+    mock_generate_payload.return_value = expected_payload\n+    plugin = webhook_plugin()\n+    webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n+    webhook.subscription_query = subscription_query\n+    webhook.save(update_fields=[\"subscription_query\"])\n+    app_identifier = tax_app.identifier\n+\n+    # when & then\n+    with pytest.raises(TaxDataError):\n+        plugin.get_taxes_for_order(order, app_identifier, None)\n+\n+\n+@freeze_time()\n+@mock.patch(\"saleor.order.calculations.fetch_order_prices_if_expired\")\n+@mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@mock.patch(\n+    \"saleor.webhook.transport.synchronous.transport.generate_payload_from_subscription\"\n+)\n+def test_get_taxes_for_order_with_app_identifier(\n+    mock_generate_payload,\n+    mock_request,\n+    mock_fetch,\n+    webhook_plugin,\n+    tax_data_response,\n+    order,\n+    tax_app,\n+):\n+    # given\n+    subscription_query = \"subscription{event{... on CalculateTaxes{taxBase{currency}}}}\"\n+    expected_payload = {\"taxBase\": {\"currency\": \"USD\"}}\n+    mock_request.return_value = tax_data_response\n+    mock_generate_payload.return_value = expected_payload\n+    plugin = webhook_plugin()\n+    webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n+    webhook.subscription_query = subscription_query\n+    webhook.save(update_fields=[\"subscription_query\"])\n+    app_identifier = tax_app.identifier\n+\n+    # when\n+    tax_data = plugin.get_taxes_for_order(order, app_identifier, None)\n+\n+    # then\n+    mock_generate_payload.assert_called_once_with(\n+        event_type=WebhookEventSyncType.ORDER_CALCULATE_TAXES,\n+        subscribable_object=order,\n+        subscription_query=subscription_query,\n+        request=ANY,  # SaleorContext,\n+        app=tax_app,\n+    )\n+    mock_request.assert_called_once()\n+    assert not EventDelivery.objects.exists()\n+\n+    delivery = mock_request.mock_calls[0].args[0]\n+    assert delivery.payload.get_payload() == json.dumps(expected_payload)\n+    assert delivery.status == EventDeliveryStatus.PENDING\n+    assert delivery.event_type == WebhookEventSyncType.ORDER_CALCULATE_TAXES\n+    assert delivery.webhook == webhook\n+    mock_fetch.assert_not_called()\n+    assert tax_data == parse_tax_data(tax_data_response, order.lines.count())\n+\n+\n+@freeze_time()\n+@mock.patch(\"saleor.order.calculations.fetch_order_prices_if_expired\")\n+@mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@mock.patch(\n+    \"saleor.webhook.transport.synchronous.transport.generate_payload_from_subscription\"\n+)\n+def test_get_taxes_for_order_with_app_identifier_empty_response(\n+    mock_generate_payload,\n+    mock_request,\n+    mock_fetch,\n+    webhook_plugin,\n+    tax_data_response,\n+    order,\n+    tax_app,\n+):\n+    # given\n+    mock_request.return_value = None\n+    subscription_query = \"subscription{event{... on CalculateTaxes{taxBase{currency}}}}\"\n+    expected_payload = {\"taxBase\": {\"currency\": \"USD\"}}\n+    mock_generate_payload.return_value = expected_payload\n+    plugin = webhook_plugin()\n+    webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n+    webhook.subscription_query = subscription_query\n+    webhook.save(update_fields=[\"subscription_query\"])\n+    app_identifier = tax_app.identifier\n+\n+    # when & then\n+    with pytest.raises(TaxDataError):\n+        plugin.get_taxes_for_order(order, app_identifier, None)\n+\n+\n+@freeze_time()\n+@mock.patch(\"saleor.checkout.calculations.fetch_checkout_data\")\n+@mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n+@mock.patch(\n+    \"saleor.webhook.transport.synchronous.transport.generate_payload_from_subscription\"\n+)\n+def test_get_taxes_for_checkout_with_app_identifier_empty_response(\n+    mock_generate_payload,\n+    mock_request,\n+    mock_fetch,\n+    webhook_plugin,\n+    tax_data_response,\n+    checkout,\n+    tax_app,\n+):\n+    # given\n+    subscription_query = \"subscription{event{... on CalculateTaxes{taxBase{currency}}}}\"\n+    expected_payload = {\"taxBase\": {\"currency\": \"USD\"}}\n+    checkout_info = fetch_checkout_info(\n+        checkout, [], get_plugins_manager(allow_replica=False)\n+    )\n+    mock_request.return_value = None\n+    mock_generate_payload.return_value = expected_payload\n+    plugin = webhook_plugin()\n+    webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n+    webhook.subscription_query = subscription_query\n+    webhook.save(update_fields=[\"subscription_query\"])\n+    app_identifier = tax_app.identifier\n+\n+    # when & then\n+    with pytest.raises(TaxDataError):\n+        plugin.get_taxes_for_checkout(checkout_info, [], app_identifier, None)\n"
        },
        {
          "path": "saleor/tax/tests/test_utils.py",
          "status": "modified",
          "diff": "Index: saleor/tax/tests/test_utils.py\n===================================================================\n--- saleor/tax/tests/test_utils.py\tf1b632e (parent)\n+++ saleor/tax/tests/test_utils.py\t1337f67 (commit)\n@@ -1,15 +1,11 @@\n-from decimal import Decimal\n-\n import pytest\n \n-from ...core.taxes import TaxData, TaxDataError, TaxLineData\n from ...core.utils.country import get_active_country\n from ..utils import (\n     get_charge_taxes,\n     get_display_gross_prices,\n     get_tax_app_id,\n-    validate_tax_data,\n )\n \n \n def test_get_display_gross_prices(channel_USD):\n@@ -114,114 +110,4 @@\n     country = get_active_country(channel_USD, shipping_address, billing_address)\n \n     # then\n     assert country == channel_USD.default_country.code\n-\n-\n-def test_validate_tax_data_no_data(order_with_lines, lines_info):\n-    # given\n-    tax_data = None\n-\n-    # when & then\n-    with pytest.raises(TaxDataError):\n-        validate_tax_data(tax_data, lines_info)\n-\n-\n-def test_validate_tax_data_with_negative_values(lines_info, caplog):\n-    # given\n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"-1\"),\n-        shipping_price_gross_amount=Decimal(\"-1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-            TaxLineData(\n-                total_net_amount=Decimal(\"4\"),\n-                total_gross_amount=Decimal(\"6\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n-    # when & then\n-    with pytest.raises(TaxDataError):\n-        validate_tax_data(tax_data, lines_info)\n-\n-\n-def test_validate_tax_data_line_number(lines_info, caplog):\n-    # given\n-    assert len(lines_info) == 2\n-\n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n-    # when & then\n-    with pytest.raises(TaxDataError):\n-        validate_tax_data(tax_data, lines_info)\n-\n-\n-def test_validate_tax_data_tax_rate_overflow(lines_info, caplog):\n-    # given\n-    assert len(lines_info) == 2\n-\n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"1\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"120\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-            TaxLineData(\n-                total_net_amount=Decimal(\"4\"),\n-                total_gross_amount=Decimal(\"6\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n-    # when & then\n-    with pytest.raises(TaxDataError):\n-        validate_tax_data(tax_data, lines_info)\n-\n-\n-def test_validate_tax_data_price_overflow(lines_info, caplog):\n-    # given\n-    assert len(lines_info) == 2\n-\n-    tax_data = TaxData(\n-        shipping_price_net_amount=Decimal(\"9999999999999999\"),\n-        shipping_price_gross_amount=Decimal(\"1.5\"),\n-        shipping_tax_rate=Decimal(\"50\"),\n-        lines=[\n-            TaxLineData(\n-                total_net_amount=Decimal(\"2\"),\n-                total_gross_amount=Decimal(\"3\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-            TaxLineData(\n-                total_net_amount=Decimal(\"4\"),\n-                total_gross_amount=Decimal(\"6\"),\n-                tax_rate=Decimal(\"50\"),\n-            ),\n-        ],\n-    )\n-\n-    # when & then\n-    with pytest.raises(TaxDataError):\n-        validate_tax_data(tax_data, lines_info)\n"
        },
        {
          "path": "saleor/tax/utils.py",
          "status": "modified",
          "diff": "Index: saleor/tax/utils.py\n===================================================================\n--- saleor/tax/utils.py\tf1b632e (parent)\n+++ saleor/tax/utils.py\t1337f67 (commit)\n@@ -5,10 +5,8 @@\n \n from django.conf import settings\n from prices import TaxedMoney\n \n-from ..core.prices import MAXIMUM_PRICE\n-from ..core.taxes import TaxData, TaxDataError, TaxDataErrorMessage\n from ..core.utils.country import get_active_country\n from . import TaxCalculationStrategy\n \n if TYPE_CHECKING:\n@@ -258,79 +256,4 @@\n         \"shipping_tax_class_name\": tax_class.name,\n         \"shipping_tax_class_private_metadata\": tax_class.private_metadata,\n         \"shipping_tax_class_metadata\": tax_class.metadata,\n     }\n-\n-\n-def validate_tax_data(\n-    tax_data: TaxData | None,\n-    lines: Iterable,\n-    allow_empty_tax_data: bool = False,\n-):\n-    if tax_data is None and not allow_empty_tax_data:\n-        raise TaxDataError(TaxDataErrorMessage.EMPTY)\n-\n-    if check_negative_values_in_tax_data(tax_data):\n-        raise TaxDataError(TaxDataErrorMessage.NEGATIVE_VALUE)\n-\n-    if check_line_number_in_tax_data(tax_data, lines):\n-        raise TaxDataError(TaxDataErrorMessage.LINE_NUMBER)\n-\n-    if check_overflows_in_tax_data(tax_data):\n-        raise TaxDataError(TaxDataErrorMessage.OVERFLOW)\n-\n-\n-def check_negative_values_in_tax_data(tax_data: TaxData | None) -> bool:\n-    \"\"\"Check if tax data contains negative values.\"\"\"\n-    if not tax_data:\n-        return False\n-\n-    if (\n-        tax_data.shipping_price_gross_amount < 0\n-        or tax_data.shipping_price_net_amount < 0\n-        or tax_data.shipping_tax_rate < 0\n-    ):\n-        return True\n-\n-    for line in tax_data.lines:\n-        if (\n-            line.total_gross_amount < 0\n-            or line.total_net_amount < 0\n-            or line.tax_rate < 0\n-        ):\n-            return True\n-\n-    return False\n-\n-\n-def check_line_number_in_tax_data(tax_data: TaxData | None, lines: Iterable) -> bool:\n-    \"\"\"Check if tax data contains same line number as input data.\"\"\"\n-    if not tax_data:\n-        return False\n-\n-    if len(tax_data.lines) != len(list(lines)):\n-        return True\n-\n-    return False\n-\n-\n-def check_overflows_in_tax_data(tax_data: TaxData | None) -> bool:\n-    \"\"\"Check if tax rates exceed 100% and line prices are lower than a billion.\"\"\"\n-    if not tax_data:\n-        return False\n-\n-    if (\n-        tax_data.shipping_price_gross_amount > MAXIMUM_PRICE\n-        or tax_data.shipping_price_net_amount > MAXIMUM_PRICE\n-        or tax_data.shipping_tax_rate > 100\n-    ):\n-        return True\n-\n-    for line in tax_data.lines:\n-        if (\n-            line.total_gross_amount > MAXIMUM_PRICE\n-            or line.total_net_amount > MAXIMUM_PRICE\n-            or line.tax_rate > 100\n-        ):\n-            return True\n-\n-    return False\n"
        },
        {
          "path": "saleor/tests/fixtures.py",
          "status": "modified",
          "diff": "Index: saleor/tests/fixtures.py\n===================================================================\n--- saleor/tests/fixtures.py\tf1b632e (parent)\n+++ saleor/tests/fixtures.py\t1337f67 (commit)\n@@ -688,23 +688,37 @@\n     }\n \n \n @pytest.fixture\n-def tax_data_response(tax_line_data_response):\n-    return {\n-        \"currency\": \"PLN\",\n-        \"total_net_amount\": 12.34,\n-        \"total_gross_amount\": 12.34,\n-        \"subtotal_net_amount\": 12.34,\n-        \"subtotal_gross_amount\": 12.34,\n-        \"shipping_price_gross_amount\": 12.34,\n-        \"shipping_price_net_amount\": 12.34,\n-        \"shipping_tax_rate\": 23,\n-        \"lines\": [tax_line_data_response] * 5,\n-    }\n+def tax_data_response(tax_data_response_factory):\n+    return tax_data_response_factory()\n \n \n @pytest.fixture\n+def tax_data_response_factory(tax_line_data_response):\n+    def factory(\n+        shipping_price_gross_amount=12.34,\n+        shipping_price_net_amount=12.34,\n+        shipping_tax_rate=23,\n+        lines_length=5,\n+    ):\n+        lines = [tax_line_data_response] * lines_length\n+        return {\n+            \"currency\": \"PLN\",\n+            \"total_net_amount\": 12.34,\n+            \"total_gross_amount\": 12.34,\n+            \"subtotal_net_amount\": 12.34,\n+            \"subtotal_gross_amount\": 12.34,\n+            \"shipping_price_gross_amount\": shipping_price_gross_amount,\n+            \"shipping_price_net_amount\": shipping_price_net_amount,\n+            \"shipping_tax_rate\": shipping_tax_rate,\n+            \"lines\": lines,\n+        }\n+\n+    return factory\n+\n+\n+@pytest.fixture\n def fake_payment_interface(mocker):\n     return mocker.Mock(spec=PaymentInterface)\n \n \n"
        },
        {
          "path": "saleor/webhook/response_schemas/annotations.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/response_schemas/annotations.py\n===================================================================\n--- saleor/webhook/response_schemas/annotations.py\tf1b632e (parent)\n+++ saleor/webhook/response_schemas/annotations.py\t1337f67 (commit)\n@@ -6,10 +6,12 @@\n from pydantic_core import PydanticUseDefault\n \n from ...core.utils.metadata_manager import metadata_is_valid\n \n+M = TypeVar(\"M\")\n \n-def skip_invalid_metadata(value: Any) -> Any:\n+\n+def skip_invalid_metadata(value: M) -> M:\n     if not metadata_is_valid(value):\n         raise PydanticUseDefault()\n     return value\n \n"
        },
        {
          "path": "saleor/webhook/response_schemas/shipping.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/response_schemas/shipping.py\n===================================================================\n--- saleor/webhook/response_schemas/shipping.py\tf1b632e (parent)\n+++ saleor/webhook/response_schemas/shipping.py\t1337f67 (commit)\n@@ -40,11 +40,11 @@\n OnErrorSkipShippingMethod = Annotated[T, WrapValidator(skip_invalid_shipping_method)]\n \n \n class ShippingMethodSchema(BaseModel):\n-    id: str = Field(coerce_numbers_to_str=True)\n-    name: str = Field(max_length=name_max_length)\n-    amount: Decimal = Field(ge=0)\n+    id: Annotated[str, Field(coerce_numbers_to_str=True)]\n+    name: Annotated[str, Field(max_length=name_max_length)]\n+    amount: Annotated[Decimal, Field(ge=0)]\n     currency: str\n     maximum_delivery_days: Annotated[int, Field(ge=0)] | None = None\n     minimum_delivery_days: Annotated[int, Field(ge=0)] | None = None\n     description: str | None = None\n"
        },
        {
          "path": "saleor/webhook/response_schemas/taxes.py",
          "status": "added",
          "diff": "Index: saleor/webhook/response_schemas/taxes.py\n===================================================================\n--- saleor/webhook/response_schemas/taxes.py\tf1b632e (parent)\n+++ saleor/webhook/response_schemas/taxes.py\t1337f67 (commit)\n@@ -0,0 +1,36 @@\n+from decimal import Decimal\n+from typing import Annotated\n+\n+from pydantic import BaseModel, Field, ValidationInfo, field_validator\n+\n+from ...core.prices import MAXIMUM_PRICE\n+\n+\n+class LineCalculateTaxesSchema(BaseModel):\n+    tax_rate: Annotated[Decimal, Field(ge=0, le=100)]\n+    total_gross_amount: Annotated[Decimal, Field(ge=0, le=MAXIMUM_PRICE)]\n+    total_net_amount: Annotated[Decimal, Field(ge=0, le=MAXIMUM_PRICE)]\n+\n+\n+class CalculateTaxesSchema(BaseModel):\n+    shipping_tax_rate: Annotated[Decimal, Field(ge=0, le=100)]\n+    shipping_price_gross_amount: Annotated[Decimal, Field(ge=0, le=MAXIMUM_PRICE)]\n+    shipping_price_net_amount: Annotated[Decimal, Field(ge=0, le=MAXIMUM_PRICE)]\n+    lines: list[LineCalculateTaxesSchema] = []\n+\n+    @field_validator(\"lines\")\n+    @classmethod\n+    def clean_lines_length(\n+        cls, lines: list[LineCalculateTaxesSchema], info: ValidationInfo\n+    ):\n+        context = info.context\n+        if not context:\n+            raise ValueError(\"Context is required to validate the number of lines.\")\n+\n+        expected_line_count = context.get(\"expected_line_count\")\n+        if expected_line_count and len(lines) != expected_line_count:\n+            raise ValueError(\n+                f\"Number of lines from tax data doesn't match the line number from order. \"\n+                f\"Expected {expected_line_count} but got {len(lines)}.\"\n+            )\n+        return lines\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_shipping.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_shipping.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_shipping.py\tf1b632e (parent)\n+++ saleor/webhook/tests/response_schemas/test_shipping.py\t1337f67 (commit)\n@@ -34,13 +34,34 @@\n             \"metadata\": {\"key1\": \"value1\", \"key2\": \"value2\"},\n         },\n         # Optional fields not provided\n         {\n-            \"id\": 2,  # Integer ID\n+            \"id\": 2,\n             \"name\": \"Express Shipping\",\n             \"amount\": Decimal(\"20.00\"),\n             \"currency\": \"EUR\",\n         },\n+        # Amount as str\n+        {\n+            \"id\": 2,\n+            \"name\": \"Express Shipping\",\n+            \"amount\": \"20.00\",\n+            \"currency\": \"EUR\",\n+        },\n+        # Amount as float\n+        {\n+            \"id\": \"2\",\n+            \"name\": \"Express Shipping\",\n+            \"amount\": 20.00,\n+            \"currency\": \"EUR\",\n+        },\n+        # Amount as int\n+        {\n+            \"id\": 2,\n+            \"name\": \"Express Shipping\",\n+            \"amount\": 20,\n+            \"currency\": \"EUR\",\n+        },\n         # Metadata is empty, delivery days, and description as None\n         {\n             \"id\": \"3\",\n             \"name\": \"Overnight Shipping\",\n@@ -77,9 +98,9 @@\n \n     # then\n     assert shipping_method_model.id == str(data[\"id\"])\n     assert shipping_method_model.name == data[\"name\"]\n-    assert shipping_method_model.amount == data[\"amount\"]\n+    assert shipping_method_model.amount == Decimal(data[\"amount\"])\n     assert shipping_method_model.currency == data[\"currency\"]\n     assert shipping_method_model.maximum_delivery_days == data.get(\n         \"maximum_delivery_days\"\n     )\n@@ -200,12 +221,14 @@\n         },\n     ],\n )\n def test_shipping_method_schema_invalid(data):\n-    with pytest.raises(ValidationError):\n+    with pytest.raises(ValidationError) as e:\n         ShippingMethodSchema.model_validate(data)\n \n+    assert len(e.value.errors()) == 1\n \n+\n @pytest.mark.parametrize(\"data\", [None, []])\n def test_list_shipping_methods_schema_skipped_values(data):\n     # when\n     list_methods = ListShippingMethodsSchema.model_validate(data)\n"
        },
        {
          "path": "saleor/webhook/tests/response_schemas/test_taxes.py",
          "status": "added",
          "diff": "Index: saleor/webhook/tests/response_schemas/test_taxes.py\n===================================================================\n--- saleor/webhook/tests/response_schemas/test_taxes.py\tf1b632e (parent)\n+++ saleor/webhook/tests/response_schemas/test_taxes.py\t1337f67 (commit)\n@@ -0,0 +1,270 @@\n+from decimal import Decimal\n+\n+import pytest\n+from pydantic import ValidationError\n+\n+from ....core.prices import MAXIMUM_PRICE\n+from ...response_schemas.taxes import CalculateTaxesSchema, LineCalculateTaxesSchema\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # Decimal values\n+        {\n+            \"tax_rate\": Decimal(\"20.12\"),\n+            \"total_gross_amount\": Decimal(\"100.33\"),\n+            \"total_net_amount\": Decimal(\"80.00\"),\n+        },\n+        # String values with decimal points\n+        {\n+            \"tax_rate\": \"20.12\",\n+            \"total_gross_amount\": \"100.33\",\n+            \"total_net_amount\": \"80.23\",\n+        },\n+        # String values\n+        {\n+            \"tax_rate\": \"20\",\n+            \"total_gross_amount\": \"100\",\n+            \"total_net_amount\": \"80\",\n+        },\n+        # Integer values\n+        {\n+            \"tax_rate\": 20,\n+            \"total_gross_amount\": 100,\n+            \"total_net_amount\": 80,\n+        },\n+        # Float values\n+        {\n+            \"tax_rate\": 20.11,\n+            \"total_gross_amount\": 100.21,\n+            \"total_net_amount\": 80.32,\n+        },\n+    ],\n+)\n+def test_line_calculate_taxes_schema_valid(data):\n+    # when\n+    line_model = LineCalculateTaxesSchema.model_validate(data)\n+\n+    # then\n+    assert line_model.tax_rate == Decimal(str(data[\"tax_rate\"]))\n+    assert line_model.total_gross_amount == Decimal(str(data[\"total_gross_amount\"]))\n+    assert line_model.total_net_amount == Decimal(str(data[\"total_net_amount\"]))\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        # Negative tax_rate\n+        {\n+            \"tax_rate\": -5,\n+            \"total_gross_amount\": 100,\n+            \"total_net_amount\": Decimal(\"80.00\"),\n+        },\n+        # Negative total_gross_amount\n+        {\n+            \"tax_rate\": 5,\n+            \"total_gross_amount\": -100,\n+            \"total_net_amount\": Decimal(\"80.00\"),\n+        },\n+        # Negative total_net_amount\n+        {\n+            \"tax_rate\": 5,\n+            \"total_gross_amount\": 100,\n+            \"total_net_amount\": Decimal(\"-80.00\"),\n+        },\n+        # Invalid tax_rate (greater than 100)\n+        {\n+            \"tax_rate\": Decimal(\"120.00\"),\n+            \"total_gross_amount\": Decimal(\"100.00\"),\n+            \"total_net_amount\": Decimal(\"80.00\"),\n+        },\n+        # Invalid total_gross_amount (greater than MAXIMUM_PRICE)\n+        {\n+            \"tax_rate\": Decimal(\"20.00\"),\n+            \"total_gross_amount\": 100000000000,\n+            \"total_net_amount\": Decimal(\"80.00\"),\n+        },\n+        # Invalid total_net_amount (greater than MAXIMUM_PRICE)\n+        {\n+            \"tax_rate\": Decimal(\"20.00\"),\n+            \"total_gross_amount\": Decimal(\"100.00\"),\n+            \"total_net_amount\": Decimal(\"10000000000\"),\n+        },\n+    ],\n+)\n+def test_line_calculate_taxes_schema_invalid(data):\n+    \"\"\"Test LineCalculateTaxesSchema with invalid data.\"\"\"\n+    with pytest.raises(ValidationError) as e:\n+        LineCalculateTaxesSchema(**data)\n+\n+    assert len(e.value.errors()) == 1\n+\n+\n+@pytest.mark.parametrize(\n+    \"data\",\n+    [\n+        {\n+            \"shipping_tax_rate\": Decimal(\"10.00\"),\n+            \"shipping_price_gross_amount\": Decimal(\"110.00\"),\n+            \"shipping_price_net_amount\": Decimal(\"100.00\"),\n+            \"lines\": [\n+                {\n+                    \"tax_rate\": Decimal(\"20.00\"),\n+                    \"total_gross_amount\": Decimal(\"120.00\"),\n+                    \"total_net_amount\": Decimal(\"100.00\"),\n+                },\n+                {\n+                    \"tax_rate\": \"15.00\",\n+                    \"total_gross_amount\": \"115.00\",\n+                    \"total_net_amount\": \"100.00\",\n+                },\n+            ],\n+        },\n+        {\n+            \"shipping_tax_rate\": 10,\n+            \"shipping_price_gross_amount\": 110,\n+            \"shipping_price_net_amount\": 100,\n+            \"lines\": [],\n+        },\n+        {\n+            \"shipping_tax_rate\": \"10.00\",\n+            \"shipping_price_gross_amount\": \"110.00\",\n+            \"shipping_price_net_amount\": \"100.00\",\n+            \"lines\": [\n+                {\n+                    \"tax_rate\": \"20.00\",\n+                    \"total_gross_amount\": \"120.00\",\n+                    \"total_net_amount\": \"100.00\",\n+                },\n+            ],\n+        },\n+    ],\n+)\n+def test_calculate_taxes_schema_valid(data):\n+    # given\n+    expected_line_count = len(data[\"lines\"])\n+\n+    # when\n+    calculate_taxes_model = CalculateTaxesSchema.model_validate(\n+        data, context={\"expected_line_count\": expected_line_count}\n+    )\n+\n+    # then\n+    assert calculate_taxes_model.shipping_tax_rate == Decimal(data[\"shipping_tax_rate\"])\n+    assert calculate_taxes_model.shipping_price_gross_amount == Decimal(\n+        data[\"shipping_price_gross_amount\"]\n+    )\n+    assert calculate_taxes_model.shipping_price_net_amount == Decimal(\n+        data[\"shipping_price_net_amount\"]\n+    )\n+    assert len(calculate_taxes_model.lines) == expected_line_count\n+\n+\n+@pytest.mark.parametrize(\n+    (\"data\", \"expected_line_count\"),\n+    [\n+        # Invalid case with mismatched line count\n+        (\n+            {\n+                \"shipping_tax_rate\": Decimal(\"10.00\"),\n+                \"shipping_price_gross_amount\": Decimal(\"110.00\"),\n+                \"shipping_price_net_amount\": Decimal(\"100.00\"),\n+                \"lines\": [\n+                    {\n+                        \"tax_rate\": Decimal(\"20.00\"),\n+                        \"total_gross_amount\": Decimal(\"120.00\"),\n+                        \"total_net_amount\": Decimal(\"100.00\"),\n+                    }\n+                ],\n+            },\n+            2,\n+        ),\n+        # Invalid case with negative shipping_price_gross_amount\n+        (\n+            {\n+                \"shipping_tax_rate\": Decimal(\"10.00\"),\n+                \"shipping_price_gross_amount\": -111,\n+                \"shipping_price_net_amount\": Decimal(\"100.00\"),\n+                \"lines\": [],\n+            },\n+            0,\n+        ),\n+        # Invalid case with negative shipping_price_net_amount\n+        (\n+            {\n+                \"shipping_tax_rate\": 10,\n+                \"shipping_price_gross_amount\": 111,\n+                \"shipping_price_net_amount\": -100,\n+                \"lines\": [],\n+            },\n+            0,\n+        ),\n+        # Invalid case with shipping_tax_rate greater than 100\n+        (\n+            {\n+                \"shipping_tax_rate\": Decimal(\"120.00\"),\n+                \"shipping_price_gross_amount\": \"110\",\n+                \"shipping_price_net_amount\": \"100\",\n+                \"lines\": [\n+                    {\n+                        \"tax_rate\": Decimal(\"20.00\"),\n+                        \"total_gross_amount\": Decimal(\"120.00\"),\n+                        \"total_net_amount\": Decimal(\"100.00\"),\n+                    }\n+                ],\n+            },\n+            1,\n+        ),\n+        # Invalid case with shipping_price_gross_amount (greater than MAXIMUM_PRICE)\n+        (\n+            {\n+                \"shipping_tax_rate\": Decimal(\"100.00\"),\n+                \"shipping_price_gross_amount\": MAXIMUM_PRICE + 1,\n+                \"shipping_price_net_amount\": \"100\",\n+                \"lines\": [\n+                    {\n+                        \"tax_rate\": Decimal(\"20.00\"),\n+                        \"total_gross_amount\": Decimal(\"120.00\"),\n+                        \"total_net_amount\": Decimal(\"100.00\"),\n+                    }\n+                ],\n+            },\n+            1,\n+        ),\n+        # Invalid case with shipping_price_net_amount (greater than MAXIMUM_PRICE)\n+        (\n+            {\n+                \"shipping_tax_rate\": Decimal(\"100.00\"),\n+                \"shipping_price_gross_amount\": \"100\",\n+                \"shipping_price_net_amount\": MAXIMUM_PRICE + 1,\n+                \"lines\": [\n+                    {\n+                        \"tax_rate\": Decimal(\"20.00\"),\n+                        \"total_gross_amount\": Decimal(\"120.00\"),\n+                        \"total_net_amount\": Decimal(\"100.00\"),\n+                    }\n+                ],\n+            },\n+            1,\n+        ),\n+    ],\n+)\n+def test_calculate_taxes_schema_invalid(data, expected_line_count):\n+    \"\"\"Test CalculateTaxesSchema with invalid data.\"\"\"\n+    with pytest.raises(ValidationError) as e:\n+        CalculateTaxesSchema.model_validate(\n+            data, context={\"expected_line_count\": expected_line_count}\n+        )\n+\n+    assert len(e.value.errors()) == 1\n+\n+\n+def test_calculate_taxes_schema_missing_context():\n+    \"\"\"Test CalculateTaxesSchema with invalid data.\"\"\"\n+    # given\n+    data = {}\n+\n+    # when & then\n+    with pytest.raises(ValidationError):\n+        CalculateTaxesSchema.model_validate(data)\n"
        },
        {
          "path": "saleor/webhook/tests/test_sync_webhooks_for_removed_app.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/test_sync_webhooks_for_removed_app.py\n===================================================================\n--- saleor/webhook/tests/test_sync_webhooks_for_removed_app.py\tf1b632e (parent)\n+++ saleor/webhook/tests/test_sync_webhooks_for_removed_app.py\t1337f67 (commit)\n@@ -3,9 +3,9 @@\n from django.utils import timezone\n \n from ...core.models import EventDelivery, EventPayload\n from ..event_types import WebhookEventSyncType\n-from ..transport.synchronous.transport import trigger_all_webhooks_sync\n+from ..transport.synchronous.transport import trigger_taxes_all_webhooks_sync\n from ..transport.utils import parse_tax_data\n \n \n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n@@ -19,9 +19,9 @@\n     event_type = WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n     data = '{\"key\": \"value\"}'\n \n     # when\n-    trigger_all_webhooks_sync(event_type, lambda: data, parse_tax_data)\n+    trigger_taxes_all_webhooks_sync(event_type, lambda: data, parse_tax_data, [0])\n \n     # then\n     assert EventPayload.objects.count() == 0\n     assert EventDelivery.objects.count() == 0\n"
        },
        {
          "path": "saleor/webhook/tests/test_tax_webhook_tasks.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/test_tax_webhook_tasks.py\n===================================================================\n--- saleor/webhook/tests/test_tax_webhook_tasks.py\tf1b632e (parent)\n+++ saleor/webhook/tests/test_tax_webhook_tasks.py\t1337f67 (commit)\n@@ -5,9 +5,9 @@\n from ...core import EventDeliveryStatus\n from ...core.models import EventDelivery\n from ..event_types import WebhookEventSyncType\n from ..models import Webhook, WebhookEvent\n-from ..transport.synchronous import trigger_all_webhooks_sync\n+from ..transport.synchronous import trigger_taxes_all_webhooks_sync\n from ..transport.utils import parse_tax_data\n \n \n @pytest.fixture\n@@ -49,11 +49,12 @@\n     data = '{\"key\": \"value\"}'\n     webhook = tax_app.webhooks.get(name=\"tax-webhook-1\")\n     webhook.subscription_query = None\n     webhook.save(update_fields=[\"subscription_query\"])\n+    lines_count = len(tax_data_response[\"lines\"])\n \n     # when\n-    tax_data = trigger_all_webhooks_sync(event_type, lambda: data, parse_tax_data)\n+    tax_data = trigger_taxes_all_webhooks_sync(event_type, lambda: data, lines_count)\n \n     # then\n     mock_request.assert_called_once()\n     assert not EventDelivery.objects.exists()\n@@ -62,9 +63,9 @@\n     assert delivery.payload.get_payload() == data\n     assert delivery.status == EventDeliveryStatus.PENDING\n     assert delivery.event_type == event_type\n     assert delivery.webhook == webhook\n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, lines_count)\n \n \n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_trigger_tax_webhook_sync_multiple_webhooks_first(\n@@ -75,11 +76,12 @@\n     # given\n     mock_request.side_effect = [tax_data_response, {}, {}]\n     event_type = WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n     data = '{\"key\": \"value\"}'\n+    lines_count = len(tax_data_response[\"lines\"])\n \n     # when\n-    tax_data = trigger_all_webhooks_sync(event_type, lambda: data, parse_tax_data)\n+    tax_data = trigger_taxes_all_webhooks_sync(event_type, lambda: data, lines_count)\n \n     # then\n     successful_webhook = tax_checkout_webhooks[0]\n     mock_request.assert_called_once()\n@@ -88,9 +90,9 @@\n     assert delivery.payload.get_payload() == data\n     assert delivery.status == EventDeliveryStatus.PENDING\n     assert delivery.event_type == event_type\n     assert delivery.webhook == successful_webhook\n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, lines_count)\n \n \n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_trigger_tax_webhook_sync_multiple_webhooks_last(\n@@ -101,11 +103,12 @@\n     # given\n     mock_request.side_effect = [{}, {}, tax_data_response]\n     event_type = WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n     data = '{\"key\": \"value\"}'\n+    lines_count = len(tax_data_response[\"lines\"])\n \n     # when\n-    tax_data = trigger_all_webhooks_sync(event_type, lambda: data, parse_tax_data)\n+    tax_data = trigger_taxes_all_webhooks_sync(event_type, lambda: data, lines_count)\n \n     # then\n     assert mock_request.call_count == 3\n     assert not EventDelivery.objects.exists()\n@@ -118,9 +121,9 @@\n         assert delivery.event_type == event_type\n         assert delivery.payload.get_payload() == data\n         assert delivery.webhook == webhook\n \n-    assert tax_data == parse_tax_data(tax_data_response)\n+    assert tax_data == parse_tax_data(tax_data_response, lines_count)\n \n \n @mock.patch(\"saleor.webhook.transport.synchronous.transport.send_webhook_request_sync\")\n def test_trigger_tax_webhook_sync_invalid_webhooks(\n@@ -133,9 +136,9 @@\n     event_type = WebhookEventSyncType.CHECKOUT_CALCULATE_TAXES\n     data = '{\"key\": \"value\"}'\n \n     # when\n-    tax_data = trigger_all_webhooks_sync(event_type, lambda: data, parse_tax_data)\n+    tax_data = trigger_taxes_all_webhooks_sync(event_type, lambda: data, 0)\n \n     # then\n     assert mock_request.call_count == len(tax_checkout_webhooks)\n     assert tax_data is None\n"
        },
        {
          "path": "saleor/webhook/tests/test_tax_webhook_utils.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/tests/test_tax_webhook_utils.py\n===================================================================\n--- saleor/webhook/tests/test_tax_webhook_utils.py\tf1b632e (parent)\n+++ saleor/webhook/tests/test_tax_webhook_utils.py\t1337f67 (commit)\n@@ -1,11 +1,11 @@\n import decimal\n \n import pytest\n+from pydantic import ValidationError\n \n from ...core.taxes import TaxData\n from ..transport.utils import (\n-    _unsafe_parse_tax_data,\n     _unsafe_parse_tax_line_data,\n     parse_tax_data,\n )\n \n@@ -44,75 +44,40 @@\n     with pytest.raises(decimal.DecimalException):\n         _unsafe_parse_tax_line_data(tax_line_data_response)\n \n \n-def test_unsafe_parse_tax_data_success(tax_data_response):\n-    # when\n-    tax_data = _unsafe_parse_tax_data(tax_data_response)\n-\n-    # then\n-    assert not tax_data.shipping_price_gross_amount.compare(\n-        decimal.Decimal(tax_data_response[\"shipping_price_gross_amount\"])\n-    )\n-    assert not tax_data.shipping_price_net_amount.compare(\n-        decimal.Decimal(tax_data_response[\"shipping_price_net_amount\"])\n-    )\n-    assert tax_data.shipping_tax_rate == tax_data_response[\"shipping_tax_rate\"]\n-    assert tax_data.lines == [\n-        _unsafe_parse_tax_line_data(line) for line in tax_data_response[\"lines\"]\n-    ]\n-\n-\n-def test_unsafe_parse_tax_data_keyerror(tax_data_response):\n+def test_parse_tax_data_success(tax_data_response):\n     # given\n-    tax_data_response[\"shipping_tax_rate_2\"] = tax_data_response[\"shipping_tax_rate\"]\n-    del tax_data_response[\"shipping_tax_rate\"]\n+    line_count = len(tax_data_response[\"lines\"])\n \n     # when\n-    with pytest.raises(KeyError):\n-        _unsafe_parse_tax_data(tax_data_response)\n+    tax_data = parse_tax_data(tax_data_response, line_count)\n \n-\n-def test_unsafe_parse_tax_data_decimalexception(tax_data_response):\n-    # given\n-    tax_data_response[\"shipping_price_gross_amount\"] = \"invalid value\"\n-\n-    # when\n-    with pytest.raises(decimal.DecimalException):\n-        _unsafe_parse_tax_data(tax_data_response)\n-\n-\n-def test_parse_tax_data_success(tax_data_response):\n-    # when\n-    tax_data = parse_tax_data(tax_data_response)\n-\n     # then\n     assert isinstance(tax_data, TaxData)\n \n \n def test_parse_tax_data_keyerror(tax_data_response):\n     # given\n     tax_data_response[\"shipping_tax_rate_2\"] = tax_data_response[\"shipping_tax_rate\"]\n     del tax_data_response[\"shipping_tax_rate\"]\n+    line_count = len(tax_data_response[\"lines\"])\n \n-    # when\n-    tax_data = parse_tax_data(tax_data_response)\n+    # when & then\n+    with pytest.raises(ValidationError):\n+        parse_tax_data(tax_data_response, line_count)\n \n-    # then\n-    assert tax_data is None\n \n-\n def test_parse_tax_data_decimalexception(tax_data_response):\n     # given\n     tax_data_response[\"shipping_price_gross_amount\"] = \"invalid value\"\n+    line_count = len(tax_data_response[\"lines\"])\n \n-    # when\n-    tax_data = parse_tax_data(tax_data_response)\n+    # when & then\n+    with pytest.raises(ValidationError):\n+        parse_tax_data(tax_data_response, line_count)\n \n-    # then\n-    assert tax_data is None\n \n-\n @pytest.mark.parametrize(\n     \"response_data\",\n     [\n         [],\n@@ -129,5 +94,6 @@\n         {\"lines\": [None]},\n     ],\n )\n def test_parse_tax_data_malformed(response_data):\n-    assert parse_tax_data(response_data) is None\n+    with pytest.raises(ValidationError):\n+        parse_tax_data(response_data, 1)\n"
        },
        {
          "path": "saleor/webhook/transport/synchronous/__init__.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/synchronous/__init__.py\n===================================================================\n--- saleor/webhook/transport/synchronous/__init__.py\tf1b632e (parent)\n+++ saleor/webhook/transport/synchronous/__init__.py\t1337f67 (commit)\n@@ -1,11 +1,11 @@\n from .transport import (\n-    trigger_all_webhooks_sync,\n+    trigger_taxes_all_webhooks_sync,\n     trigger_webhook_sync,\n     trigger_webhook_sync_if_not_cached,\n )\n \n __all__ = [\n-    \"trigger_all_webhooks_sync\",\n+    \"trigger_taxes_all_webhooks_sync\",\n     \"trigger_webhook_sync\",\n     \"trigger_webhook_sync_if_not_cached\",\n ]\n"
        },
        {
          "path": "saleor/webhook/transport/synchronous/transport.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/synchronous/transport.py\n===================================================================\n--- saleor/webhook/transport/synchronous/transport.py\tf1b632e (parent)\n+++ saleor/webhook/transport/synchronous/transport.py\t1337f67 (commit)\n@@ -7,13 +7,15 @@\n \n from django.conf import settings\n from django.core.cache import cache\n from django.db import transaction\n+from pydantic import ValidationError\n \n from ....celeryconf import app\n from ....core import EventDeliveryStatus\n from ....core.db.connection import allow_writer\n from ....core.models import EventDelivery, EventPayload\n+from ....core.taxes import TaxData\n from ....core.tracing import webhooks_opentracing_trace\n from ....core.utils import get_domain\n from ....core.utils.events import call_event\n from ....core.utils.url import sanitize_url_for_logging\n@@ -49,8 +51,9 @@\n     delivery_update,\n     generate_cache_key_for_webhook,\n     get_delivery_for_webhook,\n     handle_webhook_retry,\n+    parse_tax_data,\n     save_unsuccessful_delivery_attempt,\n     send_webhook_using_http,\n )\n \n@@ -336,17 +339,16 @@\n if breaker_board := initialize_breaker_board():\n     trigger_webhook_sync = breaker_board(trigger_webhook_sync)\n \n \n-def trigger_all_webhooks_sync(\n+def trigger_taxes_all_webhooks_sync(\n     event_type: str,\n     generate_payload: Callable,\n-    parse_response: Callable[[Any], R | None],\n+    expected_lines_count: int,\n     subscribable_object=None,\n     requestor=None,\n-    allow_replica=False,\n     pregenerated_subscription_payloads: dict | None = None,\n-) -> R | None:\n+) -> TaxData | None:\n     \"\"\"Send all synchronous webhook request for given event type.\n \n     Requests are send sequentially.\n     If the current webhook does not return expected response,\n@@ -365,9 +367,8 @@\n             if request_context is None:\n                 request_context = initialize_request(\n                     requestor,\n                     event_type in WebhookEventSyncType.ALL,\n-                    allow_replica,\n                     event_type=event_type,\n                 )\n \n             pregenerated_payload = get_pregenerated_subscription_payload(\n@@ -395,10 +396,19 @@\n                 webhook=webhook,\n             )\n \n         response_data = send_webhook_request_sync(delivery)\n-        if parsed_response := parse_response(response_data):\n-            return parsed_response\n+        try:\n+            parsed_response = parse_tax_data(response_data, expected_lines_count)\n+        except ValidationError as e:\n+            logger.warning(\n+                \"Webhook response for event %s is invalid: %s\",\n+                event_type,\n+                str(e),\n+                extra={\"errors\": e.errors()},\n+            )\n+            continue\n+        return parsed_response\n     return None\n \n \n def trigger_transaction_request(\n"
        },
        {
          "path": "saleor/webhook/transport/utils.py",
          "status": "modified",
          "diff": "Index: saleor/webhook/transport/utils.py\n===================================================================\n--- saleor/webhook/transport/utils.py\tf1b632e (parent)\n+++ saleor/webhook/transport/utils.py\t1337f67 (commit)\n@@ -46,8 +46,9 @@\n from .. import observability\n from ..const import APP_ID_PREFIX\n from ..event_types import WebhookEventSyncType\n from ..models import Webhook\n+from ..response_schemas.taxes import CalculateTaxesSchema\n from . import signature_for_payload\n \n logger = logging.getLogger(__name__)\n task_logger = get_task_logger(f\"{__name__}.celery\")\n@@ -545,13 +546,27 @@\n \n \n def parse_tax_data(\n     response_data: Any,\n-) -> TaxData | None:\n-    try:\n-        return _unsafe_parse_tax_data(response_data)\n-    except (TypeError, KeyError, decimal.DecimalException):\n-        return None\n+    lines_count: int,\n+) -> TaxData:\n+    calculated_taxes_model = CalculateTaxesSchema.model_validate(\n+        response_data,\n+        context={\"expected_line_count\": lines_count},\n+    )\n+    return TaxData(\n+        shipping_price_gross_amount=calculated_taxes_model.shipping_price_gross_amount,\n+        shipping_price_net_amount=calculated_taxes_model.shipping_price_net_amount,\n+        shipping_tax_rate=calculated_taxes_model.shipping_tax_rate,\n+        lines=[\n+            TaxLineData(\n+                tax_rate=tax_line.tax_rate,\n+                total_gross_amount=tax_line.total_gross_amount,\n+                total_net_amount=tax_line.total_net_amount,\n+            )\n+            for tax_line in calculated_taxes_model.lines\n+        ],\n+    )\n \n \n def parse_payment_action_response(\n     payment_information: \"PaymentData\",\n@@ -616,32 +631,8 @@\n         tax_rate=tax_rate,\n     )\n \n \n-def _unsafe_parse_tax_data(\n-    tax_data_response: Any,\n-) -> TaxData:\n-    \"\"\"Unsafe TaxData parser.\n-\n-    Raises KeyError or DecimalException on invalid data.\n-    \"\"\"\n-    shipping_price_gross_amount = decimal.Decimal(\n-        tax_data_response[\"shipping_price_gross_amount\"]\n-    )\n-    shipping_price_net_amount = decimal.Decimal(\n-        tax_data_response[\"shipping_price_net_amount\"]\n-    )\n-    shipping_tax_rate = decimal.Decimal(tax_data_response[\"shipping_tax_rate\"])\n-    lines = [_unsafe_parse_tax_line_data(line) for line in tax_data_response[\"lines\"]]\n-\n-    return TaxData(\n-        shipping_price_gross_amount=shipping_price_gross_amount,\n-        shipping_price_net_amount=shipping_price_net_amount,\n-        shipping_tax_rate=shipping_tax_rate,\n-        lines=lines,\n-    )\n-\n-\n def from_payment_app_id(app_gateway_id: str) -> Optional[\"PaymentAppData\"]:\n     splitted_id = app_gateway_id.split(\":\", maxsplit=2)\n     if len(splitted_id) == 3 and splitted_id[0] == APP_ID_PREFIX and all(splitted_id):\n         try:\n"
        }
      ]
    }
  ]
}